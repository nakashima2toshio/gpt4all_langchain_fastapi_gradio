<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <link href="../favicon.png" rel="icon"/>
  <meta content="width=device-width" name="viewport"/>
  <link href="../_app/immutable/assets/0.c91c2379.css" rel="stylesheet"/>
  <link href="../_app/immutable/assets/5.e72ab545.css" rel="stylesheet"/>
  <link href="../_app/immutable/entry/start.85a9379b.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/scheduler.e5b750f2.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/singletons.ecb866d8.js" rel="modulepreload"/>
  <link href="../_app/immutable/entry/app.cc28a8d6.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/preload-helper.a4192956.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/index.118a3bdc.js" rel="modulepreload"/>
  <link href="../_app/immutable/nodes/0.0990fabf.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/globals.7f7f1b26.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/copy.e05e7a77.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/navigation.c4470cd1.js" rel="modulepreload"/>
  <link href="../_app/immutable/nodes/2.58475c89.js" rel="modulepreload"/>
  <link href="../_app/immutable/nodes/5.de890892.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/each.e05f7e0a.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/FunctionDoc.ce7df69d.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/DocsNav.de6fa83d.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/clickOutside.ba99cc3a.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/VersionDropdown.6830dbd4.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/stores.f31265de.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/version.dd7cd07d.js" rel="modulepreload"/>
  <link href="../_app/immutable/chunks/MetaTags.6f08ddcd.js" rel="modulepreload"/>
  <title>
   Gradio Progress Docs
  </title>
  <!-- HEAD_svelte-ewtxl0_START -->
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap" rel="stylesheet"/>
  <script crossorigin="true" data-svelte-h="svelte-1i785pf" src="https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js" type="module">
  </script>
  <script async="" data-svelte-h="svelte-28fai2" src="https://www.googletagmanager.com/gtag/js?id=UA-156449732-1">
  </script>
  <script data-svelte-h="svelte-iepcrk">
   window.dataLayer = window.dataLayer || [];
		function gtag() {
			dataLayer.push(arguments);
		}
		gtag("js", new Date());
		gtag("config", "UA-156449732-1", {
			cookie_flags: "samesite=none;secure"
		});
  </script>
  <!-- HEAD_svelte-ewtxl0_END -->
  <!-- HEAD_svelte-dkutrw_START -->
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1" name="viewport"/>
  <meta content="The Progress class provides a custom progress tracker that is used in a function signature. To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;gradio.Progress()&lt;/code&gt; instance. The Progress tracker can then be updated in the function by calling the Progress object or using the &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;tqdm&lt;/code&gt; method on an Iterable. The Progress tracker is currently only available with &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;queue()&lt;/code&gt;." name="description"/>
  <meta content="Gradio Team" name="author"/>
  <meta content="Gradio Progress Docs" property="og:title"/>
  <meta content="website" property="og:type"/>
  <meta content="/docs/progress" property="og:url"/>
  <meta content="The Progress class provides a custom progress tracker that is used in a function signature. To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;gradio.Progress()&lt;/code&gt; instance. The Progress tracker can then be updated in the function by calling the Progress object or using the &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;tqdm&lt;/code&gt; method on an Iterable. The Progress tracker is currently only available with &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;queue()&lt;/code&gt;." property="og:description"/>
  <meta content="https://raw.githubusercontent.com/gradio-app/gradio/main/js/_website/src/lib/assets/img/header-image.jpg" property="og:image"/>
  <meta content="summary_large_image" name="twitter:card"/>
  <meta content="@Gradio" name="twitter:creator"/>
  <meta content="Gradio Progress Docs" name="twitter:title"/>
  <meta content="The Progress class provides a custom progress tracker that is used in a function signature. To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;gradio.Progress()&lt;/code&gt; instance. The Progress tracker can then be updated in the function by calling the Progress object or using the &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;tqdm&lt;/code&gt; method on an Iterable. The Progress tracker is currently only available with &lt;code class='text-orange-500' style='font-family: monospace; font-size: large;'&gt;queue()&lt;/code&gt;.." name="twitter:description"/>
  <meta content="https://raw.githubusercontent.com/gradio-app/gradio/main/js/_website/src/lib/assets/img/header-image.jpg" name="twitter:image"/>
  <link href="/docs/progress" rel="canonical"/>
  <!-- HEAD_svelte-dkutrw_END -->
  <!-- HEAD_svelte-kspch6_START -->
  <script src="https://gradio.s3-us-west-2.amazonaws.com/4.16.0/gradio.js" type="module">
  </script>
  <!-- HEAD_svelte-kspch6_END -->
 </head>
 <body data-sveltekit-preload-data="hover" style="min-height: 100vh; display: grid; grid-template-rows: auto 1fr auto">
  <div style="display: contents">
   <div class="main-header flex-row">
    <div class="relative isolate flex items-center gap-x-6 overflow-hidden bg-gradient-to-r from-white via-yellow-200 to-white px-6 py-2 sm:px-3.5 sm:before:flex-1" data-svelte-h="svelte-o2o9uj">
     <div class="flex flex-wrap items-center gap-x-4 gap-y-2">
      <p class="text-md leading-6 text-gray-700">
       <strong class="font-semibold">
        Custom Components Gallery
        <sup class="text-orange-500">
         NEW
        </sup>
       </strong>
      </p>
      <a class="flex-none rounded-full px-3.5 py-1 text-sm font-semibold text-white bg-gradient-to-br from-orange-300 via-orange-500 to-orange-300 hover:drop-shadow-md" href="/custom-components/gallery" target="_blank">
       Explore
       <span aria-hidden="true">
        ‚Üí
       </span>
      </a>
     </div>
     <div class="flex flex-1 justify-end">
     </div>
    </div>
    <div class="container mx-auto flex flex-wrap justify-between flex-row relative items-center px-4 py-5 gap-6 text-lg z-50">
     <a data-svelte-h="svelte-72mfco" href="/">
      <img alt="Gradio logo" src="/_app/immutable/assets/gradio.8a5e8876.svg"/>
     </a>
     <svg class="h-8 w-8 lg:hidden" viewbox="-10 -10 20 20">
      <rect height="2" width="14" x="-7" y="-6">
      </rect>
      <rect height="2" width="14" x="-7" y="-1">
      </rect>
      <rect height="2" width="14" x="-7" y="4">
      </rect>
     </svg>
     <nav class="w-full flex-col gap-3 lg:flex lg:w-auto lg:flex-row lg:gap-8 hidden">
      <a class="thin-link flex items-center gap-3" data-svelte-h="svelte-12q4mb7" href="/guides/quickstart">
       <span>
        ‚ö°
       </span>
       <span>
        Quickstart
       </span>
      </a>
      <a class="thin-link flex items-center gap-3" data-svelte-h="svelte-rj6sly" href="/docs">
       <span>
        ‚úçÔ∏è
       </span>
       <span>
        Docs
       </span>
      </a>
      <a class="thin-link flex items-center gap-3" data-svelte-h="svelte-xkmceu" href="/guides">
       <span>
        üí°
       </span>
       <span>
        Guides
       </span>
      </a>
      <a class="thin-link flex items-center gap-3" data-svelte-h="svelte-b4pfpk" href="/playground">
       <span>
        üé¢
       </span>
       <span>
        Playground
       </span>
      </a>
      <a class="thin-link flex items-center gap-3" data-svelte-h="svelte-1wdzyuc" href="/custom-components/gallery">
       <span>
        üñºÔ∏è
       </span>
       <span>
        Custom Components
        <sup class="text-orange-500">
         NEW
        </sup>
       </span>
      </a>
      <div class="group relative flex cursor-pointer items-center gap-3">
       <span data-svelte-h="svelte-v9wlbr">
        üñê
       </span>
       <span data-svelte-h="svelte-1ufc5dh">
        Community
       </span>
       <svg class="h-4 w-4" viewbox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
        <path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z">
        </path>
       </svg>
      </div>
      <a class="thin-link flex items-center gap-3" data-svelte-h="svelte-14vdzms" href="https://github.com/gradio-app/gradio">
       <img alt="Github logo" class="w-6" src="/_app/immutable/assets/github-black.ca3d1309.svg"/>
      </a>
     </nav>
    </div>
   </div>
   <main class="container mx-auto px-4 flex gap-4">
    <div class="flex w-full">
     <section class="top-0 fixed -ml-4 flex items-center p-4 rounded-br-lg backdrop-blur-lg z-50 bg-gray-200/50 lg:hidden" id="menu-bar">
      <button class="text-slate-500 hover:text-slate-600 dark:text-slate-400 dark:hover:text-slate-300" data-svelte-h="svelte-jlhlfo" type="button">
       <svg height="24" width="24">
        <path d="M5 6h14M5 12h14M5 18h14" fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2">
        </path>
       </svg>
      </button>
     </section>
     <div class="min-w-[200px] navigation mobile-nav overflow-y-auto fixed backdrop-blur-lg z-50 bg-gray-200/50 pr-6 pl-4 py-4 -ml-4 h-full inset-0 w-5/6 lg:inset-auto lg:ml-0 lg:z-0 lg:backdrop-blur-none lg:navigation lg:p-0 lg:pb-4 lg:h-screen lg:leading-relaxed lg:sticky lg:top-0 lg:text-md lg:block rounded-t-xl lg:bg-gradient-to-r lg:from-white lg:to-gray-50 lg:overflow-x-clip lg:w-2/12 hidden" id="mobile-nav">
      <button class="absolute z-10 top-4 right-4 w-2/12 h-4 flex items-center justify-center text-grey-500 hover:text-slate-600 dark:text-slate-400 dark:hover:text-slate-300 p-4 lg:hidden" data-svelte-h="svelte-1askwj0" tabindex="0" type="button">
       <svg class="overflow-visible" style="width: 10px" viewbox="0 0 10 10">
        <path d="M0 0L10 10M10 0L0 10" fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2">
        </path>
       </svg>
      </button>
      <div class="w-full sticky top-0 bg-gradient-to-r from-white to-gray-50 z-10 hidden lg:block my-4 ml-4">
       <input autocomplete="off" class="w-4/5 rounded-md border-gray-200 focus:placeholder-transparent focus:shadow-none focus:border-orange-500 focus:ring-0" id="search" placeholder="Search ‚åò-k / ctrl-k" type="search" value=""/>
       <select class="rounded-md border-gray-200 focus:placeholder-transparent focus:shadow-none focus:border-orange-500 focus:ring-0 text-xs mt-2 py-1 pl-2 pr-7 font-mono">
        <option value="4.16.0">
         4.16.0
        </option>
        <option value="3.50.2">
         3.50.2
        </option>
        <option value="main">
         main
        </option>
       </select>
       <select class="rounded-md border-gray-200 focus:placeholder-transparent focus:shadow-none focus:border-orange-500 focus:ring-0 text-xs mt-2 py-1 pl-2 pr-7 font-mono">
        <option data-svelte-h="svelte-1172ldq" value="js">
         js
        </option>
        <option data-svelte-h="svelte-b6n80y" value="python">
         python
        </option>
       </select>
      </div>
      <p class="font-semibold px-4 my-2 block" data-svelte-h="svelte-70lfxr">
       Building Demos
      </p>
      <a class="thin-link px-4 block" data-svelte-h="svelte-1tab5oi" href="./interface/">
       Interface
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-7i1k4a" href="./chatinterface/">
       ChatInterface
       <sup class="text-orange-500">
        NEW
       </sup>
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-1d2n7bo" href="./tabbedinterface/">
       TabbedInterface
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-vzqvdr" href="./blocks/">
       Blocks
      </a>
      <p class="font-semibold px-4 my-2 block" data-svelte-h="svelte-15t3wi1">
       Block Layouts
      </p>
      <a class="thin-link px-4 block" data-svelte-h="svelte-fnu867" href="./row/">
       Row
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-5o8zj7" href="./column/">
       Column
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-om92wm" href="./tab/">
       Tab
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-1ccpb5i" href="./group/">
       Group
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-1eeevdp" href="./accordion/">
       Accordion
      </a>
      <a class="link px-4 my-2 block" data-svelte-h="svelte-bu3rc8" href="./components/">
       Components
      </a>
      <a class="px-4 block thin-link" href="./annotatedimage/">
       AnnotatedImage
      </a>
      <a class="px-4 block thin-link" href="./audio/">
       Audio
      </a>
      <a class="px-4 block thin-link" href="./barplot/">
       BarPlot
      </a>
      <a class="px-4 block thin-link" href="./button/">
       Button
      </a>
      <a class="px-4 block thin-link" href="./chatbot/">
       Chatbot
      </a>
      <a class="px-4 block thin-link" href="./checkbox/">
       Checkbox
      </a>
      <a class="px-4 block thin-link" href="./checkboxgroup/">
       CheckboxGroup
      </a>
      <a class="px-4 block thin-link" href="./clearbutton/">
       ClearButton
      </a>
      <a class="px-4 block thin-link" href="./code/">
       Code
      </a>
      <a class="px-4 block thin-link" href="./colorpicker/">
       ColorPicker
      </a>
      <a class="px-4 block thin-link" href="./dataframe/">
       Dataframe
      </a>
      <a class="px-4 block thin-link" href="./dataset/">
       Dataset
      </a>
      <a class="px-4 block thin-link" href="./dropdown/">
       Dropdown
      </a>
      <a class="px-4 block thin-link" href="./duplicatebutton/">
       DuplicateButton
      </a>
      <a class="px-4 block thin-link" href="./file/">
       File
      </a>
      <a class="px-4 block thin-link" href="./fileexplorer/">
       FileExplorer
      </a>
      <a class="px-4 block thin-link" href="./gallery/">
       Gallery
      </a>
      <a class="px-4 block thin-link" href="./html/">
       HTML
      </a>
      <a class="px-4 block thin-link" href="./highlightedtext/">
       HighlightedText
      </a>
      <a class="px-4 block thin-link" href="./image/">
       Image
      </a>
      <a class="px-4 block thin-link" href="./imageeditor/">
       ImageEditor
      </a>
      <a class="px-4 block thin-link" href="./json/">
       JSON
      </a>
      <a class="px-4 block thin-link" href="./label/">
       Label
      </a>
      <a class="px-4 block thin-link" href="./lineplot/">
       LinePlot
      </a>
      <a class="px-4 block thin-link" href="./loginbutton/">
       LoginButton
      </a>
      <a class="px-4 block thin-link" href="./logoutbutton/">
       LogoutButton
      </a>
      <a class="px-4 block thin-link" href="./markdown/">
       Markdown
      </a>
      <a class="px-4 block thin-link" href="./model3d/">
       Model3D
      </a>
      <a class="px-4 block thin-link" href="./number/">
       Number
      </a>
      <a class="px-4 block thin-link" href="./plot/">
       Plot
      </a>
      <a class="px-4 block thin-link" href="./radio/">
       Radio
      </a>
      <a class="px-4 block thin-link" href="./scatterplot/">
       ScatterPlot
      </a>
      <a class="px-4 block thin-link" href="./slider/">
       Slider
      </a>
      <a class="px-4 block thin-link" href="./state/">
       State
      </a>
      <a class="px-4 block thin-link" href="./textbox/">
       Textbox
      </a>
      <a class="px-4 block thin-link" href="./uploadbutton/">
       UploadButton
      </a>
      <a class="px-4 block thin-link" href="./video/">
       Video
      </a>
      <p class="font-semibold px-4 my-2 block" data-svelte-h="svelte-1tdqml2">
       Helpers
      </p>
      <a class="px-4 block thin-link" href="./examples/">
       Examples
      </a>
      <a class="px-4 block thin-link current-nav-link" href="./progress/">
       Progress
      </a>
      <a class="px-4 block thin-link" href="./make_waveform/">
       make_waveform
      </a>
      <a class="px-4 block thin-link" href="./load/">
       load
      </a>
      <p class="font-semibold px-4 my-2 block" data-svelte-h="svelte-zg8gsx">
       Modals
      </p>
      <a class="px-4 block thin-link" href="./error/">
       Error
      </a>
      <a class="px-4 block thin-link" href="./eventdata/">
       EventData
      </a>
      <a class="px-4 block thin-link" href="./warning/">
       Warning
      </a>
      <a class="px-4 block thin-link" href="./info/">
       Info
      </a>
      <p class="font-semibold px-4 my-2 block" data-svelte-h="svelte-cfrpy1">
       Routes
      </p>
      <a class="px-4 block thin-link" href="./request/">
       Request
      </a>
      <a class="px-4 block thin-link" href="./mount_gradio_app/">
       mount_gradio_app
      </a>
      <p class="font-semibold px-4 my-2 block" data-svelte-h="svelte-1f99ms5">
       Other
      </p>
      <a class="thin-link px-4 block" data-svelte-h="svelte-14hvyo6" href="./flagging/">
       Flagging
      </a>
      <a class="thin-link px-4 block" data-svelte-h="svelte-104ymcv" href="./themes/">
       Themes
      </a>
      <a class="link px-4 my-2 block" data-svelte-h="svelte-1eoultx" href="./python-client/">
       Python Client
      </a>
      <a class="px-4 block thin-link" href="./client/">
       Client
      </a>
      <a class="px-4 block thin-link" href="./job/">
       Job
      </a>
      <a class="link px-4 my-2 block" data-svelte-h="svelte-1ekgh60" href="./js-client/">
       JavaScript Client
      </a>
     </div>
     <div class="flex flex-col w-full min-w-full lg:w-8/12 lg:min-w-0">
      <div data-svelte-h="svelte-1axc3a6">
       <p class="bg-gradient-to-r from-orange-100 to-orange-50 border border-orange-200 px-4 py-1 mr-2 rounded-full text-orange-800 mb-1 w-fit float-left lg:ml-10">
        New to Gradio? Start here:
        <a class="link" href="/quickstart">
         Getting Started
        </a>
       </p>
       <p class="bg-gradient-to-r from-green-100 to-green-50 border border-green-200 px-4 py-1 rounded-full text-green-800 mb-1 w-fit float-left sm:float-right">
        See the
        <a class="link" href="/changelog">
         Release History
        </a>
       </p>
      </div>
      <div class="flex justify-between mt-4 lg:ml-10">
       <a class="text-left px-4 py-1 bg-gray-50 rounded-full hover:underline" href="./examples">
        <div class="text-lg">
         <span class="text-orange-500" data-svelte-h="svelte-1gjiegn">
          ‚Üê
         </span>
         Examples
        </div>
       </a>
       <a class="text-right px-4 py-1 bg-gray-50 rounded-full hover:underline" href="./make_waveform">
        <div class="text-lg">
         make_waveform
         <span class="text-orange-500" data-svelte-h="svelte-1moj53h">
          ‚Üí
         </span>
        </div>
       </a>
      </div>
      <div class="flex flex-row">
       <div class="lg:ml-10">
        <div class="obj" id="progress">
         <div class="flex flex-row items-center justify-between">
          <h3 class="group text-3xl font-light py-4" id="progress-header">
           Progress
           <a class="invisible group-hover-visible" href="#progress-header">
            <img class="anchor-img" src="/_app/immutable/assets/anchor.ce190310.svg"/>
           </a>
          </h3>
         </div>
         <div class="codeblock">
          <pre><code class="code language-python">gradio.<span>Progress(</span>¬∑¬∑¬∑<span data-svelte-h="svelte-ntu311">)</span></code></pre>
         </div>
         <div id="description">
          <h4 class="mt-8 text-xl text-orange-500 font-light group" data-svelte-h="svelte-9hgpn7">
           Description
           <a class="invisible group-hover-visible" href="#description">
            <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
           </a>
          </h4>
          <p class="mb-2 text-lg text-gray-600">
           <!-- HTML_TAG_START -->
           The Progress class provides a custom progress tracker that is used in a function signature. To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a
           <code class="text-orange-500" style="font-family: monospace; font-size: large;">
            gradio.Progress()
           </code>
           instance. The Progress tracker can then be updated in the function by calling the Progress object or using the
           <code class="text-orange-500" style="font-family: monospace; font-size: large;">
            tqdm
           </code>
           method on an Iterable. The Progress tracker is currently only available with
           <code class="text-orange-500" style="font-family: monospace; font-size: large;">
            queue()
           </code>
           .
           <!-- HTML_TAG_END -->
          </p>
         </div>
         <div id="example-usage">
          <h4 class="mt-4 text-xl text-orange-500 font-light group" data-svelte-h="svelte-6af1cx">
           Example Usage
           <a class="invisible group-hover-visible" href="#example-usage">
            <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
           </a>
          </h4>
          <div class="codeblock">
           <pre><code class="code language-python"><!-- HTML_TAG_START --><span class="token keyword">import</span> gradio <span class="token keyword">as</span> gr
<span class="token keyword">import</span> time
<span class="token keyword">def</span> <span class="token function">my_function</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    progress<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Starting..."</span><span class="token punctuation">)</span>
    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> progress<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
gr<span class="token punctuation">.</span>Interface<span class="token punctuation">(</span>my_function<span class="token punctuation">,</span> gr<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> gr<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>queue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>launch<span class="token punctuation">(</span><span class="token punctuation">)</span><!-- HTML_TAG_END --></code></pre>
          </div>
         </div>
         <div id="initialization">
          <h4 class="mt-6 text-xl text-orange-500 font-light group" data-svelte-h="svelte-hslwde">
           Initialization
           <a class="invisible group-hover-visible" href="#initialization">
            <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
           </a>
          </h4>
          <table class="table-fixed w-full leading-loose">
           <thead class="text-left" data-svelte-h="svelte-vnrfv5">
            <tr>
             <th class="px-3 pb-3 w-2/5 text-gray-700 font-semibold">
              Parameter
             </th>
             <th class="px-3 pb-3 text-gray-700 font-semibold">
              Description
             </th>
            </tr>
           </thead>
           <tbody class="rounded-lg bg-gray-50 border border-gray-100 overflow-hidden text-left align-top divide-y">
            <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
             <td class="p-3 w-2/5 break-words">
              <code class="block">
               track_tqdm
              </code>
              <p class="text-gray-500 italic">
               bool
              </p>
              <p class="text-gray-500 font-semibold">
               default: False
              </p>
             </td>
             <td class="p-3 text-gray-700 break-words">
              <p>
               <!-- HTML_TAG_START -->
               If True, the Progress object will track any tqdm.tqdm iterations with the tqdm library in the function.
               <!-- HTML_TAG_END -->
              </p>
             </td>
            </tr>
           </tbody>
          </table>
         </div>
         <div id="demos">
          <div class="category my-8" id="examples">
           <h4 class="text-xl text-orange-500 font-light group" data-svelte-h="svelte-1m98o59">
            Demos
            <a class="invisible group-hover-visible" href="#demos">
             <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
            </a>
           </h4>
           <div>
            <div class="demo-window overflow-y-auto h-full w-full mb-4">
             <div class="relative mx-auto my-auto rounded-md bg-white" style="top: 5%; height: 90%">
              <div class="flex overflow-auto pt-4">
               <button class="demo-btn px-4 py-2 text-lg min-w-max text-gray-600 hover:text-orange-500 selected-demo-tab" name="progress">
                progress
               </button>
              </div>
              <div class="demo-content px-4 selected-demo-window">
               <div class="codeblock" id="progress_code">
                <a class="clipboard-button m-2" href="https://colab.research.google.com/github/gradio-app/gradio/blob/main/demo/progress/run.ipynb" style="right:30px" target="_blank">
                 <img src="https://colab.research.google.com/assets/colab-badge.svg"/>
                </a>
                <pre class="max-h-80 overflow-auto"><code class="code language-python"><!-- HTML_TAG_START --><span class="token keyword">import</span> gradio <span class="token keyword">as</span> gr
<span class="token keyword">import</span> random
<span class="token keyword">import</span> time
<span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token keyword">import</span> shutil
<span class="token keyword">from</span> uuid <span class="token keyword">import</span> uuid4

<span class="token keyword">with</span> gr<span class="token punctuation">.</span>Blocks<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> demo<span class="token punctuation">:</span>
    <span class="token keyword">with</span> gr<span class="token punctuation">.</span>Row<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> gr<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span><span class="token punctuation">)</span>
        textb <span class="token operator">=</span> gr<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> gr<span class="token punctuation">.</span>Row<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        load_set_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Load Set"</span><span class="token punctuation">)</span>
        load_nested_set_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Load Nested Set"</span><span class="token punctuation">)</span>
        load_random_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Load Random"</span><span class="token punctuation">)</span>
        clean_imgs_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Clean Images"</span><span class="token punctuation">)</span>
        wait_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Wait"</span><span class="token punctuation">)</span>
        do_all_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Do All"</span><span class="token punctuation">)</span>
        track_tqdm_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Bind TQDM"</span><span class="token punctuation">)</span>
        bind_internal_tqdm_btn <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"Bind Internal TQDM"</span><span class="token punctuation">)</span>

    text2 <span class="token operator">=</span> gr<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># track list</span>
    <span class="token keyword">def</span> <span class="token function">load_set</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> text2<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">24</span>
        <span class="token keyword">for</span> img <span class="token keyword">in</span> progress<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Loading from list"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    load_set_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>load_set<span class="token punctuation">,</span> <span class="token punctuation">[</span>text<span class="token punctuation">,</span> textb<span class="token punctuation">]</span><span class="token punctuation">,</span> text2<span class="token punctuation">)</span>

    <span class="token comment"># track nested list</span>
    <span class="token keyword">def</span> <span class="token function">load_nested_set</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> text2<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">3</span>
        <span class="token keyword">for</span> img_set <span class="token keyword">in</span> progress<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Nested list"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> img <span class="token keyword">in</span> progress<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>img_set<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"inner list"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    load_nested_set_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>load_nested_set<span class="token punctuation">,</span> <span class="token punctuation">[</span>text<span class="token punctuation">,</span> textb<span class="token punctuation">]</span><span class="token punctuation">,</span> text2<span class="token punctuation">)</span>

    <span class="token comment"># track iterable of unknown length</span>
    <span class="token keyword">def</span> <span class="token function">load_random</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">yielder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> <span class="token boolean">None</span>
        <span class="token keyword">for</span> img <span class="token keyword">in</span> progress<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>yielder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">pass</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    load_random_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>load_random<span class="token punctuation">,</span> <span class="token punctuation">{</span>text<span class="token punctuation">,</span> textb<span class="token punctuation">}</span><span class="token punctuation">,</span> text2<span class="token punctuation">)</span>
        
    <span class="token comment"># manual progress</span>
    <span class="token keyword">def</span> <span class="token function">clean_imgs</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        progress<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Collecting Images"</span><span class="token punctuation">)</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        progress<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Cleaning Images"</span><span class="token punctuation">)</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">)</span>
        progress<span class="token punctuation">(</span><span class="token number">0.8</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Sending Images"</span><span class="token punctuation">)</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    clean_imgs_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>clean_imgs<span class="token punctuation">,</span> text<span class="token punctuation">,</span> text2<span class="token punctuation">)</span>

    <span class="token comment"># no progress</span>
    <span class="token keyword">def</span> <span class="token function">wait</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    wait_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>wait<span class="token punctuation">,</span> text<span class="token punctuation">,</span> text2<span class="token punctuation">)</span>

    <span class="token comment"># multiple progressions</span>
    <span class="token keyword">def</span> <span class="token function">do_all</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        load_set<span class="token punctuation">(</span>data<span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span>textb<span class="token punctuation">]</span><span class="token punctuation">,</span> progress<span class="token punctuation">)</span>
        load_random<span class="token punctuation">(</span>data<span class="token punctuation">,</span> progress<span class="token punctuation">)</span>
        clean_imgs<span class="token punctuation">(</span>data<span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span> progress<span class="token punctuation">)</span>
        progress<span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">)</span>
        wait<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    do_all_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>do_all<span class="token punctuation">,</span> <span class="token punctuation">{</span>text<span class="token punctuation">,</span> textb<span class="token punctuation">}</span><span class="token punctuation">,</span> text2<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">track_tqdm</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span>track_tqdm<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"outer"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"inner"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    track_tqdm_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>track_tqdm<span class="token punctuation">,</span> <span class="token punctuation">{</span>text<span class="token punctuation">,</span> textb<span class="token punctuation">}</span><span class="token punctuation">,</span> text2<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">bind_internal_tqdm</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> progress<span class="token operator">=</span>gr<span class="token punctuation">.</span>Progress<span class="token punctuation">(</span>track_tqdm<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        outdir <span class="token operator">=</span> <span class="token string">"__tmp/"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>uuid4<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        load_dataset<span class="token punctuation">(</span><span class="token string">"beans"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">,</span> cache_dir<span class="token operator">=</span>outdir<span class="token punctuation">)</span>
        shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>outdir<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token string">"done"</span>
    bind_internal_tqdm_btn<span class="token punctuation">.</span>click<span class="token punctuation">(</span>bind_internal_tqdm<span class="token punctuation">,</span> <span class="token punctuation">{</span>text<span class="token punctuation">,</span> textb<span class="token punctuation">}</span><span class="token punctuation">,</span> text2<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    demo<span class="token punctuation">.</span>launch<span class="token punctuation">(</span><span class="token punctuation">)</span>
<!-- HTML_TAG_END --></code>
</pre>
               </div>
               <gradio-app space="gradio/progress">
               </gradio-app>
              </div>
             </div>
            </div>
           </div>
          </div>
         </div>
         <div id="methods">
          <h4 class="mt-4 p-3 text-xl text-orange-500 font-light group" data-svelte-h="svelte-1d9ap9x">
           Methods
           <a class="invisible group-hover-visible" href="#methods">
            <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
           </a>
          </h4>
          <div class="flex flex-col gap-8 pl-12">
           <div class="obj" id="progress-call">
            <div class="flex flex-row items-center justify-between">
             <h3 class="group text-3xl font-light py-4">
              __call__
              <a class="invisible group-hover-visible" href="#progress-call">
               <img class="anchor-img" src="/_app/immutable/assets/anchor.ce190310.svg"/>
              </a>
             </h3>
            </div>
            <div class="codeblock">
             <pre><code class="code language-python">gradio.Progress.<span>__call__(</span>progress, ¬∑¬∑¬∑<span data-svelte-h="svelte-cjlg1d">)</span></code></pre>
            </div>
            <h4 class="mt-8 text-xl text-orange-500 font-light group" id="progress-call-description">
             Description
             <a class="invisible group-hover-visible" href="#progress-call-description">
              <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
             </a>
            </h4>
            <p class="mb-2 text-lg">
             <!-- HTML_TAG_START -->
             Updates progress tracker with progress and message text.
             <!-- HTML_TAG_END -->
            </p>
            <h4 class="mt-6 text-xl text-orange-500 font-light group" id="progress-call-arguments">
             Agruments
             <a class="invisible group-hover-visible" href="#progress-call-arguments">
              <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
             </a>
            </h4>
            <table class="table-fixed w-full leading-loose">
             <thead class="text-left" data-svelte-h="svelte-1q69r1x">
              <tr>
               <th class="px-3 pb-3 font-semibold text-gray-700 w-2/5">
                Parameter
               </th>
               <th class="px-3 pb-3 font-semibold text-gray-700">
                Description
               </th>
              </tr>
             </thead>
             <tbody class="rounded-lg bg-gray-50 border border-gray-100 overflow-hidden text-left align-top divide-y">
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 progress
                </code>
                <p class="text-gray-500 italic">
                 float | tuple[int, int | None] | None
                </p>
                <p class="text-orange-600 font-semibold italic" data-svelte-h="svelte-16s522m">
                 required
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 If float, should be between 0 and 1 representing completion. If Tuple, first number represents steps completed, and second value represents total steps or None if unknown. If None, hides progress bar.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 desc
                </code>
                <p class="text-gray-500 italic">
                 str | None
                </p>
                <p class="text-gray-500 font-semibold">
                 default: None
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 description to display.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 total
                </code>
                <p class="text-gray-500 italic">
                 int | None
                </p>
                <p class="text-gray-500 font-semibold">
                 default: None
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 estimated total number of steps.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 unit
                </code>
                <p class="text-gray-500 italic">
                 str
                </p>
                <p class="text-gray-500 font-semibold">
                 default: "steps"
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 unit of iterations.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
             </tbody>
            </table>
           </div>
           <div class="obj" id="progress-tqdm">
            <div class="flex flex-row items-center justify-between">
             <h3 class="group text-3xl font-light py-4">
              tqdm
              <a class="invisible group-hover-visible" href="#progress-tqdm">
               <img class="anchor-img" src="/_app/immutable/assets/anchor.ce190310.svg"/>
              </a>
             </h3>
            </div>
            <div class="codeblock">
             <pre><code class="code language-python">gradio.Progress.<span>tqdm(</span>iterable, ¬∑¬∑¬∑<span data-svelte-h="svelte-cjlg1d">)</span></code></pre>
            </div>
            <h4 class="mt-8 text-xl text-orange-500 font-light group" id="progress-tqdm-description">
             Description
             <a class="invisible group-hover-visible" href="#progress-tqdm-description">
              <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
             </a>
            </h4>
            <p class="mb-2 text-lg">
             <!-- HTML_TAG_START -->
             Attaches progress tracker to iterable, like tqdm.
             <!-- HTML_TAG_END -->
            </p>
            <h4 class="mt-6 text-xl text-orange-500 font-light group" id="progress-tqdm-arguments">
             Agruments
             <a class="invisible group-hover-visible" href="#progress-tqdm-arguments">
              <img class="anchor-img-small" src="/_app/immutable/assets/anchor.ce190310.svg"/>
             </a>
            </h4>
            <table class="table-fixed w-full leading-loose">
             <thead class="text-left" data-svelte-h="svelte-1q69r1x">
              <tr>
               <th class="px-3 pb-3 font-semibold text-gray-700 w-2/5">
                Parameter
               </th>
               <th class="px-3 pb-3 font-semibold text-gray-700">
                Description
               </th>
              </tr>
             </thead>
             <tbody class="rounded-lg bg-gray-50 border border-gray-100 overflow-hidden text-left align-top divide-y">
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 iterable
                </code>
                <p class="text-gray-500 italic">
                 Iterable | None
                </p>
                <p class="text-orange-600 font-semibold italic" data-svelte-h="svelte-16s522m">
                 required
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 iterable to attach progress tracker to.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 desc
                </code>
                <p class="text-gray-500 italic">
                 str | None
                </p>
                <p class="text-gray-500 font-semibold">
                 default: None
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 description to display.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 total
                </code>
                <p class="text-gray-500 italic">
                 int | None
                </p>
                <p class="text-gray-500 font-semibold">
                 default: None
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 estimated total number of steps.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
              <tr class="group hover:bg-gray-200/60 odd:bg-gray-100/80">
               <td class="p-3 w-2/5 break-words">
                <code class="block">
                 unit
                </code>
                <p class="text-gray-500 italic">
                 str
                </p>
                <p class="text-gray-500 font-semibold">
                 default: "steps"
                </p>
               </td>
               <td class="p-3 text-gray-700 break-words">
                <p>
                 <!-- HTML_TAG_START -->
                 unit of iterations.
                 <!-- HTML_TAG_END -->
                </p>
               </td>
              </tr>
             </tbody>
            </table>
           </div>
           <div class="ml-12">
           </div>
          </div>
         </div>
        </div>
       </div>
      </div>
      <div class="lg:ml-10 flex justify-between my-4">
       <a class="text-left px-4 py-1 bg-gray-50 rounded-full hover:underline" href="./examples">
        <div class="text-lg">
         <span class="text-orange-500" data-svelte-h="svelte-1gjiegn">
          ‚Üê
         </span>
         Examples
        </div>
       </a>
       <a class="text-right px-4 py-1 bg-gray-50 rounded-full hover:underline" href="./make_waveform">
        <div class="text-lg">
         make_waveform
         <span class="text-orange-500" data-svelte-h="svelte-1moj53h">
          ‚Üí
         </span>
        </div>
       </a>
      </div>
     </div>
     <div class="float-right top-8 hidden sticky h-screen overflow-y-auto lg:block lg:w-2/12">
      <div class="mx-8">
       <a class="thin-link py-2 block text-lg" href="#progress">
        Progress
       </a>
       <ul class="text-slate-700 text-lg leading-6">
        <li>
         <a class="thin-link block py-2 font-light second-nav-link" href="#description">
          Description
         </a>
        </li>
        <li>
         <a class="thin-link block py-2 font-light second-nav-link" href="#example-usage">
          Example Usage
         </a>
        </li>
        <li>
         <a class="thin-link block py-2 font-light second-nav-link" href="#initialization">
          Initialization
         </a>
        </li>
        <li>
         <a class="thin-link block py-2 font-light second-nav-link" href="#demos">
          Demos
         </a>
        </li>
        <li>
         <a class="thin-link block py-2 font-light second-nav-link" href="#methods">
          Methods
         </a>
        </li>
        <li class="">
         <a class="thin-link block py-2 font-light second-nav-link sub-link svelte-1vjvs8s" href="#progress-call">
          __call__
         </a>
        </li>
        <li class="">
         <a class="thin-link block py-2 font-light second-nav-link sub-link svelte-1vjvs8s" href="#progress-tqdm">
          tqdm
         </a>
        </li>
       </ul>
      </div>
     </div>
    </div>
   </main>
   <footer class="main-footer container mx-auto flex-row flex items-center px-4 py-6 justify-between" data-svelte-h="svelte-rbo7yn">
    <a href="/">
     <img alt="Gradio logo" src="/_app/immutable/assets/gradio.8a5e8876.svg"/>
    </a>
    <div class="flex gap-3">
     <a class="text-gray-400 hover:text-gray-500" href="https://status.gradio.app" target="_blank">
      <span>
       Status
      </span>
     </a>
     <a class="hover:opacity-75 transition" href="https://twitter.com/Gradio">
      <img alt="Twitter logo" class="w-6" src="/_app/immutable/assets/twitter.2ed0ed10.svg"/>
     </a>
     <a class="hover:opacity-75 transition" href="https://github.com/gradio-app/gradio">
      <img alt="Github logo" class="w-6" src="/_app/immutable/assets/github.b4948cbf.svg"/>
     </a>
    </div>
   </footer>
   <script>
    {
					__sveltekit_975e71 = {
						base: new URL("..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [{"type":"data","data":null,"uses":{"url":1}},{"type":"data","data":(function(a,b,c,d,e){a.annotatedimage={class:null,name:"AnnotatedImage",description:"Displays a base image and colored subsections on top of that image. Subsections can take the from of rectangles (e.g. object detection) or masks (e.g. image segmentation). \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a {Tuple[numpy.ndarray | PIL.Image | str, List[Tuple[numpy.ndarray | Tuple[int, int, int, int], str]]]} consisting of a base image and a list of subsections, that are either (x1, y1, x2, y2) tuples identifying object boundaries, or 0-1 confidence masks of the same shape as the image. A label is provided for each subsection.",demos:"image_segmentation"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"tuple[np.ndarray | _Image.Image | str, list[tuple[np.ndarray | tuple[int, int, int, int], str]]] | None",doc:"Tuple of base image and list of (subsection, label) pairs.",default:"None"},{name:"show_legend",annotation:"bool",doc:"If True, will show a legend of the subsections.",default:"True"},{name:"height",annotation:"int | str | None",doc:"The height of the image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"color_map",annotation:"dict[str, str] | None",doc:"A dictionary mapping labels to colors. The colors must be specified as hex codes.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the AnnotatedImage. Uses event data gradio.SelectData to carry `value` referring to the label of the AnnotatedImage, and `selected` to refer to state of the AnnotatedImage. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.AnnotatedImage",slug:"annotated-image-select"}],string_shortcuts:[["AnnotatedImage","annotatedimage","Uses default values"]],demos:[["image_segmentation","import gradio as gr\nimport numpy as np\nimport random\n\nwith gr.Blocks() as demo:\n    section_labels = [\n        \"apple\",\n        \"banana\",\n        \"carrot\",\n        \"donut\",\n        \"eggplant\",\n        \"fish\",\n        \"grapes\",\n        \"hamburger\",\n        \"ice cream\",\n        \"juice\",\n    ]\n\n    with gr.Row():\n        num_boxes = gr.Slider(0, 5, 2, step=1, label=\"Number of boxes\")\n        num_segments = gr.Slider(0, 5, 1, step=1, label=\"Number of segments\")\n\n    with gr.Row():\n        img_input = gr.Image()\n        img_output = gr.AnnotatedImage(\n            color_map={\"banana\": \"#a89a00\", \"carrot\": \"#ffae00\"}\n        )\n\n    section_btn = gr.Button(\"Identify Sections\")\n    selected_section = gr.Textbox(label=\"Selected Section\")\n\n    def section(img, num_boxes, num_segments):\n        sections = []\n        for a in range(num_boxes):\n            x = random.randint(0, img.shape[1])\n            y = random.randint(0, img.shape[0])\n            w = random.randint(0, img.shape[1] - x)\n            h = random.randint(0, img.shape[0] - y)\n            sections.append(((x, y, x + w, y + h), section_labels[a]))\n        for b in range(num_segments):\n            x = random.randint(0, img.shape[1])\n            y = random.randint(0, img.shape[0])\n            r = random.randint(0, min(x, y, img.shape[1] - x, img.shape[0] - y))\n            mask = np.zeros(img.shape[:2])\n            for i in range(img.shape[0]):\n                for j in range(img.shape[1]):\n                    dist_square = (i - y) ** 2 + (j - x) ** 2\n                    if dist_square \u003C r**2:\n                        mask[i, j] = round((r**2 - dist_square) / r**2 * 4) / 4\n            sections.append((mask, section_labels[b + num_boxes]))\n        return (img, sections)\n\n    section_btn.click(section, [img_input, num_boxes, num_segments], img_output)\n\n    def select_section(evt: gr.SelectData):\n        return section_labels[evt.index]\n\n    img_output.select(select_section, None, selected_section)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Components",next_obj:"Audio",slug:"annotated-image"};a.audio={class:null,name:"Audio",description:"Creates an audio component that can be used to upload/record audio (as an input) or display audio (as an output).",tags:{preprocessing:"depending on `type`, passes the uploaded audio as {str} filepath or a {Tuple(int, numpy.array)} corresponding to (sample rate in Hz, audio data). If the latter, the audio data is a 16-bit int array whose values range from -32768 to 32767 and shape of the audio data array is (samples,) for mono audio or (samples, channels) for multi-channel audio.",postprocessing:"expects a {Tuple(int, numpy.array)} corresponding to (sample rate in Hz, audio data as a float or int numpy array) or as a {str} or {pathlib.Path} filepath or URL to an audio file, or bytes for binary content (recommended for streaming). Note: When converting audio data from float format to WAV, the audio is normalized by its peak value to avoid distortion or clipping in the resulting audio.","examples-format":"a {str} filepath to a local file that contains audio.",demos:"main_note, generate_tone, reverse_audio",guides:"real-time-speech-recognition"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Path | tuple[int, np.ndarray] | Callable | None",doc:"A path, URL, or [sample_rate, numpy array] tuple (sample rate in Hz, audio data as a float or int numpy array) for the default value that Audio component is going to take. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"sources",annotation:"list[Literal[('upload', 'microphone')]] | None",doc:"A list of sources permitted for audio. &quot;upload&quot; creates a box where user can drop an audio file, &quot;microphone&quot; creates a microphone input. The first element in the list will be used as the default source. If None, defaults to [&quot;upload&quot;, &quot;microphone&quot;], or [&quot;microphone&quot;] if `streaming` is True.",default:"None"},{name:"type",annotation:"Literal[('numpy', 'filepath')]",doc:"The format the audio file is converted to before being passed into the prediction function. &quot;numpy&quot; converts the audio to a tuple consisting of: (int sample rate, numpy.array for the data), &quot;filepath&quot; passes a str path to a temporary file containing the audio.",default:"\"numpy\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"If True, will allow users to upload and edit an audio file. If False, can only be used to play audio. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"streaming",annotation:"bool",doc:"If set to True when used in a `live` interface as an input, will automatically stream webcam feed. When used set as an output, takes audio chunks yield from the backend and combines them into one streaming audio output.",default:"False"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"format",annotation:"Literal[('wav', 'mp3')]",doc:"The file format to save audio files. Either &#x27;wav&#x27; or &#x27;mp3&#x27;. wav files are lossless but will tend to be larger files. mp3 files tend to be smaller. Default is wav. Applies both when this component is used as an input (when `type` is &quot;format&quot;) and when this component is used as an output.",default:"\"wav\""},{name:"autoplay",annotation:"bool",doc:"Whether to automatically play the audio when the component is used as an output. Note: browsers will not autoplay audio files if the user has not interacted with the page yet.",default:"False"},{name:"show_download_button",annotation:"bool | None",doc:"If True, will show a download button in the corner of the component for saving audio. If False, icon does not appear. By default, it will be True for output components and False for input components.",default:"None"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"editable",annotation:"bool",doc:"If True, allows users to manipulate the audio file if the component is interactive. Defaults to True.",default:"True"},{name:"min_length",annotation:"int | None",doc:"The minimum length of audio (in seconds) that the user can pass into the prediction function. If None, there is no minimum length.",default:"None"},{name:"max_length",annotation:"int | None",doc:"The maximum length of audio (in seconds) that the user can pass into the prediction function. If None, there is no maximum length.",default:"None"},{name:"waveform_options",annotation:"WaveformOptions | dict | None",doc:"A dictionary of options for the waveform display. Options include: waveform_color (str), waveform_progress_color (str), show_controls (bool), skip_length (int). Default is None, which uses the default values for these options.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"stream",description:"This listener is triggered when the user streams the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"hidden\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-stream"},{fn:null,name:"change",description:"Triggered when the value of the Audio changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Audio using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-clear"},{fn:null,name:"play",description:"This listener is triggered when the user plays the media in the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-play"},{fn:null,name:"pause",description:"This listener is triggered when the media in the Audio stops for any reason.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-pause"},{fn:null,name:"stop",description:"This listener is triggered when the user reaches the end of the media playing in the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-stop"},{fn:null,name:"pause",description:"This listener is triggered when the media in the Audio stops for any reason.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-pause-2"},{fn:null,name:"start_recording",description:"This listener is triggered when the user starts recording with the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-start-recording"},{fn:null,name:"pause_recording",description:"This listener is triggered when the user pauses recording with the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-pause-recording"},{fn:null,name:"stop_recording",description:"This listener is triggered when the user stops recording with the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-stop-recording"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-upload"}],string_shortcuts:[["Audio","audio","Uses default values"],["Microphone","microphone","Uses sources=[\"microphone\"]"]],demos:[["main_note","from math import log2, pow\nimport os\n\nimport numpy as np\nfrom scipy.fftpack import fft\n\nimport gradio as gr\n\nA4 = 440\nC0 = A4 * pow(2, -4.75)\nname = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\n\ndef get_pitch(freq):\n    h = round(12 * log2(freq / C0))\n    n = h % 12\n    return name[n]\n\n\ndef main_note(audio):\n    rate, y = audio\n    if len(y.shape) == 2:\n        y = y.T[0]\n    N = len(y)\n    T = 1.0 / rate\n    yf = fft(y)\n    yf2 = 2.0 / N * np.abs(yf[0 : N // 2])\n    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n\n    volume_per_pitch = {}\n    total_volume = np.sum(yf2)\n    for freq, volume in zip(xf, yf2):\n        if freq == 0:\n            continue\n        pitch = get_pitch(freq)\n        if pitch not in volume_per_pitch:\n            volume_per_pitch[pitch] = 0\n        volume_per_pitch[pitch] += 1.0 * volume / total_volume\n    volume_per_pitch = {k: float(v) for k, v in volume_per_pitch.items()}\n    return volume_per_pitch\n\n\ndemo = gr.Interface(\n    main_note,\n    gr.Audio(sources=[\"microphone\"]),\n    gr.Label(num_top_classes=4),\n    examples=[\n        [os.path.join(os.path.dirname(__file__),\"audio/recording1.wav\")],\n        [os.path.join(os.path.dirname(__file__),\"audio/cantina.wav\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["generate_tone","import numpy as np\nimport gradio as gr\n\nnotes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\ndef generate_tone(note, octave, duration):\n    sr = 48000\n    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n    duration = int(duration)\n    audio = np.linspace(0, duration, duration * sr)\n    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n    return sr, audio\n\ndemo = gr.Interface(\n    generate_tone,\n    [\n        gr.Dropdown(notes, type=\"index\"),\n        gr.Slider(4, 6, step=1),\n        gr.Textbox(value=1, label=\"Duration in seconds\"),\n    ],\n    \"audio\",\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["reverse_audio","import os\n\nimport numpy as np\n\nimport gradio as gr\n\n\ndef reverse_audio(audio):\n    sr, data = audio\n    return (sr, np.flipud(data))\n\n\ninput_audio = gr.Audio(\n    sources=[\"microphone\"],\n    waveform_options=gr.WaveformOptions(\n        waveform_color=\"#01C6FF\",\n        waveform_progress_color=\"#0066B4\",\n        skip_length=2,\n        show_controls=False,\n    ),\n)\ndemo = gr.Interface(\n    fn=reverse_audio,\n    inputs=input_audio,\n    outputs=\"audio\",\n    examples=[\n        \"https://samplelib.com/lib/preview/mp3/sample-3s.mp3\",\n        os.path.join(os.path.dirname(__file__), \"audio/recording1.wav\"),\n    ],\n    cache_examples=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"real-time-speech-recognition",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:49,pretty_name:"Real Time Speech Recognition",content:"# Real Time Speech Recognition\n\n\n\n## Introduction\n\nAutomatic speech recognition (ASR), the conversion of spoken speech to text, is a very important and thriving area of machine learning. ASR algorithms run on practically every smartphone, and are becoming increasingly embedded in professional workflows, such as digital assistants for nurses and doctors. Because ASR algorithms are designed to be used directly by customers and end users, it is important to validate that they are behaving as expected when confronted with a wide variety of speech patterns (different accents, pitches, and background audio conditions).\n\nUsing `gradio`, you can easily build a demo of your ASR model and share that with a testing team, or test it yourself by speaking through the microphone on your device.\n\nThis tutorial will show how to take a pretrained speech-to-text model and deploy it with a Gradio interface. We will start with a **_full-context_** model, in which the user speaks the entire audio before the prediction runs. Then we will adapt the demo to make it **_streaming_**, meaning that the audio model will convert speech as you speak. \n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained speech recognition model. In this tutorial, we will build demos from 2 ASR libraries:\n\n- Transformers (for this, `pip install transformers` and `pip install torch`)\n\nMake sure you have at least one of these installed so that you can follow along the tutorial. You will also need `ffmpeg` [installed on your system](https://www.ffmpeg.org/download.html), if you do not already have it, to process files from the microphone.\n\nHere's how to build a real time speech recognition (ASR) app:\n\n1. [Set up the Transformers ASR Model](#1-set-up-the-transformers-asr-model)\n2. [Create a Full-Context ASR Demo with Transformers](#2-create-a-full-context-asr-demo-with-transformers)\n3. [Create a Streaming ASR Demo with Transformers](#3-create-a-streaming-asr-demo-with-transformers)\n\n## 1. Set up the Transformers ASR Model\n\nFirst, you will need to have an ASR model that you have either trained yourself or you will need to download a pretrained model. In this tutorial, we will start by using a pretrained ASR model from the model, `whisper`.\n\nHere is the code to load `whisper` from Hugging Face `transformers`.\n\n```python\nfrom transformers import pipeline\n\np = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n```\n\nThat's it!\n\n## 2. Create a Full-Context ASR Demo with Transformers\n\nWe will start by creating a _full-context_ ASR demo, in which the user speaks the full audio before using the ASR model to run inference. This is very easy with Gradio -- we simply create a function around the `pipeline` object above.\n\nWe will use `gradio`'s built in `Audio` component, configured to take input from the user's microphone and return a filepath for the recorded audio. The output component will be a plain `Textbox`.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(audio):\n    sr, y = audio\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    gr.Audio(sources=[\"microphone\"]),\n    \"text\",\n)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/asr'>\u003C/gradio-app>\n\nThe `transcribe` function takes a single parameter, `audio`, which is a numpy array of the audio the user recorded. The `pipeline` object expects this in float32 format, so we convert it first to float32, and then extract the transcribed text.\n\n## 3. Create a Streaming ASR Demo with Transformers\n\nTo make this a *streaming* demo, we need to make these changes:\n\n1. Set `streaming=True` in the `Audio` component\n2. Set `live=True` in the `Interface`\n3. Add a `state` to the interface to store the recorded audio of a user\n\nTake a look below.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(stream, new_chunk):\n    sr, y = new_chunk\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    if stream is not None:\n        stream = np.concatenate([stream, y])\n    else:\n        stream = y\n    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n    [\"state\", \"text\"],\n    live=True,\n)\n\ndemo.launch()\n\n```\n\nNotice now we have a state variable now, because we need to track all the audio history. `transcribe` gets called whenever there is a new small chunk of audio, but we also need to keep track of all the audio that has been spoken so far in state. \nAs the interface runs, the `transcribe` function gets called, with a record of all the previously spoken audio in `stream`, as well as the new chunk of audio as `new_chunk`. We return the new full audio so that can be stored back in state, and we also return the transcription.\nHere we naively append the audio together and simply call the `transcriber` object on the entire audio. You can imagine more efficient ways of handling this, such as re-processing only the last 5 seconds of audio whenever a new chunk of audio received. \n\n\u003Cgradio-app space='gradio/stream_asr'>\u003C/gradio-app>\n\nNow the ASR model will run inference as you speak! ",tags:["ASR","SPEECH","STREAMING"],spaces:[],url:"/guides/real-time-speech-recognition/",contributor:null}],parent:"gradio",prev_obj:"AnnotatedImage",next_obj:"BarPlot",slug:"audio"};a.barplot={class:null,name:"BarPlot",description:"Create a bar plot. \u003Cbr> \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a pandas dataframe with the data to plot.",demos:"bar_plot, chicago-bikeshare-dashboard"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Callable | None",doc:"The pandas dataframe containing the data to display in a scatter plot.",default:"None"},{name:"x",annotation:"str | None",doc:"Column corresponding to the x axis.",default:"None"},{name:"y",annotation:"str | None",doc:"Column corresponding to the y axis.",default:"None"},{name:"color",annotation:"str | None",doc:"The column to determine the bar color. Must be categorical (discrete values).",default:"None"},{name:"vertical",annotation:"bool",doc:"If True, the bars will be displayed vertically. If False, the x and y axis will be switched, displaying the bars horizontally. Default is True.",default:"True"},{name:"group",annotation:"str | None",doc:"The column with which to split the overall plot into smaller subplots.",default:"None"},{name:"title",annotation:"str | None",doc:"The title to display on top of the chart.",default:"None"},{name:"tooltip",annotation:"list[str] | str | None",doc:"The column (or list of columns) to display on the tooltip when a user hovers over a bar.",default:"None"},{name:"x_title",annotation:"str | None",doc:"The title given to the x axis. By default, uses the value of the x parameter.",default:"None"},{name:"y_title",annotation:"str | None",doc:"The title given to the y axis. By default, uses the value of the y parameter.",default:"None"},{name:"x_label_angle",annotation:"float | None",doc:"The angle (in degrees) of the x axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"y_label_angle",annotation:"float | None",doc:"The angle (in degrees) of the y axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"color_legend_title",annotation:"str | None",doc:"The title given to the color legend. By default, uses the value of color parameter.",default:"None"},{name:"group_title",annotation:"str | None",doc:"The label displayed on top of the subplot columns (or rows if vertical=True). Use an empty string to omit.",default:"None"},{name:"color_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the color legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"y_lim",annotation:"list[int] | None",doc:"A tuple of list containing the limits for the y-axis, specified as [y_min, y_max].",default:"None"},{name:"caption",annotation:"str | None",doc:"The (optional) caption to display below the plot.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether users should be able to interact with the plot by panning or zooming with their mouse or trackpad.",default:"True"},{name:"label",annotation:"str | None",doc:"The (optional) label to display on the top left corner of the plot.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"Whether the label should be displayed.",default:"None"},{name:"container",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"None"},{name:"min_width",annotation:"int",doc:null,default:"160"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"visible",annotation:"bool",doc:"Whether the plot should be visible.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"sort",annotation:"Literal[('x', 'y', '-x', '-y')] | None",doc:"Specifies the sorting axis as either &quot;x&quot;, &quot;y&quot;, &quot;-x&quot; or &quot;-y&quot;. If None, no sorting is applied.",default:"None"},{name:"show_actions_button",annotation:"bool",doc:"Whether to show the actions button on the top right corner of the plot.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.BarPlot",slug:"bar-plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.BarPlot",slug:"bar-plot-clear"}],string_shortcuts:[["BarPlot","barplot","Uses default values"]],demos:[["bar_plot","import gradio as gr\nimport pandas as pd\nimport random\n\nsimple = pd.DataFrame(\n    {\n        \"a\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"],\n        \"b\": [28, 55, 43, 91, 81, 53, 19, 87, 52],\n    }\n)\n\nfake_barley = pd.DataFrame(\n    {\n        \"site\": [\n            random.choice(\n                [\n                    \"University Farm\",\n                    \"Waseca\",\n                    \"Morris\",\n                    \"Crookston\",\n                    \"Grand Rapids\",\n                    \"Duluth\",\n                ]\n            )\n            for _ in range(120)\n        ],\n        \"yield\": [random.randint(25, 75) for _ in range(120)],\n        \"variety\": [\n            random.choice(\n                [\n                    \"Manchuria\",\n                    \"Wisconsin No. 38\",\n                    \"Glabron\",\n                    \"No. 457\",\n                    \"No. 462\",\n                    \"No. 475\",\n                ]\n            )\n            for _ in range(120)\n        ],\n        \"year\": [\n            random.choice(\n                [\n                    \"1931\",\n                    \"1932\",\n                ]\n            )\n            for _ in range(120)\n        ],\n    }\n)\n\n\ndef bar_plot_fn(display):\n    if display == \"simple\":\n        return gr.BarPlot(\n            simple,\n            x=\"a\",\n            y=\"b\",\n            title=\"Simple Bar Plot with made up data\",\n            tooltip=[\"a\", \"b\"],\n            y_lim=[20, 100],\n        )\n    elif display == \"stacked\":\n        return gr.BarPlot(\n            fake_barley,\n            x=\"variety\",\n            y=\"yield\",\n            color=\"site\",\n            title=\"Barley Yield Data\",\n            tooltip=[\"variety\", \"site\"],\n        )\n    elif display == \"grouped\":\n        return gr.BarPlot(\n            fake_barley.astype({\"year\": str}),\n            x=\"year\",\n            y=\"yield\",\n            color=\"year\",\n            group=\"site\",\n            title=\"Barley Yield by Year and Site\",\n            group_title=\"\",\n            tooltip=[\"yield\", \"site\", \"year\"],\n        )\n    elif display == \"simple-horizontal\":\n        return gr.BarPlot(\n            simple,\n            x=\"a\",\n            y=\"b\",\n            x_title=\"Variable A\",\n            y_title=\"Variable B\",\n            title=\"Simple Bar Plot with made up data\",\n            tooltip=[\"a\", \"b\"],\n            vertical=False,\n            y_lim=[20, 100],\n        )\n    elif display == \"stacked-horizontal\":\n        return gr.BarPlot(\n            fake_barley,\n            x=\"variety\",\n            y=\"yield\",\n            color=\"site\",\n            title=\"Barley Yield Data\",\n            vertical=False,\n            tooltip=[\"variety\", \"site\"],\n        )\n    elif display == \"grouped-horizontal\":\n        return gr.BarPlot(\n            fake_barley.astype({\"year\": str}),\n            x=\"year\",\n            y=\"yield\",\n            color=\"year\",\n            group=\"site\",\n            title=\"Barley Yield by Year and Site\",\n            group_title=\"\",\n            tooltip=[\"yield\", \"site\", \"year\"],\n            vertical=False,\n        )\n\n\nwith gr.Blocks() as bar_plot:\n    with gr.Row():\n        with gr.Column():\n            display = gr.Dropdown(\n                choices=[\n                    \"simple\",\n                    \"stacked\",\n                    \"grouped\",\n                    \"simple-horizontal\",\n                    \"stacked-horizontal\",\n                    \"grouped-horizontal\",\n                ],\n                value=\"simple\",\n                label=\"Type of Bar Plot\",\n            )\n        with gr.Column():\n            plot = gr.BarPlot()\n    display.change(bar_plot_fn, inputs=display, outputs=plot)\n    bar_plot.load(fn=bar_plot_fn, inputs=display, outputs=plot)\n\nbar_plot.launch()\n"],["chicago-bikeshare-dashboard","import os\nimport gradio as gr\nimport pandas as pd\n\nDB_USER = os.getenv(\"DB_USER\")\nDB_PASSWORD = os.getenv(\"DB_PASSWORD\")\nDB_HOST = os.getenv(\"DB_HOST\")\nPORT = 8080\nDB_NAME = \"bikeshare\"\n\nconnection_string = (\n    f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}?port={PORT}&dbname={DB_NAME}\"\n)\n\n\ndef get_count_ride_type():\n    df = pd.read_sql(\n        \"\"\"\n        SELECT COUNT(ride_id) as n, rideable_type\n        FROM rides\n        GROUP BY rideable_type\n        ORDER BY n DESC\n    \"\"\",\n        con=connection_string,\n    )\n    return df\n\n\ndef get_most_popular_stations():\n\n    df = pd.read_sql(\n        \"\"\"\n    SELECT COUNT(ride_id) as n, MAX(start_station_name) as station\n    FROM RIDES\n    WHERE start_station_name is NOT NULL\n    GROUP BY start_station_id\n    ORDER BY n DESC\n    LIMIT 5\n    \"\"\",\n        con=connection_string,\n    )\n    return df\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n    # Chicago Bike Share Dashboard\n    \n    This demo pulls Chicago bike share data for March 2022 from a postgresql database hosted on AWS.\n    This demo uses psycopg2 but any postgresql client library (SQLAlchemy)\n    is compatible with gradio.\n    \n    Connection credentials are handled by environment variables\n    defined as secrets in the Space.\n\n    If data were added to the database, the plots in this demo would update\n    whenever the webpage is reloaded.\n    \n    This demo serves as a starting point for your database-connected apps!\n    \"\"\"\n    )\n    with gr.Row():\n        bike_type = gr.BarPlot(\n            x=\"rideable_type\",\n            y='n',\n            title=\"Number of rides per bicycle type\",\n            y_title=\"Number of Rides\",\n            x_title=\"Bicycle Type\",\n            vertical=False,\n            tooltip=['rideable_type', \"n\"],\n            height=300,\n            width=300,\n        )\n        station = gr.BarPlot(\n            x='station',\n            y='n',\n            title=\"Most Popular Stations\",\n            y_title=\"Number of Rides\",\n            x_title=\"Station Name\",\n            vertical=False,\n            tooltip=['station', 'n'],\n            height=300,\n            width=300\n        )\n\n    demo.load(get_count_ride_type, inputs=None, outputs=bike_type)\n    demo.load(get_most_popular_stations, inputs=None, outputs=station)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Audio",next_obj:"Button",slug:"bar-plot"};a.button={class:null,name:"Button",description:"Used to create a button, that can be assigned arbitrary click() events. The label (value) of the button can be used as an input or set via the output of a function. \u003Cbr>",tags:{preprocessing:"passes the button value as a {str} into the function",postprocessing:"expects a {str} to be returned from a function, which is set as the label of the button",demos:"blocks_inputs, blocks_kinematics"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Run\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed. Must be within the working directory of the Gradio app or an external URL.",default:"None"},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Button",slug:"button-click"}],string_shortcuts:[["Button","button","Uses default values"],["ClearButton","clearbutton","Uses default values"],["DuplicateButton","duplicatebutton","Uses default values"],["LoginButton","loginbutton","Uses default values"],["LogoutButton","logoutbutton","Uses default values"]],demos:[["blocks_inputs","import gradio as gr\nimport os\n\n\ndef combine(a, b):\n    return a + \" \" + b\n\n\ndef mirror(x):\n    return x\n\n\nwith gr.Blocks() as demo:\n\n    txt = gr.Textbox(label=\"Input\", lines=2)\n    txt_2 = gr.Textbox(label=\"Input 2\")\n    txt_3 = gr.Textbox(value=\"\", label=\"Output\")\n    btn = gr.Button(value=\"Submit\")\n    btn.click(combine, inputs=[txt, txt_2], outputs=[txt_3])\n\n    with gr.Row():\n        im = gr.Image()\n        im_2 = gr.Image()\n\n    btn = gr.Button(value=\"Mirror Image\")\n    btn.click(mirror, inputs=[im], outputs=[im_2])\n\n    gr.Markdown(\"## Text Examples\")\n    gr.Examples(\n        [[\"hi\", \"Adam\"], [\"hello\", \"Eve\"]],\n        [txt, txt_2],\n        txt_3,\n        combine,\n        cache_examples=True,\n    )\n    gr.Markdown(\"## Image Examples\")\n    gr.Examples(\n        examples=[os.path.join(os.path.dirname(__file__), \"lion.jpg\")],\n        inputs=im,\n        outputs=im_2,\n        fn=mirror,\n        cache_examples=True,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_kinematics","import pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"BarPlot",next_obj:"Chatbot",slug:"button"};a.chatbot={class:null,name:"Chatbot",description:"Displays a chatbot output showing both user submitted messages and responses. Supports a subset of Markdown including bold, italics, code, tables. Also supports audio/video/image files, which are displayed in the Chatbot, and other kinds of files which are displayed as links. \u003Cbr>",tags:{preprocessing:"passes the messages in the Chatbot as a {List[List[str | None | Tuple]]}, i.e. a list of lists. The inner list has 2 elements: the user message and the response message. See `Postprocessing` for the format of these messages.",postprocessing:"expects function to return a {List[List[str | None | Tuple]]}, i.e. a list of lists. The inner list should have 2 elements: the user message and the response message. The individual messages can be (1) strings in valid Markdown, (2) tuples if sending files: (a filepath or URL to a file, [optional string alt text]) -- if the file is image/video/audio, it is displayed in the Chatbot, or (3) None, in which case the message is not displayed.",demos:"chatbot_simple, chatbot_multimodal",guides:"creating-a-chatbot"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"list[list[str | tuple[str] | tuple[str | Path, str] | None]] | Callable | None",doc:"Default value to show in chatbot. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"height",annotation:"int | str | None",doc:"The height of the component, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"latex_delimiters",annotation:"list[dict[str, str | bool]] | None",doc:"A list of dicts of the form {&quot;left&quot;: open delimiter (str), &quot;right&quot;: close delimiter (str), &quot;display&quot;: whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ &quot;left&quot;: &quot;$$&quot;, &quot;right&quot;: &quot;$$&quot;, &quot;display&quot;: True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html).",default:"None"},{name:"rtl",annotation:"bool",doc:"If True, sets the direction of the rendered text to right-to-left. Default is False, which renders text left-to-right.",default:"False"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"show_copy_button",annotation:"bool",doc:"If True, will show a copy button for each chatbot message.",default:"False"},{name:"avatar_images",annotation:"tuple[str | Path | None, str | Path | None] | None",doc:"Tuple of two avatar image paths or URLs for user and bot (in that order). Pass None for either the user or bot image to skip. Must be within the working directory of the Gradio app or an external URL.",default:"None"},{name:"sanitize_html",annotation:"bool",doc:"If False, will disable HTML sanitization for chatbot messages. This is not recommended, as it can lead to security vulnerabilities.",default:"True"},{name:"render_markdown",annotation:"bool",doc:"If False, will disable Markdown rendering for chatbot messages.",default:"True"},{name:"bubble_full_width",annotation:"bool",doc:"If False, the chat bubble will fit to the content of the message. If True (default), the chat bubble will be the full width of the component.",default:"True"},{name:"line_breaks",annotation:"bool",doc:"If True (default), will enable Github-flavored Markdown line breaks in chatbot messages. If False, single new lines will be ignored. Only applies if `render_markdown` is True.",default:"True"},{name:"likeable",annotation:"bool",doc:"Whether the chat messages display a like or dislike button. Set automatically by the .like method but has to be present in the signature for it to show up in the config.",default:"False"},{name:"layout",annotation:"Literal[('panel', 'bubble')] | None",doc:"If &quot;panel&quot;, will display the chatbot in a llm style layout. If &quot;bubble&quot;, will display the chatbot with message bubbles, with the user and bot messages on alterating sides. Will default to &quot;bubble&quot;.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Chatbot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Chatbot",slug:"chatbot-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Chatbot. Uses event data gradio.SelectData to carry `value` referring to the label of the Chatbot, and `selected` to refer to state of the Chatbot. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Chatbot",slug:"chatbot-select"},{fn:null,name:"like",description:"This listener is triggered when the user likes/dislikes from within the Chatbot. This event has EventData of type gradio.LikeData that carries information, accessible through LikeData.index and LikeData.value. See EventData documentation on how to use this event data.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Chatbot",slug:"chatbot-like"}],string_shortcuts:[["Chatbot","chatbot","Uses default values"]],demos:[["chatbot_simple","import gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chat_history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        chat_history.append((message, bot_message))\n        time.sleep(2)\n        return \"\", chat_history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["chatbot_multimodal","import gradio as gr\nimport os\nimport time\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n\n\ndef print_like_dislike(x: gr.LikeData):\n    print(x.index, x.value, x.liked)\n\n\ndef add_text(history, text):\n    history = history + [(text, None)]\n    return history, gr.Textbox(value=\"\", interactive=False)\n\n\ndef add_file(history, file):\n    history = history + [((file.name,), None)]\n    return history\n\n\ndef bot(history):\n    response = \"**That's cool!**\"\n    history[-1][1] = \"\"\n    for character in response:\n        history[-1][1] += character\n        time.sleep(0.05)\n        yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(\n        [],\n        elem_id=\"chatbot\",\n        bubble_full_width=False,\n        avatar_images=(None, (os.path.join(os.path.dirname(__file__), \"avatar.png\"))),\n    )\n\n    with gr.Row():\n        txt = gr.Textbox(\n            scale=4,\n            show_label=False,\n            placeholder=\"Enter text and press enter, or upload an image\",\n            container=False,\n        )\n        btn = gr.UploadButton(\"üìÅ\", file_types=[\"image\", \"video\", \"audio\"])\n\n    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n        bot, chatbot, chatbot, api_name=\"bot_response\"\n    )\n    txt_msg.then(lambda: gr.Textbox(interactive=True), None, [txt], queue=False)\n    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n\n    chatbot.like(print_like_dislike, None, None)\n\n\ndemo.queue()\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[],parent:"gradio",prev_obj:"Button",next_obj:"Checkbox",slug:"chatbot"};a.checkbox={class:null,name:"Checkbox",description:"Creates a checkbox that can be set to `True` or `False`. \u003Cbr>",tags:{preprocessing:"passes the status of the checkbox as a {bool} into the function.",postprocessing:"expects a {bool} returned from the function and, if it is True, checks the checkbox.","examples-format":"a {bool} representing whether the box is checked.",demos:"sentence_builder, titanic_survival"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"bool | Callable",doc:"if True, checked by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"False"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, this checkbox can be checked; if False, checking will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Checkbox changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Checkbox",slug:"checkbox-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Checkbox.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Checkbox",slug:"checkbox-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Checkbox. Uses event data gradio.SelectData to carry `value` referring to the label of the Checkbox, and `selected` to refer to state of the Checkbox. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Checkbox",slug:"checkbox-select"}],string_shortcuts:[["Checkbox","checkbox","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Chatbot",next_obj:"CheckboxGroup",slug:"checkbox"};a.checkboxgroup={class:null,name:"CheckboxGroup",description:"Creates a set of checkboxes of which a subset can be checked.",tags:{preprocessing:"passes the list of checked checkboxes as a {List[str | int | float]} or their indices as a {List[int]} into the function, depending on `type`.",postprocessing:"expects a {List[str | int | float]}, each element of which becomes a checked checkbox.","examples-format":"a {List[str | int | float]} representing the values to be checked.",demos:"sentence_builder, titanic_survival"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"choices",annotation:"list[str | int | float | tuple[str, str | int | float]] | None",doc:"A list of string or numeric options to select from. An option can also be a tuple of the form (name, value), where name is the displayed name of the checkbox button and value is the value to be passed to the function, or returned by the function.",default:"None"},{name:"value",annotation:"list[str | float | int] | str | float | int | Callable | None",doc:"Default selected list of options. If a single choice is selected, it can be passed in as a string or numeric type. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"type",annotation:"Literal[('value', 'index')]",doc:"Type of value to be returned by component. &quot;value&quot; returns the list of strings of the choices selected, &quot;index&quot; returns the list of indices of the choices selected.",default:"\"value\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"Additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"If True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"Relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"Minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"If True, choices in this checkbox group will be checkable; if False, checking will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the CheckboxGroup changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.CheckboxGroup",slug:"checkbox-group-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the CheckboxGroup.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.CheckboxGroup",slug:"checkbox-group-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the CheckboxGroup. Uses event data gradio.SelectData to carry `value` referring to the label of the CheckboxGroup, and `selected` to refer to state of the CheckboxGroup. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.CheckboxGroup",slug:"checkbox-group-select"}],string_shortcuts:[["CheckboxGroup","checkboxgroup","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Checkbox",next_obj:"ClearButton",slug:"checkbox-group"};a.clearbutton={class:null,name:"ClearButton",description:"Button that clears the value of a component or a list of components when clicked. It is instantiated with the list of components to clear.",tags:{preprocessing:"passes the button value as a {str} into the function",postprocessing:"expects a {str} to be returned from a function, which is set as the label of the button"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"components",annotation:"None | list[Component] | Component",doc:null,default:"None"},{name:"value",annotation:"str",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Clear\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed. Must be within the working directory of the Gradio app or an external URL.",default:"None"},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"},{name:"api_name",annotation:"str | None | Literal['False']",doc:null,default:"None"},{name:"show_api",annotation:"bool",doc:null,default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"add",description:"Adds a component or list of components to the list of components that will be cleared when the button is clicked.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"components",annotation:"None | Component | list[Component]",doc:null}],returns:{},example:null,override_signature:null,parent:"gradio.ClearButton",slug:"clear-button-add"},{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ClearButton",slug:"clear-button-click"}],string_shortcuts:[["ClearButton","clearbutton","Uses default values"]],parent:"gradio",prev_obj:"CheckboxGroup",next_obj:"Code",slug:"clear-button"};a.code={class:null,name:"Code",description:"Creates a Code editor for entering, editing or viewing code.",tags:{preprocessing:"passes a {str} of code into the function.",postprocessing:"expects the function to return a {str} of code or a single-element {tuple}: {(string_filepath,)}"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | tuple[str] | None",doc:"Default value to show in the code editor. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"language",annotation:"Literal[('python', 'markdown', 'json', 'html', 'css', 'javascript', 'typescript', 'yaml', 'dockerfile', 'shell', 'r')] | None",doc:"The language to display the code as. Supported languages listed in `gr.Code.languages`.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"lines",annotation:"int",doc:null,default:"5"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether user should be able to enter code or only view it.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"languages",description:"[&#x27;python&#x27;, &#x27;markdown&#x27;, &#x27;json&#x27;, &#x27;html&#x27;, &#x27;css&#x27;, &#x27;javascript&#x27;, &#x27;typescript&#x27;, &#x27;yaml&#x27;, &#x27;dockerfile&#x27;, &#x27;shell&#x27;, &#x27;r&#x27;, None]",tags:{},parameters:[],returns:{},example:"",override_signature:"gr.Code.languages",parent:"gradio.Code",slug:"code-languages"},{fn:null,name:"change",description:"Triggered when the value of the Code changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Code.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-input"},{fn:null,name:"focus",description:"This listener is triggered when the Code is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-focus"},{fn:null,name:"blur",description:"This listener is triggered when the Code is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-blur"}],string_shortcuts:[["Code","code","Uses default values"]],parent:"gradio",prev_obj:"ClearButton",next_obj:"ColorPicker",slug:"code"};a.colorpicker={class:null,name:"ColorPicker",description:"Creates a color picker for user to select a color as string input.",tags:{preprocessing:"passes selected color value as a {str} into the function.",postprocessing:"expects a {str} returned from function and sets color picker value to it.","examples-format":"a {str} with a hexadecimal representation of a color, e.g. &quot;#ff0000&quot; for red.",demos:"color_picker, color_generator"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable | None",doc:"default text to provide in color picker. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will be rendered as an editable color picker; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the ColorPicker changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the ColorPicker.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-input"},{fn:null,name:"submit",description:"This listener is triggered when the user presses the Enter key while the ColorPicker is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-submit"},{fn:null,name:"focus",description:"This listener is triggered when the ColorPicker is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-focus"},{fn:null,name:"blur",description:"This listener is triggered when the ColorPicker is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-blur"}],string_shortcuts:[["ColorPicker","colorpicker","Uses default values"]],demos:[["color_picker","import gradio as gr\nimport numpy as np\nimport os\nfrom PIL import Image, ImageColor\n\n\ndef change_color(icon, color):\n\n    \"\"\"\n    Function that given an icon in .png format changes its color\n    Args:\n        icon: Icon whose color needs to be changed.\n        color: Chosen color with which to edit the input icon.\n    Returns:\n        edited_image: Edited icon.\n    \"\"\"\n    img = icon.convert(\"LA\")\n    img = img.convert(\"RGBA\")\n    image_np = np.array(icon)\n    _, _, _, alpha = image_np.T\n    mask = alpha > 0\n    image_np[..., :-1][mask.T] = ImageColor.getcolor(color, \"RGB\")\n    edited_image = Image.fromarray(image_np)\n    return edited_image\n\n\ninputs = [\n    gr.Image(label=\"icon\", type=\"pil\", image_mode=\"RGBA\"),\n    gr.ColorPicker(label=\"color\"),\n]\noutputs = gr.Image(label=\"colored icon\")\n\ndemo = gr.Interface(\n    fn=change_color,\n    inputs=inputs,\n    outputs=outputs,\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"rabbit.png\"), \"#ff0000\"],\n        [os.path.join(os.path.dirname(__file__), \"rabbit.png\"), \"#0000FF\"],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["color_generator","import gradio as gr\nimport cv2\nimport numpy as np\nimport random\n\n\n# Convert decimal color to hexadecimal color\ndef RGB_to_Hex(rgb):\n    color = \"#\"\n    for i in rgb:\n        num = int(i)\n        color += str(hex(num))[-2:].replace(\"x\", \"0\").upper()\n    return color\n\n\n# Randomly generate light or dark colors\ndef random_color(is_light=True):\n    return (\n        random.randint(0, 127) + int(is_light) * 128,\n        random.randint(0, 127) + int(is_light) * 128,\n        random.randint(0, 127) + int(is_light) * 128,\n    )\n\n\ndef switch_color(color_style):\n    if color_style == \"light\":\n        is_light = True\n    elif color_style == \"dark\":\n        is_light = False\n    back_color_ = random_color(is_light)  # Randomly generate colors\n    back_color = RGB_to_Hex(back_color_)  # Convert to hexadecimal\n\n    # Draw color pictures.\n    w, h = 50, 50\n    img = np.zeros((h, w, 3), np.uint8)\n    cv2.rectangle(img, (0, 0), (w, h), back_color_, thickness=-1)\n\n    return back_color, back_color, img\n\n\ninputs = [gr.Radio([\"light\", \"dark\"], value=\"light\")]\n\noutputs = [\n    gr.ColorPicker(label=\"color\"),\n    gr.Textbox(label=\"hexadecimal color\"),\n    gr.Image(type=\"numpy\", label=\"color picture\"),\n]\n\ntitle = \"Color Generator\"\ndescription = (\n    \"Click the Submit button, and a dark or light color will be randomly generated.\"\n)\n\ndemo = gr.Interface(\n    fn=switch_color,\n    inputs=inputs,\n    outputs=outputs,\n    title=title,\n    description=description,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Code",next_obj:"Dataframe",slug:"color-picker"};a.dataframe={class:null,name:"Dataframe",description:"Accepts or displays 2D input through a spreadsheet-like component for dataframes.",tags:{preprocessing:"passes the uploaded spreadsheet data as a {pandas.DataFrame}, {numpy.array}, {polars.DataFrame}, or {List[List]} depending on `type`",postprocessing:"expects a {pandas.DataFrame}, {pandas.Styler}, {numpy.array}, {polars.DataFrame}, {List[List]}, {List}, a {Dict} with keys `data` (and optionally `headers`), or {str} path to a csv, which is rendered in the spreadsheet.","examples-format":"a {str} filepath to a csv with data, a pandas dataframe, a polars dataframe, or a list of lists (excluding headers) where each sublist is a row of data.",demos:"filter_records, matrix_transpose, tax_calculator, sort_records"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Styler | np.ndarray | pl.DataFrame | list | list[list] | dict | str | Callable | None",doc:"Default value to display in the DataFrame. If a Styler is provided, it will be used to set the displayed value in the DataFrame (e.g. to set precision of numbers) if the `interactive` is False. If a Callable function is provided, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"headers",annotation:"list[str] | None",doc:"List of str header names. If None, no headers are shown.",default:"None"},{name:"row_count",annotation:"int | tuple[int, str]",doc:"Limit number of rows for input and decide whether user can create new rows. The first element of the tuple is an `int`, the row count; the second should be &#x27;fixed&#x27; or &#x27;dynamic&#x27;, the new row behaviour. If an `int` is passed the rows default to &#x27;dynamic&#x27;",default:"(1, 'dynamic')"},{name:"col_count",annotation:"int | tuple[int, str] | None",doc:"Limit number of columns for input and decide whether user can create new columns. The first element of the tuple is an `int`, the number of columns; the second should be &#x27;fixed&#x27; or &#x27;dynamic&#x27;, the new column behaviour. If an `int` is passed the columns default to &#x27;dynamic&#x27;",default:"None"},{name:"datatype",annotation:"str | list[str]",doc:"Datatype of values in sheet. Can be provided per column as a list of strings, or for the entire sheet as a single string. Valid datatypes are &quot;str&quot;, &quot;number&quot;, &quot;bool&quot;, &quot;date&quot;, and &quot;markdown&quot;.",default:"\"str\""},{name:"type",annotation:"Literal[('pandas', 'numpy', 'array', 'polars')]",doc:"Type of value to be returned by component. &quot;pandas&quot; for pandas dataframe, &quot;numpy&quot; for numpy array, &quot;polars&quot; for polars dataframe, or &quot;array&quot; for a Python list of lists.",default:"\"pandas\""},{name:"latex_delimiters",annotation:"list[dict[str, str | bool]] | None",doc:"A list of dicts of the form {&quot;left&quot;: open delimiter (str), &quot;right&quot;: close delimiter (str), &quot;display&quot;: whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ &quot;left&quot;: &quot;$$&quot;, &quot;right&quot;: &quot;$$&quot;, &quot;display&quot;: True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html). Only applies to columns whose datatype is &quot;markdown&quot;.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"height",annotation:"int",doc:"The maximum height of the dataframe, specified in pixels if a number is passed, or in CSS units if a string is passed. If more rows are created than can fit in the height, a scrollbar will appear.",default:"500"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to edit the dataframe; if False, can only be used to display data. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"wrap",annotation:"bool",doc:"If True, the text in table cells will wrap when appropriate. If False and the `column_width` parameter is not set, the column widths will expand based on the cell contents and the table may need to be horizontally scrolled. If `column_width` is set, then any overflow text will be hidden.",default:"False"},{name:"line_breaks",annotation:"bool",doc:"If True (default), will enable Github-flavored Markdown line breaks in chatbot messages. If False, single new lines will be ignored. Only applies for columns of type &quot;markdown.&quot;",default:"True"},{name:"column_widths",annotation:"list[str | int] | None",doc:"An optional list representing the width of each column. The elements of the list should be in the format &quot;100px&quot; (ints are also accepted and converted to pixel values) or &quot;10%&quot;. If not provided, the column widths will be automatically determined based on the content of the cells. Setting this parameter will cause the browser to try to fit the table within the page width.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Dataframe changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataframe",slug:"dataframe-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Dataframe.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataframe",slug:"dataframe-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Dataframe. Uses event data gradio.SelectData to carry `value` referring to the label of the Dataframe, and `selected` to refer to state of the Dataframe. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataframe",slug:"dataframe-select"}],string_shortcuts:[["Dataframe","dataframe","Uses default values"],["Numpy","numpy","Uses type=\"numpy\""],["Matrix","matrix","Uses type=\"array\""],["List","list","Uses type=\"array\", col_count=1"]],demos:[["filter_records","import gradio as gr\n\n\ndef filter_records(records, gender):\n    return records[records[\"gender\"] == gender]\n\n\ndemo = gr.Interface(\n    filter_records,\n    [\n        gr.Dataframe(\n            headers=[\"name\", \"age\", \"gender\"],\n            datatype=[\"str\", \"number\", \"str\"],\n            row_count=5,\n            col_count=(3, \"fixed\"),\n        ),\n        gr.Dropdown([\"M\", \"F\", \"O\"]),\n    ],\n    \"dataframe\",\n    description=\"Enter gender as 'M', 'F', or 'O' for other.\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["matrix_transpose","import numpy as np\n\nimport gradio as gr\n\n\ndef transpose(matrix):\n    return matrix.T\n\n\ndemo = gr.Interface(\n    transpose,\n    gr.Dataframe(type=\"numpy\", datatype=\"number\", row_count=5, col_count=3),\n    \"numpy\",\n    examples=[\n        [np.zeros((3, 3)).tolist()],\n        [np.ones((2, 2)).tolist()],\n        [np.random.randint(0, 10, (3, 10)).tolist()],\n        [np.random.randint(0, 10, (10, 3)).tolist()],\n        [np.random.randint(0, 10, (10, 10)).tolist()],\n    ],\n    cache_examples=False\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["tax_calculator","import gradio as gr\n\ndef tax_calculator(income, marital_status, assets):\n    tax_brackets = [(10, 0), (25, 8), (60, 12), (120, 20), (250, 30)]\n    total_deductible = sum(assets[\"Cost\"])\n    taxable_income = income - total_deductible\n\n    total_tax = 0\n    for bracket, rate in tax_brackets:\n        if taxable_income > bracket:\n            total_tax += (taxable_income - bracket) * rate / 100\n\n    if marital_status == \"Married\":\n        total_tax *= 0.75\n    elif marital_status == \"Divorced\":\n        total_tax *= 0.8\n\n    return round(total_tax)\n\ndemo = gr.Interface(\n    tax_calculator,\n    [\n        \"number\",\n        gr.Radio([\"Single\", \"Married\", \"Divorced\"]),\n        gr.Dataframe(\n            headers=[\"Item\", \"Cost\"],\n            datatype=[\"str\", \"number\"],\n            label=\"Assets Purchased this Year\",\n        ),\n    ],\n    \"number\",\n    examples=[\n        [10000, \"Married\", [[\"Suit\", 5000], [\"Laptop\", 800], [\"Car\", 1800]]],\n        [80000, \"Single\", [[\"Suit\", 800], [\"Watch\", 1800], [\"Car\", 800]]],\n    ],\n)\n\ndemo.launch()\n"],["sort_records","import gradio as gr\nimport os\n\ndef sort_records(records):\n    return records.sort(\"Quantity\")\n\ndemo = gr.Interface(\n    sort_records,\n    gr.Dataframe(\n        headers=[\"Item\", \"Quantity\"],\n        datatype=[\"str\", \"number\"],\n        row_count=3,\n        col_count=(2, \"fixed\"),\n        type=\"polars\"\n    ),\n    \"dataframe\",\n    description=\"Sort by Quantity\",\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"polars_sort.csv\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()"]],parent:"gradio",prev_obj:"ColorPicker",next_obj:"Dataset",slug:"dataframe"};a.dataset={class:null,name:"Dataset",description:"Used to create an output widget for showing datasets. Used to render the examples box.",tags:{preprocessing:"passes the selected sample either as a {list} of data (if type=&quot;value&quot;) or as an {int} index (if type=&quot;index&quot;)",postprocessing:"expects a {list} of {lists} corresponding to the dataset data."},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"label",annotation:"str | None",doc:null,default:"None"},{name:"components",annotation:"list[Component] | list[str]",doc:"Which component types to show in this dataset widget, can be passed in as a list of string names or Components instances. The following components are supported in a Dataset: Audio, Checkbox, CheckboxGroup, ColorPicker, Dataframe, Dropdown, File, HTML, Image, Markdown, Model3D, Number, Radio, Slider, Textbox, TimeSeries, Video"},{name:"samples",annotation:"list[list[Any]] | None",doc:"a nested list of samples. Each sublist within the outer list represents a data sample, and each element within the sublist represents an value for each component",default:"None"},{name:"headers",annotation:"list[str] | None",doc:"Column headers in the Dataset widget, should be the same len as components. If not provided, inferred from component labels",default:"None"},{name:"type",annotation:"Literal[('values', 'index')]",doc:"&#x27;values&#x27; if clicking on a sample should pass the value of the sample, or &quot;index&quot; if it should pass the index of the sample",default:"\"values\""},{name:"samples_per_page",annotation:"int",doc:"how many examples to show per page.",default:"10"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"proxy_url",annotation:"str | None",doc:"The URL of the external Space used to load this component. Set automatically when using `gr.load()`. This should not be set manually.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Dataset is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataset",slug:"dataset-click"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Dataset. Uses event data gradio.SelectData to carry `value` referring to the label of the Dataset, and `selected` to refer to state of the Dataset. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataset",slug:"dataset-select"}],string_shortcuts:[["Dataset","dataset","Uses default values"]],override_signature:"gr.Dataset(components, samples)",parent:"gradio",prev_obj:"Dataframe",next_obj:"Dropdown",slug:"dataset"};a.dropdown={class:null,name:"Dropdown",description:"Creates a dropdown of choices from which entries can be selected.",tags:{preprocessing:"passes the value of the selected dropdown entry as a {str} or its index as an {int} into the function, depending on `type`.",postprocessing:"expects a {str} corresponding to the value of the dropdown entry to be selected.","examples-format":"a {str} representing the drop down value to select.",demos:"sentence_builder, titanic_survival"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"choices",annotation:"list[str | int | float | tuple[str, str | int | float]] | None",doc:"A list of string options to choose from. An option can also be a tuple of the form (name, value), where name is the displayed name of the dropdown choice and value is the value to be passed to the function, or returned by the function.",default:"None"},{name:"value",annotation:"str | int | float | list[str | int | float] | Callable | None",doc:"default value(s) selected in dropdown. If None, no value is selected by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"type",annotation:"Literal[('value', 'index')]",doc:"Type of value to be returned by component. &quot;value&quot; returns the string of the choice selected, &quot;index&quot; returns the index of the choice selected.",default:"\"value\""},{name:"multiselect",annotation:"bool | None",doc:"if True, multiple choices can be selected.",default:"None"},{name:"allow_custom_value",annotation:"bool",doc:"If True, allows user to enter a custom value that is not in the list of choices.",default:"False"},{name:"max_choices",annotation:"int | None",doc:"maximum number of choices that can be selected. If None, no limit is enforced.",default:"None"},{name:"filterable",annotation:"bool",doc:"If True, user will be able to type into the dropdown and filter the choices by typing. Can only be set to False if `allow_custom_value` is False.",default:"True"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, choices in this dropdown will be selectable; if False, selection will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Dropdown changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Dropdown.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Dropdown. Uses event data gradio.SelectData to carry `value` referring to the label of the Dropdown, and `selected` to refer to state of the Dropdown. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-select"},{fn:null,name:"focus",description:"This listener is triggered when the Dropdown is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-focus"},{fn:null,name:"blur",description:"This listener is triggered when the Dropdown is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-blur"}],string_shortcuts:[["Dropdown","dropdown","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Dataset",next_obj:"DuplicateButton",slug:"dropdown"};a.duplicatebutton={class:null,name:"DuplicateButton",description:"Button that triggers a Spaces Duplication, when the demo is on Hugging Face Spaces. Does nothing locally.",tags:{preprocessing:"passes the button value as a {str} into the function",postprocessing:"expects a {str} to be returned from a function, which is set as the label of the button"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Duplicate Space\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"\"sm\""},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed.",default:"None"},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"0"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.DuplicateButton",slug:"duplicate-button-click"}],string_shortcuts:[["DuplicateButton","duplicatebutton","Uses default values"]],parent:"gradio",prev_obj:"Dropdown",next_obj:"File",slug:"duplicate-button"};a.file={class:null,name:"File",description:"Creates a file component that allows uploading generic file (when used as an input) and or displaying generic files (output).",tags:{preprocessing:"passes the uploaded file as a {tempfile._TemporaryFileWrapper} or {List[tempfile._TemporaryFileWrapper]} depending on `file_count` (or a {bytes}/{List[bytes]} depending on `type`)",postprocessing:"expects function to return a {str} path to a file, or {List[str]} consisting of paths to files.","examples-format":"a {str} path to a local file that populates the component.",demos:"zip_to_json, zip_files"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | list[str] | Callable | None",doc:"Default file to display, given as str file path. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"file_count",annotation:"Literal[('single', 'multiple', 'directory')]",doc:"if single, allows user to upload one file. If &quot;multiple&quot;, user uploads multiple files. If &quot;directory&quot;, user uploads all files in selected directory. Return type will be list for each file in case of &quot;multiple&quot; or &quot;directory&quot;.",default:"\"single\""},{name:"file_types",annotation:"list[str] | None",doc:"List of file extensions or types of files to be uploaded (e.g. [&#x27;image&#x27;, &#x27;.json&#x27;, &#x27;.mp4&#x27;]). &quot;file&quot; allows any file to be uploaded, &quot;image&quot; allows only image files to be uploaded, &quot;audio&quot; allows only audio files to be uploaded, &quot;video&quot; allows only video files to be uploaded, &quot;text&quot; allows only text files to be uploaded.",default:"None"},{name:"type",annotation:"Literal[('filepath', 'binary')]",doc:"Type of value to be returned by component. &quot;file&quot; returns a temporary file object with the same base name as the uploaded file, whose full path can be retrieved by file_obj.name, &quot;binary&quot; returns an bytes object.",default:"\"filepath\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"height",annotation:"int | float | None",doc:"The maximum height of the file component, specified in pixels if a number is passed, or in CSS units if a string is passed. If more files are uploaded than can fit in the height, a scrollbar will appear.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a file; if False, can only be used to display files. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the File changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the File. Uses event data gradio.SelectData to carry `value` referring to the label of the File, and `selected` to refer to state of the File. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-select"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the File using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-clear"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the File.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-upload"}],string_shortcuts:[["File","file","Uses default values"],["Files","files","Uses file_count=\"multiple\""]],demos:[["zip_to_json","from zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["zip_files","import os\nfrom zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_files(files):\n    with ZipFile(\"tmp.zip\", \"w\") as zipObj:\n        for idx, file in enumerate(files):\n            zipObj.write(file.name, file.name.split(\"/\")[-1])\n    return \"tmp.zip\"\n\ndemo = gr.Interface(\n    zip_files,\n    gr.File(file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\"]),\n    \"file\",\n    examples=[[[os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\")]]], \n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"DuplicateButton",next_obj:"FileExplorer",slug:"file"};a.fileexplorer={class:null,name:"FileExplorer",description:"Creates a file explorer component that allows users to browse and select files on the machine hosting the Gradio app.",tags:{preprocessing:"passes the selected file or directory as a {str} path (relative to root) or {list[str}} depending on `file_count`",postprocessing:"expects function to return a {str} path to a file, or {List[str]} consisting of paths to files.","examples-format":"a {str} path to a local file that populates the component.",demos:"zip_to_json, zip_files"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"glob",annotation:"str",doc:"The glob-style pattern used to select which files to display, e.g. &quot;*&quot; to match all files, &quot;*.png&quot; to match all .png files, &quot;**/*.txt&quot; to match any .txt file in any subdirectory, etc. The default value matches all files and folders recursively. See the Python glob documentation at https://docs.python.org/3/library/glob.html for more information.",default:"\"**/*.*\""},{name:"value",annotation:"str | list[str] | Callable | None",doc:"The file (or list of files, depending on the `file_count` parameter) to show as &quot;selected&quot; when the component is first loaded. If a callable is provided, it will be called when the app loads to set the initial value of the component. If not provided, no files are shown as selected.",default:"None"},{name:"file_count",annotation:"Literal[('single', 'multiple')]",doc:"Whether to allow single or multiple files to be selected. If &quot;single&quot;, the component will return a single absolute file path as a string. If &quot;multiple&quot;, the component will return a list of absolute file paths as a list of strings.",default:"\"multiple\""},{name:"root_dir",annotation:"str | Path",doc:"Path to root directory to select files from. If not provided, defaults to current working directory.",default:"\".\""},{name:"ignore_glob",annotation:"str | None",doc:"The glob-tyle pattern that will be used to exclude files from the list. For example, &quot;*.py&quot; will exclude all .py files from the list. See the Python glob documentation at https://docs.python.org/3/library/glob.html for more information.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"height",annotation:"int | float | None",doc:"The maximum height of the file component, specified in pixels if a number is passed, or in CSS units if a string is passed. If more files are uploaded than can fit in the height, a scrollbar will appear.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a file; if False, can only be used to display files. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"root",annotation:"None",doc:null,default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.FileExplorer",slug:"file-explorer-change"}],string_shortcuts:[["FileExplorer","fileexplorer","Uses default values"]],demos:[["zip_to_json","from zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["zip_files","import os\nfrom zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_files(files):\n    with ZipFile(\"tmp.zip\", \"w\") as zipObj:\n        for idx, file in enumerate(files):\n            zipObj.write(file.name, file.name.split(\"/\")[-1])\n    return \"tmp.zip\"\n\ndemo = gr.Interface(\n    zip_files,\n    gr.File(file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\"]),\n    \"file\",\n    examples=[[[os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\")]]], \n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"File",next_obj:"Gallery",slug:"file-explorer"};a.gallery={class:null,name:"Gallery",description:"Used to display a list of images as a gallery that can be scrolled through. \u003Cbr>",tags:{preprocessing:"A list of (image, caption) tuples. Each image is a filepath, numpy array or PIL.image depending on the `type` parameter. {List[tuple[str | PIL.Image | numpy.array, str | None]]}.",postprocessing:"expects a list of images in any format, {List[numpy.array | PIL.Image | str | pathlib.Path]}, or a {List} of (image, {str} caption) tuples and displays them.",demos:"fake_gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"list[np.ndarray | _Image.Image | str | Path | tuple] | Callable | None",doc:"List of images to display in the gallery by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"columns",annotation:"int | tuple | None",doc:"Represents the number of images that should be shown in one row, for each of the six standard screen sizes (&lt;576px, &lt;768px, &lt;992px, &lt;1200px, &lt;1400px, &gt;1400px). If fewer than 6 are given then the last will be used for all subsequent breakpoints",default:"2"},{name:"rows",annotation:"int | tuple | None",doc:"Represents the number of rows in the image grid, for each of the six standard screen sizes (&lt;576px, &lt;768px, &lt;992px, &lt;1200px, &lt;1400px, &gt;1400px). If fewer than 6 are given then the last will be used for all subsequent breakpoints",default:"None"},{name:"height",annotation:"int | float | None",doc:"The height of the gallery component, specified in pixels if a number is passed, or in CSS units if a string is passed. If more images are displayed than can fit in the height, a scrollbar will appear.",default:"None"},{name:"allow_preview",annotation:"bool",doc:"If True, images in the gallery will be enlarged when they are clicked. Default is True.",default:"True"},{name:"preview",annotation:"bool | None",doc:"If True, Gallery will start in preview mode, which shows all of the images as thumbnails and allows the user to click on them to view them in full size. Only works if allow_preview is True.",default:"None"},{name:"selected_index",annotation:"int | None",doc:"The index of the image that should be initially selected. If None, no image will be selected at start. If provided, will set Gallery to preview mode unless allow_preview is set to False.",default:"None"},{name:"object_fit",annotation:"Literal[('contain', 'cover', 'fill', 'none', 'scale-down')] | None",doc:"CSS object-fit property for the thumbnail images in the gallery. Can be &quot;contain&quot;, &quot;cover&quot;, &quot;fill&quot;, &quot;none&quot;, or &quot;scale-down&quot;.",default:"None"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"show_download_button",annotation:"bool | None",doc:"If True, will show a download button in the corner of the selected image. If False, the icon does not appear. Default is True.",default:"True"},{name:"interactive",annotation:"bool | None",doc:"If True, the gallery will be interactive, allowing the user to upload images. If False, the gallery will be static. Default is True.",default:"None"},{name:"type",annotation:"Literal[('numpy', 'pil', 'filepath')]",doc:"The format the image is converted to before being passed into the prediction function. &quot;numpy&quot; converts the image to a numpy array with shape (height, width, 3) and values from 0 to 255, &quot;pil&quot; converts the image to a PIL image object, &quot;filepath&quot; passes a str path to a temporary file containing the image. If the image is SVG, the `type` is ignored and the filepath of the SVG is returned.",default:"\"filepath\""}],returns:{annotation:null},example:null,fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Gallery. Uses event data gradio.SelectData to carry `value` referring to the label of the Gallery, and `selected` to refer to state of the Gallery. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Gallery",slug:"gallery-select"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Gallery.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Gallery",slug:"gallery-upload"},{fn:null,name:"change",description:"Triggered when the value of the Gallery changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Gallery",slug:"gallery-change"}],string_shortcuts:[["Gallery","gallery","Uses default values"]],demos:[["fake_gan","# This demo needs to be run from the repo folder.\n# python demo/fake_gan/run.py\nimport random\n\nimport gradio as gr\n\n\ndef fake_gan():\n    images = [\n        (random.choice(\n            [\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1151ce9f4b2043de0d2e3b7826127998.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-116b5e92936b766b7fdfc242649337f7.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1163530ca19b5cebe1b002b8ec67b6fc.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1116395d6e6a6581eef8b8038f4c8e55.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-11319be65db395d0e8e6855d18ddcef0.jpg\",\n            ]\n        ), f\"label {i}\")\n        for i in range(3)\n    ]\n    return images\n\n\nwith gr.Blocks() as demo:\n    gallery = gr.Gallery(\n        label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n    , columns=[3], rows=[1], object_fit=\"contain\", height=\"auto\")\n    btn = gr.Button(\"Generate images\", scale=0)\n\n    btn.click(fake_gan, None, gallery)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"FileExplorer",next_obj:"HTML",slug:"gallery"};a.html={class:null,name:"HTML",description:"Used to display arbitrary HTML output. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a valid HTML {str}.",demos:"text_analysis",guides:"key-features"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable",doc:"Default value. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"\""},{name:"label",annotation:"str | None",doc:"The label for this component. Is used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"This parameter has no effect.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the HTML changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.HTML",slug:"html-change"}],string_shortcuts:[["HTML","html","Uses default values"]],demos:[["text_analysis","import gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"\u003Cdiv style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"\u003C/div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n"]],guides:[{name:"key-features",category:"getting-started",pretty_category:"Getting Started",guide_index:2,absolute_index:1,pretty_name:"Key Features",content:"# Key Features\n\nLet's go through some of the key features of Gradio. This guide is intended to be a high-level overview of various things that you should be aware of as you build your demo. Where appropriate, we link to more detailed guides on specific topics.\n\n1. [Components](#components)\n2. [Queuing](#queuing)\n3. [Streaming outputs](#streaming-outputs)\n4. [Streaming inputs](#streaming-inputs)\n5. [Alert modals](#alert-modals)\n6. [Styling](#styling)\n7. [Progress bars](#progress-bars)\n8. [Batch functions](#batch-functions)\n\n## Components\n\nGradio includes more than 30 pre-built components (as well as many user-built _custom components_) that can be used as inputs or outputs in your demo with a single line of code. These components correspond to common data types in machine learning and data science, e.g. the `gr.Image` component is designed to handle input or output images, the `gr.Label` component displays classification labels and probabilities, the `gr.Plot` component displays various kinds of plots, and so on.\n\nEach component includes various constructor attributes that control the properties of the component. For example, you can control the number of lines in a `gr.Textbox` using the `lines` argument (which takes a positive integer) in its constructor. Or you can control the way that a user can provide an image in the `gr.Image` component using the `sources` parameter (which takes a list like `[\"webcam\", \"upload\"]`).\n\n**Static and Interactive Components**\n\nEvery component has a _static_ version that is designed to *display* data, and most components also have an _interactive_ version designed to let users input or modify the data. Typically, you don't need to think about this distinction, because when you build a Gradio demo, Gradio automatically figures out whether the component should be static or interactive based on whether it is being used as an input or output. However, you can set this manually using the `interactive` argument that every component supports.\n\n**Preprocessing and Postprocessing**\n\nWhen a component is used as an input, Gradio automatically handles the _preprocessing_ needed to convert the data from a type sent by the user's browser (such as an uploaded image) to a form that can be accepted by your function (such as a `numpy` array).\n\n\nSimilarly, when a component is used as an output, Gradio automatically handles the _postprocessing_ needed to convert the data from what is returned by your function (such as a list of image paths) to a form that can be displayed in the user's browser (a gallery of images).\n\nConsider an example demo with three input components (`gr.Textbox`, `gr.Number`, and `gr.Image`) and two outputs (`gr.Number` and `gr.Gallery`) that serve as a UI for your image-to-image generation model. Below is a diagram of what our preprocessing will send to the model and what our postprocessing will require from it.\n\n![](https://github.com/gradio-app/gradio/blob/main/guides/assets/dataflow.svg?raw=true)\n\nIn this image, the following preprocessing steps happen to send the data from the browser to your function:\n\n* The text in the textbox is converted to a Python `str` (essentially no preprocessing)\n* The number in the number input in converted to a Python `float` (essentially no preprocessing)\n* Most importantly, ihe image supplied by the user is converted to a `numpy.array` representation of the RGB values in the image\n\nImages are converted to NumPy arrays because they are a common format for machine learning workflows. You can control the _preprocessing_ using the component's parameters when constructing the component. For example, if you instantiate the `Image` component with the following parameters, it will preprocess the image to the `PIL` format instead:\n\n```py\nimg = gr.Image(type=\"pil\")\n```\n\nPostprocessing is even simpler! Gradio automatically recognizes the format of the returned data (e.g. does the user's function return a `numpy` array or a `str` filepath for the `gr.Image` component?) and postprocesses it appropriately into a format that can be displayed by the browser.\n\nSo in the image above, the following postprocessing steps happen to send the data returned from a user's function to the browser:\n\n* The `float` is displayed as a number and displayed directly to the user\n* The list of string filepaths (`list[str]`) is interpreted as a list of image filepaths and displayed as a gallery in the browser\n\nTake a look at the [Docs](https://gradio.app/docs) to see all the parameters for each Gradio component.\n\n## Queuing\n\nEvery Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. You can configure the queue by using `queue()` method which is supported by the `gr.Interface`, `gr.Blocks`, and `gr.ChatInterface` classes. \n\nFor example, you can control the number of requests processed at a single time by setting the `default_concurrency_limit` parameter of `queue()`, e.g.\n\n```python\ndemo = gr.Interface(...).queue(default_concurrency_limit=5)\ndemo.launch()\n```\n\nThis limits the number of requests processed for this event listener at a single time to 5. By default, the `default_concurrency_limit` is actually set to `1`, which means that when many users are using your app, only a single user's request will be processed at a time. This is because many machine learning functions consume a significant amount of memory and so it is only suitable to have a single user using the demo at a time. However, you can change this parameter in your demo easily.\n\nSee the [docs on queueing](/docs/interface#interface-queue) for more details on configuring the queuing parameters.\n\n## Streaming outputs\n\nIn some cases, you may want to stream a sequence of outputs rather than show a single output at once. For example, you might have an image generation model and you want to show the image that is generated at each step, leading up to the final image. Or you might have a chatbot which streams its response one token at a time instead of returning it all at once.\n\nIn such cases, you can supply a **generator** function into Gradio instead of a regular function. Creating generators in Python is very simple: instead of a single `return` value, a function should `yield` a series of values instead. Usually the `yield` statement is put in some kind of loop. Here's an example of an generator that simply counts up to a given number:\n\n```python\ndef my_generator(x):\n    for i in range(x):\n        yield i\n```\n\nYou supply a generator into Gradio the same way as you would a regular function. For example, here's a a (fake) image generation model that generates noise for several steps before outputting an image using the `gr.Interface` class:\n\n```python\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef fake_diffusion(steps):\n    for i in range(steps):\n        time.sleep(1)\n        image = np.random.random((600, 600, 3))\n        yield image\n    image = np.ones((1000,1000,3), np.uint8)\n    image[:] = [255, 124, 0]\n    yield image\n\n\ndemo = gr.Interface(fake_diffusion, inputs=gr.Slider(1, 10, 3), outputs=\"image\")\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/fake_diffusion'>\u003C/gradio-app>\n\nNote that we've added a `time.sleep(1)` in the iterator to create an artificial pause between steps so that you are able to observe the steps of the iterator (in a real image generation model, this probably wouldn't be necessary).\n\n## Streaming inputs\n\nSimilarly, Gradio can handle streaming inputs, e.g. a live audio stream that can gets transcribed to text in real time, or an image generation model that reruns every time a user types a letter in a textbox. This is covered in more details in our guide on building [reactive Interfaces](/guides/reactive-interfaces). \n\n## Alert modals\n\nYou may wish to raise alerts to the user. To do so, raise a `gr.Error(\"custom message\")` to display an error message. You can also issue `gr.Warning(\"message\")` and `gr.Info(\"message\")` by having them as standalone lines in your function, which will immediately display modals while continuing the execution of your function. Queueing needs to be enabled for this to work.\n\nNote below how the `gr.Error` has to be raised, while the `gr.Warning` and `gr.Info` are single lines.\n\n```python\ndef start_process(name):\n    gr.Info(\"Starting process\")\n    if name is None:\n        gr.Warning(\"Name is empty\")\n    ...\n    if success == False:\n        raise gr.Error(\"Process failed\")\n```\n\n\n\n## Styling\n\nGradio themes are the easiest way to customize the look and feel of your app. You can choose from a variety of themes, or create your own. To do so, pass the `theme=` kwarg to the `Interface` constructor. For example:\n\n```python\ndemo = gr.Interface(..., theme=gr.themes.Monochrome())\n```\n\nGradio comes with a set of prebuilt themes which you can load from `gr.themes.*`. You can extend these themes or create your own themes from scratch - see the [theming guide](https://gradio.app/guides/theming-guide) for more details.\n\nFor additional styling ability, you can pass any CSS (as well as custom JavaScript) to your Gradio application. This is discussed in more detail in our [custom JS and CSS guide](/guides/custom-CSS-and-JS).\n\n\n## Progress bars\n\nGradio supports the ability to create custom Progress Bars so that you have customizability and control over the progress update that you show to the user. In order to enable this, simply add an argument to your method that has a default value of a `gr.Progress` instance. Then you can update the progress levels by calling this instance directly with a float between 0 and 1, or using the `tqdm()` method of the `Progress` instance to track progress over an iterable, as shown below.\n\n```python\nimport gradio as gr\nimport time\n\ndef slowly_reverse(word, progress=gr.Progress()):\n    progress(0, desc=\"Starting\")\n    time.sleep(1)\n    progress(0.05)\n    new_string = \"\"\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\n        time.sleep(0.25)\n        new_string = letter + new_string\n    return new_string\n\ndemo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/progress_simple'>\u003C/gradio-app>\n\nIf you use the `tqdm` library, you can even report progress updates automatically from any `tqdm.tqdm` that already exists within your function by setting the default argument as `gr.Progress(track_tqdm=True)`!\n\n## Batch functions\n\nGradio supports the ability to pass _batch_ functions. Batch functions are just\nfunctions which take in a list of inputs and return a list of predictions.\n\nFor example, here is a batched function that takes in two lists of inputs (a list of\nwords and a list of ints), and returns a list of trimmed words as output:\n\n```py\nimport time\n\ndef trim_words(words, lens):\n    trimmed_words = []\n    time.sleep(5)\n    for w, l in zip(words, lens):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n```\n\nThe advantage of using batched functions is that if you enable queuing, the Gradio server can automatically _batch_ incoming requests and process them in parallel,\npotentially speeding up your demo. Here's what the Gradio code looks like (notice the `batch=True` and `max_batch_size=16`)\n\nWith the `gr.Interface` class:\n\n```python\ndemo = gr.Interface(\n    fn=trim_words, \n    inputs=[\"textbox\", \"number\"], \n    outputs=[\"output\"],\n    batch=True, \n    max_batch_size=16\n)\n\ndemo.launch()\n```\n\nWith the `gr.Blocks` class:\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        word = gr.Textbox(label=\"word\")\n        leng = gr.Number(label=\"leng\")\n        output = gr.Textbox(label=\"Output\")\n    with gr.Row():\n        run = gr.Button()\n\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\n\ndemo.launch()\n```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference time of 5 seconds), instead of each request being processed separately (for a total\ninference time of 80 seconds). Many Hugging Face `transformers` and `diffusers` models work very naturally with Gradio's batch mode: here's [an example demo using diffusers to\ngenerate images in batches](https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.py)\n\n\n",tags:[],spaces:[],url:"/guides/key-features/",contributor:null}],parent:"gradio",prev_obj:"Gallery",next_obj:"HighlightedText",slug:"html"};a.highlightedtext={class:null,name:"HighlightedText",description:"Displays text that contains spans that are highlighted by category or numerical value. \u003Cbr>",tags:{preprocessing:"passes a list of tuples as a {List[Tuple[str, float | str | None]]]} into the function. If no labels are provided, the text will be displayed as a single span.",postprocessing:"expects a {List[Tuple[str, float | str]]]} consisting of spans of text and their associated labels, or a {Dict} with two keys: (1) &quot;text&quot; whose value is the complete text, and (2) &quot;entities&quot;, which is a list of dictionaries, each of which have the keys: &quot;entity&quot; (consisting of the entity label, can alternatively be called &quot;entity_group&quot;), &quot;start&quot; (the character index where the label starts), and &quot;end&quot; (the character index where the label ends). Entities should not overlap.",demos:"diff_texts, text_analysis",guides:"named-entity-recognition"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"list[tuple[str, str | float | None]] | dict | Callable | None",doc:"Default value to show. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"color_map",annotation:"dict[str, str] | None",doc:"A dictionary mapping labels to colors. The colors may be specified as hex codes or by their names. For example: {&quot;person&quot;: &quot;red&quot;, &quot;location&quot;: &quot;#FFEE22&quot;}",default:"None"},{name:"show_legend",annotation:"bool",doc:"whether to show span categories in a separate legend or inline.",default:"False"},{name:"combine_adjacent",annotation:"bool",doc:"If True, will merge the labels of adjacent tokens belonging to the same category.",default:"False"},{name:"adjacent_separator",annotation:"str",doc:"Specifies the separator to be used between tokens if combine_adjacent is True.",default:"\"\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"interactive",annotation:"bool | None",doc:"If True, the component will be editable, and allow user to select spans of text and label them.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the HighlightedText changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.HighlightedText",slug:"highlighted-text-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the HighlightedText. Uses event data gradio.SelectData to carry `value` referring to the label of the HighlightedText, and `selected` to refer to state of the HighlightedText. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.HighlightedText",slug:"highlighted-text-select"}],string_shortcuts:[["HighlightedText","highlightedtext","Uses default values"]],demos:[["diff_texts","from difflib import Differ\n\nimport gradio as gr\n\n\ndef diff_texts(text1, text2):\n    d = Differ()\n    return [\n        (token[2:], token[0] if token[0] != \" \" else None)\n        for token in d.compare(text1, text2)\n    ]\n\n\ndemo = gr.Interface(\n    diff_texts,\n    [\n        gr.Textbox(\n            label=\"Text 1\",\n            info=\"Initial text\",\n            lines=3,\n            value=\"The quick brown fox jumped over the lazy dogs.\",\n        ),\n        gr.Textbox(\n            label=\"Text 2\",\n            info=\"Text to compare\",\n            lines=3,\n            value=\"The fast brown fox jumps over lazy dogs.\",\n        ),\n    ],\n    gr.HighlightedText(\n        label=\"Diff\",\n        combine_adjacent=True,\n        show_legend=True,\n        color_map={\"+\": \"red\", \"-\": \"green\"}),\n    theme=gr.themes.Base()\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["text_analysis","import gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"\u003Cdiv style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"\u003C/div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n"]],guides:[{name:"named-entity-recognition",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:48,pretty_name:"Named Entity Recognition",content:"# Named-Entity Recognition\n\n\n\n\n## Introduction\n\nNamed-entity recognition (NER), also known as token classification or text tagging, is the task of taking a sentence and classifying every word (or \"token\") into different categories, such as names of people or names of locations, or different parts of speech.\n\nFor example, given the sentence:\n\n> Does Chicago have any Pakistani restaurants?\n\nA named-entity recognition algorithm may identify:\n\n- \"Chicago\" as a **location**\n- \"Pakistani\" as an **ethnicity**\n\nand so on.\n\nUsing `gradio` (specifically the `HighlightedText` component), you can easily build a web demo of your NER model and share that with the rest of your team.\n\nHere is an example of a demo that you'll be able to build:\n\n\u003Cgradio-app space='gradio/ner_pipeline'>\u003C/gradio-app>\n\nThis tutorial will show how to take a pretrained NER model and deploy it with a Gradio interface. We will show two different ways to use the `HighlightedText` component -- depending on your NER model, either of these two ways may be easier to learn!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained named-entity recognition model. You can use your own, while in this tutorial, we will use one from the `transformers` library.\n\n### Approach 1: List of Entity Dictionaries\n\nMany named-entity recognition models output a list of dictionaries. Each dictionary consists of an _entity_, a \"start\" index, and an \"end\" index. This is, for example, how NER models in the `transformers` library operate:\n\n```py\nfrom transformers import pipeline\nner_pipeline = pipeline(\"ner\")\nner_pipeline(\"Does Chicago have any Pakistani restaurants\")\n```\n\nOutput:\n\n```bash\n[{'entity': 'I-LOC',\n  'score': 0.9988978,\n  'index': 2,\n  'word': 'Chicago',\n  'start': 5,\n  'end': 12},\n {'entity': 'I-MISC',\n  'score': 0.9958592,\n  'index': 5,\n  'word': 'Pakistani',\n  'start': 22,\n  'end': 31}]\n```\n\nIf you have such a model, it is very easy to hook it up to Gradio's `HighlightedText` component. All you need to do is pass in this **list of entities**, along with the **original text** to the model, together as dictionary, with the keys being `\"entities\"` and `\"text\"` respectively.\n\nHere is a complete example:\n\n```python\nfrom transformers import pipeline\n\nimport gradio as gr\n\nner_pipeline = pipeline(\"ner\")\n\nexamples = [\n    \"Does Chicago have any stores and does Joe live here?\",\n]\n\ndef ner(text):\n    output = ner_pipeline(text)\n    return {\"text\": text, \"entities\": output}    \n\ndemo = gr.Interface(ner,\n             gr.Textbox(placeholder=\"Enter sentence here...\"), \n             gr.HighlightedText(),\n             examples=examples)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/ner_pipeline'>\u003C/gradio-app>\n\n### Approach 2: List of Tuples\n\nAn alternative way to pass data into the `HighlightedText` component is a list of tuples. The first element of each tuple should be the word or words that are being classified into a particular entity. The second element should be the entity label (or `None` if they should be unlabeled). The `HighlightedText` component automatically strings together the words and labels to display the entities.\n\nIn some cases, this can be easier than the first approach. Here is a demo showing this approach using Spacy's parts-of-speech tagger:\n\n```python\nimport gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"\u003Cdiv style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"\u003C/div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/text_analysis'>\u003C/gradio-app>\n\n---\n\nAnd you're done! That's all you need to know to build a web-based GUI for your NER model.\n\nFun tip: you can share your NER demo instantly with others simply by setting `share=True` in `launch()`.\n",tags:["NER","TEXT","HIGHLIGHT"],spaces:["https://huggingface.co/spaces/rajistics/biobert_ner_demo","https://huggingface.co/spaces/abidlabs/ner","https://huggingface.co/spaces/rajistics/Financial_Analyst_AI"],url:"/guides/named-entity-recognition/",contributor:null}],parent:"gradio",prev_obj:"HTML",next_obj:"Image",slug:"highlighted-text"};a.image={class:null,name:"Image",description:"Creates an image component that can be used to upload images (as an input) or display images (as an output).",tags:{preprocessing:"passes the uploaded image as a {numpy.array}, {PIL.Image} or {str} filepath depending on `type`. For SVGs, the `type` parameter is ignored and the filepath of the SVG is returned.",postprocessing:"expects a {numpy.array}, {PIL.Image} or {str} or {pathlib.Path} filepath to an image and displays the image.","examples-format":"a {str} local filepath or URL to an image.",demos:"image_mod, image_mod_default_image",guides:"image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers, create-your-own-friends-with-a-gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | _Image.Image | np.ndarray | None",doc:"A PIL Image, numpy array, path or URL for the default value that Image component is going to take. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the displayed image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the displayed image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"image_mode",annotation:"Literal[('1', 'L', 'P', 'RGB', 'RGBA', 'CMYK', 'YCbCr', 'LAB', 'HSV', 'I', 'F')]",doc:"&quot;RGB&quot; if color, or &quot;L&quot; if black and white. See https://pillow.readthedocs.io/en/stable/handbook/concepts.html for other supported image modes and their meaning.",default:"\"RGB\""},{name:"sources",annotation:"list[Literal[('upload', 'webcam', 'clipboard')]] | None",doc:"List of sources for the image. &quot;upload&quot; creates a box where user can drop an image file, &quot;webcam&quot; allows user to take snapshot from their webcam, &quot;clipboard&quot; allows users to paste an image from the clipboard. If None, defaults to [&quot;upload&quot;, &quot;webcam&quot;, &quot;clipboard&quot;] if streaming is False, otherwise defaults to [&quot;webcam&quot;].",default:"None"},{name:"type",annotation:"Literal[('numpy', 'pil', 'filepath')]",doc:"The format the image is converted before being passed into the prediction function. &quot;numpy&quot; converts the image to a numpy array with shape (height, width, 3) and values from 0 to 255, &quot;pil&quot; converts the image to a PIL image object, &quot;filepath&quot; passes a str path to a temporary file containing the image. If the image is SVG, the `type` is ignored and the filepath of the SVG is returned.",default:"\"numpy\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"show_download_button",annotation:"bool",doc:"If True, will display button to download image.",default:"True"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload and edit an image; if False, can only be used to display images. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"streaming",annotation:"bool",doc:"If True when used in a `live` interface, will automatically stream webcam feed. Only valid is source is &#x27;webcam&#x27;.",default:"False"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"mirror_webcam",annotation:"bool",doc:"If True webcam will be mirrored. Default is True.",default:"True"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"clear",description:"This listener is triggered when the user clears the Image using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-clear"},{fn:null,name:"change",description:"Triggered when the value of the Image changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-change"},{fn:null,name:"stream",description:"This listener is triggered when the user streams the Image.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"hidden\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-stream"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Image. Uses event data gradio.SelectData to carry `value` referring to the label of the Image, and `selected` to refer to state of the Image. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-select"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Image.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-upload"}],string_shortcuts:[["Image","image","Uses default values"]],demos:[["image_mod","import gradio as gr\nimport os\n\n\ndef image_mod(image):\n    return image.rotate(45)\n\n\ndemo = gr.Interface(\n    image_mod,\n    gr.Image(type=\"pil\"),\n    \"image\",\n    flagging_options=[\"blurry\", \"incorrect\", \"other\"],\n    examples=[\n        os.path.join(os.path.dirname(__file__), \"images/cheetah1.jpg\"),\n        os.path.join(os.path.dirname(__file__), \"images/lion.jpg\"),\n        os.path.join(os.path.dirname(__file__), \"images/logo.png\"),\n        os.path.join(os.path.dirname(__file__), \"images/tower.jpg\"),\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["image_mod_default_image","import gradio as gr\nimport os\n\n\ndef image_mod(image):\n    return image.rotate(45)\n\n\ncheetah = os.path.join(os.path.dirname(__file__), \"images/cheetah1.jpg\")\n\ndemo = gr.Interface(image_mod, gr.Image(type=\"pil\", value=cheetah), \"image\",\n    flagging_options=[\"blurry\", \"incorrect\", \"other\"], examples=[\n        os.path.join(os.path.dirname(__file__), \"images/lion.jpg\"),\n        os.path.join(os.path.dirname(__file__), \"images/logo.png\")\n        ])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"image-classification-in-pytorch",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:29,pretty_name:"Image Classification In Pytorch",content:"# Image Classification in PyTorch\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own.\n\n```python\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\nBecause we will be using the model for inference, we have called the `.eval()` method.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `PIL` image\n\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image.\n\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/pytorch-image-classifier\">\n\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","RESNET","PYTORCH"],spaces:["https://huggingface.co/spaces/abidlabs/pytorch-image-classifier","https://huggingface.co/spaces/pytorch/ResNet","https://huggingface.co/spaces/pytorch/ResNext","https://huggingface.co/spaces/pytorch/SqueezeNet"],url:"/guides/image-classification-in-pytorch/",contributor:null},{name:"image-classification-in-tensorflow",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:30,pretty_name:"Image Classification In Tensorflow",content:"# Image Classification in TensorFlow and Keras\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own.\n\n```python\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\nThis line automatically downloads the MobileNet model and weights using the Keras library.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `numpy` array\n\nThen, the function adds a batch dimension, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(shape=(224, 224)),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/keras-image-classifier\">\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","MOBILENET","TENSORFLOW"],spaces:["https://huggingface.co/spaces/abidlabs/keras-image-classifier"],url:"/guides/image-classification-in-tensorflow/",contributor:null},{name:"image-classification-with-vision-transformers",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:31,pretty_name:"Image Classification With Vision Transformers",content:"# Image Classification with Vision Transformers\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control.\n\nState-of-the-art image classifiers are based on the _transformers_ architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started).\n\n## Step 1 ‚Äî Choosing a Vision Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks.\n\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\n\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at a resolution of 224x224 pixels. We will use this model for our demo.\n\n## Step 2 ‚Äî Loading the Vision Transformer Model with Gradio\n\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing.\nAll of these are automatically inferred from the model tags.\n\nBesides the import statement, it only takes a single line of Python to load and launch the demo.\n\nWe use the `gr.Interface.load()` method and pass in the path to the model including the `huggingface/` to designate that it is from the Hugging Face Hub.\n\n```python\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples.\n\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a human-interpretable prediction. Try uploading your own image!\n\n\u003Cgradio-app space=\"gradio/vision-transformer\">\n\n---\n\nAnd you're done! In one line of code, you have built a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","TRANSFORMERS","HUB"],spaces:["https://huggingface.co/spaces/abidlabs/vision-transformer"],url:"/guides/image-classification-with-vision-transformers/",contributor:null},{name:"create-your-own-friends-with-a-gan",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:44,pretty_name:"Create Your Own Friends With A Gan",content:"# Create Your Own Friends with a GAN\n\n\n\n\n\n\n## Introduction\n\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we'll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\n\nGenerative Adversarial Networks, often known just as _GANs_, are a specific class of deep-learning models that are designed to learn from an input dataset to create (_generate!_) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\n\nToday we'll briefly look at the high-level intuition behind GANs, and then we'll build a small demo around a pre-trained GAN to see what all the fuss is about. Here's a [peek](https://nimaboscarino-cryptopunks.hf.space) at what we're going to be putting together.\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\n\n## GANs: a very brief introduction\n\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the _generator_, is responsible for generating images. The other network, the _discriminator_, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\n\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (_adversarial!_) relationship, the images that get generated improve to the point where they become indistinguishable to human eyes!\n\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\n\n## Step 1 ‚Äî Create the Generator model\n\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\n\n```python\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\n\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n## Step 2 ‚Äî Defining a `predict` function\n\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it's common to pass random noise into our model as the input, so we'll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`'s `save_image` function to save the output of the model as a `png` file, and return the file name:\n\n```python\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWe're giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We'll then be able to reproduce punks if we want to see them again by passing in the same seed.\n\n_Note!_ Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we'll start by generating 4 punks at a time.\n\n## Step 3 ‚Äî Creating a Gradio interface\n\nAt this point you can even run the code you have with `predict(\u003CSOME_NUMBER>)`, and you'll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we'll build out a simple interface with Gradio. Our goals here are to:\n\n- Set a slider input so users can choose the \"seed\" value\n- Use an image component for our output to showcase the generated punks\n- Use our `predict()` to take the seed and generate the images\n\nWith `gr.Interface()`, we can define all of that with a single function call:\n\n```python\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n\n## Step 4 ‚Äî Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\n\n```python\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\n\n```python\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWhen you relaunch your interface, you should see a second slider that'll let you control the number of punks!\n\n## Step 5 - Polishing it up\n\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ‚ú®\n\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\n\n```python\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we've listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\n\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens üëÄ `article` will also accept HTML, as [explored in a previous guide](/guides/key-features/#descriptive-content)!\n\nWhen you're all done, you may end up with something like [this](https://nimaboscarino-cryptopunks.hf.space).\n\nFor reference, here is our full code:\n\n```python\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n---\n\nCongratulations! You've built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making even more awesome demos ü§ó\n",tags:["GAN","IMAGE","HUB"],spaces:["https://huggingface.co/spaces/NimaBoscarino/cryptopunks","https://huggingface.co/spaces/nateraw/cryptopunks-generator"],url:"/guides/create-your-own-friends-with-a-gan/",contributor:"\u003Ca href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino\u003C/a> and \u003Ca href=\"https://huggingface.co/nateraw\">Nate Raw\u003C/a>"}],parent:"gradio",prev_obj:"HighlightedText",next_obj:"ImageEditor",slug:"image"};a.imageeditor={class:null,name:"ImageEditor",description:"Creates an image component that can be used to upload and edit images (as an input) or display images (as an output).",tags:{preprocessing:"passes the uploaded images as a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` are images, while `layers` is a list of images. The images are of type PIL.Image, np.array, or str filepath, depending on the `type` parameter.",postprocessing:"expects a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` should be images or None, while `layers` should be a list of images. Images can be of type PIL.Image, np.array, or str filepath/URL. Or, the value can be simply a single image, in which case it will be used as the background.","examples-format":"a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` should be strings or None, while `layers` should be a list of strings. The image corresponding to `composite`, if not None, is used as the example image. Otherwise, the image corresonding to `background` is used. The strings should be filepaths or URLs. Or, the value can be simply a single string filepath/URL to an image, which is used directly as the example image.",demos:"image_editor"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"EditorValue | ImageType | None",doc:"Optional initial image(s) to populate the image editor. Should be a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` should be images or None, while `layers` should be a list of images. Images can be of type PIL.Image, np.array, or str filepath/URL. Or, the value can be a callable, in which case the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the displayed images, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the displayed images, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"image_mode",annotation:"Literal[('1', 'L', 'P', 'RGB', 'RGBA', 'CMYK', 'YCbCr', 'LAB', 'HSV', 'I', 'F')]",doc:"&quot;RGB&quot; if color, or &quot;L&quot; if black and white. See https://pillow.readthedocs.io/en/stable/handbook/concepts.html for other supported image modes and their meaning.",default:"\"RGBA\""},{name:"sources",annotation:"Iterable[Literal[('upload', 'webcam', 'clipboard')]]",doc:"List of sources that can be used to set the background image. &quot;upload&quot; creates a box where user can drop an image file, &quot;webcam&quot; allows user to take snapshot from their webcam, &quot;clipboard&quot; allows users to paste an image from the clipboard.",default:"('upload', 'webcam', 'clipboard')"},{name:"type",annotation:"Literal[('numpy', 'pil', 'filepath')]",doc:"The format the images are converted to before being passed into the prediction function. &quot;numpy&quot; converts the images to numpy arrays with shape (height, width, 3) and values from 0 to 255, &quot;pil&quot; converts the images to PIL image objects, &quot;filepath&quot; passes images as str filepaths to temporary copies of the images.",default:"\"numpy\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"show_download_button",annotation:"bool",doc:"If True, will display button to download image.",default:"True"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload and edit an image; if False, can only be used to display images. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"mirror_webcam",annotation:"bool",doc:"If True webcam will be mirrored. Default is True.",default:"True"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"crop_size",annotation:"tuple[int | float, int | float] | str | None",doc:"The size of the crop box in pixels. If a tuple, the first value is the width and the second value is the height. If a string, the value must be a ratio in the form `width:height` (e.g. &quot;16:9&quot;).",default:"None"},{name:"transforms",annotation:"Iterable[Literal['crop']]",doc:"The transforms tools to make available to users. &quot;crop&quot; allows the user to crop the image.",default:"('crop',)"},{name:"eraser",annotation:"Eraser | None | Literal[False]",doc:"The options for the eraser tool in the image editor. Should be an instance of the `gr.Eraser` class, or None to use the default settings. Can also be False to hide the eraser tool.",default:"None"},{name:"brush",annotation:"Brush | None | Literal[False]",doc:"The options for the brush tool in the image editor. Should be an instance of the `gr.Brush` class, or None to use the default settings. Can also be False to hide the brush tool, which will also hide the eraser tool.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"clear",description:"This listener is triggered when the user clears the ImageEditor using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-clear"},{fn:null,name:"change",description:"Triggered when the value of the ImageEditor changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the ImageEditor. Uses event data gradio.SelectData to carry `value` referring to the label of the ImageEditor, and `selected` to refer to state of the ImageEditor. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-select"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the ImageEditor.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-upload"}],string_shortcuts:[["ImageEditor","imageeditor","Uses default values"],["Sketchpad","sketchpad","Uses sources=(), brush=Brush(colors=[\"#000000\"], color_mode=\"fixed\")"],["Paint","paint","Uses sources=()"],["ImageMask","imagemask","Uses brush=Brush(colors=[\"#000000\"], color_mode=\"fixed\")"]],demos:[["image_editor","import gradio as gr\nimport time\n\n\ndef sleep(im):\n    time.sleep(5)\n    return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1], im[\"composite\"]]\n\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(\n        type=\"pil\",\n        crop_size=\"1:1\",\n    )\n\n    with gr.Group():\n        with gr.Row():\n            im_out_1 = gr.Image(type=\"pil\")\n            im_out_2 = gr.Image(type=\"pil\")\n            im_out_3 = gr.Image(type=\"pil\")\n            im_out_4 = gr.Image(type=\"pil\")\n\n    btn = gr.Button()\n    im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3, im_out_4], inputs=im)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Image",next_obj:"JSON",slug:"image-editor"};a.json={class:null,name:"JSON",description:"Used to display arbitrary JSON output prettily. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a {str} filepath to a file containing valid JSON -- or a {list} or {dict} that is valid JSON",demos:"zip_to_json, blocks_xray"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | dict | list | Callable | None",doc:"Default value. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the JSON changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.JSON",slug:"json-change"}],string_shortcuts:[["JSON","json","Uses default values"]],demos:[["zip_to_json","from zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_xray","import gradio as gr\nimport time\n\ndisease_values = [0.25, 0.5, 0.75]\n\ndef xray_model(diseases, img):\n    return [{disease: disease_values[idx] for idx,disease in enumerate(diseases)}]\n\n\ndef ct_model(diseases, img):\n    return [{disease: 0.1 for disease in diseases}]\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n# Detect Disease From Scan\nWith this model you can lorem ipsum\n- ipsum 1\n- ipsum 2\n\"\"\"\n    )\n    gr.DuplicateButton()\n    disease = gr.CheckboxGroup(\n        info=\"Select the diseases you want to scan for.\",\n        choices=[\"Covid\", \"Malaria\", \"Lung Cancer\"], label=\"Disease to Scan For\"\n    )\n    slider = gr.Slider(0, 100)\n\n    with gr.Tab(\"X-ray\") as x_tab:\n        with gr.Row():\n            xray_scan = gr.Image()\n            xray_results = gr.JSON()\n        xray_run = gr.Button(\"Run\")\n        xray_run.click(\n            xray_model,\n            inputs=[disease, xray_scan],\n            outputs=xray_results,\n            api_name=\"xray_model\"\n        )\n\n    with gr.Tab(\"CT Scan\"):\n        with gr.Row():\n            ct_scan = gr.Image()\n            ct_results = gr.JSON()\n        ct_run = gr.Button(\"Run\")\n        ct_run.click(\n            ct_model,\n            inputs=[disease, ct_scan],\n            outputs=ct_results,\n            api_name=\"ct_model\"\n        )\n\n    upload_btn = gr.Button(\"Upload Results\", variant=\"primary\")\n    upload_btn.click(\n        lambda ct, xr: None,\n        inputs=[ct_results, xray_results],\n        outputs=[],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"ImageEditor",next_obj:"Label",slug:"json"};a.label={class:null,name:"Label",description:"Displays a classification label, along with confidence scores of top categories, if provided. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a {Dict[str, float]} of classes and confidences, or {str} with just the class or an {int}/{float} for regression outputs, or a {str} path to a .json file containing a json dictionary in the structure produced by Label.postprocess().",demos:"main_note, titanic_survival",guides:"image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"dict[str, float] | str | float | Callable | None",doc:"Default value to show in the component. If a str or number is provided, simply displays the string or number. If a {Dict[str, float]} of classes and confidences is provided, displays the top class on top and the `num_top_classes` below, along with their confidence bars. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"num_top_classes",annotation:"int | None",doc:"number of most confident classes to show.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"color",annotation:"str | None",doc:"The background color of the label (either a valid css color name or hexadecimal string).",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Label changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Label",slug:"label-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Label. Uses event data gradio.SelectData to carry `value` referring to the label of the Label, and `selected` to refer to state of the Label. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Label",slug:"label-select"}],string_shortcuts:[["Label","label","Uses default values"]],demos:[["main_note","from math import log2, pow\nimport os\n\nimport numpy as np\nfrom scipy.fftpack import fft\n\nimport gradio as gr\n\nA4 = 440\nC0 = A4 * pow(2, -4.75)\nname = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\n\ndef get_pitch(freq):\n    h = round(12 * log2(freq / C0))\n    n = h % 12\n    return name[n]\n\n\ndef main_note(audio):\n    rate, y = audio\n    if len(y.shape) == 2:\n        y = y.T[0]\n    N = len(y)\n    T = 1.0 / rate\n    yf = fft(y)\n    yf2 = 2.0 / N * np.abs(yf[0 : N // 2])\n    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n\n    volume_per_pitch = {}\n    total_volume = np.sum(yf2)\n    for freq, volume in zip(xf, yf2):\n        if freq == 0:\n            continue\n        pitch = get_pitch(freq)\n        if pitch not in volume_per_pitch:\n            volume_per_pitch[pitch] = 0\n        volume_per_pitch[pitch] += 1.0 * volume / total_volume\n    volume_per_pitch = {k: float(v) for k, v in volume_per_pitch.items()}\n    return volume_per_pitch\n\n\ndemo = gr.Interface(\n    main_note,\n    gr.Audio(sources=[\"microphone\"]),\n    gr.Label(num_top_classes=4),\n    examples=[\n        [os.path.join(os.path.dirname(__file__),\"audio/recording1.wav\")],\n        [os.path.join(os.path.dirname(__file__),\"audio/cantina.wav\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"image-classification-in-pytorch",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:29,pretty_name:"Image Classification In Pytorch",content:"# Image Classification in PyTorch\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own.\n\n```python\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\nBecause we will be using the model for inference, we have called the `.eval()` method.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `PIL` image\n\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image.\n\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/pytorch-image-classifier\">\n\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","RESNET","PYTORCH"],spaces:["https://huggingface.co/spaces/abidlabs/pytorch-image-classifier","https://huggingface.co/spaces/pytorch/ResNet","https://huggingface.co/spaces/pytorch/ResNext","https://huggingface.co/spaces/pytorch/SqueezeNet"],url:"/guides/image-classification-in-pytorch/",contributor:null},{name:"image-classification-in-tensorflow",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:30,pretty_name:"Image Classification In Tensorflow",content:"# Image Classification in TensorFlow and Keras\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own.\n\n```python\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\nThis line automatically downloads the MobileNet model and weights using the Keras library.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `numpy` array\n\nThen, the function adds a batch dimension, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(shape=(224, 224)),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/keras-image-classifier\">\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","MOBILENET","TENSORFLOW"],spaces:["https://huggingface.co/spaces/abidlabs/keras-image-classifier"],url:"/guides/image-classification-in-tensorflow/",contributor:null},{name:"image-classification-with-vision-transformers",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:31,pretty_name:"Image Classification With Vision Transformers",content:"# Image Classification with Vision Transformers\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control.\n\nState-of-the-art image classifiers are based on the _transformers_ architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started).\n\n## Step 1 ‚Äî Choosing a Vision Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks.\n\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\n\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at a resolution of 224x224 pixels. We will use this model for our demo.\n\n## Step 2 ‚Äî Loading the Vision Transformer Model with Gradio\n\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing.\nAll of these are automatically inferred from the model tags.\n\nBesides the import statement, it only takes a single line of Python to load and launch the demo.\n\nWe use the `gr.Interface.load()` method and pass in the path to the model including the `huggingface/` to designate that it is from the Hugging Face Hub.\n\n```python\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples.\n\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a human-interpretable prediction. Try uploading your own image!\n\n\u003Cgradio-app space=\"gradio/vision-transformer\">\n\n---\n\nAnd you're done! In one line of code, you have built a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","TRANSFORMERS","HUB"],spaces:["https://huggingface.co/spaces/abidlabs/vision-transformer"],url:"/guides/image-classification-with-vision-transformers/",contributor:null}],parent:"gradio",prev_obj:"JSON",next_obj:"LinePlot",slug:"label"};a.lineplot={class:null,name:"LinePlot",description:"Create a line plot. \u003Cbr> \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a pandas dataframe with the data to plot.",demos:"line_plot, live_dashboard"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Callable | None",doc:"The pandas dataframe containing the data to display in a scatter plot.",default:"None"},{name:"x",annotation:"str | None",doc:"Column corresponding to the x axis.",default:"None"},{name:"y",annotation:"str | None",doc:"Column corresponding to the y axis.",default:"None"},{name:"color",annotation:"str | None",doc:"The column to determine the point color. If the column contains numeric data, gradio will interpolate the column data so that small values correspond to light colors and large values correspond to dark values.",default:"None"},{name:"stroke_dash",annotation:"str | None",doc:"The column to determine the symbol used to draw the line, e.g. dashed lines, dashed lines with points.",default:"None"},{name:"overlay_point",annotation:"bool | None",doc:"Whether to draw a point on the line for each (x, y) coordinate pair.",default:"None"},{name:"title",annotation:"str | None",doc:"The title to display on top of the chart.",default:"None"},{name:"tooltip",annotation:"list[str] | str | None",doc:"The column (or list of columns) to display on the tooltip when a user hovers a point on the plot.",default:"None"},{name:"x_title",annotation:"str | None",doc:"The title given to the x axis. By default, uses the value of the x parameter.",default:"None"},{name:"y_title",annotation:"str | None",doc:"The title given to the y axis. By default, uses the value of the y parameter.",default:"None"},{name:"x_label_angle",annotation:"float | None",doc:"The angle for the x axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"y_label_angle",annotation:"float | None",doc:"The angle for the y axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"color_legend_title",annotation:"str | None",doc:"The title given to the color legend. By default, uses the value of color parameter.",default:"None"},{name:"stroke_dash_legend_title",annotation:"str | None",doc:"The title given to the stroke_dash legend. By default, uses the value of the stroke_dash parameter.",default:"None"},{name:"color_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the color legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"stroke_dash_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the stoke_dash legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"x_lim",annotation:"list[int] | None",doc:"A tuple or list containing the limits for the x-axis, specified as [x_min, x_max].",default:"None"},{name:"y_lim",annotation:"list[int] | None",doc:"A tuple of list containing the limits for the y-axis, specified as [y_min, y_max].",default:"None"},{name:"caption",annotation:"str | None",doc:"The (optional) caption to display below the plot.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether users should be able to interact with the plot by panning or zooming with their mouse or trackpad.",default:"True"},{name:"label",annotation:"str | None",doc:"The (optional) label to display on the top left corner of the plot.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"Whether the label should be displayed.",default:"None"},{name:"container",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"None"},{name:"min_width",annotation:"int",doc:null,default:"160"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"visible",annotation:"bool",doc:"Whether the plot should be visible.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"show_actions_button",annotation:"bool",doc:"Whether to show the actions button on the top right corner of the plot.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LinePlot",slug:"line-plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LinePlot",slug:"line-plot-clear"}],string_shortcuts:[["LinePlot","lineplot","Uses default values"]],demos:[["line_plot","import gradio as gr\nfrom vega_datasets import data\n\nstocks = data.stocks()\ngapminder = data.gapminder()\ngapminder = gapminder.loc[\n    gapminder.country.isin([\"Argentina\", \"Australia\", \"Afghanistan\"])\n]\nclimate = data.climate()\nseattle_weather = data.seattle_weather()\n\n## Or generate your own fake data, here's an example for stocks:\n#\n# import pandas as pd\n# import random\n#\n# stocks = pd.DataFrame(\n#     {\n#         \"symbol\": [\n#             random.choice(\n#                 [\n#                     \"MSFT\",\n#                     \"AAPL\",\n#                     \"AMZN\",\n#                     \"IBM\",\n#                     \"GOOG\",\n#                 ]\n#             )\n#             for _ in range(120)\n#         ],\n#         \"date\": [\n#             pd.Timestamp(year=2000 + i, month=j, day=1)\n#             for i in range(10)\n#             for j in range(1, 13)\n#         ],\n#         \"price\": [random.randint(10, 200) for _ in range(120)],\n#     }\n# )\n\n\ndef line_plot_fn(dataset):\n    if dataset == \"stocks\":\n        return gr.LinePlot(\n            stocks,\n            x=\"date\",\n            y=\"price\",\n            color=\"symbol\",\n            color_legend_position=\"bottom\",\n            title=\"Stock Prices\",\n            tooltip=[\"date\", \"price\", \"symbol\"],\n            height=300,\n            width=500,\n        )\n    elif dataset == \"climate\":\n        return gr.LinePlot(\n            climate,\n            x=\"DATE\",\n            y=\"HLY-TEMP-NORMAL\",\n            y_lim=[250, 500],\n            title=\"Climate\",\n            tooltip=[\"DATE\", \"HLY-TEMP-NORMAL\"],\n            height=300,\n            width=500,\n        )\n    elif dataset == \"seattle_weather\":\n        return gr.LinePlot(\n            seattle_weather,\n            x=\"date\",\n            y=\"temp_min\",\n            tooltip=[\"weather\", \"date\"],\n            overlay_point=True,\n            title=\"Seattle Weather\",\n            height=300,\n            width=500,\n        )\n    elif dataset == \"gapminder\":\n        return gr.LinePlot(\n            gapminder,\n            x=\"year\",\n            y=\"life_expect\",\n            color=\"country\",\n            title=\"Life expectancy for countries\",\n            stroke_dash=\"cluster\",\n            x_lim=[1950, 2010],\n            tooltip=[\"country\", \"life_expect\"],\n            stroke_dash_legend_title=\"Country Cluster\",\n            height=300,\n            width=500,\n        )\n\n\nwith gr.Blocks() as line_plot:\n    with gr.Row():\n        with gr.Column():\n            dataset = gr.Dropdown(\n                choices=[\"stocks\", \"climate\", \"seattle_weather\", \"gapminder\"],\n                value=\"stocks\",\n            )\n        with gr.Column():\n            plot = gr.LinePlot()\n    dataset.change(line_plot_fn, inputs=dataset, outputs=plot)\n    line_plot.load(fn=line_plot_fn, inputs=dataset, outputs=plot)\n\n\nif __name__ == \"__main__\":\n    line_plot.launch()\n"],["live_dashboard","import math\n\nimport pandas as pd\n\nimport gradio as gr\nimport datetime\nimport numpy as np\n\n\ndef get_time():\n    return datetime.datetime.now()\n\n\nplot_end = 2 * math.pi\n\n\ndef get_plot(period=1):\n    global plot_end\n    x = np.arange(plot_end - 2 * math.pi, plot_end, 0.02)\n    y = np.sin(2 * math.pi * period * x)\n    update = gr.LinePlot(\n        value=pd.DataFrame({\"x\": x, \"y\": y}),\n        x=\"x\",\n        y=\"y\",\n        title=\"Plot (updates every second)\",\n        width=600,\n        height=350,\n    )\n    plot_end += 2 * math.pi\n    if plot_end > 1000:\n        plot_end = 2 * math.pi\n    return update\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            c_time2 = gr.Textbox(label=\"Current Time refreshed every second\")\n            gr.Textbox(\n                \"Change the value of the slider to automatically update the plot\",\n                label=\"\",\n            )\n            period = gr.Slider(\n                label=\"Period of plot\", value=1, minimum=0, maximum=10, step=1\n            )\n            plot = gr.LinePlot(show_label=False)\n        with gr.Column():\n            name = gr.Textbox(label=\"Enter your name\")\n            greeting = gr.Textbox(label=\"Greeting\")\n            button = gr.Button(value=\"Greet\")\n            button.click(lambda s: f\"Hello {s}\", name, greeting)\n\n    demo.load(lambda: datetime.datetime.now(), None, c_time2, every=1)\n    dep = demo.load(get_plot, None, plot, every=1)\n    period.change(get_plot, period, plot, every=1, cancels=[dep])\n\nif __name__ == \"__main__\":\n    demo.queue().launch()\n"]],parent:"gradio",prev_obj:"Label",next_obj:"LoginButton",slug:"line-plot"};a.loginbutton={class:null,name:"LoginButton",description:"Button that redirects the user to Sign with Hugging Face using OAuth.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str",doc:null,default:"\"Sign in with Hugging Face\""},{name:"logout_value",annotation:"str",doc:"The text to display when the user is signed in. The string should contain a placeholder for the username with a call-to-action to logout, e.g. &quot;Logout ({})&quot;.",default:"\"Logout ({})\""},{name:"every",annotation:"float | None",doc:null,default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:null,default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:null,default:"None"},{name:"icon",annotation:"str | None",doc:null,default:"\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\""},{name:"link",annotation:"str | None",doc:null,default:"None"},{name:"visible",annotation:"bool",doc:null,default:"True"},{name:"interactive",annotation:"bool",doc:null,default:"True"},{name:"elem_id",annotation:"str | None",doc:null,default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:null,default:"None"},{name:"render",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"0"},{name:"min_width",annotation:"int | None",doc:null,default:"None"},{name:"signed_in_value",annotation:"str",doc:null,default:"\"Signed in as {}\""}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LoginButton",slug:"login-button-click"}],string_shortcuts:[["LoginButton","loginbutton","Uses default values"]],parent:"gradio",prev_obj:"LinePlot",next_obj:"LogoutButton",slug:"login-button"};a.logoutbutton={class:null,name:"LogoutButton",description:"Button to log out a user from a Space. \u003Cbr>       which handles both the login and logout processes.",tags:{note:"`LogoutButton` component is deprecated. Please use `gr.LoginButton` instead"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Logout\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed. Must be within the working directory of the Gradio app or an external URL.",default:"\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\""},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"\"/logout\""},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"0"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LogoutButton",slug:"logout-button-click"}],string_shortcuts:[["LogoutButton","logoutbutton","Uses default values"]],parent:"gradio",prev_obj:"LoginButton",next_obj:"Markdown",slug:"logout-button"};a.markdown={class:null,name:"Markdown",description:"Used to render arbitrary Markdown output. Can also render latex enclosed by dollar signs. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a valid {str} that can be rendered as Markdown.",demos:"blocks_hello, blocks_kinematics",guides:"key-features"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable",doc:"Value to show in Markdown component. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"\""},{name:"label",annotation:"str | None",doc:"The label for this component. Is used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"This parameter has no effect.",default:"None"},{name:"rtl",annotation:"bool",doc:"If True, sets the direction of the rendered text to right-to-left. Default is False, which renders text left-to-right.",default:"False"},{name:"latex_delimiters",annotation:"list[dict[str, str | bool]] | None",doc:"A list of dicts of the form {&quot;left&quot;: open delimiter (str), &quot;right&quot;: close delimiter (str), &quot;display&quot;: whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ &quot;left&quot;: &quot;$$&quot;, &quot;right&quot;: &quot;$$&quot;, &quot;display&quot;: True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html).",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"sanitize_html",annotation:"bool",doc:"If False, will disable HTML sanitization when converted from markdown. This is not recommended, as it can lead to security vulnerabilities.",default:"True"},{name:"line_breaks",annotation:"bool",doc:"If True, will enable Github-flavored Markdown line breaks in chatbot messages. If False (default), single new lines will be ignored.",default:"False"},{name:"header_links",annotation:"bool",doc:"If True, will automatically create anchors for headings, displaying a link icon on hover.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Markdown changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Markdown",slug:"markdown-change"}],string_shortcuts:[["Markdown","markdown","Uses default values"]],demos:[["blocks_hello","import gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    \"\"\"\n    # Hello World!\n    Start typing below to see the output.\n    \"\"\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\nif __name__ == \"__main__\":\n    demo.launch()"],["blocks_kinematics","import pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"key-features",category:"getting-started",pretty_category:"Getting Started",guide_index:2,absolute_index:1,pretty_name:"Key Features",content:"# Key Features\n\nLet's go through some of the key features of Gradio. This guide is intended to be a high-level overview of various things that you should be aware of as you build your demo. Where appropriate, we link to more detailed guides on specific topics.\n\n1. [Components](#components)\n2. [Queuing](#queuing)\n3. [Streaming outputs](#streaming-outputs)\n4. [Streaming inputs](#streaming-inputs)\n5. [Alert modals](#alert-modals)\n6. [Styling](#styling)\n7. [Progress bars](#progress-bars)\n8. [Batch functions](#batch-functions)\n\n## Components\n\nGradio includes more than 30 pre-built components (as well as many user-built _custom components_) that can be used as inputs or outputs in your demo with a single line of code. These components correspond to common data types in machine learning and data science, e.g. the `gr.Image` component is designed to handle input or output images, the `gr.Label` component displays classification labels and probabilities, the `gr.Plot` component displays various kinds of plots, and so on.\n\nEach component includes various constructor attributes that control the properties of the component. For example, you can control the number of lines in a `gr.Textbox` using the `lines` argument (which takes a positive integer) in its constructor. Or you can control the way that a user can provide an image in the `gr.Image` component using the `sources` parameter (which takes a list like `[\"webcam\", \"upload\"]`).\n\n**Static and Interactive Components**\n\nEvery component has a _static_ version that is designed to *display* data, and most components also have an _interactive_ version designed to let users input or modify the data. Typically, you don't need to think about this distinction, because when you build a Gradio demo, Gradio automatically figures out whether the component should be static or interactive based on whether it is being used as an input or output. However, you can set this manually using the `interactive` argument that every component supports.\n\n**Preprocessing and Postprocessing**\n\nWhen a component is used as an input, Gradio automatically handles the _preprocessing_ needed to convert the data from a type sent by the user's browser (such as an uploaded image) to a form that can be accepted by your function (such as a `numpy` array).\n\n\nSimilarly, when a component is used as an output, Gradio automatically handles the _postprocessing_ needed to convert the data from what is returned by your function (such as a list of image paths) to a form that can be displayed in the user's browser (a gallery of images).\n\nConsider an example demo with three input components (`gr.Textbox`, `gr.Number`, and `gr.Image`) and two outputs (`gr.Number` and `gr.Gallery`) that serve as a UI for your image-to-image generation model. Below is a diagram of what our preprocessing will send to the model and what our postprocessing will require from it.\n\n![](https://github.com/gradio-app/gradio/blob/main/guides/assets/dataflow.svg?raw=true)\n\nIn this image, the following preprocessing steps happen to send the data from the browser to your function:\n\n* The text in the textbox is converted to a Python `str` (essentially no preprocessing)\n* The number in the number input in converted to a Python `float` (essentially no preprocessing)\n* Most importantly, ihe image supplied by the user is converted to a `numpy.array` representation of the RGB values in the image\n\nImages are converted to NumPy arrays because they are a common format for machine learning workflows. You can control the _preprocessing_ using the component's parameters when constructing the component. For example, if you instantiate the `Image` component with the following parameters, it will preprocess the image to the `PIL` format instead:\n\n```py\nimg = gr.Image(type=\"pil\")\n```\n\nPostprocessing is even simpler! Gradio automatically recognizes the format of the returned data (e.g. does the user's function return a `numpy` array or a `str` filepath for the `gr.Image` component?) and postprocesses it appropriately into a format that can be displayed by the browser.\n\nSo in the image above, the following postprocessing steps happen to send the data returned from a user's function to the browser:\n\n* The `float` is displayed as a number and displayed directly to the user\n* The list of string filepaths (`list[str]`) is interpreted as a list of image filepaths and displayed as a gallery in the browser\n\nTake a look at the [Docs](https://gradio.app/docs) to see all the parameters for each Gradio component.\n\n## Queuing\n\nEvery Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. You can configure the queue by using `queue()` method which is supported by the `gr.Interface`, `gr.Blocks`, and `gr.ChatInterface` classes. \n\nFor example, you can control the number of requests processed at a single time by setting the `default_concurrency_limit` parameter of `queue()`, e.g.\n\n```python\ndemo = gr.Interface(...).queue(default_concurrency_limit=5)\ndemo.launch()\n```\n\nThis limits the number of requests processed for this event listener at a single time to 5. By default, the `default_concurrency_limit` is actually set to `1`, which means that when many users are using your app, only a single user's request will be processed at a time. This is because many machine learning functions consume a significant amount of memory and so it is only suitable to have a single user using the demo at a time. However, you can change this parameter in your demo easily.\n\nSee the [docs on queueing](/docs/interface#interface-queue) for more details on configuring the queuing parameters.\n\n## Streaming outputs\n\nIn some cases, you may want to stream a sequence of outputs rather than show a single output at once. For example, you might have an image generation model and you want to show the image that is generated at each step, leading up to the final image. Or you might have a chatbot which streams its response one token at a time instead of returning it all at once.\n\nIn such cases, you can supply a **generator** function into Gradio instead of a regular function. Creating generators in Python is very simple: instead of a single `return` value, a function should `yield` a series of values instead. Usually the `yield` statement is put in some kind of loop. Here's an example of an generator that simply counts up to a given number:\n\n```python\ndef my_generator(x):\n    for i in range(x):\n        yield i\n```\n\nYou supply a generator into Gradio the same way as you would a regular function. For example, here's a a (fake) image generation model that generates noise for several steps before outputting an image using the `gr.Interface` class:\n\n```python\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef fake_diffusion(steps):\n    for i in range(steps):\n        time.sleep(1)\n        image = np.random.random((600, 600, 3))\n        yield image\n    image = np.ones((1000,1000,3), np.uint8)\n    image[:] = [255, 124, 0]\n    yield image\n\n\ndemo = gr.Interface(fake_diffusion, inputs=gr.Slider(1, 10, 3), outputs=\"image\")\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/fake_diffusion'>\u003C/gradio-app>\n\nNote that we've added a `time.sleep(1)` in the iterator to create an artificial pause between steps so that you are able to observe the steps of the iterator (in a real image generation model, this probably wouldn't be necessary).\n\n## Streaming inputs\n\nSimilarly, Gradio can handle streaming inputs, e.g. a live audio stream that can gets transcribed to text in real time, or an image generation model that reruns every time a user types a letter in a textbox. This is covered in more details in our guide on building [reactive Interfaces](/guides/reactive-interfaces). \n\n## Alert modals\n\nYou may wish to raise alerts to the user. To do so, raise a `gr.Error(\"custom message\")` to display an error message. You can also issue `gr.Warning(\"message\")` and `gr.Info(\"message\")` by having them as standalone lines in your function, which will immediately display modals while continuing the execution of your function. Queueing needs to be enabled for this to work.\n\nNote below how the `gr.Error` has to be raised, while the `gr.Warning` and `gr.Info` are single lines.\n\n```python\ndef start_process(name):\n    gr.Info(\"Starting process\")\n    if name is None:\n        gr.Warning(\"Name is empty\")\n    ...\n    if success == False:\n        raise gr.Error(\"Process failed\")\n```\n\n\n\n## Styling\n\nGradio themes are the easiest way to customize the look and feel of your app. You can choose from a variety of themes, or create your own. To do so, pass the `theme=` kwarg to the `Interface` constructor. For example:\n\n```python\ndemo = gr.Interface(..., theme=gr.themes.Monochrome())\n```\n\nGradio comes with a set of prebuilt themes which you can load from `gr.themes.*`. You can extend these themes or create your own themes from scratch - see the [theming guide](https://gradio.app/guides/theming-guide) for more details.\n\nFor additional styling ability, you can pass any CSS (as well as custom JavaScript) to your Gradio application. This is discussed in more detail in our [custom JS and CSS guide](/guides/custom-CSS-and-JS).\n\n\n## Progress bars\n\nGradio supports the ability to create custom Progress Bars so that you have customizability and control over the progress update that you show to the user. In order to enable this, simply add an argument to your method that has a default value of a `gr.Progress` instance. Then you can update the progress levels by calling this instance directly with a float between 0 and 1, or using the `tqdm()` method of the `Progress` instance to track progress over an iterable, as shown below.\n\n```python\nimport gradio as gr\nimport time\n\ndef slowly_reverse(word, progress=gr.Progress()):\n    progress(0, desc=\"Starting\")\n    time.sleep(1)\n    progress(0.05)\n    new_string = \"\"\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\n        time.sleep(0.25)\n        new_string = letter + new_string\n    return new_string\n\ndemo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/progress_simple'>\u003C/gradio-app>\n\nIf you use the `tqdm` library, you can even report progress updates automatically from any `tqdm.tqdm` that already exists within your function by setting the default argument as `gr.Progress(track_tqdm=True)`!\n\n## Batch functions\n\nGradio supports the ability to pass _batch_ functions. Batch functions are just\nfunctions which take in a list of inputs and return a list of predictions.\n\nFor example, here is a batched function that takes in two lists of inputs (a list of\nwords and a list of ints), and returns a list of trimmed words as output:\n\n```py\nimport time\n\ndef trim_words(words, lens):\n    trimmed_words = []\n    time.sleep(5)\n    for w, l in zip(words, lens):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n```\n\nThe advantage of using batched functions is that if you enable queuing, the Gradio server can automatically _batch_ incoming requests and process them in parallel,\npotentially speeding up your demo. Here's what the Gradio code looks like (notice the `batch=True` and `max_batch_size=16`)\n\nWith the `gr.Interface` class:\n\n```python\ndemo = gr.Interface(\n    fn=trim_words, \n    inputs=[\"textbox\", \"number\"], \n    outputs=[\"output\"],\n    batch=True, \n    max_batch_size=16\n)\n\ndemo.launch()\n```\n\nWith the `gr.Blocks` class:\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        word = gr.Textbox(label=\"word\")\n        leng = gr.Number(label=\"leng\")\n        output = gr.Textbox(label=\"Output\")\n    with gr.Row():\n        run = gr.Button()\n\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\n\ndemo.launch()\n```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference time of 5 seconds), instead of each request being processed separately (for a total\ninference time of 80 seconds). Many Hugging Face `transformers` and `diffusers` models work very naturally with Gradio's batch mode: here's [an example demo using diffusers to\ngenerate images in batches](https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.py)\n\n\n",tags:[],spaces:[],url:"/guides/key-features/",contributor:null}],parent:"gradio",prev_obj:"LogoutButton",next_obj:"Model3D",slug:"markdown"};a.model3d={class:null,name:"Model3D",description:"Component allows users to upload or view 3D Model files (.obj, .glb, or .gltf). \u003Cbr>",tags:{preprocessing:"This component passes the uploaded file as a {str}filepath.",postprocessing:"expects function to return a {str} or {pathlib.Path} filepath of type (.obj, glb, or .gltf)",demos:"model3D",guides:"how-to-use-3D-model-component"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable | None",doc:"path to (.obj, glb, or .gltf) file to show in model3D viewer. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"clear_color",annotation:"tuple[float, float, float, float] | None",doc:"background color of scene, should be a tuple of 4 floats between 0 and 1 representing RGBA values.",default:"None"},{name:"camera_position",annotation:"tuple[int | float | None, int | float | None, int | float | None]",doc:"initial camera position of scene, provided as a tuple of `(alpha, beta, radius)`. Each value is optional. If provided, `alpha` and `beta` should be in degrees reflecting the angular position along the longitudinal and latitudinal axes, respectively. Radius corresponds to the distance from the center of the object to the camera.",default:"(None, None, None)"},{name:"zoom_speed",annotation:"float",doc:"the speed of zooming in and out of the scene when the cursor wheel is rotated or when screen is pinched on a mobile device. Should be a positive float, increase this value to make zooming faster, decrease to make it slower. Affects the wheelPrecision property of the camera.",default:"1"},{name:"pan_speed",annotation:"float",doc:"the speed of panning the scene when the cursor is dragged or when the screen is dragged on a mobile device. Should be a positive float, increase this value to make panning faster, decrease to make it slower. Affects the panSensibility property of the camera.",default:"1"},{name:"height",annotation:"int | str | None",doc:"The height of the model3D component, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a file; if False, can only be used to display files. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Model3D changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-change"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Model3D.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-upload"},{fn:null,name:"edit",description:"This listener is triggered when the user edits the Model3D (e.g. image) using the built-in editor.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-edit"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Model3D using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-clear"}],string_shortcuts:[["Model3D","model3d","Uses default values"]],demos:[["model3D","import gradio as gr\nimport os\n\n\ndef load_mesh(mesh_file_name):\n    return mesh_file_name\n\n\ndemo = gr.Interface(\n    fn=load_mesh,\n    inputs=gr.Model3D(),\n    outputs=gr.Model3D(\n            clear_color=[0.0, 0.0, 0.0, 0.0],  label=\"3D Model\"),\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"files/Bunny.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Duck.glb\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Fox.gltf\")],\n        [os.path.join(os.path.dirname(__file__), \"files/face.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/sofia.stl\")],\n    ],\n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"how-to-use-3D-model-component",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:46,pretty_name:"How To Use 3D Model Component",content:"# How to Use the 3D Model Component\n\n\n\n\n## Introduction\n\n3D models are becoming more popular in machine learning and make for some of the most fun demos to experiment with. Using `gradio`, you can easily build a demo of your 3D image model and share it with anyone. The Gradio 3D Model component accepts 3 file types including: _.obj_, _.glb_, & _.gltf_.\n\nThis guide will show you how to build a demo for your 3D image model in a few lines of code; like the one below. Play around with 3D object by clicking around, dragging and zooming:\n\n\u003Cgradio-app space=\"gradio/Model3D\"> \u003C/gradio-app>\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](https://gradio.app/guides/quickstart).\n\n## Taking a Look at the Code\n\nLet's take a look at how to create the minimal interface above. The prediction function in this case will just return the original 3D model mesh, but you can change this function to run inference on your machine learning model. We'll take a look at more complex examples below.\n\n```python\nimport gradio as gr\nimport os\n\n\ndef load_mesh(mesh_file_name):\n    return mesh_file_name\n\n\ndemo = gr.Interface(\n    fn=load_mesh,\n    inputs=gr.Model3D(),\n    outputs=gr.Model3D(\n            clear_color=[0.0, 0.0, 0.0, 0.0],  label=\"3D Model\"),\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"files/Bunny.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Duck.glb\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Fox.gltf\")],\n        [os.path.join(os.path.dirname(__file__), \"files/face.obj\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\nLet's break down the code above:\n\n`load_mesh`: This is our 'prediction' function and for simplicity, this function will take in the 3D model mesh and return it.\n\nCreating the Interface:\n\n- `fn`: the prediction function that is used when the user clicks submit. In our case this is the `load_mesh` function.\n- `inputs`: create a model3D input component. The input expects an uploaded file as a {str} filepath.\n- `outputs`: create a model3D output component. The output component also expects a file as a {str} filepath.\n  - `clear_color`: this is the background color of the 3D model canvas. Expects RGBa values.\n  - `label`: the label that appears on the top left of the component.\n- `examples`: list of 3D model files. The 3D model component can accept _.obj_, _.glb_, & _.gltf_ file types.\n- `cache_examples`: saves the predicted output for the examples, to save time on inference.\n\n## Exploring a more complex Model3D Demo:\n\nBelow is a demo that uses the DPT model to predict the depth of an image and then uses 3D Point Cloud to create a 3D object. Take a look at the [app.py](https://huggingface.co/spaces/gradio/dpt-depth-estimation-3d-obj/blob/main/app.py) file for a peek into the code and the model prediction function.\n\u003Cgradio-app space=\"gradio/dpt-depth-estimation-3d-obj\"> \u003C/gradio-app>\n\n---\n\nAnd you're done! That's all the code you need to build an interface for your Model3D model. Here are some references that you may find useful:\n\n- Gradio's [\"Getting Started\" guide](https://gradio.app/getting_started/)\n- The first [3D Model Demo](https://huggingface.co/spaces/gradio/Model3D) and [complete code](https://huggingface.co/spaces/gradio/Model3D/tree/main) (on Hugging Face Spaces)\n",tags:["VISION","IMAGE"],spaces:["https://huggingface.co/spaces/gradio/Model3D","https://huggingface.co/spaces/gradio/PIFu-Clothed-Human-Digitization","https://huggingface.co/spaces/gradio/dpt-depth-estimation-3d-obj"],url:"/guides/how-to-use-3D-model-component/",contributor:null}],parent:"gradio",prev_obj:"Markdown",next_obj:"Number",slug:"model3-d"};a.number={class:null,name:"Number",description:"Creates a numeric field for user to enter numbers as input or display numeric output. \u003Cbr>",tags:{preprocessing:"passes field value as a {float} or {int} into the function, depending on `precision`.",postprocessing:"expects an {int} or {float} returned from the function and sets field value to it.","examples-format":"a {float} or {int} representing the number&#x27;s value.",demos:"tax_calculator, titanic_survival, blocks_simple_squares"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"float | Callable | None",doc:"default value. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will be editable; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"precision",annotation:"int | None",doc:"Precision to round input/output to. If set to 0, will round to nearest integer and convert type to int. If None, no rounding happens.",default:"None"},{name:"minimum",annotation:"float | None",doc:"Minimum value. Only applied when component is used as an input. If a user provides a smaller value, a gr.Error exception is raised by the backend.",default:"None"},{name:"maximum",annotation:"float | None",doc:"Maximum value. Only applied when component is used as an input. If a user provides a larger value, a gr.Error exception is raised by the backend.",default:"None"},{name:"step",annotation:"float",doc:"The interval between allowed numbers in the component. Can be used along with optional parameters `minimum` and `maximum` to create a range of legal values starting from `minimum` and incrementing according to this parameter.",default:"1"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Number changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Number.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-input"},{fn:null,name:"submit",description:"This listener is triggered when the user presses the Enter key while the Number is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-submit"},{fn:null,name:"focus",description:"This listener is triggered when the Number is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-focus"}],string_shortcuts:[["Number","number","Uses default values"]],demos:[["tax_calculator","import gradio as gr\n\ndef tax_calculator(income, marital_status, assets):\n    tax_brackets = [(10, 0), (25, 8), (60, 12), (120, 20), (250, 30)]\n    total_deductible = sum(assets[\"Cost\"])\n    taxable_income = income - total_deductible\n\n    total_tax = 0\n    for bracket, rate in tax_brackets:\n        if taxable_income > bracket:\n            total_tax += (taxable_income - bracket) * rate / 100\n\n    if marital_status == \"Married\":\n        total_tax *= 0.75\n    elif marital_status == \"Divorced\":\n        total_tax *= 0.8\n\n    return round(total_tax)\n\ndemo = gr.Interface(\n    tax_calculator,\n    [\n        \"number\",\n        gr.Radio([\"Single\", \"Married\", \"Divorced\"]),\n        gr.Dataframe(\n            headers=[\"Item\", \"Cost\"],\n            datatype=[\"str\", \"number\"],\n            label=\"Assets Purchased this Year\",\n        ),\n    ],\n    \"number\",\n    examples=[\n        [10000, \"Married\", [[\"Suit\", 5000], [\"Laptop\", 800], [\"Car\", 1800]]],\n        [80000, \"Single\", [[\"Suit\", 800], [\"Watch\", 1800], [\"Car\", 800]]],\n    ],\n)\n\ndemo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_simple_squares","import gradio as gr\n\ndemo = gr.Blocks(css=\"\"\"#btn {color: red} .abc {font-family: \"Comic Sans MS\", \"Comic Sans\", cursive !important}\"\"\")\n\nwith demo:\n    default_json = {\"a\": \"a\"}\n\n    num = gr.State(value=0)\n    squared = gr.Number(value=0)\n    btn = gr.Button(\"Next Square\", elem_id=\"btn\", elem_classes=[\"abc\", \"def\"])\n\n    stats = gr.State(value=default_json)\n    table = gr.JSON()\n\n    def increase(var, stats_history):\n        var += 1\n        stats_history[str(var)] = var**2\n        return var, var**2, stats_history, stats_history\n\n    btn.click(increase, [num, stats], [num, squared, stats, table])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Model3D",next_obj:"Plot",slug:"number"};a.plot={class:null,name:"Plot",description:"Used to display various kinds of plots (matplotlib, plotly, or bokeh are supported). \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects either a {matplotlib.figure.Figure}, a {plotly.graph_objects._figure.Figure}, or a {dict} corresponding to a bokeh plot (json_item format)",demos:"altair_plot, outbreak_forecast, blocks_kinematics, stock_forecast, map_airbnb",guides:"plot-component-for-maps"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"Callable | None | pd.DataFrame",doc:"Optionally, supply a default plot object to display, must be a matplotlib, plotly, altair, or bokeh figure, or a callable. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Plot",slug:"plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Plot",slug:"plot-clear"}],string_shortcuts:[["Plot","plot","Uses default values"]],demos:[["altair_plot","import altair as alt\nimport gradio as gr\nimport numpy as np\nimport pandas as pd\nfrom vega_datasets import data\n\n\ndef make_plot(plot_type):\n    if plot_type == \"scatter_plot\":\n        cars = data.cars()\n        return alt.Chart(cars).mark_point().encode(\n            x='Horsepower',\n            y='Miles_per_Gallon',\n            color='Origin',\n        )\n    elif plot_type == \"heatmap\":\n        # Compute x^2 + y^2 across a 2D grid\n        x, y = np.meshgrid(range(-5, 5), range(-5, 5))\n        z = x ** 2 + y ** 2\n\n        # Convert this grid to columnar data expected by Altair\n        source = pd.DataFrame({'x': x.ravel(),\n                            'y': y.ravel(),\n                            'z': z.ravel()})\n        return alt.Chart(source).mark_rect().encode(\n            x='x:O',\n            y='y:O',\n            color='z:Q'\n        )\n    elif plot_type == \"us_map\":\n        states = alt.topo_feature(data.us_10m.url, 'states')\n        source = data.income.url\n\n        return alt.Chart(source).mark_geoshape().encode(\n            shape='geo:G',\n            color='pct:Q',\n            tooltip=['name:N', 'pct:Q'],\n            facet=alt.Facet('group:N', columns=2),\n        ).transform_lookup(\n            lookup='id',\n            from_=alt.LookupData(data=states, key='id'),\n            as_='geo'\n        ).properties(\n            width=300,\n            height=175,\n        ).project(\n            type='albersUsa'\n        )\n    elif plot_type == \"interactive_barplot\":\n        source = data.movies.url\n\n        pts = alt.selection(type=\"single\", encodings=['x'])\n\n        rect = alt.Chart(data.movies.url).mark_rect().encode(\n            alt.X('IMDB_Rating:Q', bin=True),\n            alt.Y('Rotten_Tomatoes_Rating:Q', bin=True),\n            alt.Color('count()',\n                scale=alt.Scale(scheme='greenblue'),\n                legend=alt.Legend(title='Total Records')\n            )\n        )\n\n        circ = rect.mark_point().encode(\n            alt.ColorValue('grey'),\n            alt.Size('count()',\n                legend=alt.Legend(title='Records in Selection')\n            )\n        ).transform_filter(\n            pts\n        )\n\n        bar = alt.Chart(source).mark_bar().encode(\n            x='Major_Genre:N',\n            y='count()',\n            color=alt.condition(pts, alt.ColorValue(\"steelblue\"), alt.ColorValue(\"grey\"))\n        ).properties(\n            width=550,\n            height=200\n        ).add_selection(pts)\n\n        plot = alt.vconcat(\n            rect + circ,\n            bar\n        ).resolve_legend(\n            color=\"independent\",\n            size=\"independent\"\n        )\n        return plot\n    elif plot_type == \"radial\":\n        source = pd.DataFrame({\"values\": [12, 23, 47, 6, 52, 19]})\n\n        base = alt.Chart(source).encode(\n            theta=alt.Theta(\"values:Q\", stack=True),\n            radius=alt.Radius(\"values\", scale=alt.Scale(type=\"sqrt\", zero=True, rangeMin=20)),\n            color=\"values:N\",\n        )\n\n        c1 = base.mark_arc(innerRadius=20, stroke=\"#fff\")\n\n        c2 = base.mark_text(radiusOffset=10).encode(text=\"values:Q\")\n\n        return c1 + c2\n    elif plot_type == \"multiline\":\n        source = data.stocks()\n\n        highlight = alt.selection(type='single', on='mouseover',\n                                fields=['symbol'], nearest=True)\n\n        base = alt.Chart(source).encode(\n            x='date:T',\n            y='price:Q',\n            color='symbol:N'\n        )\n\n        points = base.mark_circle().encode(\n            opacity=alt.value(0)\n        ).add_selection(\n            highlight\n        ).properties(\n            width=600\n        )\n\n        lines = base.mark_line().encode(\n            size=alt.condition(~highlight, alt.value(1), alt.value(3))\n        )\n\n        return points + lines\n\n\nwith gr.Blocks() as demo:\n    button = gr.Radio(label=\"Plot type\",\n                      choices=['scatter_plot', 'heatmap', 'us_map',\n                               'interactive_barplot', \"radial\", \"multiline\"], value='scatter_plot')\n    plot = gr.Plot(label=\"Plot\")\n    button.change(make_plot, inputs=button, outputs=[plot])\n    demo.load(make_plot, inputs=[button], outputs=[plot])\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["outbreak_forecast","import altair\n\nimport gradio as gr\nfrom math import sqrt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport pandas as pd\n\n\ndef outbreak(plot_type, r, month, countries, social_distancing):\n    months = [\"January\", \"February\", \"March\", \"April\", \"May\"]\n    m = months.index(month)\n    start_day = 30 * m\n    final_day = 30 * (m + 1)\n    x = np.arange(start_day, final_day + 1)\n    pop_count = {\"USA\": 350, \"Canada\": 40, \"Mexico\": 300, \"UK\": 120}\n    if social_distancing:\n        r = sqrt(r)\n    df = pd.DataFrame({\"day\": x})\n    for country in countries:\n        df[country] = x ** (r) * (pop_count[country] + 1)\n\n    if plot_type == \"Matplotlib\":\n        fig = plt.figure()\n        plt.plot(df[\"day\"], df[countries].to_numpy())\n        plt.title(\"Outbreak in \" + month)\n        plt.ylabel(\"Cases\")\n        plt.xlabel(\"Days since Day 0\")\n        plt.legend(countries)\n        return fig\n    elif plot_type == \"Plotly\":\n        fig = px.line(df, x=\"day\", y=countries)\n        fig.update_layout(\n            title=\"Outbreak in \" + month,\n            xaxis_title=\"Cases\",\n            yaxis_title=\"Days Since Day 0\",\n        )\n        return fig\n    elif plot_type == \"Altair\":\n        df = df.melt(id_vars=\"day\").rename(columns={\"variable\": \"country\"})\n        fig = altair.Chart(df).mark_line().encode(x=\"day\", y='value', color='country')\n        return fig\n    else:\n        raise ValueError(\"A plot type must be selected\")\n\n\ninputs = [\n    gr.Dropdown([\"Matplotlib\", \"Plotly\", \"Altair\"], label=\"Plot Type\"),\n    gr.Slider(1, 4, 3.2, label=\"R\"),\n    gr.Dropdown([\"January\", \"February\", \"March\", \"April\", \"May\"], label=\"Month\"),\n    gr.CheckboxGroup(\n        [\"USA\", \"Canada\", \"Mexico\", \"UK\"], label=\"Countries\", value=[\"USA\", \"Canada\"]\n    ),\n    gr.Checkbox(label=\"Social Distancing?\"),\n]\noutputs = gr.Plot()\n\ndemo = gr.Interface(\n    fn=outbreak,\n    inputs=inputs,\n    outputs=outputs,\n    examples=[\n        [\"Matplotlib\", 2, \"March\", [\"Mexico\", \"UK\"], True],\n        [\"Altair\", 2, \"March\", [\"Mexico\", \"Canada\"], True],\n        [\"Plotly\", 3.6, \"February\", [\"Canada\", \"Mexico\", \"UK\"], False],\n    ],\n    cache_examples=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n\n\n"],["blocks_kinematics","import pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["stock_forecast","import matplotlib.pyplot as plt\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot_forecast(final_year, companies, noise, show_legend, point_style):\n    start_year = 2020\n    x = np.arange(start_year, final_year + 1)\n    year_count = x.shape[0]\n    plt_format = ({\"cross\": \"X\", \"line\": \"-\", \"circle\": \"o--\"})[point_style]\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    for i, company in enumerate(companies):\n        series = np.arange(0, year_count, dtype=float)\n        series = series**2 * (i + 1)\n        series += np.random.rand(year_count) * noise\n        ax.plot(x, series, plt_format)\n    if show_legend:\n        plt.legend(companies)\n    return fig\n\n\ndemo = gr.Interface(\n    plot_forecast,\n    [\n        gr.Radio([2025, 2030, 2035, 2040], label=\"Project to:\"),\n        gr.CheckboxGroup([\"Google\", \"Microsoft\", \"Gradio\"], label=\"Company Selection\"),\n        gr.Slider(1, 100, label=\"Noise Level\"),\n        gr.Checkbox(label=\"Show Legend\"),\n        gr.Dropdown([\"cross\", \"line\", \"circle\"], label=\"Style\"),\n    ],\n    gr.Plot(label=\"forecast\"),\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["map_airbnb","import gradio as gr\nimport plotly.graph_objects as go\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n\n    filtered_df = df[(df['neighbourhood_group'].isin(boroughs)) & \n          (df['price'] > min_price) & (df['price'] \u003C max_price)]\n    names = filtered_df[\"name\"].tolist()\n    prices = filtered_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n    fig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=filtered_df['latitude'].tolist(),\n            lon=filtered_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='\u003Cb>Name\u003C/b>: %{customdata[0]}\u003Cbr>\u003Cb>Price\u003C/b>: $%{customdata[1]}'\n        ))\n\n    fig.update_layout(\n        mapbox_style=\"open-street-map\",\n        hovermode='closest',\n        mapbox=dict(\n            bearing=0,\n            center=go.layout.mapbox.Center(\n                lat=40.67,\n                lon=-73.90\n            ),\n            pitch=0,\n            zoom=9\n        ),\n    )\n\n    return fig\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n\nif __name__ == \"__main__\":\n    demo.launch()"]],guides:[{name:"plot-component-for-maps",category:"tabular-data-science-and-plots",pretty_category:"Tabular Data Science And Plots",guide_index:null,absolute_index:36,pretty_name:"Plot Component For Maps",content:"# How to Use the Plot Component for Maps\n\n\n\n## Introduction\n\nThis guide explains how you can use Gradio to plot geographical data on a map using the `gradio.Plot` component. The Gradio `Plot` component works with Matplotlib, Bokeh and Plotly. Plotly is what we will be working with in this guide. Plotly allows developers to easily create all sorts of maps with their geographical data. Take a look [here](https://plotly.com/python/maps/) for some examples.\n\n## Overview\n\nWe will be using the New York City Airbnb dataset, which is hosted on kaggle [here](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data). I've uploaded it to the Hugging Face Hub as a dataset [here](https://huggingface.co/datasets/gradio/NYC-Airbnb-Open-Data) for easier use and download. Using this data we will plot Airbnb locations on a map output and allow filtering based on price and location. Below is the demo that we will be building. ‚ö°Ô∏è\n\n\u003Cgradio-app space='gradio/map_airbnb'>\u003C/gradio-app>\n\n## Step 1 - Loading CSV data üíæ\n\nLet's start by loading the Airbnb NYC data from the Hugging Face Hub.\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n    new_df = df[(df['neighbourhood_group'].isin(boroughs)) &\n            (df['price'] > min_price) & (df['price'] \u003C max_price)]\n    names = new_df[\"name\"].tolist()\n    prices = new_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n```\n\nIn the code above, we first load the csv data into a pandas dataframe. Let's begin by defining a function that we will use as the prediction function for the gradio app. This function will accept the minimum price and maximum price range as well as the list of boroughs to filter the resulting map. We can use the passed in values (`min_price`, `max_price`, and list of `boroughs`) to filter the dataframe and create `new_df`. Next we will create `text_list` of the names and prices of each Airbnb to use as labels on the map.\n\n## Step 2 - Map Figure üåê\n\nPlotly makes it easy to work with maps. Let's take a look below how we can create a map figure.\n\n```python\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=new_df['latitude'].tolist(),\n            lon=new_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='\u003Cb>Name\u003C/b>: %{customdata[0]}\u003Cbr>\u003Cb>Price\u003C/b>: $%{customdata[1]}'\n        ))\n\nfig.update_layout(\n    mapbox_style=\"open-street-map\",\n    hovermode='closest',\n    mapbox=dict(\n        bearing=0,\n        center=go.layout.mapbox.Center(\n            lat=40.67,\n            lon=-73.90\n        ),\n        pitch=0,\n        zoom=9\n    ),\n)\n```\n\nAbove, we create a scatter plot on mapbox by passing it our list of latitudes and longitudes to plot markers. We also pass in our custom data of names and prices for additional info to appear on every marker we hover over. Next we use `update_layout` to specify other map settings such as zoom, and centering.\n\nMore info [here](https://plotly.com/python/scattermapbox/) on scatter plots using Mapbox and Plotly.\n\n## Step 3 - Gradio App ‚ö°Ô∏è\n\nWe will use two `gr.Number` components and a `gr.CheckboxGroup` to allow users of our app to specify price ranges and borough locations. We will then use the `gr.Plot` component as an output for our Plotly + Mapbox map we created earlier.\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n```\n\nWe layout these components using the `gr.Column` and `gr.Row` and we'll also add event triggers for when the demo first loads and when our \"Update Filter\" button is clicked in order to trigger the map to update with our new filters.\n\nThis is what the full demo code looks like:\n\n```python\nimport gradio as gr\nimport plotly.graph_objects as go\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n\n    filtered_df = df[(df['neighbourhood_group'].isin(boroughs)) & \n          (df['price'] > min_price) & (df['price'] \u003C max_price)]\n    names = filtered_df[\"name\"].tolist()\n    prices = filtered_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n    fig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=filtered_df['latitude'].tolist(),\n            lon=filtered_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='\u003Cb>Name\u003C/b>: %{customdata[0]}\u003Cbr>\u003Cb>Price\u003C/b>: $%{customdata[1]}'\n        ))\n\n    fig.update_layout(\n        mapbox_style=\"open-street-map\",\n        hovermode='closest',\n        mapbox=dict(\n            bearing=0,\n            center=go.layout.mapbox.Center(\n                lat=40.67,\n                lon=-73.90\n            ),\n            pitch=0,\n            zoom=9\n        ),\n    )\n\n    return fig\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n\ndemo.launch()\n```\n\n## Step 4 - Deployment ü§ó\n\nIf you run the code above, your app will start running locally.\nYou can even get a temporary shareable link by passing the `share=True` parameter to `launch`.\n\nBut what if you want to a permanent deployment solution?\nLet's deploy our Gradio app to the free HuggingFace Spaces platform.\n\nIf you haven't used Spaces before, follow the previous guide [here](/using_hugging_face_integrations).\n\n## Conclusion üéâ\n\nAnd you're all done! That's all the code you need to build a map demo.\n\nHere's a link to the demo [Map demo](https://huggingface.co/spaces/gradio/map_airbnb) and [complete code](https://huggingface.co/spaces/gradio/map_airbnb/blob/main/run.py) (on Hugging Face Spaces)\n",tags:["PLOTS","MAPS"],spaces:[],url:"/guides/plot-component-for-maps/",contributor:null}],parent:"gradio",prev_obj:"Number",next_obj:"Radio",slug:"plot"};a.radio={class:null,name:"Radio",description:"Creates a set of (string or numeric type) radio buttons of which only one can be selected. \u003Cbr>",tags:{preprocessing:"passes the value of the selected radio button as a {str} or {int} or {float} or its index as an {int} into the function, depending on `type`.",postprocessing:"expects a {str} or {int} or {float} corresponding to the value of the radio button to be selected.","examples-format":"a {str} representing the radio option to select.",demos:"sentence_builder, titanic_survival, blocks_essay"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"choices",annotation:"list[str | int | float | tuple[str, str | int | float]] | None",doc:"A list of string or numeric options to select from. An option can also be a tuple of the form (name, value), where name is the displayed name of the radio button and value is the value to be passed to the function, or returned by the function.",default:"None"},{name:"value",annotation:"str | int | float | Callable | None",doc:"The option selected by default. If None, no option is selected by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"type",annotation:"str",doc:"Type of value to be returned by component. &quot;value&quot; returns the string of the choice selected, &quot;index&quot; returns the index of the choice selected.",default:"\"value\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"Additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"Relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"Minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"If True, choices in this radio group will be selectable; if False, selection will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Radio. Uses event data gradio.SelectData to carry `value` referring to the label of the Radio, and `selected` to refer to state of the Radio. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Radio",slug:"radio-select"},{fn:null,name:"change",description:"Triggered when the value of the Radio changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Radio",slug:"radio-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Radio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Radio",slug:"radio-input"}],string_shortcuts:[["Radio","radio","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_essay","import gradio as gr\n\ncountries_cities_dict = {\n    \"USA\": [\"New York\", \"Los Angeles\", \"Chicago\"],\n    \"Canada\": [\"Toronto\", \"Montreal\", \"Vancouver\"],\n    \"Pakistan\": [\"Karachi\", \"Lahore\", \"Islamabad\"],\n}\n\n\ndef change_textbox(choice):\n    if choice == \"short\":\n        return gr.Textbox(lines=2, visible=True), gr.Button(interactive=True)\n    elif choice == \"long\":\n        return gr.Textbox(lines=8, visible=True, value=\"Lorem ipsum dolor sit amet\"), gr.Button(interactive=True)\n    else:\n        return gr.Textbox(visible=False), gr.Button(interactive=False)\n\n\nwith gr.Blocks() as demo:\n    radio = gr.Radio(\n        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n    )\n    text = gr.Textbox(lines=2, interactive=True, show_copy_button=True)\n\n    with gr.Row():\n        num = gr.Number(minimum=0, maximum=100, label=\"input\")\n        out = gr.Number(label=\"output\")\n    minimum_slider = gr.Slider(0, 100, 0, label=\"min\")\n    maximum_slider = gr.Slider(0, 100, 100, label=\"max\")\n    submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n\n    with gr.Row():\n        country = gr.Dropdown(list(countries_cities_dict.keys()), label=\"Country\")\n        cities = gr.Dropdown([], label=\"Cities\")\n        \n    @country.change(inputs=country, outputs=cities)\n    def update_cities(country):\n        cities = list(countries_cities_dict[country])\n        return gr.Dropdown(choices=cities, value=cities[0], interactive=True)\n\n    def reset_bounds(minimum, maximum):\n        return gr.Number(minimum=minimum, maximum=maximum)\n\n    radio.change(fn=change_textbox, inputs=radio, outputs=[text, submit_btn])\n    gr.on(\n        [minimum_slider.change, maximum_slider.change],\n        reset_bounds,\n        [minimum_slider, maximum_slider],\n        outputs=num,\n    )\n    num.submit(lambda x: x, num, out)\n\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Plot",next_obj:"ScatterPlot",slug:"radio"};a.scatterplot={class:null,name:"ScatterPlot",description:"Create a scatter plot. \u003Cbr> \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a pandas dataframe with the data to plot.",demos:"scatter_plot",guides:"creating-a-dashboard-from-bigquery-data"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Callable | None",doc:"The pandas dataframe containing the data to display in a scatter plot, or a callable. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"x",annotation:"str | None",doc:"Column corresponding to the x axis.",default:"None"},{name:"y",annotation:"str | None",doc:"Column corresponding to the y axis.",default:"None"},{name:"color",annotation:"str | None",doc:"The column to determine the point color. If the column contains numeric data, gradio will interpolate the column data so that small values correspond to light colors and large values correspond to dark values.",default:"None"},{name:"size",annotation:"str | None",doc:"The column used to determine the point size. Should contain numeric data so that gradio can map the data to the point size.",default:"None"},{name:"shape",annotation:"str | None",doc:"The column used to determine the point shape. Should contain categorical data. Gradio will map each unique value to a different shape.",default:"None"},{name:"title",annotation:"str | None",doc:"The title to display on top of the chart.",default:"None"},{name:"tooltip",annotation:"list[str] | str | None",doc:"The column (or list of columns) to display on the tooltip when a user hovers a point on the plot.",default:"None"},{name:"x_title",annotation:"str | None",doc:"The title given to the x-axis. By default, uses the value of the x parameter.",default:"None"},{name:"y_title",annotation:"str | None",doc:"The title given to the y-axis. By default, uses the value of the y parameter.",default:"None"},{name:"x_label_angle",annotation:"float | None",doc:" The angle for the x axis labels rotation. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"y_label_angle",annotation:"float | None",doc:" The angle for the y axis labels rotation. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"color_legend_title",annotation:"str | None",doc:"The title given to the color legend. By default, uses the value of color parameter.",default:"None"},{name:"size_legend_title",annotation:"str | None",doc:"The title given to the size legend. By default, uses the value of the size parameter.",default:"None"},{name:"shape_legend_title",annotation:"str | None",doc:"The title given to the shape legend. By default, uses the value of the shape parameter.",default:"None"},{name:"color_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the color legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"size_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the size legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"shape_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the shape legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"x_lim",annotation:"list[int | float] | None",doc:"A tuple or list containing the limits for the x-axis, specified as [x_min, x_max].",default:"None"},{name:"y_lim",annotation:"list[int | float] | None",doc:"A tuple of list containing the limits for the y-axis, specified as [y_min, y_max].",default:"None"},{name:"caption",annotation:"str | None",doc:"The (optional) caption to display below the plot.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether users should be able to interact with the plot by panning or zooming with their mouse or trackpad.",default:"True"},{name:"label",annotation:"str | None",doc:"The (optional) label to display on the top left corner of the plot.",default:"None"},{name:"every",annotation:"float | None",doc:" If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"Whether the label should be displayed.",default:"None"},{name:"container",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"None"},{name:"min_width",annotation:"int",doc:null,default:"160"},{name:"visible",annotation:"bool",doc:"Whether the plot should be visible.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"show_actions_button",annotation:"bool",doc:"Whether to show the actions button on the top right corner of the plot.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ScatterPlot",slug:"scatter-plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ScatterPlot",slug:"scatter-plot-clear"}],string_shortcuts:[["ScatterPlot","scatterplot","Uses default values"]],demos:[["scatter_plot","import gradio as gr\nfrom vega_datasets import data\n\ncars = data.cars()\niris = data.iris()\n\n# # Or generate your own fake data\n\n# import pandas as pd\n# import random\n\n# cars_data = {\n#     \"Name\": [\"car name \" + f\" {int(i/10)}\" for i in range(400)],\n#     \"Miles_per_Gallon\": [random.randint(10, 30) for _ in range(400)],\n#     \"Origin\": [random.choice([\"USA\", \"Europe\", \"Japan\"]) for _ in range(400)],\n#     \"Horsepower\": [random.randint(50, 250) for _ in range(400)],\n# }\n\n# iris_data = {\n#     \"petalWidth\": [round(random.uniform(0, 2.5), 2) for _ in range(150)],\n#     \"petalLength\": [round(random.uniform(0, 7), 2) for _ in range(150)],\n#     \"species\": [\n#         random.choice([\"setosa\", \"versicolor\", \"virginica\"]) for _ in range(150)\n#     ],\n# }\n\n# cars = pd.DataFrame(cars_data)\n# iris = pd.DataFrame(iris_data)\n\n\ndef scatter_plot_fn(dataset):\n    if dataset == \"iris\":\n        return gr.ScatterPlot(\n            value=iris,\n            x=\"petalWidth\",\n            y=\"petalLength\",\n            color=\"species\",\n            title=\"Iris Dataset\",\n            color_legend_title=\"Species\",\n            x_title=\"Petal Width\",\n            y_title=\"Petal Length\",\n            tooltip=[\"petalWidth\", \"petalLength\", \"species\"],\n            caption=\"\",\n        )\n    else:\n        return gr.ScatterPlot(\n            value=cars,\n            x=\"Horsepower\",\n            y=\"Miles_per_Gallon\",\n            color=\"Origin\",\n            tooltip=\"Name\",\n            title=\"Car Data\",\n            y_title=\"Miles per Gallon\",\n            color_legend_title=\"Origin of Car\",\n            caption=\"MPG vs Horsepower of various cars\",\n        )\n\n\nwith gr.Blocks() as scatter_plot:\n    with gr.Row():\n        with gr.Column():\n            dataset = gr.Dropdown(choices=[\"cars\", \"iris\"], value=\"cars\")\n        with gr.Column():\n            plot = gr.ScatterPlot()\n    dataset.change(scatter_plot_fn, inputs=dataset, outputs=plot)\n    scatter_plot.load(fn=scatter_plot_fn, inputs=dataset, outputs=plot)\n\nif __name__ == \"__main__\":\n    scatter_plot.launch()\n"]],guides:[{name:"creating-a-dashboard-from-bigquery-data",category:"tabular-data-science-and-plots",pretty_category:"Tabular Data Science And Plots",guide_index:null,absolute_index:33,pretty_name:"Creating A Dashboard From Bigquery Data",content:"# Creating a Real-Time Dashboard from BigQuery Data\n\n\n\n[Google BigQuery](https://cloud.google.com/bigquery) is a cloud-based service for processing very large data sets. It is a serverless and highly scalable data warehousing solution that enables users to analyze data [using SQL-like queries](https://www.oreilly.com/library/view/google-bigquery-the/9781492044451/ch01.html).\n\nIn this tutorial, we will show you how to query a BigQuery dataset in Python and display the data in a dashboard that updates in real time using `gradio`. The dashboard will look like this:\n\n\u003Cimg src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/bigquery-dashboard.gif\">\n\nWe'll cover the following steps in this Guide:\n\n1. Setting up your BigQuery credentials\n2. Using the BigQuery client\n3. Building the real-time dashboard (in just _7 lines of Python_)\n\nWe'll be working with the [New York Times' COVID dataset](https://www.nytimes.com/interactive/2021/us/covid-cases.html) that is available as a public dataset on BigQuery. The dataset, named `covid19_nyt.us_counties` contains the latest information about the number of confirmed cases and deaths from COVID across US counties.\n\n**Prerequisites**: This Guide uses [Gradio Blocks](/guides/quickstart/#blocks-more-flexibility-and-control), so make your are familiar with the Blocks class.\n\n## Setting up your BigQuery Credentials\n\nTo use Gradio with BigQuery, you will need to obtain your BigQuery credentials and use them with the [BigQuery Python client](https://pypi.org/project/google-cloud-bigquery/). If you already have BigQuery credentials (as a `.json` file), you can skip this section. If not, you can do this for free in just a couple of minutes.\n\n1. First, log in to your Google Cloud account and go to the Google Cloud Console (https://console.cloud.google.com/)\n\n2. In the Cloud Console, click on the hamburger menu in the top-left corner and select \"APIs & Services\" from the menu. If you do not have an existing project, you will need to create one.\n\n3. Then, click the \"+ Enabled APIs & services\" button, which allows you to enable specific services for your project. Search for \"BigQuery API\", click on it, and click the \"Enable\" button. If you see the \"Manage\" button, then the BigQuery is already enabled, and you're all set.\n\n4. In the APIs & Services menu, click on the \"Credentials\" tab and then click on the \"Create credentials\" button.\n\n5. In the \"Create credentials\" dialog, select \"Service account key\" as the type of credentials to create, and give it a name. Also grant the service account permissions by giving it a role such as \"BigQuery User\", which will allow you to run queries.\n\n6. After selecting the service account, select the \"JSON\" key type and then click on the \"Create\" button. This will download the JSON key file containing your credentials to your computer. It will look something like this:\n\n```json\n{\n\t\"type\": \"service_account\",\n\t\"project_id\": \"your project\",\n\t\"private_key_id\": \"your private key id\",\n\t\"private_key\": \"private key\",\n\t\"client_email\": \"email\",\n\t\"client_id\": \"client id\",\n\t\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n\t\"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n\t\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n\t\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/email_id\"\n}\n```\n\n## Using the BigQuery Client\n\nOnce you have the credentials, you will need to use the BigQuery Python client to authenticate using your credentials. To do this, you will need to install the BigQuery Python client by running the following command in the terminal:\n\n```bash\npip install google-cloud-bigquery[pandas]\n```\n\nYou'll notice that we've installed the pandas add-on, which will be helpful for processing the BigQuery dataset as a pandas dataframe. Once the client is installed, you can authenticate using your credentials by running the following code:\n\n```py\nfrom google.cloud import bigquery\n\nclient = bigquery.Client.from_service_account_json(\"path/to/key.json\")\n```\n\nWith your credentials authenticated, you can now use the BigQuery Python client to interact with your BigQuery datasets.\n\nHere is an example of a function which queries the `covid19_nyt.us_counties` dataset in BigQuery to show the top 20 counties with the most confirmed cases as of the current day:\n\n```py\nimport numpy as np\n\nQUERY = (\n    'SELECT * FROM `bigquery-public-data.covid19_nyt.us_counties` '\n    'ORDER BY date DESC,confirmed_cases DESC '\n    'LIMIT 20')\n\ndef run_query():\n    query_job = client.query(QUERY)\n    query_result = query_job.result()\n    df = query_result.to_dataframe()\n    # Select a subset of columns\n    df = df[[\"confirmed_cases\", \"deaths\", \"county\", \"state_name\"]]\n    # Convert numeric columns to standard numpy types\n    df = df.astype({\"deaths\": np.int64, \"confirmed_cases\": np.int64})\n    return df\n```\n\n## Building the Real-Time Dashboard\n\nOnce you have a function to query the data, you can use the `gr.DataFrame` component from the Gradio library to display the results in a tabular format. This is a useful way to inspect the data and make sure that it has been queried correctly.\n\nHere is an example of how to use the `gr.DataFrame` component to display the results. By passing in the `run_query` function to `gr.DataFrame`, we instruct Gradio to run the function as soon as the page loads and show the results. In addition, you also pass in the keyword `every` to tell the dashboard to refresh every hour (60\\*60 seconds).\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.DataFrame(run_query, every=60*60)\n\ndemo.queue().launch()  # Run the demo using queuing\n```\n\nPerhaps you'd like to add a visualization to our dashboard. You can use the `gr.ScatterPlot()` component to visualize the data in a scatter plot. This allows you to see the relationship between different variables such as case count and case deaths in the dataset and can be useful for exploring the data and gaining insights. Again, we can do this in real-time\nby passing in the `every` parameter.\n\nHere is a complete example showing how to use the `gr.ScatterPlot` to visualize in addition to displaying data with the `gr.DataFrame`\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# üíâ Covid Dashboard (Updated Hourly)\")\n    with gr.Row():\n        gr.DataFrame(run_query, every=60*60)\n        gr.ScatterPlot(run_query, every=60*60, x=\"confirmed_cases\",\n                        y=\"deaths\", tooltip=\"county\", width=500, height=500)\n\ndemo.queue().launch()  # Run the demo with queuing enabled\n```\n",tags:["TABULAR","DASHBOARD","PLOTS"],spaces:[],url:"/guides/creating-a-dashboard-from-bigquery-data/",contributor:null}],parent:"gradio",prev_obj:"Radio",next_obj:"Slider",slug:"scatter-plot"};a.slider={class:null,name:"Slider",description:"Creates a slider that ranges from {minimum} to {maximum} with a step size of {step}. \u003Cbr>",tags:{preprocessing:"passes slider value as a {float} into the function.",postprocessing:"expects an {int} or {float} returned from function and sets slider value to it as long as it is within range.","examples-format":"A {float} or {int} representing the slider&#x27;s value.",demos:"sentence_builder, slider_release, interface_random_slider, blocks_random_slider",guides:"create-your-own-friends-with-a-gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"minimum",annotation:"float",doc:"minimum value for slider.",default:"0"},{name:"maximum",annotation:"float",doc:"maximum value for slider.",default:"100"},{name:"value",annotation:"float | Callable | None",doc:"default value. If callable, the function will be called whenever the app loads to set the initial value of the component. Ignored if randomized=True.",default:"None"},{name:"step",annotation:"float | None",doc:"increment between slider values.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, slider will be adjustable; if False, adjusting will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"randomize",annotation:"bool",doc:"If True, the value of the slider when the app loads is taken uniformly at random from the range given by the minimum and maximum.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Slider changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Slider",slug:"slider-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Slider.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Slider",slug:"slider-input"},{fn:null,name:"release",description:"This listener is triggered when the user releases the mouse on this Slider.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Slider",slug:"slider-release"}],string_shortcuts:[["Slider","slider","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["slider_release","import gradio as gr\n\n\ndef identity(x, state):\n    state += 1\n    return x, state, state\n\n\nwith gr.Blocks() as demo:\n    slider = gr.Slider(0, 100, step=0.1)\n    state = gr.State(value=0)\n    with gr.Row():\n        number = gr.Number(label=\"On release\")\n        number2 = gr.Number(label=\"Number of events fired\")\n    slider.release(identity, inputs=[slider, state], outputs=[number, state, number2], api_name=\"predict\")\n\nif __name__ == \"__main__\":\n    print(\"here\")\n    demo.launch()\n    print(demo.server_port)\n"],["interface_random_slider","import gradio as gr\n\n\ndef func(slider_1, slider_2, *args):\n    return slider_1 + slider_2 * 5\n\n\ndemo = gr.Interface(\n    func,\n    [\n        gr.Slider(minimum=1.5, maximum=250000.89, randomize=True, label=\"Random Big Range\"),\n        gr.Slider(minimum=-1, maximum=1, randomize=True, step=0.05, label=\"Random only multiple of 0.05 allowed\"),\n        gr.Slider(minimum=0, maximum=1, randomize=True, step=0.25, label=\"Random only multiples of 0.25 allowed\"),\n        gr.Slider(minimum=-100, maximum=100, randomize=True, step=3, label=\"Random between -100 and 100 step 3\"),\n        gr.Slider(minimum=-100, maximum=100, randomize=True, label=\"Random between -100 and 100\"),\n        gr.Slider(value=0.25, minimum=5, maximum=30, step=-1),\n    ],\n    \"number\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_random_slider","\nimport gradio as gr\n\n\ndef func(slider_1, slider_2):\n    return slider_1 * 5 + slider_2\n\n\nwith gr.Blocks() as demo:\n    slider = gr.Slider(minimum=-10.2, maximum=15, label=\"Random Slider (Static)\", randomize=True)\n    slider_1 = gr.Slider(minimum=100, maximum=200, label=\"Random Slider (Input 1)\", randomize=True)\n    slider_2 = gr.Slider(minimum=10, maximum=23.2, label=\"Random Slider (Input 2)\", randomize=True)\n    slider_3 = gr.Slider(value=3, label=\"Non random slider\")\n    btn = gr.Button(\"Run\")\n    btn.click(func, inputs=[slider_1, slider_2], outputs=gr.Number())\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"create-your-own-friends-with-a-gan",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:44,pretty_name:"Create Your Own Friends With A Gan",content:"# Create Your Own Friends with a GAN\n\n\n\n\n\n\n## Introduction\n\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we'll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\n\nGenerative Adversarial Networks, often known just as _GANs_, are a specific class of deep-learning models that are designed to learn from an input dataset to create (_generate!_) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\n\nToday we'll briefly look at the high-level intuition behind GANs, and then we'll build a small demo around a pre-trained GAN to see what all the fuss is about. Here's a [peek](https://nimaboscarino-cryptopunks.hf.space) at what we're going to be putting together.\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\n\n## GANs: a very brief introduction\n\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the _generator_, is responsible for generating images. The other network, the _discriminator_, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\n\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (_adversarial!_) relationship, the images that get generated improve to the point where they become indistinguishable to human eyes!\n\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\n\n## Step 1 ‚Äî Create the Generator model\n\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\n\n```python\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\n\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n## Step 2 ‚Äî Defining a `predict` function\n\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it's common to pass random noise into our model as the input, so we'll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`'s `save_image` function to save the output of the model as a `png` file, and return the file name:\n\n```python\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWe're giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We'll then be able to reproduce punks if we want to see them again by passing in the same seed.\n\n_Note!_ Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we'll start by generating 4 punks at a time.\n\n## Step 3 ‚Äî Creating a Gradio interface\n\nAt this point you can even run the code you have with `predict(\u003CSOME_NUMBER>)`, and you'll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we'll build out a simple interface with Gradio. Our goals here are to:\n\n- Set a slider input so users can choose the \"seed\" value\n- Use an image component for our output to showcase the generated punks\n- Use our `predict()` to take the seed and generate the images\n\nWith `gr.Interface()`, we can define all of that with a single function call:\n\n```python\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n\n## Step 4 ‚Äî Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\n\n```python\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\n\n```python\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWhen you relaunch your interface, you should see a second slider that'll let you control the number of punks!\n\n## Step 5 - Polishing it up\n\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ‚ú®\n\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\n\n```python\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we've listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\n\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens üëÄ `article` will also accept HTML, as [explored in a previous guide](/guides/key-features/#descriptive-content)!\n\nWhen you're all done, you may end up with something like [this](https://nimaboscarino-cryptopunks.hf.space).\n\nFor reference, here is our full code:\n\n```python\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n---\n\nCongratulations! You've built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making even more awesome demos ü§ó\n",tags:["GAN","IMAGE","HUB"],spaces:["https://huggingface.co/spaces/NimaBoscarino/cryptopunks","https://huggingface.co/spaces/nateraw/cryptopunks-generator"],url:"/guides/create-your-own-friends-with-a-gan/",contributor:"\u003Ca href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino\u003C/a> and \u003Ca href=\"https://huggingface.co/nateraw\">Nate Raw\u003C/a>"}],parent:"gradio",prev_obj:"ScatterPlot",next_obj:"State",slug:"slider"};a.state={class:null,name:"State",description:"A base class for defining methods that all input/output components should have.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"Any",doc:"the initial value (of arbitrary type) of the state. The provided argument is deepcopied. If a callable is provided, the function will be called whenever the app loads to set the initial value of the state.",default:"None"},{name:"render",annotation:"bool",doc:"has no effect, but is included for consistency with other components.",default:"True"}],returns:{annotation:null},example:null,fns:[],parent:"gradio",prev_obj:"Slider",next_obj:"Textbox",slug:"state"};a.textbox={class:null,name:"Textbox",description:"Creates a textarea for user to enter string input or display string output. \u003Cbr>",tags:{preprocessing:"passes textarea value as a {str} into the function.",postprocessing:"expects a {str} returned from function and sets textarea value to it.","examples-format":"a {str} representing the textbox input.",demos:"hello_world, diff_texts, sentence_builder",guides:"creating-a-chatbot, real-time-speech-recognition"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable | None",doc:"default text to provide in textarea. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"\""},{name:"lines",annotation:"int",doc:"minimum number of line rows to provide in textarea.",default:"1"},{name:"max_lines",annotation:"int",doc:"maximum number of line rows to provide in textarea.",default:"20"},{name:"placeholder",annotation:"str | None",doc:"placeholder hint to provide behind textarea.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will be rendered as an editable textbox; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"autofocus",annotation:"bool",doc:"If True, will focus on the textbox when the page loads. Use this carefully, as it can cause usability issues for sighted and non-sighted users.",default:"False"},{name:"autoscroll",annotation:"bool",doc:"If True, will automatically scroll to the bottom of the textbox when the value changes, unless the user scrolls up. If False, will not scroll to the bottom of the textbox when the value changes.",default:"True"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"type",annotation:"Literal[('text', 'password', 'email')]",doc:"The type of textbox. One of: &#x27;text&#x27;, &#x27;password&#x27;, &#x27;email&#x27;, Default is &#x27;text&#x27;.",default:"\"text\""},{name:"text_align",annotation:"Literal[('left', 'right')] | None",doc:"How to align the text in the textbox, can be: &quot;left&quot;, &quot;right&quot;, or None (default). If None, the alignment is left if `rtl` is False, or right if `rtl` is True. Can only be changed if `type` is &quot;text&quot;.",default:"None"},{name:"rtl",annotation:"bool",doc:"If True and `type` is &quot;text&quot;, sets the direction of the text to right-to-left (cursor appears on the left of the text). Default is False, which renders cursor on the right.",default:"False"},{name:"show_copy_button",annotation:"bool",doc:"If True, includes a copy button to copy the text in the textbox. Only applies if show_label is True.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Textbox changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Textbox.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Textbox. Uses event data gradio.SelectData to carry `value` referring to the label of the Textbox, and `selected` to refer to state of the Textbox. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-select"},{fn:null,name:"submit",description:"This listener is triggered when the user presses the Enter key while the Textbox is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-submit"},{fn:null,name:"focus",description:"This listener is triggered when the Textbox is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-focus"},{fn:null,name:"blur",description:"This listener is triggered when the Textbox is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-blur"}],string_shortcuts:[["Textbox","textbox","Uses default values"],["TextArea","textarea","Uses lines=7"]],demos:[["hello_world","import gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \nif __name__ == \"__main__\":\n    demo.launch()   "],["diff_texts","from difflib import Differ\n\nimport gradio as gr\n\n\ndef diff_texts(text1, text2):\n    d = Differ()\n    return [\n        (token[2:], token[0] if token[0] != \" \" else None)\n        for token in d.compare(text1, text2)\n    ]\n\n\ndemo = gr.Interface(\n    diff_texts,\n    [\n        gr.Textbox(\n            label=\"Text 1\",\n            info=\"Initial text\",\n            lines=3,\n            value=\"The quick brown fox jumped over the lazy dogs.\",\n        ),\n        gr.Textbox(\n            label=\"Text 2\",\n            info=\"Text to compare\",\n            lines=3,\n            value=\"The fast brown fox jumps over lazy dogs.\",\n        ),\n    ],\n    gr.HighlightedText(\n        label=\"Diff\",\n        combine_adjacent=True,\n        show_legend=True,\n        color_map={\"+\": \"red\", \"-\": \"green\"}),\n    theme=gr.themes.Base()\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"real-time-speech-recognition",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:49,pretty_name:"Real Time Speech Recognition",content:"# Real Time Speech Recognition\n\n\n\n## Introduction\n\nAutomatic speech recognition (ASR), the conversion of spoken speech to text, is a very important and thriving area of machine learning. ASR algorithms run on practically every smartphone, and are becoming increasingly embedded in professional workflows, such as digital assistants for nurses and doctors. Because ASR algorithms are designed to be used directly by customers and end users, it is important to validate that they are behaving as expected when confronted with a wide variety of speech patterns (different accents, pitches, and background audio conditions).\n\nUsing `gradio`, you can easily build a demo of your ASR model and share that with a testing team, or test it yourself by speaking through the microphone on your device.\n\nThis tutorial will show how to take a pretrained speech-to-text model and deploy it with a Gradio interface. We will start with a **_full-context_** model, in which the user speaks the entire audio before the prediction runs. Then we will adapt the demo to make it **_streaming_**, meaning that the audio model will convert speech as you speak. \n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained speech recognition model. In this tutorial, we will build demos from 2 ASR libraries:\n\n- Transformers (for this, `pip install transformers` and `pip install torch`)\n\nMake sure you have at least one of these installed so that you can follow along the tutorial. You will also need `ffmpeg` [installed on your system](https://www.ffmpeg.org/download.html), if you do not already have it, to process files from the microphone.\n\nHere's how to build a real time speech recognition (ASR) app:\n\n1. [Set up the Transformers ASR Model](#1-set-up-the-transformers-asr-model)\n2. [Create a Full-Context ASR Demo with Transformers](#2-create-a-full-context-asr-demo-with-transformers)\n3. [Create a Streaming ASR Demo with Transformers](#3-create-a-streaming-asr-demo-with-transformers)\n\n## 1. Set up the Transformers ASR Model\n\nFirst, you will need to have an ASR model that you have either trained yourself or you will need to download a pretrained model. In this tutorial, we will start by using a pretrained ASR model from the model, `whisper`.\n\nHere is the code to load `whisper` from Hugging Face `transformers`.\n\n```python\nfrom transformers import pipeline\n\np = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n```\n\nThat's it!\n\n## 2. Create a Full-Context ASR Demo with Transformers\n\nWe will start by creating a _full-context_ ASR demo, in which the user speaks the full audio before using the ASR model to run inference. This is very easy with Gradio -- we simply create a function around the `pipeline` object above.\n\nWe will use `gradio`'s built in `Audio` component, configured to take input from the user's microphone and return a filepath for the recorded audio. The output component will be a plain `Textbox`.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(audio):\n    sr, y = audio\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    gr.Audio(sources=[\"microphone\"]),\n    \"text\",\n)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/asr'>\u003C/gradio-app>\n\nThe `transcribe` function takes a single parameter, `audio`, which is a numpy array of the audio the user recorded. The `pipeline` object expects this in float32 format, so we convert it first to float32, and then extract the transcribed text.\n\n## 3. Create a Streaming ASR Demo with Transformers\n\nTo make this a *streaming* demo, we need to make these changes:\n\n1. Set `streaming=True` in the `Audio` component\n2. Set `live=True` in the `Interface`\n3. Add a `state` to the interface to store the recorded audio of a user\n\nTake a look below.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(stream, new_chunk):\n    sr, y = new_chunk\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    if stream is not None:\n        stream = np.concatenate([stream, y])\n    else:\n        stream = y\n    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n    [\"state\", \"text\"],\n    live=True,\n)\n\ndemo.launch()\n\n```\n\nNotice now we have a state variable now, because we need to track all the audio history. `transcribe` gets called whenever there is a new small chunk of audio, but we also need to keep track of all the audio that has been spoken so far in state. \nAs the interface runs, the `transcribe` function gets called, with a record of all the previously spoken audio in `stream`, as well as the new chunk of audio as `new_chunk`. We return the new full audio so that can be stored back in state, and we also return the transcription.\nHere we naively append the audio together and simply call the `transcriber` object on the entire audio. You can imagine more efficient ways of handling this, such as re-processing only the last 5 seconds of audio whenever a new chunk of audio received. \n\n\u003Cgradio-app space='gradio/stream_asr'>\u003C/gradio-app>\n\nNow the ASR model will run inference as you speak! ",tags:["ASR","SPEECH","STREAMING"],spaces:[],url:"/guides/real-time-speech-recognition/",contributor:null}],parent:"gradio",prev_obj:"State",next_obj:"UploadButton",slug:"textbox"};a.uploadbutton={class:null,name:"UploadButton",description:"Used to create an upload button, when clicked allows a user to upload files that satisfy the specified file type or generic files (if file_type not set).",tags:{preprocessing:"passes the uploaded file as a {file-object} or {List[file-object]} depending on `file_count` (or a {bytes}/{List[bytes]} depending on `type`)",postprocessing:"expects function to return a {str} path to a file, or {List[str]} consisting of paths to files.","examples-format":"a {str} path to a local file that populates the component.",demos:"upload_button"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"label",annotation:"str",doc:"Text to display on the button. Defaults to &quot;Upload a File&quot;.",default:"\"Upload a File\""},{name:"value",annotation:"str | list[str] | Callable | None",doc:"File or list of files to upload by default.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:null,default:"None"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"},{name:"interactive",annotation:"bool",doc:"If False, the UploadButton will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"type",annotation:"Literal[('filepath', 'bytes')]",doc:"Type of value to be returned by component. &quot;file&quot; returns a temporary file object with the same base name as the uploaded file, whose full path can be retrieved by file_obj.name, &quot;binary&quot; returns an bytes object.",default:"\"filepath\""},{name:"file_count",annotation:"Literal[('single', 'multiple', 'directory')]",doc:"if single, allows user to upload one file. If &quot;multiple&quot;, user uploads multiple files. If &quot;directory&quot;, user uploads all files in selected directory. Return type will be list for each file in case of &quot;multiple&quot; or &quot;directory&quot;.",default:"\"single\""},{name:"file_types",annotation:"list[str] | None",doc:"List of type of files to be uploaded. &quot;file&quot; allows any file to be uploaded, &quot;image&quot; allows only image files to be uploaded, &quot;audio&quot; allows only audio files to be uploaded, &quot;video&quot; allows only video files to be uploaded, &quot;text&quot; allows only text files to be uploaded.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the UploadButton is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.UploadButton",slug:"upload-button-click"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the UploadButton.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.UploadButton",slug:"upload-button-upload"}],string_shortcuts:[["UploadButton","uploadbutton","Uses default values"]],demos:[["upload_button","import gradio as gr\n\ndef upload_file(files):\n    file_paths = [file.name for file in files]\n    return file_paths\n\nwith gr.Blocks() as demo:\n    file_output = gr.File()\n    upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"image\", \"video\"], file_count=\"multiple\")\n    upload_button.upload(upload_file, upload_button, file_output)\n\ndemo.launch()\n"]],parent:"gradio",prev_obj:"Textbox",next_obj:"Video",slug:"upload-button"};a.video={class:null,name:"Video",description:"Creates a video component that can be used to upload/record videos (as an input) or display videos (as an output). For the video to be playable in the browser it must have a compatible container and codec combination. Allowed combinations are .mp4 with h264 codec, .ogg with theora codec, and .webm with vp9 codec. If the component detects that the output video would not be playable in the browser it will attempt to convert it to a playable mp4 video. If the conversion fails, the original video is returned.",tags:{preprocessing:"passes the uploaded video as a {str} filepath or URL whose extension can be modified by `format`.",postprocessing:"expects a {str} or {pathlib.Path} filepath to a video which is displayed, or a {Tuple[str | pathlib.Path, str | pathlib.Path | None]} where the first element is a filepath to a video and the second element is an optional filepath to a subtitle file.","examples-format":"a {str} filepath to a local file that contains the video, or a {Tuple[str, str]} where the first element is a filepath to a video file and the second element is a filepath to a subtitle file.",demos:"video_identity, video_subtitle"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Path | tuple[str | Path, str | Path | None] | Callable | None",doc:"A path or URL for the default value that Video component is going to take. Can also be a tuple consisting of (video filepath, subtitle filepath). If a subtitle file is provided, it should be of type .srt or .vtt. Or can be callable, in which case the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"format",annotation:"str | None",doc:"Format of video format to be returned by component, such as &#x27;avi&#x27; or &#x27;mp4&#x27;. Use &#x27;mp4&#x27; to ensure browser playability. If set to None, video will keep uploaded format.",default:"None"},{name:"sources",annotation:"list[Literal[('upload', 'webcam')]] | None",doc:"A list of sources permitted for video. &quot;upload&quot; creates a box where user can drop an video file, &quot;webcam&quot; allows user to record a video from their webcam. If None, defaults to [&quot;upload, &quot;webcam&quot;].",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the displayed video, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the displayed video, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a video; if False, can only be used to display videos. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"mirror_webcam",annotation:"bool",doc:"If True webcam will be mirrored. Default is True.",default:"True"},{name:"include_audio",annotation:"bool | None",doc:"Whether the component should record/retain the audio track for a video. By default, audio is excluded for webcam videos and included for uploaded videos.",default:"None"},{name:"autoplay",annotation:"bool",doc:"Whether to automatically play the video when the component is used as an output. Note: browsers will not autoplay video files if the user has not interacted with the page yet.",default:"False"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"show_download_button",annotation:"bool | None",doc:"If True, will show a download icon in the corner of the component that allows user to download the output. If False, icon does not appear. By default, it will be True for output components and False for input components.",default:"None"},{name:"min_length",annotation:"int | None",doc:"The minimum length of video (in seconds) that the user can pass into the prediction function. If None, there is no minimum length.",default:"None"},{name:"max_length",annotation:"int | None",doc:"The maximum length of video (in seconds) that the user can pass into the prediction function. If None, there is no maximum length.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Video changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Video using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-clear"},{fn:null,name:"start_recording",description:"This listener is triggered when the user starts recording with the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-start-recording"},{fn:null,name:"stop_recording",description:"This listener is triggered when the user stops recording with the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-stop-recording"},{fn:null,name:"stop",description:"This listener is triggered when the user reaches the end of the media playing in the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-stop"},{fn:null,name:"play",description:"This listener is triggered when the user plays the media in the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-play"},{fn:null,name:"pause",description:"This listener is triggered when the media in the Video stops for any reason.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-pause"},{fn:null,name:"end",description:"This listener is triggered when the user reaches the end of the media playing in the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-end"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-upload"}],string_shortcuts:[["Video","video","Uses default values"],["PlayableVideo","playablevideo","Uses format=\"mp4\""]],demos:[["video_identity","import gradio as gr\nimport os\n\n\ndef video_identity(video):\n    return video\n\n\ndemo = gr.Interface(video_identity, \n                    gr.Video(), \n                    \"playable_video\", \n                    examples=[\n                        os.path.join(os.path.dirname(__file__), \n                                     \"video/video_sample.mp4\")], \n                    cache_examples=True)\n\nif __name__ == \"__main__\":\n    demo.launch()"],["video_subtitle","import gradio as gr\nimport os\n\na = os.path.join(os.path.dirname(__file__), \"files/a.mp4\")  # Video\nb = os.path.join(os.path.dirname(__file__), \"files/b.mp4\")  # Video\ns1 = os.path.join(os.path.dirname(__file__), \"files/s1.srt\")  # Subtitle\ns2 = os.path.join(os.path.dirname(__file__), \"files/s2.vtt\")  # Subtitle\n\n\ndef video_demo(video, subtitle=None):\n    if subtitle is None:\n        return video\n\n    return [video, subtitle.name]\n\n\ndemo = gr.Interface(\n    fn=video_demo,\n    inputs=[\n        gr.Video(label=\"In\", interactive=True),\n        gr.File(label=\"Subtitle\", file_types=[\".srt\", \".vtt\"]),\n    ],\n    outputs=gr.Video(label=\"Out\"),\n    examples=[\n        [a, s1],\n        [b, s2],\n        [a, None],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"UploadButton",next_obj:"load",slug:"video"};b.examples={class:null,name:"Examples",description:"This class is a wrapper over the Dataset component and can be used to create Examples for Blocks / Interfaces. Populates the Dataset component with examples and assigns event listener so that clicking on an example populates the input/output components. Optionally handles example caching for fast inference. \u003Cbr>",tags:{demos:"blocks_inputs, fake_gan",guides:"more-on-examples-and-flagging, using-hugging-face-integrations, image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers, create-your-own-friends-with-a-gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"examples",annotation:"list[Any] | list[list[Any]] | str",doc:"example inputs that can be clicked to populate specific components. Should be nested list, in which the outer list consists of samples and each inner list consists of an input corresponding to each input component. A string path to a directory of examples can also be provided but it should be within the directory with the python file running the gradio app. If there are multiple input components and a directory is provided, a log.csv file must be present in the directory to link corresponding inputs."},{name:"inputs",annotation:"Component | list[Component]",doc:"the component or list of components corresponding to the examples"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"optionally, provide the component or list of components corresponding to the output of the examples. Required if `cache_examples` is True.",default:"None"},{name:"fn",annotation:"Callable | None",doc:"optionally, provide the function to run to generate the outputs corresponding to the examples. Required if `cache_examples` is True.",default:"None"},{name:"cache_examples",annotation:"bool",doc:"if True, caches examples for fast runtime. If True, then `fn` and `outputs` must be provided. If `fn` is a generator function, then the last yielded value will be used as the output.",default:"False"},{name:"examples_per_page",annotation:"int",doc:"how many examples to show per page.",default:"10"},{name:"label",annotation:"str | None",doc:"the label to use for the examples component (by default, &quot;Examples&quot;)",default:"\"Examples\""},{name:"elem_id",annotation:"str | None",doc:"an optional string that is assigned as the id of this component in the HTML DOM.",default:"None"},{name:"run_on_click",annotation:"bool",doc:"if cache_examples is False, clicking on an example does not run the function when an example is clicked. Set this to True to run the function when an example is clicked. Has no effect if cache_examples is True.",default:"False"},{name:"preprocess",annotation:"bool",doc:"if True, preprocesses the example input before running the prediction function and caching the output. Only applies if `cache_examples` is True.",default:"True"},{name:"postprocess",annotation:"bool",doc:"if True, postprocesses the example output after running the prediction function and before caching. Only applies if `cache_examples` is True.",default:"True"},{name:"api_name",annotation:"str | Literal[False]",doc:"Defines how the event associated with clicking on the examples appears in the API docs. Can be a string or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use the example function.",default:"\"load_example\""},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. Used only if cache_examples is True.",default:"False"}],returns:{annotation:null},example:null,fns:[],demos:[["blocks_inputs","import gradio as gr\nimport os\n\n\ndef combine(a, b):\n    return a + \" \" + b\n\n\ndef mirror(x):\n    return x\n\n\nwith gr.Blocks() as demo:\n\n    txt = gr.Textbox(label=\"Input\", lines=2)\n    txt_2 = gr.Textbox(label=\"Input 2\")\n    txt_3 = gr.Textbox(value=\"\", label=\"Output\")\n    btn = gr.Button(value=\"Submit\")\n    btn.click(combine, inputs=[txt, txt_2], outputs=[txt_3])\n\n    with gr.Row():\n        im = gr.Image()\n        im_2 = gr.Image()\n\n    btn = gr.Button(value=\"Mirror Image\")\n    btn.click(mirror, inputs=[im], outputs=[im_2])\n\n    gr.Markdown(\"## Text Examples\")\n    gr.Examples(\n        [[\"hi\", \"Adam\"], [\"hello\", \"Eve\"]],\n        [txt, txt_2],\n        txt_3,\n        combine,\n        cache_examples=True,\n    )\n    gr.Markdown(\"## Image Examples\")\n    gr.Examples(\n        examples=[os.path.join(os.path.dirname(__file__), \"lion.jpg\")],\n        inputs=im,\n        outputs=im_2,\n        fn=mirror,\n        cache_examples=True,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["fake_gan","# This demo needs to be run from the repo folder.\n# python demo/fake_gan/run.py\nimport random\n\nimport gradio as gr\n\n\ndef fake_gan():\n    images = [\n        (random.choice(\n            [\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1151ce9f4b2043de0d2e3b7826127998.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-116b5e92936b766b7fdfc242649337f7.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1163530ca19b5cebe1b002b8ec67b6fc.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1116395d6e6a6581eef8b8038f4c8e55.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-11319be65db395d0e8e6855d18ddcef0.jpg\",\n            ]\n        ), f\"label {i}\")\n        for i in range(3)\n    ]\n    return images\n\n\nwith gr.Blocks() as demo:\n    gallery = gr.Gallery(\n        label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n    , columns=[3], rows=[1], object_fit=\"contain\", height=\"auto\")\n    btn = gr.Button(\"Generate images\", scale=0)\n\n    btn.click(fake_gan, None, gallery)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"using-hugging-face-integrations",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:1,absolute_index:25,pretty_name:"Using Hugging Face Integrations",content:"# Using Hugging Face Integrations\n\n\n\n\n\n\n## Introduction\n\nThe Hugging Face Hub is a central platform that has hundreds of thousands of [models](https://huggingface.co/models), [datasets](https://huggingface.co/datasets) and [demos](https://huggingface.co/spaces) (also known as Spaces). \n\nGradio has multiple features that make it extremely easy to leverage existing models and Spaces on the Hub. This guide walks through these features.\n\n\n## Demos with the Hugging Face Inference API\n\nHugging Face has a free service called the [Inference API](https://huggingface.co/inference-api), which allows you to send HTTP requests to models in the Hub. For transformers or diffusers-based models, the API can be 2 to 10 times faster than running the inference yourself. The API is free (rate limited), and you can switch to dedicated [Inference Endpoints](https://huggingface.co/pricing) when you want to use it in production. Gradio integrates directly with the Hugging Face Inference API so that you can create a demo simply by specifying a model's name (e.g. `Helsinki-NLP/opus-mt-en-es`), like this:\n\n```python\nimport gradio as gr\n\ndemo = gr.load(\"Helsinki-NLP/opus-mt-en-es\", src=\"models\")\n\ndemo.launch()\n```\n\nFor any Hugging Face model supported in the Inference API, Gradio automatically infers the expected input and output and make the underlying server calls, so you don't have to worry about defining the prediction function. \n\nNotice that we just put specify the model name and state that the `src` should be `models` (Hugging Face's Model Hub). There is no need to install any dependencies (except `gradio`) since you are not loading the model on your computer.\n\nYou might notice that the first inference takes about 20 seconds. This happens since the Inference API is loading the model in the server. You get some benefits afterward:\n\n- The inference will be much faster.\n- The server caches your requests.\n- You get built-in automatic scaling.\n\n## Hosting your Gradio demos on Spaces\n\n[Hugging Face Spaces](https://hf.co/spaces) allows anyone to host their Gradio demos freely, and uploading your Gradio demos take a couple of minutes. You can head to [hf.co/new-space](https://huggingface.co/new-space), select the Gradio SDK, create an `app.py` file, and voila! You have a demo you can share with anyone else. To learn more, read [this guide how to host on Hugging Face Spaces using the website](https://huggingface.co/blog/gradio-spaces).\n\nAlternatively, you can create a Space programmatically, making use of the [huggingface_hub client library](https://huggingface.co/docs/huggingface_hub/index) library. Here's an example:\n\n```python\nfrom huggingface_hub import (\n    create_repo,\n    get_full_repo_name,\n    upload_file,\n)\ncreate_repo(name=target_space_name, token=hf_token, repo_type=\"space\", space_sdk=\"gradio\")\nrepo_name = get_full_repo_name(model_id=target_space_name, token=hf_token)\nfile_url = upload_file(\n    path_or_fileobj=\"file.txt\",\n    path_in_repo=\"app.py\",\n    repo_id=repo_name,\n    repo_type=\"space\",\n    token=hf_token,\n)\n```\n\nHere, `create_repo` creates a gradio repo with the target name under a specific account using that account's Write Token. `repo_name` gets the full repo name of the related repo. Finally `upload_file` uploads a file inside the repo with the name `app.py`.\n\n\n## Loading demos from Spaces\n\nYou can also use and remix existing Gradio demos on Hugging Face Spaces. For example, you could take two existing Gradio demos on Spaces and put them as separate tabs and create a new demo. You can run this new demo locally, or upload it to Spaces, allowing endless possibilities to remix and create new demos!\n\nHere's an example that does exactly that:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n  with gr.Tab(\"Translate to Spanish\"):\n    gr.load(\"gradio/en2es\", src=\"spaces\")\n  with gr.Tab(\"Translate to French\"):\n    gr.load(\"abidlabs/en2fr\", src=\"spaces\")\n\ndemo.launch()\n```\n\nNotice that we use `gr.load()`, the same method we used to load models using the Inference API. However, here we specify that the `src` is `spaces` (Hugging Face Spaces). \n\nNote: loading a Space in this way may result in slight differences from the original Space. In particular, any attributes that apply to the entire Blocks, such as the theme or custom CSS/JS, will not be loaded. You can copy these properties from the Space you are loading into your own `Blocks` object. \n\n## Demos with the `Pipeline` in `transformers`\n\nHugging Face's popular `transformers` library has a very easy-to-use abstraction, [`pipeline()`](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/pipelines#transformers.pipeline) that handles most of the complex code to offer a simple API for common tasks. By specifying the task and an (optional) model, you can build a demo around an existing model with few lines of Python:\n\n```python\nimport gradio as gr\n\nfrom transformers import pipeline\n\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ndef predict(text):\n  return pipe(text)[0][\"translation_text\"]\n\ndemo = gr.Interface(\n  fn=predict,\n  inputs='text',\n  outputs='text',\n)\n\ndemo.launch()\n```\n\nBut `gradio` actually makes it even easier to convert a `pipeline` to a demo, simply by using the `gradio.Interface.from_pipeline` methods, which skips the need to specify the input and output components:\n\n```python\nfrom transformers import pipeline\nimport gradio as gr\n\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ndemo = gr.Interface.from_pipeline(pipe)\ndemo.launch()\n```\n\nThe previous code produces the following interface, which you can try right here in your browser:\n\n\u003Cgradio-app space=\"gradio/en2es\">\u003C/gradio-app>\n\n\n## Recap\n\nThat's it! Let's recap the various ways Gradio and Hugging Face work together:\n\n1. You can build a demo around the Inference API without having to load the model easily using `gr.load()`.\n2. You host your Gradio demo on Hugging Face Spaces, either using the GUI or entirely in Python.\n3. You can load demos from Hugging Face Spaces to remix and create new Gradio demos using `gr.load()`.\n4. You can convert a `transformers` pipeline into a Gradio demo using `from_pipeline()`.\n\nü§ó\n",tags:["HUB","SPACES","EMBED"],spaces:["https://huggingface.co/spaces/gradio/en2es"],url:"/guides/using-hugging-face-integrations/",contributor:"\u003Ca href=\"https://huggingface.co/osanseviero\">Omar Sanseviero\u003C/a> ü¶ô"},{name:"image-classification-in-pytorch",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:29,pretty_name:"Image Classification In Pytorch",content:"# Image Classification in PyTorch\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own.\n\n```python\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\nBecause we will be using the model for inference, we have called the `.eval()` method.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `PIL` image\n\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image.\n\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/pytorch-image-classifier\">\n\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","RESNET","PYTORCH"],spaces:["https://huggingface.co/spaces/abidlabs/pytorch-image-classifier","https://huggingface.co/spaces/pytorch/ResNet","https://huggingface.co/spaces/pytorch/ResNext","https://huggingface.co/spaces/pytorch/SqueezeNet"],url:"/guides/image-classification-in-pytorch/",contributor:null},{name:"image-classification-in-tensorflow",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:30,pretty_name:"Image Classification In Tensorflow",content:"# Image Classification in TensorFlow and Keras\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own.\n\n```python\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\nThis line automatically downloads the MobileNet model and weights using the Keras library.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `numpy` array\n\nThen, the function adds a batch dimension, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(shape=(224, 224)),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/keras-image-classifier\">\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","MOBILENET","TENSORFLOW"],spaces:["https://huggingface.co/spaces/abidlabs/keras-image-classifier"],url:"/guides/image-classification-in-tensorflow/",contributor:null},{name:"image-classification-with-vision-transformers",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:31,pretty_name:"Image Classification With Vision Transformers",content:"# Image Classification with Vision Transformers\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control.\n\nState-of-the-art image classifiers are based on the _transformers_ architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started).\n\n## Step 1 ‚Äî Choosing a Vision Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks.\n\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\n\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at a resolution of 224x224 pixels. We will use this model for our demo.\n\n## Step 2 ‚Äî Loading the Vision Transformer Model with Gradio\n\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing.\nAll of these are automatically inferred from the model tags.\n\nBesides the import statement, it only takes a single line of Python to load and launch the demo.\n\nWe use the `gr.Interface.load()` method and pass in the path to the model including the `huggingface/` to designate that it is from the Hugging Face Hub.\n\n```python\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples.\n\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a human-interpretable prediction. Try uploading your own image!\n\n\u003Cgradio-app space=\"gradio/vision-transformer\">\n\n---\n\nAnd you're done! In one line of code, you have built a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","TRANSFORMERS","HUB"],spaces:["https://huggingface.co/spaces/abidlabs/vision-transformer"],url:"/guides/image-classification-with-vision-transformers/",contributor:null},{name:"create-your-own-friends-with-a-gan",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:44,pretty_name:"Create Your Own Friends With A Gan",content:"# Create Your Own Friends with a GAN\n\n\n\n\n\n\n## Introduction\n\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we'll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\n\nGenerative Adversarial Networks, often known just as _GANs_, are a specific class of deep-learning models that are designed to learn from an input dataset to create (_generate!_) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\n\nToday we'll briefly look at the high-level intuition behind GANs, and then we'll build a small demo around a pre-trained GAN to see what all the fuss is about. Here's a [peek](https://nimaboscarino-cryptopunks.hf.space) at what we're going to be putting together.\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\n\n## GANs: a very brief introduction\n\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the _generator_, is responsible for generating images. The other network, the _discriminator_, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\n\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (_adversarial!_) relationship, the images that get generated improve to the point where they become indistinguishable to human eyes!\n\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\n\n## Step 1 ‚Äî Create the Generator model\n\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\n\n```python\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\n\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n## Step 2 ‚Äî Defining a `predict` function\n\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it's common to pass random noise into our model as the input, so we'll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`'s `save_image` function to save the output of the model as a `png` file, and return the file name:\n\n```python\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWe're giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We'll then be able to reproduce punks if we want to see them again by passing in the same seed.\n\n_Note!_ Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we'll start by generating 4 punks at a time.\n\n## Step 3 ‚Äî Creating a Gradio interface\n\nAt this point you can even run the code you have with `predict(\u003CSOME_NUMBER>)`, and you'll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we'll build out a simple interface with Gradio. Our goals here are to:\n\n- Set a slider input so users can choose the \"seed\" value\n- Use an image component for our output to showcase the generated punks\n- Use our `predict()` to take the seed and generate the images\n\nWith `gr.Interface()`, we can define all of that with a single function call:\n\n```python\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n\n## Step 4 ‚Äî Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\n\n```python\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\n\n```python\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWhen you relaunch your interface, you should see a second slider that'll let you control the number of punks!\n\n## Step 5 - Polishing it up\n\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ‚ú®\n\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\n\n```python\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we've listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\n\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens üëÄ `article` will also accept HTML, as [explored in a previous guide](/guides/key-features/#descriptive-content)!\n\nWhen you're all done, you may end up with something like [this](https://nimaboscarino-cryptopunks.hf.space).\n\nFor reference, here is our full code:\n\n```python\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n---\n\nCongratulations! You've built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making even more awesome demos ü§ó\n",tags:["GAN","IMAGE","HUB"],spaces:["https://huggingface.co/spaces/NimaBoscarino/cryptopunks","https://huggingface.co/spaces/nateraw/cryptopunks-generator"],url:"/guides/create-your-own-friends-with-a-gan/",contributor:"\u003Ca href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino\u003C/a> and \u003Ca href=\"https://huggingface.co/nateraw\">Nate Raw\u003C/a>"}],parent:"gradio",prev_obj:"Video",next_obj:"Progress",slug:"examples"};b.progress={class:null,name:"Progress",description:"The Progress class provides a custom progress tracker that is used in a function signature. To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a \u003Ccode class='text-orange-500' style='font-family: monospace; font-size: large;'>gradio.Progress()\u003C/code> instance. The Progress tracker can then be updated in the function by calling the Progress object or using the \u003Ccode class='text-orange-500' style='font-family: monospace; font-size: large;'>tqdm\u003C/code> method on an Iterable. The Progress tracker is currently only available with \u003Ccode class='text-orange-500' style='font-family: monospace; font-size: large;'>queue()\u003C/code>.",tags:{demos:"progress"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"track_tqdm",annotation:"bool",doc:"If True, the Progress object will track any tqdm.tqdm iterations with the tqdm library in the function.",default:"False"}],returns:{annotation:null},example:"import gradio as gr\nimport time\ndef my_function(x, progress=gr.Progress()):\n    progress(0, desc=\"Starting...\")\n    time.sleep(1)\n    for i in progress.tqdm(range(100)):\n        time.sleep(0.1)\n    return x\ngr.Interface(my_function, gr.Textbox(), gr.Textbox()).queue().launch()",fns:[{fn:null,name:"__call__",description:"Updates progress tracker with progress and message text.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"progress",annotation:"float | tuple[int, int | None] | None",doc:"If float, should be between 0 and 1 representing completion. If Tuple, first number represents steps completed, and second value represents total steps or None if unknown. If None, hides progress bar."},{name:"desc",annotation:"str | None",doc:"description to display.",default:"None"},{name:"total",annotation:"int | None",doc:"estimated total number of steps.",default:"None"},{name:"unit",annotation:"str",doc:"unit of iterations.",default:"\"steps\""}],returns:{},example:null,override_signature:null,parent:"gradio.Progress",slug:"progress-call"},{fn:null,name:"tqdm",description:"Attaches progress tracker to iterable, like tqdm.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"iterable",annotation:"Iterable | None",doc:"iterable to attach progress tracker to."},{name:"desc",annotation:"str | None",doc:"description to display.",default:"None"},{name:"total",annotation:"int | None",doc:"estimated total number of steps.",default:"None"},{name:"unit",annotation:"str",doc:"unit of iterations.",default:"\"steps\""}],returns:{},example:null,override_signature:null,parent:"gradio.Progress",slug:"progress-tqdm"}],demos:[["progress","import gradio as gr\nimport random\nimport time\nimport tqdm\nfrom datasets import load_dataset\nimport shutil\nfrom uuid import uuid4\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text = gr.Textbox()\n        textb = gr.Textbox()\n    with gr.Row():\n        load_set_btn = gr.Button(\"Load Set\")\n        load_nested_set_btn = gr.Button(\"Load Nested Set\")\n        load_random_btn = gr.Button(\"Load Random\")\n        clean_imgs_btn = gr.Button(\"Clean Images\")\n        wait_btn = gr.Button(\"Wait\")\n        do_all_btn = gr.Button(\"Do All\")\n        track_tqdm_btn = gr.Button(\"Bind TQDM\")\n        bind_internal_tqdm_btn = gr.Button(\"Bind Internal TQDM\")\n\n    text2 = gr.Textbox()\n\n    # track list\n    def load_set(text, text2, progress=gr.Progress()):\n        imgs = [None] * 24\n        for img in progress.tqdm(imgs, desc=\"Loading from list\"):\n            time.sleep(0.1)\n        return \"done\"\n    load_set_btn.click(load_set, [text, textb], text2)\n\n    # track nested list\n    def load_nested_set(text, text2, progress=gr.Progress()):\n        imgs = [[None] * 8] * 3\n        for img_set in progress.tqdm(imgs, desc=\"Nested list\"):\n            time.sleep(2)\n            for img in progress.tqdm(img_set, desc=\"inner list\"):\n                time.sleep(0.1)\n        return \"done\"\n    load_nested_set_btn.click(load_nested_set, [text, textb], text2)\n\n    # track iterable of unknown length\n    def load_random(data, progress=gr.Progress()):\n        def yielder():\n            for i in range(0, random.randint(15, 20)):\n                time.sleep(0.1)\n                yield None\n        for img in progress.tqdm(yielder()):\n            pass\n        return \"done\"\n    load_random_btn.click(load_random, {text, textb}, text2)\n        \n    # manual progress\n    def clean_imgs(text, progress=gr.Progress()):\n        progress(0.2, desc=\"Collecting Images\")\n        time.sleep(1)\n        progress(0.5, desc=\"Cleaning Images\")\n        time.sleep(1.5)\n        progress(0.8, desc=\"Sending Images\")\n        time.sleep(1.5)\n        return \"done\"\n    clean_imgs_btn.click(clean_imgs, text, text2)\n\n    # no progress\n    def wait(text):\n        time.sleep(4)\n        return \"done\"\n    wait_btn.click(wait, text, text2)\n\n    # multiple progressions\n    def do_all(data, progress=gr.Progress()):\n        load_set(data[text], data[textb], progress)\n        load_random(data, progress)\n        clean_imgs(data[text], progress)\n        progress(None)\n        wait(text)\n        return \"done\"\n    do_all_btn.click(do_all, {text, textb}, text2)\n\n    def track_tqdm(data, progress=gr.Progress(track_tqdm=True)):\n        for i in tqdm.tqdm(range(5), desc=\"outer\"):\n            for j in tqdm.tqdm(range(4), desc=\"inner\"):\n                time.sleep(1)\n        return \"done\"\n    track_tqdm_btn.click(track_tqdm, {text, textb}, text2)\n\n    def bind_internal_tqdm(data, progress=gr.Progress(track_tqdm=True)):\n        outdir = \"__tmp/\" + str(uuid4())\n        load_dataset(\"beans\", split=\"train\", cache_dir=outdir)\n        shutil.rmtree(outdir)\n        return \"done\"\n    bind_internal_tqdm_btn.click(bind_internal_tqdm, {text, textb}, text2)\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n","\u003Cspan class=\"token keyword\">import\u003C/span> gradio \u003Cspan class=\"token keyword\">as\u003C/span> gr\n\u003Cspan class=\"token keyword\">import\u003C/span> random\n\u003Cspan class=\"token keyword\">import\u003C/span> time\n\u003Cspan class=\"token keyword\">import\u003C/span> tqdm\n\u003Cspan class=\"token keyword\">from\u003C/span> datasets \u003Cspan class=\"token keyword\">import\u003C/span> load_dataset\n\u003Cspan class=\"token keyword\">import\u003C/span> shutil\n\u003Cspan class=\"token keyword\">from\u003C/span> uuid \u003Cspan class=\"token keyword\">import\u003C/span> uuid4\n\n\u003Cspan class=\"token keyword\">with\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Blocks\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span> \u003Cspan class=\"token keyword\">as\u003C/span> demo\u003Cspan class=\"token punctuation\">:\u003C/span>\n    \u003Cspan class=\"token keyword\">with\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Row\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        text \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        textb \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    \u003Cspan class=\"token keyword\">with\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Row\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        load_set_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Load Set\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_nested_set_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Load Nested Set\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_random_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Load Random\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        clean_imgs_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Clean Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        wait_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Wait\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        do_all_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Do All\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        track_tqdm_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Bind TQDM\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        bind_internal_tqdm_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Bind Internal TQDM\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    text2 \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># track list\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">load_set\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        imgs \u003Cspan class=\"token operator\">=\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>\u003Cspan class=\"token boolean\">None\u003C/span>\u003Cspan class=\"token punctuation\">]\u003C/span> \u003Cspan class=\"token operator\">*\u003C/span> \u003Cspan class=\"token number\">24\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> img \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>imgs\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Loading from list\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    load_set_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>load_set\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># track nested list\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">load_nested_set\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        imgs \u003Cspan class=\"token operator\">=\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>\u003Cspan class=\"token punctuation\">[\u003C/span>\u003Cspan class=\"token boolean\">None\u003C/span>\u003Cspan class=\"token punctuation\">]\u003C/span> \u003Cspan class=\"token operator\">*\u003C/span> \u003Cspan class=\"token number\">8\u003C/span>\u003Cspan class=\"token punctuation\">]\u003C/span> \u003Cspan class=\"token operator\">*\u003C/span> \u003Cspan class=\"token number\">3\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> img_set \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>imgs\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Nested list\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">2\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n            \u003Cspan class=\"token keyword\">for\u003C/span> img \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>img_set\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"inner list\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n                time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    load_nested_set_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>load_nested_set\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># track iterable of unknown length\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">load_random\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">yielder\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            \u003Cspan class=\"token keyword\">for\u003C/span> i \u003Cspan class=\"token keyword\">in\u003C/span> \u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> random\u003Cspan class=\"token punctuation\">.\u003C/span>randint\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">15\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token number\">20\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n                time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n                \u003Cspan class=\"token keyword\">yield\u003C/span> \u003Cspan class=\"token boolean\">None\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> img \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>yielder\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            \u003Cspan class=\"token keyword\">pass\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    load_random_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>load_random\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \n    \u003Cspan class=\"token comment\"># manual progress\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">clean_imgs\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.2\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Collecting Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.5\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Cleaning Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1.5\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.8\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Sending Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1.5\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    clean_imgs_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>clean_imgs\u003Cspan class=\"token punctuation\">,\u003C/span> text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># no progress\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">wait\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">4\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    wait_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>wait\u003Cspan class=\"token punctuation\">,\u003C/span> text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># multiple progressions\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">do_all\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        load_set\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> data\u003Cspan class=\"token punctuation\">[\u003C/span>textb\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_random\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token punctuation\">)\u003C/span>\n        clean_imgs\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token punctuation\">)\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token boolean\">None\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        wait\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    do_all_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>do_all\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">track_tqdm\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>track_tqdm\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token boolean\">True\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> i \u003Cspan class=\"token keyword\">in\u003C/span> tqdm\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">5\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"outer\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            \u003Cspan class=\"token keyword\">for\u003C/span> j \u003Cspan class=\"token keyword\">in\u003C/span> tqdm\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">4\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"inner\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n                time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    track_tqdm_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>track_tqdm\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">bind_internal_tqdm\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>track_tqdm\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token boolean\">True\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        outdir \u003Cspan class=\"token operator\">=\u003C/span> \u003Cspan class=\"token string\">\"__tmp/\"\u003C/span> \u003Cspan class=\"token operator\">+\u003C/span> \u003Cspan class=\"token builtin\">str\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>uuid4\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_dataset\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"beans\"\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> split\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"train\"\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> cache_dir\u003Cspan class=\"token operator\">=\u003C/span>outdir\u003Cspan class=\"token punctuation\">)\u003C/span>\n        shutil\u003Cspan class=\"token punctuation\">.\u003C/span>rmtree\u003Cspan class=\"token punctuation\">(\u003C/span>outdir\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    bind_internal_tqdm_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>bind_internal_tqdm\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n\n\u003Cspan class=\"token keyword\">if\u003C/span> __name__ \u003Cspan class=\"token operator\">==\u003C/span> \u003Cspan class=\"token string\">\"__main__\"\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n    demo\u003Cspan class=\"token punctuation\">.\u003C/span>launch\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n"]],parent:"gradio",prev_obj:"Examples",next_obj:"make_waveform",slug:"progress",highlighted_example:"\u003Cspan class=\"token keyword\">import\u003C/span> gradio \u003Cspan class=\"token keyword\">as\u003C/span> gr\n\u003Cspan class=\"token keyword\">import\u003C/span> time\n\u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">my_function\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>x\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n    progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Starting...\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    \u003Cspan class=\"token keyword\">for\u003C/span> i \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">100\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    \u003Cspan class=\"token keyword\">return\u003C/span> x\ngr\u003Cspan class=\"token punctuation\">.\u003C/span>Interface\u003Cspan class=\"token punctuation\">(\u003C/span>my_function\u003Cspan class=\"token punctuation\">,\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">.\u003C/span>queue\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">.\u003C/span>launch\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>"};b.make_waveform={class:null,name:"make_waveform",description:"Generates a waveform video from an audio file. Useful for creating an easy to share audio visualization. The output should be passed into a `gr.Video` component.",tags:{parameters:"audio: Audio file path or tuple of (sample_rate, audio_data)\u003Cbr>bg_color: Background color of waveform (ignored if bg_image is provided)\u003Cbr>bg_image: Background image of waveform\u003Cbr>fg_alpha: Opacity of foreground waveform\u003Cbr>bars_color: Color of waveform bars. Can be a single color or a tuple of (start_color, end_color) of gradient\u003Cbr>bar_count: Number of bars in waveform\u003Cbr>bar_width: Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.\u003Cbr>animate: If true, the audio waveform overlay will be animated, if false, it will be static.",returns:"A filepath to the output video in mp4 format."},parameters:[{name:"audio",annotation:"str | tuple[int, np.ndarray]",doc:"Audio file path or tuple of (sample_rate, audio_data)"},{name:"bg_color",annotation:"str",doc:"Background color of waveform (ignored if bg_image is provided)",default:"\"#f3f4f6\""},{name:"bg_image",annotation:"str | None",doc:"Background image of waveform",default:"None"},{name:"fg_alpha",annotation:"float",doc:"Opacity of foreground waveform",default:"0.75"},{name:"bars_color",annotation:"str | tuple[str, str]",doc:"Color of waveform bars. Can be a single color or a tuple of (start_color, end_color) of gradient",default:"('#fbbf24', '#ea580c')"},{name:"bar_count",annotation:"int",doc:"Number of bars in waveform",default:"50"},{name:"bar_width",annotation:"float",doc:"Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.",default:"0.6"},{name:"animate",annotation:"bool",doc:"If true, the audio waveform overlay will be animated, if false, it will be static.",default:"False"}],returns:{annotation:null,doc:"A filepath to the output video in mp4 format."},example:null,fns:[],parent:"gradio",prev_obj:"Progress",next_obj:"load",slug:"make-waveform"};b.load={class:null,name:"load",description:"Method that constructs a Blocks from a Hugging Face repo. Can accept model repos (if src is \"models\") or Space repos (if src is \"spaces\"). The input and output components are automatically loaded from the repo.",tags:{parameters:"name: the name of the model (e.g. \"gpt2\" or \"facebook/bart-base\") or space (e.g. \"flax-community/spanish-gpt2\"), can include the `src` as prefix (e.g. \"models/facebook/bart-base\")\u003Cbr>src: the source of the model: `models` or `spaces` (or leave empty if source is provided as a prefix in `name`)\u003Cbr>hf_token: optional access token for loading private Hugging Face Hub models or spaces. Find your token here: https://huggingface.co/settings/tokens.  Warning: only provide this if you are loading a trusted private Space as it can be read by the Space you are loading.\u003Cbr>alias: optional string used as the name of the loaded model instead of the default name (only applies if loading a Space running Gradio 2.x)",returns:"a Gradio Blocks object for the given model"},parameters:[{name:"name",annotation:"str",doc:"the name of the model (e.g. &quot;gpt2&quot; or &quot;facebook/bart-base&quot;) or space (e.g. &quot;flax-community/spanish-gpt2&quot;), can include the `src` as prefix (e.g. &quot;models/facebook/bart-base&quot;)"},{name:"src",annotation:"str | None",doc:"the source of the model: `models` or `spaces` (or leave empty if source is provided as a prefix in `name`)",default:"None"},{name:"hf_token",annotation:"str | None",doc:"optional access token for loading private Hugging Face Hub models or spaces. Find your token here: https://huggingface.co/settings/tokens.  Warning: only provide this if you are loading a trusted private Space as it can be read by the Space you are loading.",default:"None"},{name:"alias",annotation:"str | None",doc:"optional string used as the name of the loaded model instead of the default name (only applies if loading a Space running Gradio 2.x)",default:"None"}],returns:{annotation:null,doc:"a Gradio Blocks object for the given model"},example:"import gradio as gr\ndemo = gr.load(\"gradio/question-answering\", src=\"spaces\")\ndemo.launch()",fns:[],parent:"gradio",prev_obj:"make_waveform",next_obj:"Error",slug:"load"};c.error={class:null,name:"Error",description:"This class allows you to pass custom error messages to the user. You can do so by raising a gr.Error(\"custom message\") anywhere in the code, and when that line is executed the custom message will appear in a modal on the demo.",tags:{demos:"calculator, blocks_chained_events"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"message",annotation:"\u003Cclass 'str'>",doc:"The error message to be displayed to the user.",default:"\"Error raised.\""}],returns:{annotation:null},example:"import gradio as gr\ndef divide(numerator, denominator):\n    if denominator == 0:\n        raise gr.Error(\"Cannot divide by zero!\")\ngr.Interface(divide, [\"number\", \"number\"], \"number\").launch()",fns:[],demos:[["calculator","import gradio as gr\n#from foo import BAR\n#\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        if num2 == 0:\n            raise gr.Error(\"Cannot divide by zero!\")\n        return num1 / num2\n\ndemo = gr.Interface(\n    calculator,\n    [\n        \"number\", \n        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n        \"number\"\n    ],\n    \"number\",\n    examples=[\n        [45, \"add\", 3],\n        [3.14, \"divide\", 2],\n        [144, \"multiply\", 2.5],\n        [0, \"subtract\", 1.2],\n    ],\n    title=\"Toy Calculator\",\n    description=\"Here's a sample toy calculator. Allows you to calculate things like $2+2=4$\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_chained_events","import gradio as gr\nimport time\n\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\ndemo.queue()\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)"]],parent:"gradio",prev_obj:"EventData",next_obj:"EventData",slug:"error"};c.eventdata={class:null,name:"EventData",description:"When a subclass of EventData is added as a type hint to an argument of an event listener method, this object will be passed as that argument. It contains information about the event that triggered the listener, such the target object, and other data related to the specific event that are attributes of the subclass. \u003Cbr>",tags:{demos:"gallery_selections, tictactoe"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"target",annotation:"Block | None",doc:"The target object that triggered the event. Can be used to distinguish if multiple components are bound to the same listener."}],returns:{annotation:null},example:"table = gr.Dataframe([[1, 2, 3], [4, 5, 6]])\ngallery = gr.Gallery([(\"cat.jpg\", \"Cat\"), (\"dog.jpg\", \"Dog\")])\ntextbox = gr.Textbox(\"Hello World!\")\n\nstatement = gr.Textbox()\n\ndef on_select(evt: gr.SelectData):  # SelectData is a subclass of EventData\n    return f\"You selected {evt.value} at {evt.index} from {evt.target}\"\n\ntable.select(on_select, None, statement)\ngallery.select(on_select, None, statement)\ntextbox.select(on_select, None, statement)",fns:[],demos:[["gallery_selections","import gradio as gr\nimport numpy as np\n\nwith gr.Blocks() as demo:\n    imgs = gr.State()\n    gallery = gr.Gallery(allow_preview=False)\n\n    def deselect_images():\n        return gr.Gallery(selected_index=None)\n\n    def generate_images():\n        images = []\n        for _ in range(9):\n            image = np.ones((100, 100, 3), dtype=np.uint8) * np.random.randint(\n                0, 255, 3\n            )  # image is a solid single color\n            images.append(image)\n        return images, images\n\n    demo.load(generate_images, None, [gallery, imgs])\n\n    with gr.Row():\n        selected = gr.Number(show_label=False)\n        darken_btn = gr.Button(\"Darken selected\")\n    deselect_button = gr.Button(\"Deselect\")\n\n    deselect_button.click(deselect_images, None, gallery)\n\n    def get_select_index(evt: gr.SelectData):\n        return evt.index\n\n    gallery.select(get_select_index, None, selected)\n\n    def darken_img(imgs, index):\n        index = int(index)\n        imgs[index] = np.round(imgs[index] * 0.8).astype(np.uint8)\n        return imgs, imgs\n\n    darken_btn.click(darken_img, [imgs, selected], [imgs, gallery])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["tictactoe","import gradio as gr\n\nwith gr.Blocks() as demo:\n    turn = gr.Textbox(\"X\", interactive=False, label=\"Turn\")\n    board = gr.Dataframe(value=[[\"\", \"\", \"\"]] * 3, interactive=False, type=\"array\")\n\n    def place(board, turn, evt: gr.SelectData):\n        if evt.value:\n            return board, turn\n        board[evt.index[0]][evt.index[1]] = turn\n        turn = \"O\" if turn == \"X\" else \"X\"\n        return board, turn\n\n    board.select(place, [board, turn], [board, turn], show_progress=\"hidden\")\n\nif __name__ == \"__main__\":\n    demo.launch()"]],parent:"gradio",prev_obj:"Error",next_obj:"Warning",slug:"event-data"};c.warning={class:null,name:"Warning",description:"This function allows you to pass custom warning messages to the user. You can do so simply by writing `gr.Warning('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is yellow by default and has the heading: \"Warning.\" Queue must be enabled for this behavior; otherwise, the warning will be printed to the console using the `warnings` library.",tags:{demos:"blocks_chained_events",parameters:"message: The warning message to be displayed to the user."},parameters:[{name:"message",annotation:"str",doc:"The warning message to be displayed to the user.",default:"\"Warning issued.\""}],returns:{annotation:null},example:"import gradio as gr\ndef hello_world():\n    gr.Warning('This is a warning message.')\n    return \"hello world\"\nwith gr.Blocks() as demo:\n    md = gr.Markdown()\n    demo.load(hello_world, inputs=None, outputs=[md])\ndemo.queue().launch()",fns:[],demos:[["blocks_chained_events","import gradio as gr\nimport time\n\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\ndemo.queue()\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)"]],parent:"gradio",prev_obj:"EventData",next_obj:"Info",slug:"warning"};c.info={class:null,name:"Info",description:"This function allows you to pass custom info messages to the user. You can do so simply by writing `gr.Info('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is gray by default and has the heading: \"Info.\" Queue must be enabled for this behavior; otherwise, the message will be printed to the console.",tags:{demos:"blocks_chained_events",parameters:"message: The info message to be displayed to the user."},parameters:[{name:"message",annotation:"str",doc:"The info message to be displayed to the user.",default:"\"Info issued.\""}],returns:{annotation:null},example:"import gradio as gr\ndef hello_world():\n    gr.Info('This is some info.')\n    return \"hello world\"\nwith gr.Blocks() as demo:\n    md = gr.Markdown()\n    demo.load(hello_world, inputs=None, outputs=[md])\ndemo.queue().launch()",fns:[],demos:[["blocks_chained_events","import gradio as gr\nimport time\n\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\ndemo.queue()\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)"]],parent:"gradio",prev_obj:"Warning",next_obj:"Request",slug:"info"};d.request={class:null,name:"Request",description:"A Gradio request object that can be used to access the request headers, cookies, query parameters and other information about the request from within the prediction function. The class is a thin wrapper around the fastapi.Request class. Attributes of this class include: `headers`, `client`, `query_params`, and `path_params`. If auth is enabled, the `username` attribute can be used to get the logged in user.",tags:{demos:"request_ip_headers"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"request",annotation:"fastapi.Request | None",doc:"A fastapi.Request",default:"None"},{name:"username",annotation:"str | None",doc:null,default:"None"}],returns:{annotation:null},example:"import gradio as gr\ndef echo(text, request: gr.Request):\n    if request:\n        print(\"Request headers dictionary:\", request.headers)\n        print(\"IP address:\", request.client.host)\n        print(\"Query parameters:\", dict(request.query_params))\n    return text\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()",fns:[],demos:[["request_ip_headers","import gradio as gr\n\n\ndef predict(text, request: gr.Request):\n    headers = request.headers\n    host = request.client.host\n    user_agent = request.headers[\"user-agent\"]\n    return {\n        \"ip\": host,\n        \"user_agent\": user_agent,\n        \"headers\": headers,\n    }\n\n\ngr.Interface(predict, \"text\", \"json\").queue().launch()\n"]],parent:"gradio",prev_obj:"Info",next_obj:"mount_gradio_app",slug:"request"};d.mount_gradio_app={class:null,name:"mount_gradio_app",description:"Mount a gradio.Blocks to an existing FastAPI application. \u003Cbr>",tags:{parameters:"app: The parent FastAPI application.\u003Cbr>blocks: The blocks object we want to mount to the parent app.\u003Cbr>path: The path at which the gradio application will be mounted.\u003Cbr>app_kwargs: Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{\"docs_url\": \"/docs\"}`"},parameters:[{name:"app",annotation:"fastapi.FastAPI",doc:"The parent FastAPI application."},{name:"blocks",annotation:"gradio.Blocks",doc:"The blocks object we want to mount to the parent app."},{name:"path",annotation:"str",doc:"The path at which the gradio application will be mounted."},{name:"app_kwargs",annotation:"dict[str, Any] | None",doc:"Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{&quot;docs_url&quot;: &quot;/docs&quot;}`",default:"None"}],returns:{annotation:null},example:"from fastapi import FastAPI\nimport gradio as gr\napp = FastAPI()\n@app.get(\"/\")\ndef read_main():\n    return {\"message\": \"This is your main app\"}\nio = gr.Interface(lambda x: \"Hello, \" + x + \"!\", \"textbox\", \"textbox\")\napp = gr.mount_gradio_app(app, io, path=\"/gradio\")\n# Then run `uvicorn run:app` from the terminal and navigate to http://localhost:8000/gradio.",fns:[],parent:"gradio",prev_obj:"Request",next_obj:"Flagging",slug:"mount-gradio-app"};e.client={class:null,name:"Client",description:"The main Client class for the Python client. This class is used to connect to a remote Gradio app and call its API endpoints. \u003Cbr>",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"src",annotation:"str",doc:"Either the name of the Hugging Face Space to load, (e.g. &quot;abidlabs/whisper-large-v2&quot;) or the full URL (including &quot;http&quot; or &quot;https&quot;) of the hosted Gradio app to load (e.g. &quot;http://mydomain.com/app&quot; or &quot;https://bec81a83-5b5c-471e.gradio.live/&quot;)."},{name:"hf_token",annotation:"str | None",doc:"The Hugging Face token to use to access private Spaces. Automatically fetched if you are logged in via the Hugging Face Hub CLI. Obtain from: https://huggingface.co/settings/token",default:"None"},{name:"max_workers",annotation:"int",doc:"The maximum number of thread workers that can be used to make requests to the remote Gradio app simultaneously.",default:"40"},{name:"serialize",annotation:"bool",doc:"Whether the client should serialize the inputs and deserialize the outputs of the remote API. If set to False, the client will pass the inputs and outputs as-is, without serializing/deserializing them. E.g. you if you set this to False, you&#x27;d submit an image in base64 format instead of a filepath, and you&#x27;d get back an image in base64 format from the remote API instead of a filepath.",default:"True"},{name:"output_dir",annotation:"str | Path",doc:"The directory to save files that are downloaded from the remote API. If None, reads from the GRADIO_TEMP_DIR environment variable. Defaults to a temporary directory on your machine.",default:"\"/tmp/gradio\""},{name:"verbose",annotation:"bool",doc:"Whether the client should print statements to the console.",default:"True"},{name:"auth",annotation:"tuple[str, str] | None",doc:null,default:"None"}],returns:{annotation:null},example:"from gradio_client import Client\n\nclient = Client(\"abidlabs/whisper-large-v2\")  # connecting to a Hugging Face Space\nclient.predict(\"test.mp4\", api_name=\"/predict\")\n>> What a nice recording! # returns the result of the remote API call\n\nclient = Client(\"https://bec81a83-5b5c-471e.gradio.live\")  # connecting to a temporary Gradio share URL\njob = client.submit(\"hello\", api_name=\"/predict\")  # runs the prediction in a background thread\njob.result()\n>> 49 # returns the result of the remote API call (blocking call)",fns:[{fn:null,name:"predict",description:"Calls the Gradio API and returns the result (this is a blocking call). &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"args",annotation:"\u003Cclass 'inspect._empty'>",doc:"The arguments to pass to the remote API. The order of the arguments must match the order of the inputs in the Gradio app."},{name:"api_name",annotation:"str | None",doc:"The name of the API endpoint to call starting with a leading slash, e.g. &quot;/predict&quot;. Does not need to be provided if the Gradio app has only one named API endpoint.",default:"None"},{name:"fn_index",annotation:"int | None",doc:"As an alternative to api_name, this parameter takes the index of the API endpoint to call, e.g. 0. Both api_name and fn_index can be provided, but if they conflict, api_name will take precedence.",default:"None"}],returns:{annotation:"Any",doc:"The result of the API call. Will be a Tuple if the API has multiple outputs."},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\nclient.predict(5, \"add\", 4, api_name=\"/predict\")\n>> 9.0",override_signature:null,parent:"gradio.Client",slug:"client-predict"},{fn:null,name:"submit",description:"Creates and returns a Job object which calls the Gradio API in a background thread. The job can be used to retrieve the status and result of the remote API call. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"args",annotation:"\u003Cclass 'inspect._empty'>",doc:"The arguments to pass to the remote API. The order of the arguments must match the order of the inputs in the Gradio app."},{name:"api_name",annotation:"str | None",doc:"The name of the API endpoint to call starting with a leading slash, e.g. &quot;/predict&quot;. Does not need to be provided if the Gradio app has only one named API endpoint.",default:"None"},{name:"fn_index",annotation:"int | None",doc:"As an alternative to api_name, this parameter takes the index of the API endpoint to call, e.g. 0. Both api_name and fn_index can be provided, but if they conflict, api_name will take precedence.",default:"None"},{name:"result_callbacks",annotation:"Callable | list[Callable] | None",doc:"A callback function, or list of callback functions, to be called when the result is ready. If a list of functions is provided, they will be called in order. The return values from the remote API are provided as separate parameters into the callback. If None, no callback will be called.",default:"None"}],returns:{annotation:"Job",doc:"A Job object that can be used to retrieve the status and result of the remote API call."},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\njob = client.submit(5, \"add\", 4, api_name=\"/predict\")\njob.status()\n>> \u003CStatus.STARTING: 'STARTING'>\njob.result()  # blocking call\n>> 9.0",override_signature:null,parent:"gradio.Client",slug:"client-submit"},{fn:null,name:"view_api",description:"Prints the usage info for the API. If the Gradio app has multiple API endpoints, the usage info for each endpoint will be printed separately. If return_format=&quot;dict&quot; the info is returned in dictionary format, as shown in the example below. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"all_endpoints",annotation:"bool | None",doc:"If True, prints information for both named and unnamed endpoints in the Gradio app. If False, will only print info about named endpoints. If None (default), will print info about named endpoints, unless there aren&#x27;t any -- in which it will print info about unnamed endpoints.",default:"None"},{name:"print_info",annotation:"bool",doc:"If True, prints the usage info to the console. If False, does not print the usage info.",default:"True"},{name:"return_format",annotation:"Literal[('dict', 'str')] | None",doc:"If None, nothing is returned. If &quot;str&quot;, returns the same string that would be printed to the console. If &quot;dict&quot;, returns the usage info as a dictionary that can be programmatically parsed, and *all endpoints are returned in the dictionary* regardless of the value of `all_endpoints`. The format of the dictionary is in the docstring of this method.",default:"None"}],returns:{},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\nclient.view_api(return_format=\"dict\")\n>> {\n    'named_endpoints': {\n        '/predict': {\n            'parameters': [\n                {\n                    'label': 'num1',\n                    'type_python': 'int | float',\n                    'type_description': 'numeric value',\n                    'component': 'Number',\n                    'example_input': '5'\n                },\n                {\n                    'label': 'operation',\n                    'type_python': 'str',\n                    'type_description': 'string value',\n                    'component': 'Radio',\n                    'example_input': 'add'\n                },\n                {\n                    'label': 'num2',\n                    'type_python': 'int | float',\n                    'type_description': 'numeric value',\n                    'component': 'Number',\n                    'example_input': '5'\n                },\n            ],\n            'returns': [\n                {\n                    'label': 'output',\n                    'type_python': 'int | float',\n                    'type_description': 'numeric value',\n                    'component': 'Number',\n                },\n            ]\n        },\n        '/flag': {\n            'parameters': [\n                ...\n                ],\n            'returns': [\n                ...\n                ]\n            }\n        }\n    'unnamed_endpoints': {\n        2: {\n            'parameters': [\n                ...\n                ],\n            'returns': [\n                ...\n                ]\n            }\n        }\n    }\n}",override_signature:null,parent:"gradio.Client",slug:"client-view-api"},{fn:null,name:"duplicate",description:"Duplicates a Hugging Face Space under your account and returns a Client object for the new Space. No duplication is created if the Space already exists in your account (to override this, provide a new name for the new Space using `to_id`). To use this method, you must provide an `hf_token` or be logged in via the Hugging Face Hub CLI. &lt;br&gt; The new Space will be private by default and use the same hardware as the original Space. This can be changed by using the `private` and `hardware` parameters. For hardware upgrades (beyond the basic CPU tier), you may be required to provide billing information on Hugging Face: https://huggingface.co/settings/billing &lt;br&gt;",tags:{},parameters:[{name:"from_id",annotation:"str",doc:"The name of the Hugging Face Space to duplicate in the format &quot;{username}/{space_id}&quot;, e.g. &quot;gradio/whisper&quot;."},{name:"to_id",annotation:"str | None",doc:"The name of the new Hugging Face Space to create, e.g. &quot;abidlabs/whisper-duplicate&quot;. If not provided, the new Space will be named &quot;{your_HF_username}/{space_id}&quot;.",default:"None"},{name:"hf_token",annotation:"str | None",doc:"The Hugging Face token to use to access private Spaces. Automatically fetched if you are logged in via the Hugging Face Hub CLI. Obtain from: https://huggingface.co/settings/token",default:"None"},{name:"private",annotation:"bool",doc:"Whether the new Space should be private (True) or public (False). Defaults to True.",default:"True"},{name:"hardware",annotation:"Literal[('cpu-basic', 'cpu-upgrade', 't4-small', 't4-medium', 'a10g-small', 'a10g-large', 'a100-large')] | SpaceHardware | None",doc:"The hardware tier to use for the new Space. Defaults to the same hardware tier as the original Space. Options include &quot;cpu-basic&quot;, &quot;cpu-upgrade&quot;, &quot;t4-small&quot;, &quot;t4-medium&quot;, &quot;a10g-small&quot;, &quot;a10g-large&quot;, &quot;a100-large&quot;, subject to availability.",default:"None"},{name:"secrets",annotation:"dict[str, str] | None",doc:"A dictionary of (secret key, secret value) to pass to the new Space. Defaults to None. Secrets are only used when the Space is duplicated for the first time, and are not updated if the duplicated Space already exists.",default:"None"},{name:"sleep_timeout",annotation:"int",doc:"The number of minutes after which the duplicate Space will be puased if no requests are made to it (to minimize billing charges). Defaults to 5 minutes.",default:"5"},{name:"max_workers",annotation:"int",doc:"The maximum number of thread workers that can be used to make requests to the remote Gradio app simultaneously.",default:"40"},{name:"verbose",annotation:"bool",doc:"Whether the client should print statements to the console.",default:"True"}],returns:{},example:"import os\nfrom gradio_client import Client\nHF_TOKEN = os.environ.get(\"HF_TOKEN\")\nclient = Client.duplicate(\"abidlabs/whisper\", hf_token=HF_TOKEN)\nclient.predict(\"audio_sample.wav\")\n>> \"This is a test of the whisper speech recognition model.\"",override_signature:null,parent:"gradio.Client",slug:"client-duplicate"},{fn:null,name:"deploy_discord",description:"Deploy the upstream app as a discord bot. Currently only supports gr.ChatInterface.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"discord_bot_token",annotation:"str | None",doc:"This is the &quot;password&quot; needed to be able to launch the bot. Users can get a token by creating a bot app on the discord website. If run the method without specifying a token, the space will explain how to get one. See here: https://huggingface.co/spaces/freddyaboulton/test-discord-bot-v1.",default:"None"},{name:"api_names",annotation:"list[str | tuple[str, str]] | None",doc:"The api_names of the app to turn into bot commands. This parameter currently has no effect as ChatInterface only has one api_name (&#x27;/chat&#x27;).",default:"None"},{name:"to_id",annotation:"str | None",doc:"The name of the space hosting the discord bot. If None, the name will be gradio-discord-bot-{random-substring}",default:"None"},{name:"hf_token",annotation:"str | None",doc:"HF api token with write priviledges in order to upload the files to HF space. Can be ommitted if logged in via the HuggingFace CLI, unless the upstream space is private. Obtain from: https://huggingface.co/settings/token",default:"None"},{name:"private",annotation:"bool",doc:"Whether the space hosting the discord bot is private. The visibility of the discord bot itself is set via the discord website. See https://huggingface.co/spaces/freddyaboulton/test-discord-bot-v1",default:"False"}],returns:{},example:null,override_signature:null,parent:"gradio.Client",slug:"client-deploy-discord"}],parent:"gradio",prev_obj:"Python-Client",next_obj:"Job",slug:"client"};e.job={class:null,name:"Job",description:"A Job is a wrapper over the Future class that represents a prediction call that has been submitted by the Gradio client. This class is not meant to be instantiated directly, but rather is created by the Client.submit() method. \u003Cbr> A Job object includes methods to get the status of the prediction call, as well to get the outputs of the prediction call. Job objects are also iterable, and can be used in a loop to get the outputs of prediction calls as they become available for generator endpoints.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"future",annotation:"Future",doc:"The future object that represents the prediction call, created by the Client.submit() method"},{name:"communicator",annotation:"Communicator | None",doc:"The communicator object that is used to communicate between the client and the background thread running the job",default:"None"},{name:"verbose",annotation:"bool",doc:"Whether to print any status-related messages to the console",default:"True"},{name:"space_id",annotation:"str | None",doc:"The space ID corresponding to the Client object that created this Job object",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"result",description:"Return the result of the call that the future represents. Raises CancelledError: If the future was cancelled, TimeoutError: If the future didn&#x27;t finish executing before the given timeout, and Exception: If the call raised then that exception will be raised. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"timeout",annotation:"float | None",doc:"The number of seconds to wait for the result if the future isn&#x27;t done. If None, then there is no limit on the wait time.",default:"None"}],returns:{annotation:"Any",doc:"The result of the call that the future represents. For generator functions, it will return the final iteration."},example:"from gradio_client import Client\ncalculator = Client(src=\"gradio/calculator\")\njob = calculator.submit(\"foo\", \"add\", 4, fn_index=0)\njob.result(timeout=5)\n>> 9",override_signature:null,parent:"gradio.Job",slug:"job-result"},{fn:null,name:"outputs",description:"Returns a list containing the latest outputs from the Job. &lt;br&gt; If the endpoint has multiple output components, the list will contain a tuple of results. Otherwise, it will contain the results without storing them in tuples. &lt;br&gt; For endpoints that are queued, this list will contain the final job output even if that endpoint does not use a generator function. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{},example:"from gradio_client import Client\nclient = Client(src=\"gradio/count_generator\")\njob = client.submit(3, api_name=\"/count\")\nwhile not job.done():\n    time.sleep(0.1)\njob.outputs()\n>> ['0', '1', '2']",override_signature:null,parent:"gradio.Job",slug:"job-outputs"},{fn:null,name:"status",description:"Returns the latest status update from the Job in the form of a StatusUpdate object, which contains the following fields: code, rank, queue_size, success, time, eta, and progress_data. &lt;br&gt; progress_data is a list of updates emitted by the gr.Progress() tracker of the event handler. Each element of the list has the following fields: index, length, unit, progress, desc. If the event handler does not have a gr.Progress() tracker, the progress_data field will be None. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\njob = client.submit(5, \"add\", 4, api_name=\"/predict\")\njob.status()\n>> \u003CStatus.STARTING: 'STARTING'>\njob.status().eta\n>> 43.241  # seconds",override_signature:null,parent:"gradio.Job",slug:"job-status"}],parent:"gradio",prev_obj:"Client",next_obj:"JS-Client",slug:"job"};return {docs:{building:{simplecsvlogger:{class:null,name:"SimpleCSVLogger",description:"A simplified implementation of the FlaggingCallback abstract class provided for illustrative purposes.  Each flagged sample (both the input and output data) is logged to a CSV file on the machine running the gradio app.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{annotation:null},example:"import gradio as gr\ndef image_classifier(inp):\n    return {'cat': 0.3, 'dog': 0.7}\ndemo = gr.Interface(fn=image_classifier, inputs=\"image\", outputs=\"label\",\n                    flagging_callback=SimpleCSVLogger())",fns:[],parent:"gradio",slug:"simple-csv-logger"},csvlogger:{class:null,name:"CSVLogger",description:"The default implementation of the FlaggingCallback abstract class. Each flagged sample (both the input and output data) is logged to a CSV file with headers on the machine running the gradio app.",tags:{guides:"using-flagging"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{annotation:null},example:"import gradio as gr\ndef image_classifier(inp):\n    return {'cat': 0.3, 'dog': 0.7}\ndemo = gr.Interface(fn=image_classifier, inputs=\"image\", outputs=\"label\",\n                    flagging_callback=CSVLogger())",fns:[],guides:[{name:"using-flagging",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:54,pretty_name:"Using Flagging",content:"# Using Flagging\n\n\n\n\n## Introduction\n\nWhen you demo a machine learning model, you might want to collect data from users who try the model, particularly data points in which the model is not behaving as expected. Capturing these \"hard\" data points is valuable because it allows you to improve your machine learning model and make it more reliable and robust.\n\nGradio simplifies the collection of this data by including a **Flag** button with every `Interface`. This allows a user or tester to easily send data back to the machine where the demo is running. In this Guide, we discuss more about how to use the flagging feature, both with `gradio.Interface` as well as with `gradio.Blocks`.\n\n## The **Flag** button in `gradio.Interface`\n\nFlagging with Gradio's `Interface` is especially easy. By default, underneath the output components, there is a button marked **Flag**. When a user testing your model sees input with interesting output, they can click the flag button to send the input and output data back to the machine where the demo is running. The sample is saved to a CSV log file (by default). If the demo involves images, audio, video, or other types of files, these are saved separately in a parallel directory and the paths to these files are saved in the CSV file.\n\nThere are [four parameters](https://gradio.app/docs/interface#initialization) in `gradio.Interface` that control how flagging works. We will go over them in greater detail.\n\n- `allow_flagging`: this parameter can be set to either `\"manual\"` (default), `\"auto\"`, or `\"never\"`.\n  - `manual`: users will see a button to flag, and samples are only flagged when the button is clicked.\n  - `auto`: users will not see a button to flag, but every sample will be flagged automatically.\n  - `never`: users will not see a button to flag, and no sample will be flagged.\n- `flagging_options`: this parameter can be either `None` (default) or a list of strings.\n  - If `None`, then the user simply clicks on the **Flag** button and no additional options are shown.\n  - If a list of strings are provided, then the user sees several buttons, corresponding to each of the strings that are provided. For example, if the value of this parameter is `[\"Incorrect\", \"Ambiguous\"]`, then buttons labeled **Flag as Incorrect** and **Flag as Ambiguous** appear. This only applies if `allow_flagging` is `\"manual\"`.\n  - The chosen option is then logged along with the input and output.\n- `flagging_dir`: this parameter takes a string.\n  - It represents what to name the directory where flagged data is stored.\n- `flagging_callback`: this parameter takes an instance of a subclass of the `FlaggingCallback` class\n  - Using this parameter allows you to write custom code that gets run when the flag button is clicked\n  - By default, this is set to an instance of `gr.CSVLogger`\n  - One example is setting it to an instance of `gr.HuggingFaceDatasetSaver` which can allow you to pipe any flagged data into a HuggingFace Dataset. (See more below.)\n\n## What happens to flagged data?\n\nWithin the directory provided by the `flagging_dir` argument, a CSV file will log the flagged data.\n\nHere's an example: The code below creates the calculator interface embedded below it:\n\n```python\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    allow_flagging=\"manual\"\n)\n\niface.launch()\n```\n\n\u003Cgradio-app space=\"gradio/calculator-flag-basic/\">\u003C/gradio-app>\n\nWhen you click the flag button above, the directory where the interface was launched will include a new flagged subfolder, with a csv file inside it. This csv file includes all the data that was flagged.\n\n```directory\n+-- flagged/\n|   +-- logs.csv\n```\n\n_flagged/logs.csv_\n\n```csv\nnum1,operation,num2,Output,timestamp\n5,add,7,12,2022-01-31 11:40:51.093412\n6,subtract,1.5,4.5,2022-01-31 03:25:32.023542\n```\n\nIf the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well. For example an `image` input to `image` output interface will create the following structure.\n\n```directory\n+-- flagged/\n|   +-- logs.csv\n|   +-- image/\n|   |   +-- 0.png\n|   |   +-- 1.png\n|   +-- Output/\n|   |   +-- 0.png\n|   |   +-- 1.png\n```\n\n_flagged/logs.csv_\n\n```csv\nim,Output timestamp\nim/0.png,Output/0.png,2022-02-04 19:49:58.026963\nim/1.png,Output/1.png,2022-02-02 10:40:51.093412\n```\n\nIf you wish for the user to provide a reason for flagging, you can pass a list of strings to the `flagging_options` argument of Interface. Users will have to select one of these choices when flagging, and the option will be saved as an additional column to the CSV.\n\nIf we go back to the calculator example, the following code will create the interface embedded below it.\n\n```python\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    allow_flagging=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"]\n)\n\niface.launch()\n```\n\n\u003Cgradio-app space=\"gradio/calculator-flagging-options/\">\u003C/gradio-app>\n\nWhen users click the flag button, the csv file will now include a column indicating the selected option.\n\n_flagged/logs.csv_\n\n```csv\nnum1,operation,num2,Output,flag,timestamp\n5,add,7,-12,wrong sign,2022-02-04 11:40:51.093412\n6,subtract,1.5,3.5,off by one,2022-02-04 11:42:32.062512\n```\n\n## The HuggingFaceDatasetSaver Callback\n\nSometimes, saving the data to a local CSV file doesn't make sense. For example, on Hugging Face\nSpaces, developers typically don't have access to the underlying ephemeral machine hosting the Gradio\ndemo. That's why, by default, flagging is turned off in Hugging Face Space. However,\nyou may want to do something else with the flagged data.\n\nWe've made this super easy with the `flagging_callback` parameter.\n\nFor example, below we're going to pipe flagged data from our calculator example into a Hugging Face Dataset, e.g. so that we can build a \"crowd-sourced\" dataset:\n\n```python\nimport os\n\nHF_TOKEN = os.getenv('HF_TOKEN')\nhf_writer = gr.HuggingFaceDatasetSaver(HF_TOKEN, \"crowdsourced-calculator-demo\")\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    description=\"Check out the crowd-sourced dataset at: [https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo)\",\n    allow_flagging=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"],\n    flagging_callback=hf_writer\n)\n\niface.launch()\n```\n\nNotice that we define our own\ninstance of `gradio.HuggingFaceDatasetSaver` using our Hugging Face token and\nthe name of a dataset we'd like to save samples to. In addition, we also set `allow_flagging=\"manual\"`\nbecause on Hugging Face Spaces, `allow_flagging` is set to `\"never\"` by default. Here's our demo:\n\n\u003Cgradio-app space=\"gradio/calculator-flagging-crowdsourced/\">\u003C/gradio-app>\n\nYou can now see all the examples flagged above in this [public Hugging Face dataset](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo).\n\n![flagging callback hf](https://github.com/gradio-app/gradio/blob/main/guides/assets/flagging-callback-hf.png?raw=true)\n\nWe created the `gradio.HuggingFaceDatasetSaver` class, but you can pass your own custom class as long as it inherits from `FLaggingCallback` defined in [this file](https://github.com/gradio-app/gradio/blob/master/gradio/flagging.py). If you create a cool callback, contribute it to the repo!\n\n## Flagging with Blocks\n\nWhat about if you are using `gradio.Blocks`? On one hand, you have even more flexibility\nwith Blocks -- you can write whatever Python code you want to run when a button is clicked,\nand assign that using the built-in events in Blocks.\n\nAt the same time, you might want to use an existing `FlaggingCallback` to avoid writing extra code.\nThis requires two steps:\n\n1. You have to run your callback's `.setup()` somewhere in the code prior to the\n   first time you flag data\n2. When the flagging button is clicked, then you trigger the callback's `.flag()` method,\n   making sure to collect the arguments correctly and disabling the typical preprocessing.\n\nHere is an example with an image sepia filter Blocks demo that lets you flag\ndata using the default `CSVLogger`:\n\n```python\nimport numpy as np\nimport gradio as gr\n\ndef sepia(input_img, strength):\n    sepia_filter = strength * np.array(\n        [[0.393, 0.769, 0.189], [0.349, 0.686, 0.168], [0.272, 0.534, 0.131]]\n    ) + (1-strength) * np.identity(3)\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ncallback = gr.CSVLogger()\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            img_input = gr.Image()\n            strength = gr.Slider(0, 1, 0.5)\n        img_output = gr.Image()\n    with gr.Row():\n        btn = gr.Button(\"Flag\")\n        \n    # This needs to be called at some point prior to the first call to callback.flag()\n    callback.setup([img_input, strength, img_output], \"flagged_data_points\")\n\n    img_input.change(sepia, [img_input, strength], img_output)\n    strength.change(sepia, [img_input, strength], img_output)\n    \n    # We can choose which components to flag -- in this case, we'll flag all of them\n    btn.click(lambda *args: callback.flag(args), [img_input, strength, img_output], None, preprocess=False)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_flag'>\u003C/gradio-app>\n\n## Privacy\n\nImportant Note: please make sure your users understand when the data they submit is being saved, and what you plan on doing with it. This is especially important when you use `allow_flagging=auto` (when all of the data submitted through the demo is being flagged)\n\n### That's all! Happy building :)\n",tags:["FLAGGING","DATA"],spaces:["https://huggingface.co/spaces/gradio/calculator-flagging-crowdsourced","https://huggingface.co/spaces/gradio/calculator-flagging-options","https://huggingface.co/spaces/gradio/calculator-flag-basic"],url:"/guides/using-flagging/",contributor:null}],parent:"gradio",slug:"csv-logger"},huggingfacedatasetsaver:{class:null,name:"HuggingFaceDatasetSaver",description:"A callback that saves each flagged sample (both the input and output data) to a HuggingFace dataset. \u003Cbr>",tags:{guides:"using-flagging"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"hf_token",annotation:"str",doc:"The HuggingFace token to use to create (and write the flagged sample to) the HuggingFace dataset (defaults to the registered one)."},{name:"dataset_name",annotation:"str",doc:"The repo_id of the dataset to save the data to, e.g. &quot;image-classifier-1&quot; or &quot;username/image-classifier-1&quot;."},{name:"private",annotation:"bool",doc:"Whether the dataset should be private (defaults to False).",default:"False"},{name:"info_filename",annotation:"str",doc:"The name of the file to save the dataset info (defaults to &quot;dataset_infos.json&quot;).",default:"\"dataset_info.json\""},{name:"separate_dirs",annotation:"bool",doc:"If True, each flagged item will be saved in a separate directory. This makes the flagging more robust to concurrent editing, but may be less convenient to use.",default:"False"}],returns:{annotation:null},example:"import gradio as gr\nhf_writer = gr.HuggingFaceDatasetSaver(HF_API_TOKEN, \"image-classification-mistakes\")\ndef image_classifier(inp):\n    return {'cat': 0.3, 'dog': 0.7}\ndemo = gr.Interface(fn=image_classifier, inputs=\"image\", outputs=\"label\",\n                    allow_flagging=\"manual\", flagging_callback=hf_writer)",fns:[],guides:[{name:"using-flagging",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:54,pretty_name:"Using Flagging",content:"# Using Flagging\n\n\n\n\n## Introduction\n\nWhen you demo a machine learning model, you might want to collect data from users who try the model, particularly data points in which the model is not behaving as expected. Capturing these \"hard\" data points is valuable because it allows you to improve your machine learning model and make it more reliable and robust.\n\nGradio simplifies the collection of this data by including a **Flag** button with every `Interface`. This allows a user or tester to easily send data back to the machine where the demo is running. In this Guide, we discuss more about how to use the flagging feature, both with `gradio.Interface` as well as with `gradio.Blocks`.\n\n## The **Flag** button in `gradio.Interface`\n\nFlagging with Gradio's `Interface` is especially easy. By default, underneath the output components, there is a button marked **Flag**. When a user testing your model sees input with interesting output, they can click the flag button to send the input and output data back to the machine where the demo is running. The sample is saved to a CSV log file (by default). If the demo involves images, audio, video, or other types of files, these are saved separately in a parallel directory and the paths to these files are saved in the CSV file.\n\nThere are [four parameters](https://gradio.app/docs/interface#initialization) in `gradio.Interface` that control how flagging works. We will go over them in greater detail.\n\n- `allow_flagging`: this parameter can be set to either `\"manual\"` (default), `\"auto\"`, or `\"never\"`.\n  - `manual`: users will see a button to flag, and samples are only flagged when the button is clicked.\n  - `auto`: users will not see a button to flag, but every sample will be flagged automatically.\n  - `never`: users will not see a button to flag, and no sample will be flagged.\n- `flagging_options`: this parameter can be either `None` (default) or a list of strings.\n  - If `None`, then the user simply clicks on the **Flag** button and no additional options are shown.\n  - If a list of strings are provided, then the user sees several buttons, corresponding to each of the strings that are provided. For example, if the value of this parameter is `[\"Incorrect\", \"Ambiguous\"]`, then buttons labeled **Flag as Incorrect** and **Flag as Ambiguous** appear. This only applies if `allow_flagging` is `\"manual\"`.\n  - The chosen option is then logged along with the input and output.\n- `flagging_dir`: this parameter takes a string.\n  - It represents what to name the directory where flagged data is stored.\n- `flagging_callback`: this parameter takes an instance of a subclass of the `FlaggingCallback` class\n  - Using this parameter allows you to write custom code that gets run when the flag button is clicked\n  - By default, this is set to an instance of `gr.CSVLogger`\n  - One example is setting it to an instance of `gr.HuggingFaceDatasetSaver` which can allow you to pipe any flagged data into a HuggingFace Dataset. (See more below.)\n\n## What happens to flagged data?\n\nWithin the directory provided by the `flagging_dir` argument, a CSV file will log the flagged data.\n\nHere's an example: The code below creates the calculator interface embedded below it:\n\n```python\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    allow_flagging=\"manual\"\n)\n\niface.launch()\n```\n\n\u003Cgradio-app space=\"gradio/calculator-flag-basic/\">\u003C/gradio-app>\n\nWhen you click the flag button above, the directory where the interface was launched will include a new flagged subfolder, with a csv file inside it. This csv file includes all the data that was flagged.\n\n```directory\n+-- flagged/\n|   +-- logs.csv\n```\n\n_flagged/logs.csv_\n\n```csv\nnum1,operation,num2,Output,timestamp\n5,add,7,12,2022-01-31 11:40:51.093412\n6,subtract,1.5,4.5,2022-01-31 03:25:32.023542\n```\n\nIf the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well. For example an `image` input to `image` output interface will create the following structure.\n\n```directory\n+-- flagged/\n|   +-- logs.csv\n|   +-- image/\n|   |   +-- 0.png\n|   |   +-- 1.png\n|   +-- Output/\n|   |   +-- 0.png\n|   |   +-- 1.png\n```\n\n_flagged/logs.csv_\n\n```csv\nim,Output timestamp\nim/0.png,Output/0.png,2022-02-04 19:49:58.026963\nim/1.png,Output/1.png,2022-02-02 10:40:51.093412\n```\n\nIf you wish for the user to provide a reason for flagging, you can pass a list of strings to the `flagging_options` argument of Interface. Users will have to select one of these choices when flagging, and the option will be saved as an additional column to the CSV.\n\nIf we go back to the calculator example, the following code will create the interface embedded below it.\n\n```python\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    allow_flagging=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"]\n)\n\niface.launch()\n```\n\n\u003Cgradio-app space=\"gradio/calculator-flagging-options/\">\u003C/gradio-app>\n\nWhen users click the flag button, the csv file will now include a column indicating the selected option.\n\n_flagged/logs.csv_\n\n```csv\nnum1,operation,num2,Output,flag,timestamp\n5,add,7,-12,wrong sign,2022-02-04 11:40:51.093412\n6,subtract,1.5,3.5,off by one,2022-02-04 11:42:32.062512\n```\n\n## The HuggingFaceDatasetSaver Callback\n\nSometimes, saving the data to a local CSV file doesn't make sense. For example, on Hugging Face\nSpaces, developers typically don't have access to the underlying ephemeral machine hosting the Gradio\ndemo. That's why, by default, flagging is turned off in Hugging Face Space. However,\nyou may want to do something else with the flagged data.\n\nWe've made this super easy with the `flagging_callback` parameter.\n\nFor example, below we're going to pipe flagged data from our calculator example into a Hugging Face Dataset, e.g. so that we can build a \"crowd-sourced\" dataset:\n\n```python\nimport os\n\nHF_TOKEN = os.getenv('HF_TOKEN')\nhf_writer = gr.HuggingFaceDatasetSaver(HF_TOKEN, \"crowdsourced-calculator-demo\")\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    description=\"Check out the crowd-sourced dataset at: [https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo)\",\n    allow_flagging=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"],\n    flagging_callback=hf_writer\n)\n\niface.launch()\n```\n\nNotice that we define our own\ninstance of `gradio.HuggingFaceDatasetSaver` using our Hugging Face token and\nthe name of a dataset we'd like to save samples to. In addition, we also set `allow_flagging=\"manual\"`\nbecause on Hugging Face Spaces, `allow_flagging` is set to `\"never\"` by default. Here's our demo:\n\n\u003Cgradio-app space=\"gradio/calculator-flagging-crowdsourced/\">\u003C/gradio-app>\n\nYou can now see all the examples flagged above in this [public Hugging Face dataset](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo).\n\n![flagging callback hf](https://github.com/gradio-app/gradio/blob/main/guides/assets/flagging-callback-hf.png?raw=true)\n\nWe created the `gradio.HuggingFaceDatasetSaver` class, but you can pass your own custom class as long as it inherits from `FLaggingCallback` defined in [this file](https://github.com/gradio-app/gradio/blob/master/gradio/flagging.py). If you create a cool callback, contribute it to the repo!\n\n## Flagging with Blocks\n\nWhat about if you are using `gradio.Blocks`? On one hand, you have even more flexibility\nwith Blocks -- you can write whatever Python code you want to run when a button is clicked,\nand assign that using the built-in events in Blocks.\n\nAt the same time, you might want to use an existing `FlaggingCallback` to avoid writing extra code.\nThis requires two steps:\n\n1. You have to run your callback's `.setup()` somewhere in the code prior to the\n   first time you flag data\n2. When the flagging button is clicked, then you trigger the callback's `.flag()` method,\n   making sure to collect the arguments correctly and disabling the typical preprocessing.\n\nHere is an example with an image sepia filter Blocks demo that lets you flag\ndata using the default `CSVLogger`:\n\n```python\nimport numpy as np\nimport gradio as gr\n\ndef sepia(input_img, strength):\n    sepia_filter = strength * np.array(\n        [[0.393, 0.769, 0.189], [0.349, 0.686, 0.168], [0.272, 0.534, 0.131]]\n    ) + (1-strength) * np.identity(3)\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ncallback = gr.CSVLogger()\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            img_input = gr.Image()\n            strength = gr.Slider(0, 1, 0.5)\n        img_output = gr.Image()\n    with gr.Row():\n        btn = gr.Button(\"Flag\")\n        \n    # This needs to be called at some point prior to the first call to callback.flag()\n    callback.setup([img_input, strength, img_output], \"flagged_data_points\")\n\n    img_input.change(sepia, [img_input, strength], img_output)\n    strength.change(sepia, [img_input, strength], img_output)\n    \n    # We can choose which components to flag -- in this case, we'll flag all of them\n    btn.click(lambda *args: callback.flag(args), [img_input, strength, img_output], None, preprocess=False)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_flag'>\u003C/gradio-app>\n\n## Privacy\n\nImportant Note: please make sure your users understand when the data they submit is being saved, and what you plan on doing with it. This is especially important when you use `allow_flagging=auto` (when all of the data submitted through the demo is being flagged)\n\n### That's all! Happy building :)\n",tags:["FLAGGING","DATA"],spaces:["https://huggingface.co/spaces/gradio/calculator-flagging-crowdsourced","https://huggingface.co/spaces/gradio/calculator-flagging-options","https://huggingface.co/spaces/gradio/calculator-flag-basic"],url:"/guides/using-flagging/",contributor:null}],parent:"gradio",slug:"hugging-face-dataset-saver"},base:{class:null,name:"Base",description:"",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"primary_hue",annotation:"colors.Color | str",doc:"The primary hue of the theme. Load a preset, like gradio.themes.colors.green (or just the string &quot;green&quot;), or pass your own gradio.themes.utils.Color object.",default:"Color()"},{name:"secondary_hue",annotation:"colors.Color | str",doc:"The secondary hue of the theme. Load a preset, like gradio.themes.colors.green (or just the string &quot;green&quot;), or pass your own gradio.themes.utils.Color object.",default:"Color()"},{name:"neutral_hue",annotation:"colors.Color | str",doc:"The neutral hue of the theme, used . Load a preset, like gradio.themes.colors.green (or just the string &quot;green&quot;), or pass your own gradio.themes.utils.Color object.",default:"Color()"},{name:"text_size",annotation:"sizes.Size | str",doc:"The size of the text. Load a preset, like gradio.themes.sizes.text_sm (or just the string &quot;sm&quot;), or pass your own gradio.themes.utils.Size object.",default:"Size()"},{name:"spacing_size",annotation:"sizes.Size | str",doc:"The size of the spacing. Load a preset, like gradio.themes.sizes.spacing_sm (or just the string &quot;sm&quot;), or pass your own gradio.themes.utils.Size object.",default:"Size()"},{name:"radius_size",annotation:"sizes.Size | str",doc:"The radius size of corners. Load a preset, like gradio.themes.sizes.radius_sm (or just the string &quot;sm&quot;), or pass your own gradio.themes.utils.Size object.",default:"Size()"},{name:"font",annotation:"fonts.Font | str | Iterable[fonts.Font | str]",doc:"The primary font to use for the theme. Pass a string for a system font, or a gradio.themes.font.GoogleFont object to load a font from Google Fonts. Pass a list of fonts for fallbacks.",default:"(\u003Cgradio.themes.utils.fonts.GoogleFont (name='Source Sans Pro', weights=(400, 600))>, 'ui-sans-serif', 'system-ui', 'sans-serif')"},{name:"font_mono",annotation:"fonts.Font | str | Iterable[fonts.Font | str]",doc:"The monospace font to use for the theme, applies to code. Pass a string for a system font, or a gradio.themes.font.GoogleFont object to load a font from Google Fonts. Pass a list of fonts for fallbacks.",default:"(\u003Cgradio.themes.utils.fonts.GoogleFont (name='IBM Plex Mono', weights=(400, 600))>, 'ui-monospace', 'Consolas', 'monospace')"}],returns:{annotation:null},example:"",fns:[{fn:null,name:"push_to_hub",description:"Upload a theme to the HuggingFace hub. &lt;br&gt; This requires a HuggingFace account. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"repo_name",annotation:"str",doc:"The name of the repository to store the theme assets, e.g. &#x27;my_theme&#x27; or &#x27;sunset&#x27;."},{name:"org_name",annotation:"str | None",doc:"The name of the org to save the space in. If None (the default), the username corresponding to the logged in user, or h∆í_token is used.",default:"None"},{name:"version",annotation:"str | None",doc:"A semantic version tag for theme. Bumping the version tag lets you publish updates to a theme without changing the look of applications that already loaded your theme.",default:"None"},{name:"hf_token",annotation:"str | None",doc:"API token for your HuggingFace account",default:"None"},{name:"theme_name",annotation:"str | None",doc:"Name for the name. If None, defaults to repo_name",default:"None"},{name:"description",annotation:"str | None",doc:"A long form description to your theme.",default:"None"},{name:"private",annotation:"bool",doc:null,default:"False"}],returns:{},example:null,override_signature:null,parent:"gradio.Base",slug:"base-push-to-hub"},{fn:null,name:"from_hub",description:"Load a theme from the hub. &lt;br&gt; This DOES NOT require a HuggingFace account for downloading publicly available themes. &lt;br&gt;",tags:{},parameters:[{name:"repo_name",annotation:"str",doc:"string of the form &lt;author&gt;/&lt;theme-name&gt;@&lt;semantic-version-expression&gt;.  If a semantic version expression is omitted, the latest version will be fetched."},{name:"hf_token",annotation:"str | None",doc:"HuggingFace Token. Only needed to download private themes.",default:"None"}],returns:{},example:null,override_signature:null,parent:"gradio.Base",slug:"base-from-hub"},{fn:null,name:"load",description:"Load a theme from a json file. &lt;br&gt;",tags:{},parameters:[{name:"path",annotation:"str",doc:"The filepath to read."}],returns:{},example:null,override_signature:null,parent:"gradio.Base",slug:"base-load"},{fn:null,name:"dump",description:"Write the theme to a json file. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"filename",annotation:"str",doc:"The path to write the theme too"}],returns:{},example:null,override_signature:null,parent:"gradio.Base",slug:"base-dump"},{fn:null,name:"from_dict",description:"Create a theme instance from a dictionary representation. &lt;br&gt;",tags:{},parameters:[{name:"theme",annotation:"dict[str, dict[str, str]]",doc:"The dictionary representation of the theme."}],returns:{},example:null,override_signature:null,parent:"gradio.Base",slug:"base-from-dict"},{fn:null,name:"to_dict",description:"Convert the theme into a python dictionary.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{},example:null,override_signature:null,parent:"gradio.Base",slug:"base-to-dict"}],parent:"gradio",slug:"base"},queue:{class:null,name:"queue",description:"By enabling the queue you can control when users know their position in the queue, and set a limit on maximum number of events allowed.",tags:{parameters:"status_update_rate: If \"auto\", Queue will send status estimations to all clients whenever a job is finished. Otherwise Queue will send status at regular intervals set by this parameter as the number of seconds.\u003Cbr>api_open: If True, the REST routes of the backend will be open, allowing requests made directly to those endpoints to skip the queue.\u003Cbr>max_size: The maximum number of events the queue will store at any given moment. If the queue is full, new events will not be added and a user will receive a message saying that the queue is full. If None, the queue size will be unlimited.\u003Cbr>concurrency_count: Deprecated. Set the concurrency_limit directly on event listeners e.g. btn.click(fn, ..., concurrency_limit=10) or gr.Interface(concurrency_limit=10). If necessary, the total number of workers can be configured via `max_threads` in launch().\u003Cbr>default_concurrency_limit: The default value of `concurrency_limit` to use for event listeners that don't specify a value. Can be set by environment variable GRADIO_DEFAULT_CONCURRENCY_LIMIT. Defaults to 1 if not set otherwise.\u003Cbr>with gr.Blocks() as demo:\u003Cbr>    button = gr.Button(label=\"Generate Image\")\u003Cbr>    button.click(fn=image_generator, inputs=gr.Textbox(), outputs=gr.Image())\u003Cbr>demo.queue(max_size=10)\u003Cbr>demo.launch()\u003Cbr>demo = gr.Interface(image_generator, gr.Textbox(), gr.Image())\u003Cbr>demo.queue(max_size=20)\u003Cbr>demo.launch()"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"status_update_rate",annotation:"float | Literal['auto']",doc:"If &quot;auto&quot;, Queue will send status estimations to all clients whenever a job is finished. Otherwise Queue will send status at regular intervals set by this parameter as the number of seconds.",default:"\"auto\""},{name:"api_open",annotation:"bool | None",doc:"If True, the REST routes of the backend will be open, allowing requests made directly to those endpoints to skip the queue.",default:"None"},{name:"max_size",annotation:"int | None",doc:"The maximum number of events the queue will store at any given moment. If the queue is full, new events will not be added and a user will receive a message saying that the queue is full. If None, the queue size will be unlimited.",default:"None"},{name:"concurrency_count",annotation:"int | None",doc:"Deprecated. Set the concurrency_limit directly on event listeners e.g. btn.click(fn, ..., concurrency_limit=10) or gr.Interface(concurrency_limit=10). If necessary, the total number of workers can be configured via `max_threads` in launch().",default:"None"},{name:"default_concurrency_limit",annotation:"int | None | Literal['not_set']",doc:"The default value of `concurrency_limit` to use for event listeners that don&#x27;t specify a value. Can be set by environment variable GRADIO_DEFAULT_CONCURRENCY_LIMIT. Defaults to 1 if not set otherwise.",default:"\"not_set\""}],returns:{annotation:null},example:"(\nI\nn\nt\ne\nr\nf\na\nc\ne\n)",fns:[],parent:"gradio",slug:"queue"},blocks:{class:null,name:"Blocks",description:"Blocks is Gradio's low-level API that allows you to create more custom web applications and demos than Interfaces (yet still entirely in Python). \u003Cbr> \u003Cbr> Compared to the Interface class, Blocks offers more flexibility and control over: (1) the layout of components (2) the events that trigger the execution of functions (3) data flows (e.g. inputs can trigger outputs, which can trigger the next level of outputs). Blocks also offers ways to group together related demos such as with tabs. \u003Cbr> \u003Cbr> The basic usage of Blocks is as follows: create a Blocks object, then use it as a context (with the \"with\" statement), and then define layouts, components, or events within the Blocks context. Finally, call the launch() method to launch the demo. \u003Cbr>",tags:{demos:"blocks_hello, blocks_flipper, blocks_speech_text_sentiment, generate_english_german",guides:"blocks-and-event-listeners, controlling-layout, state-in-blocks, custom-CSS-and-JS, using-blocks-like-functions"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"theme",annotation:"Theme | str | None",doc:"A Theme object or a string representing a theme. If a string, will look for a built-in theme with that name (e.g. &quot;soft&quot; or &quot;default&quot;), or will attempt to load a theme from the HF Hub (e.g. &quot;gradio/monochrome&quot;). If None, will use the Default theme.",default:"None"},{name:"analytics_enabled",annotation:"bool | None",doc:"Whether to allow basic telemetry. If None, will use GRADIO_ANALYTICS_ENABLED environment variable or default to True.",default:"None"},{name:"mode",annotation:"str",doc:"A human-friendly name for the kind of Blocks or Interface being created. Used internally for analytics.",default:"\"blocks\""},{name:"title",annotation:"str",doc:"The tab title to display when this is opened in a browser window.",default:"\"Gradio\""},{name:"css",annotation:"str | None",doc:"Custom css as a string or path to a css file. This css will be included in the demo webpage.",default:"None"},{name:"js",annotation:"str | None",doc:"Custom js or path to js file to run when demo is first loaded. This javascript will be included in the demo webpage.",default:"None"},{name:"head",annotation:"str | None",doc:"Custom html to insert into the head of the demo webpage. This can be used to add custom meta tags, scripts, stylesheets, etc. to the page.",default:"None"}],returns:{annotation:null},example:"import gradio as gr\ndef update(name):\n    return f\"Welcome to Gradio, {name}!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Start typing below and then click **Run** to see the output.\")\n    with gr.Row():\n        inp = gr.Textbox(placeholder=\"What is your name?\")\n        out = gr.Textbox()\n    btn = gr.Button(\"Run\")\n    btn.click(fn=update, inputs=inp, outputs=out)\n\ndemo.launch()",fns:[{fn:null,name:"launch",description:"Launches a simple web server that serves the demo. Can also be used to create a public link used by anyone to access the demo from their browser by setting share=True. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"inline",annotation:"bool | None",doc:"whether to display in the interface inline in an iframe. Defaults to True in python notebooks; False otherwise.",default:"None"},{name:"inbrowser",annotation:"bool",doc:"whether to automatically launch the interface in a new tab on the default browser.",default:"False"},{name:"share",annotation:"bool | None",doc:"whether to create a publicly shareable link for the interface. Creates an SSH tunnel to make your UI accessible from anywhere. If not provided, it is set to False by default every time, except when running in Google Colab. When localhost is not accessible (e.g. Google Colab), setting share=False is not supported.",default:"None"},{name:"debug",annotation:"bool",doc:"if True, blocks the main thread from running. If running in Google Colab, this is needed to print the errors in the cell output.",default:"False"},{name:"max_threads",annotation:"int",doc:"the maximum number of total threads that the Gradio app can generate in parallel. The default is inherited from the starlette library (currently 40).",default:"40"},{name:"auth",annotation:"Callable | tuple[str, str] | list[tuple[str, str]] | None",doc:"If provided, username and password (or list of username-password tuples) required to access interface. Can also provide function that takes username and password and returns True if valid login.",default:"None"},{name:"auth_message",annotation:"str | None",doc:"If provided, HTML message provided on login page.",default:"None"},{name:"prevent_thread_lock",annotation:"bool",doc:"If True, the interface will block the main thread while the server is running.",default:"False"},{name:"show_error",annotation:"bool",doc:"If True, any errors in the interface will be displayed in an alert modal and printed in the browser console log",default:"False"},{name:"server_name",annotation:"str | None",doc:"to make app accessible on local network, set this to &quot;0.0.0.0&quot;. Can be set by environment variable GRADIO_SERVER_NAME. If None, will use &quot;127.0.0.1&quot;.",default:"None"},{name:"server_port",annotation:"int | None",doc:"will start gradio app on this port (if available). Can be set by environment variable GRADIO_SERVER_PORT. If None, will search for an available port starting at 7860.",default:"None"},{name:"height",annotation:"int",doc:"The height in pixels of the iframe element containing the interface (used if inline=True)",default:"500"},{name:"width",annotation:"int | str",doc:"The width in pixels of the iframe element containing the interface (used if inline=True)",default:"\"100%\""},{name:"favicon_path",annotation:"str | None",doc:"If a path to a file (.png, .gif, or .ico) is provided, it will be used as the favicon for the web page.",default:"None"},{name:"ssl_keyfile",annotation:"str | None",doc:"If a path to a file is provided, will use this as the private key file to create a local server running on https.",default:"None"},{name:"ssl_certfile",annotation:"str | None",doc:"If a path to a file is provided, will use this as the signed certificate for https. Needs to be provided if ssl_keyfile is provided.",default:"None"},{name:"ssl_keyfile_password",annotation:"str | None",doc:"If a password is provided, will use this with the ssl certificate for https.",default:"None"},{name:"ssl_verify",annotation:"bool",doc:"If False, skips certificate validation which allows self-signed certificates to be used.",default:"True"},{name:"quiet",annotation:"bool",doc:"If True, suppresses most print statements.",default:"False"},{name:"show_api",annotation:"bool",doc:"If True, shows the api docs in the footer of the app. Default True.",default:"True"},{name:"allowed_paths",annotation:"list[str] | None",doc:"List of complete filepaths or parent directories that gradio is allowed to serve (in addition to the directory containing the gradio python file). Must be absolute paths. Warning: if you provide directories, any files in these directories or their subdirectories are accessible to all users of your app.",default:"None"},{name:"blocked_paths",annotation:"list[str] | None",doc:"List of complete filepaths or parent directories that gradio is not allowed to serve (i.e. users of your app are not allowed to access). Must be absolute paths. Warning: takes precedence over `allowed_paths` and all other directories exposed by Gradio by default.",default:"None"},{name:"root_path",annotation:"str | None",doc:"The root path (or &quot;mount point&quot;) of the application, if it&#x27;s not served from the root (&quot;/&quot;) of the domain. Often used when the application is behind a reverse proxy that forwards requests to the application. For example, if the application is served at &quot;https://example.com/myapp&quot;, the `root_path` should be set to &quot;/myapp&quot;. Can be set by environment variable GRADIO_ROOT_PATH. Defaults to &quot;&quot;.",default:"None"},{name:"app_kwargs",annotation:"dict[str, Any] | None",doc:"Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{&quot;docs_url&quot;: &quot;/docs&quot;}`",default:"None"},{name:"state_session_capacity",annotation:"int",doc:"The maximum number of sessions whose information to store in memory. If the number of sessions exceeds this number, the oldest sessions will be removed. Reduce capacity to reduce memory usage when using gradio.State or returning updated components from functions. Defaults to 10000.",default:"10000"},{name:"share_server_address",annotation:"str | None",doc:"Use this to specify a custom FRP server and port for sharing Gradio apps (only applies if share=True). If not provided, will use the default FRP server at https://gradio.live. See https://github.com/huggingface/frp for more information.",default:"None"},{name:"share_server_protocol",annotation:"Literal[('http', 'https')] | None",doc:"Use this to specify the protocol to use for the share links. Defaults to &quot;https&quot;, unless a custom share_server_address is provided, in which case it defaults to &quot;http&quot;. If you are using a custom share_server_address and want to use https, you must set this to &quot;https&quot;.",default:"None"}],returns:{},example:"import gradio as gr\ndef reverse(text):\n    return text[::-1]\nwith gr.Blocks() as demo:\n    button = gr.Button(value=\"Reverse\")\n    button.click(reverse, gr.Textbox(), gr.Textbox())\ndemo.launch(share=True, auth=(\"username\", \"password\"))",override_signature:null,parent:"gradio.Blocks",slug:"blocks-launch"},{fn:null,name:"queue",description:"By enabling the queue you can control when users know their position in the queue, and set a limit on maximum number of events allowed.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"status_update_rate",annotation:"float | Literal['auto']",doc:"If &quot;auto&quot;, Queue will send status estimations to all clients whenever a job is finished. Otherwise Queue will send status at regular intervals set by this parameter as the number of seconds.",default:"\"auto\""},{name:"api_open",annotation:"bool | None",doc:"If True, the REST routes of the backend will be open, allowing requests made directly to those endpoints to skip the queue.",default:"None"},{name:"max_size",annotation:"int | None",doc:"The maximum number of events the queue will store at any given moment. If the queue is full, new events will not be added and a user will receive a message saying that the queue is full. If None, the queue size will be unlimited.",default:"None"},{name:"concurrency_count",annotation:"int | None",doc:"Deprecated. Set the concurrency_limit directly on event listeners e.g. btn.click(fn, ..., concurrency_limit=10) or gr.Interface(concurrency_limit=10). If necessary, the total number of workers can be configured via `max_threads` in launch().",default:"None"},{name:"default_concurrency_limit",annotation:"int | None | Literal['not_set']",doc:"The default value of `concurrency_limit` to use for event listeners that don&#x27;t specify a value. Can be set by environment variable GRADIO_DEFAULT_CONCURRENCY_LIMIT. Defaults to 1 if not set otherwise.",default:"\"not_set\""}],returns:{},example:"with gr.Blocks() as demo:\n    button = gr.Button(label=\"Generate Image\")\n    button.click(fn=image_generator, inputs=gr.Textbox(), outputs=gr.Image())\ndemo.queue(max_size=10)\ndemo.launch()",override_signature:null,parent:"gradio.Blocks",slug:"blocks-queue"},{fn:null,name:"integrate",description:"A catch-all method for integrating with other libraries. This method should be run after launch()",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"comet_ml",annotation:"\u003Cclass 'inspect._empty'>",doc:"If a comet_ml Experiment object is provided, will integrate with the experiment and appear on Comet dashboard",default:"None"},{name:"wandb",annotation:"ModuleType | None",doc:"If the wandb module is provided, will integrate with it and appear on WandB dashboard",default:"None"},{name:"mlflow",annotation:"ModuleType | None",doc:"If the mlflow module  is provided, will integrate with the experiment and appear on ML Flow dashboard",default:"None"}],returns:{},example:null,override_signature:null,parent:"gradio.Blocks",slug:"blocks-integrate"},{fn:null,name:"load",description:"This listener is triggered when the Blocks initially loads in the browser.",tags:{},parameters:[{name:"block",annotation:"Block | None",doc:null},{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Blocks",slug:"blocks-load"}],demos:[["blocks_hello","import gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    \"\"\"\n    # Hello World!\n    Start typing below to see the output.\n    \"\"\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\nif __name__ == \"__main__\":\n    demo.launch()"],["blocks_flipper","import numpy as np\nimport gradio as gr\n\n\ndef flip_text(x):\n    return x[::-1]\n\n\ndef flip_image(x):\n    return np.fliplr(x)\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\"):\n        gr.Markdown(\"Look at me...\")\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_speech_text_sentiment","from transformers import pipeline\n\nimport gradio as gr\n\nasr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\nclassifier = pipeline(\"text-classification\")\n\n\ndef speech_to_text(speech):\n    text = asr(speech)[\"text\"]\n    return text\n\n\ndef text_to_sentiment(text):\n    return classifier(text)[0][\"label\"]\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    audio_file = gr.Audio(type=\"filepath\")\n    text = gr.Textbox()\n    label = gr.Label()\n\n    b1 = gr.Button(\"Recognize Speech\")\n    b2 = gr.Button(\"Classify Sentiment\")\n\n    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n    b2.click(text_to_sentiment, inputs=text, outputs=label)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["generate_english_german","import gradio as gr\n\nfrom transformers import pipeline\n\nenglish_translator = gr.load(name=\"spaces/gradio/english_translator\")\nenglish_generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n\n\ndef generate_text(text):\n    english_text = english_generator(text)[0][\"generated_text\"]\n    german_text = english_translator(english_text)\n    return english_text, german_text\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            seed = gr.Text(label=\"Input Phrase\")\n        with gr.Column():\n            english = gr.Text(label=\"Generated English Text\")\n            german = gr.Text(label=\"Generated German Text\")\n    btn = gr.Button(\"Generate\")\n    btn.click(generate_text, inputs=[seed], outputs=[english, german])\n    gr.Examples([\"My name is Clara and I am\"], inputs=[seed])\n\nif __name__ == \"__main__\":\n    demo.launch()"]],guides:[{name:"blocks-and-event-listeners",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:1,absolute_index:8,pretty_name:"Blocks And Event Listeners",content:"# Blocks and Event Listeners\n\nWe briefly descirbed the Blocks class in the [Quickstart](/main/guides/quickstart#custom-demos-with-gr-blocks) as a way to build custom demos. Let's dive deeper. \n\n\n## Blocks Structure\n\nTake a look at the demo below.\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/hello_blocks'>\u003C/gradio-app>\n\n- First, note the `with gr.Blocks() as demo:` clause. The Blocks app code will be contained within this clause.\n- Next come the Components. These are the same Components used in `Interface`. However, instead of being passed to some constructor, Components are automatically added to the Blocks as they are created within the `with` clause.\n- Finally, the `click()` event listener. Event listeners define the data flow within the app. In the example above, the listener ties the two Textboxes together. The Textbox `name` acts as the input and Textbox `output` acts as the output to the `greet` method. This dataflow is triggered when the Button `greet_btn` is clicked. Like an Interface, an event listener can take multiple inputs or outputs.\n\nYou can also attach event listeners using decorators - skip the `fn` argument and assign `inputs` and `outputs` directly:\n\n```python\nimport gradio as gr\n\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n\n    @greet_btn.click(inputs=name, outputs=output)\n    def greet(name):\n        return \"Hello \" + name + \"!\"\n\n   \n\ndemo.launch()\n```\n\n## Event Listeners and Interactivity\n\nIn the example above, you'll notice that you are able to edit Textbox `name`, but not Textbox `output`. This is because any Component that acts as an input to an event listener is made interactive. However, since Textbox `output` acts only as an output, Gradio determines that it should not be made interactive. You can override the default behavior and directly configure the interactivity of a Component with the boolean `interactive` keyword argument.\n\n```python\noutput = gr.Textbox(label=\"Output\", interactive=True)\n```\n\n_Note_: What happens if a Gradio component is neither an input nor an output? If a component is constructed with a default value, then it is presumed to be displaying content and is rendered non-interactive. Otherwise, it is rendered interactive. Again, this behavior can be overridden by specifying a value for the `interactive` argument.\n\n## Types of Event Listeners\n\nTake a look at the demo below:\n\n```python\nimport gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    \"\"\"\n    # Hello World!\n    Start typing below to see the output.\n    \"\"\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/blocks_hello'>\u003C/gradio-app>\n\nInstead of being triggered by a click, the `welcome` function is triggered by typing in the Textbox `inp`. This is due to the `change()` event listener. Different Components support different event listeners. For example, the `Video` Component supports a `play()` event listener, triggered when a user presses play. See the [Docs](http://gradio.app/docs#components) for the event listeners for each Component.\n\n## Multiple Data Flows\n\nA Blocks app is not limited to a single data flow the way Interfaces are. Take a look at the demo below:\n\n```python\nimport gradio as gr\n\ndef increase(num):\n    return num + 1\n\nwith gr.Blocks() as demo:\n    a = gr.Number(label=\"a\")\n    b = gr.Number(label=\"b\")\n    atob = gr.Button(\"a > b\")\n    btoa = gr.Button(\"b > a\")\n    atob.click(increase, a, b)\n    btoa.click(increase, b, a)\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/reversible_flow'>\u003C/gradio-app>\n\nNote that `num1` can act as input to `num2`, and also vice-versa! As your apps get more complex, you will have many data flows connecting various Components.\n\nHere's an example of a \"multi-step\" demo, where the output of one model (a speech-to-text model) gets fed into the next model (a sentiment classifier).\n\n```python\nfrom transformers import pipeline\n\nimport gradio as gr\n\nasr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\nclassifier = pipeline(\"text-classification\")\n\n\ndef speech_to_text(speech):\n    text = asr(speech)[\"text\"]\n    return text\n\n\ndef text_to_sentiment(text):\n    return classifier(text)[0][\"label\"]\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    audio_file = gr.Audio(type=\"filepath\")\n    text = gr.Textbox()\n    label = gr.Label()\n\n    b1 = gr.Button(\"Recognize Speech\")\n    b2 = gr.Button(\"Classify Sentiment\")\n\n    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n    b2.click(text_to_sentiment, inputs=text, outputs=label)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_speech_text_sentiment'>\u003C/gradio-app>\n\n## Function Input List vs Dict\n\nThe event listeners you've seen so far have a single input component. If you'd like to have multiple input components pass data to the function, you have two options on how the function can accept input component values:\n\n1. as a list of arguments, or\n2. as a single dictionary of values, keyed by the component\n\nLet's see an example of each:\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    a = gr.Number(label=\"a\")\n    b = gr.Number(label=\"b\")\n    with gr.Row():\n        add_btn = gr.Button(\"Add\")\n        sub_btn = gr.Button(\"Subtract\")\n    c = gr.Number(label=\"sum\")\n\n    def add(num1, num2):\n        return num1 + num2\n    add_btn.click(add, inputs=[a, b], outputs=c)\n\n    def sub(data):\n        return data[a] - data[b]\n    sub_btn.click(sub, inputs={a, b}, outputs=c)\n\n\ndemo.launch()\n```\n\nBoth `add()` and `sub()` take `a` and `b` as inputs. However, the syntax is different between these listeners.\n\n1. To the `add_btn` listener, we pass the inputs as a list. The function `add()` takes each of these inputs as arguments. The value of `a` maps to the argument `num1`, and the value of `b` maps to the argument `num2`.\n2. To the `sub_btn` listener, we pass the inputs as a set (note the curly brackets!). The function `sub()` takes a single dictionary argument `data`, where the keys are the input components, and the values are the values of those components.\n\nIt is a matter of preference which syntax you prefer! For functions with many input components, option 2 may be easier to manage.\n\n\u003Cgradio-app space='gradio/calculator_list_and_dict'>\u003C/gradio-app>\n\n## Function Return List vs Dict\n\nSimilarly, you may return values for multiple output components either as:\n\n1. a list of values, or\n2. a dictionary keyed by the component\n\nLet's first see an example of (1), where we set the values of two output components by returning two values:\n\n```python\nwith gr.Blocks() as demo:\n    food_box = gr.Number(value=10, label=\"Food Count\")\n    status_box = gr.Textbox()\n    def eat(food):\n        if food > 0:\n            return food - 1, \"full\"\n        else:\n            return 0, \"hungry\"\n    gr.Button(\"EAT\").click(\n        fn=eat,\n        inputs=food_box,\n        outputs=[food_box, status_box]\n    )\n```\n\nAbove, each return statement returns two values corresponding to `food_box` and `status_box`, respectively.\n\nInstead of returning a list of values corresponding to each output component in order, you can also return a dictionary, with the key corresponding to the output component and the value as the new value. This also allows you to skip updating some output components.\n\n```python\nwith gr.Blocks() as demo:\n    food_box = gr.Number(value=10, label=\"Food Count\")\n    status_box = gr.Textbox()\n    def eat(food):\n        if food > 0:\n            return {food_box: food - 1, status_box: \"full\"}\n        else:\n            return {status_box: \"hungry\"}\n    gr.Button(\"EAT\").click(\n        fn=eat,\n        inputs=food_box,\n        outputs=[food_box, status_box]\n    )\n```\n\nNotice how when there is no food, we only update the `status_box` element. We skipped updating the `food_box` component.\n\nDictionary returns are helpful when an event listener affects many components on return, or conditionally affects outputs and not others.\n\nKeep in mind that with dictionary returns, we still need to specify the possible outputs in the event listener.\n\n## Updating Component Configurations\n\nThe return value of an event listener function is usually the updated value of the corresponding output Component. Sometimes we want to update the configuration of the Component as well, such as the visibility. In this case, we return a new Component, setting the properties we want to change.\n\n```python\nimport gradio as gr\n\n\ndef change_textbox(choice):\n    if choice == \"short\":\n        return gr.Textbox(lines=2, visible=True)\n    elif choice == \"long\":\n        return gr.Textbox(lines=8, visible=True, value=\"Lorem ipsum dolor sit amet\")\n    else:\n        return gr.Textbox(visible=False)\n\n\nwith gr.Blocks() as demo:\n    radio = gr.Radio(\n        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n    )\n    text = gr.Textbox(lines=2, interactive=True, show_copy_button=True)\n    radio.change(fn=change_textbox, inputs=radio, outputs=text)\n\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_essay_simple'>\u003C/gradio-app>\n\nSee how we can configure the Textbox itself through a new `gr.Textbox()` method. The `value=` argument can still be used to update the value along with Component configuration. Any arguments we do not set will use their previous values.\n\n## Examples\n\nJust like with `gr.Interface`, you can also add examples for your functions when you are working with `gr.Blocks`. In this case, instantiate a `gr.Examples` similar to how you would instantiate any other component. The constructor of `gr.Examples` takes two required arguments:\n\n* `examples`: a nested list of examples, in which the outer list consists of examples and each inner list consists of an input corresponding to each input component\n* `inputs`: the component or list of components that should be populated when the examples are clicked\n\nYou can also set `cache_examples=True` similar to `gr.Interface`, in which case two additional arguments must be provided:\n\n* `outputs`: the component or list of components corresponding to the output of the examples\n* `fn`: the function to run to generate the outputs corresponding to the examples\n\nHere's an example showing how to use `gr.Examples` in a `gr.Blocks` app:\n\n```python\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            num_1 = gr.Number(value=4)\n            operation = gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"])\n            num_2 = gr.Number(value=0)\n            submit_btn = gr.Button(value=\"Calculate\")\n        with gr.Column():\n            result = gr.Number()\n\n    submit_btn.click(calculator, inputs=[num_1, operation, num_2], outputs=[result], api_name=False)\n    examples = gr.Examples(examples=[[5, \"add\", 3],\n                                     [4, \"divide\", 2],\n                                     [-4, \"multiply\", 2.5],\n                                     [0, \"subtract\", 1.2]],\n                           inputs=[num_1, operation, num_2])\n\nif __name__ == \"__main__\":\n    demo.launch(show_api=False)\n```\n\n**Note**: In Gradio 4.0 or later, when you click on examples, not only does the value of the input component update to the example value, but the component's configuration also reverts to the properties with which you constructed the component. This ensures that the examples are compatible with the component even if its configuration has been changed. \n\n\n\n## Running Events Consecutively\n\nYou can also run events consecutively by using the `then` method of an event listener. This will run an event after the previous event has finished running. This is useful for running events that update components in multiple steps.\n\nFor example, in the chatbot example below, we first update the chatbot with the user message immediately, and then update the chatbot with the computer response after a simulated delay.\n\n```python\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.Button(\"Clear\")\n\n    def user(user_message, history):\n        return \"\", history + [[user_message, None]]\n\n    def bot(history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        time.sleep(2)\n        history[-1][1] = bot_message\n        return history\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    clear.click(lambda: None, None, chatbot, queue=False)\n    \ndemo.queue()\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/chatbot_consecutive'>\u003C/gradio-app>\n\nThe `.then()` method of an event listener executes the subsequent event regardless of whether the previous event raised any errors. If you'd like to only run subsequent events if the previous event executed successfully, use the `.success()` method, which takes the same arguments as `.then()`.\n\n## Running Events Continuously\n\nYou can run events on a fixed schedule using the `every` parameter of the event listener. This will run the event `every` number of seconds while the client connection is open. If the connection is closed, the event will stop running after the following iteration. Note that this does not take into account the runtime of the event itself. So a function with a 1 second runtime running with `every=5`, would actually run every 6 seconds. Also note that this parameter does not apply to the `js` function, only the Python function associated with the event listener.\n\nHere is an example of a sine curve that updates every second!\n\n```python\nimport math\nimport gradio as gr\nimport plotly.express as px\nimport numpy as np\n\n\nplot_end = 2 * math.pi\n\n\ndef get_plot(period=1):\n    global plot_end\n    x = np.arange(plot_end - 2 * math.pi, plot_end, 0.02)\n    y = np.sin(2*math.pi*period * x)\n    fig = px.line(x=x, y=y)\n    plot_end += 2 * math.pi\n    if plot_end > 1000:\n        plot_end = 2 * math.pi\n    return fig\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            gr.Markdown(\"Change the value of the slider to automatically update the plot\")\n            period = gr.Slider(label=\"Period of plot\", value=1, minimum=0, maximum=10, step=1)\n            plot = gr.Plot(label=\"Plot (updates every half second)\")\n\n    dep = demo.load(get_plot, None, plot, every=1)\n    period.change(get_plot, period, plot, every=1, cancels=[dep])\n\n\nif __name__ == \"__main__\":\n    demo.queue().launch()\n\n```\n\u003Cgradio-app space='gradio/sine_curve'>\u003C/gradio-app>\n\n## Gathering Event Data\n\nYou can gather specific data about an event by adding the associated event data class as a type hint to an argument in the event listener function.\n\nFor example, event data for `.select()` can be type hinted by a `gradio.SelectData` argument. This event is triggered when a user selects some part of the triggering component, and the event data includes information about what the user specifically selected. If a user selected a specific word in a `Textbox`, a specific image in a `Gallery`, or a specific cell in a `DataFrame`, the event data argument would contain information about the specific selection.\n\nIn the 2 player tic-tac-toe demo below, a user can select a cell in the `DataFrame` to make a move. The event data argument contains information about the specific cell that was selected. We can first check to see if the cell is empty, and then update the cell with the user's move.\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    turn = gr.Textbox(\"X\", interactive=False, label=\"Turn\")\n    board = gr.Dataframe(value=[[\"\", \"\", \"\"]] * 3, interactive=False, type=\"array\")\n\n    def place(board, turn, evt: gr.SelectData):\n        if evt.value:\n            return board, turn\n        board[evt.index[0]][evt.index[1]] = turn\n        turn = \"O\" if turn == \"X\" else \"X\"\n        return board, turn\n\n    board.select(place, [board, turn], [board, turn], show_progress=\"hidden\")\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/tictactoe'>\u003C/gradio-app>\n\n## Binding Multiple Triggers to a Function\n\nOften times, you may want to bind multiple triggers to the same function. For example, you may want to allow a user to click a submit button, or press enter to submit a form. You can do this using the `gr.on` method and passing a list of triggers to the `trigger`.\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    trigger = gr.Textbox(label=\"Trigger Box\")\n    trigger2 = gr.Textbox(label=\"Trigger Box\")\n\n    def greet(name, evt_data: gr.EventData):\n        return \"Hello \" + name + \"!\", evt_data.target.__class__.__name__\n    \n    def clear_name(evt_data: gr.EventData):\n        return \"\", evt_data.target.__class__.__name__\n    \n    gr.on(\n        triggers=[name.submit, greet_btn.click],\n        fn=greet,\n        inputs=name,\n        outputs=[output, trigger],\n    ).then(clear_name, outputs=[name, trigger2])\n\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/on_listener_basic'>\u003C/gradio-app>\n\nYou can use decorator syntax as well:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n\n    @gr.on(triggers=[name.submit, greet_btn.click], inputs=name, outputs=output)\n    def greet(name):\n        return \"Hello \" + name + \"!\"\n\n\ndemo.launch()\n\n```\n\nYou can use `gr.on` to create \"live\" events by binding to the change event of all components. If you do not specify any triggers, the function will automatically bind to the change event of all input components. \n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        num1 = gr.Slider(1, 10)\n        num2 = gr.Slider(1, 10)\n        num3 = gr.Slider(1, 10)\n    output = gr.Number(label=\"Sum\")\n\n    @gr.on(inputs=[num1, num2, num3], outputs=output)\n    def sum(a, b, c):\n        return a + b + c\n\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/on_listener_live'>\u003C/gradio-app>\n\nYou can follow `gr.on` with `.then`, just like any regular event listener. This handy method should save you from having to write a lot of repetitive code!",tags:[],spaces:[],url:"/guides/blocks-and-event-listeners/",contributor:null},{name:"controlling-layout",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:2,absolute_index:9,pretty_name:"Controlling Layout",content:"# Controlling Layout\n\nBy default, Components in Blocks are arranged vertically. Let's take a look at how we can rearrange Components. Under the hood, this layout structure uses the [flexbox model of web development](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox).\n\n## Rows\n\nElements within a `with gr.Row` clause will all be displayed horizontally. For example, to display two Buttons side by side:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn1 = gr.Button(\"Button 1\")\n        btn2 = gr.Button(\"Button 2\")\n```\n\nTo make every element in a Row have the same height, use the `equal_height` argument of the `style` method.\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row(equal_height=True):\n        textbox = gr.Textbox()\n        btn2 = gr.Button(\"Button 2\")\n```\n\nThe widths of elements in a Row can be controlled via a combination of `scale` and `min_width` arguments that are present in every Component.\n\n- `scale` is an integer that defines how an element will take up space in a Row. If scale is set to `0`, and element will not expand to take up space. If scale is set to `1` or greater, the element well expand. Multiple elements in a row will expand proportional to their scale. Below, `btn1` will expand twice as much as `btn2`, while `btn0` will not expand at all:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn0 = gr.Button(\"Button 0\", scale=0)\n        btn1 = gr.Button(\"Button 1\", scale=1)\n        btn2 = gr.Button(\"Button 2\", scale=2)\n```\n\n- `min_width` will set the minimum width the element will take. The Row will wrap if there isn't sufficient space to satisfy all `min_width` values.\n\nLearn more about Rows in the [docs](https://gradio.app/docs/row).\n\n## Columns and Nesting\n\nComponents within a Column will be placed vertically atop each other. Since the vertical layout is the default layout for Blocks apps anyway, to be useful, Columns are usually nested within Rows. For example:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text1 = gr.Textbox(label=\"t1\")\n        slider2 = gr.Textbox(label=\"s2\")\n        drop3 = gr.Dropdown([\"a\", \"b\", \"c\"], label=\"d3\")\n    with gr.Row():\n        with gr.Column(scale=1, min_width=600):\n            text1 = gr.Textbox(label=\"prompt 1\")\n            text2 = gr.Textbox(label=\"prompt 2\")\n            inbtw = gr.Button(\"Between\")\n            text4 = gr.Textbox(label=\"prompt 1\")\n            text5 = gr.Textbox(label=\"prompt 2\")\n        with gr.Column(scale=2, min_width=600):\n            img1 = gr.Image(\"images/cheetah.jpg\")\n            btn = gr.Button(\"Go\")\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/rows_and_columns'>\u003C/gradio-app>\n\nSee how the first column has two Textboxes arranged vertically. The second column has an Image and Button arranged vertically. Notice how the relative widths of the two columns is set by the `scale` parameter. The column with twice the `scale` value takes up twice the width.\n\nLearn more about Columns in the [docs](https://gradio.app/docs/column).\n\n# Dimensions\n\nYou can control the height and width of various components, where the parameters are available. These parameters accept either a number (interpreted as pixels) or a string. Using a string allows the direct application of any CSS unit to the encapsulating Block element, catering to more specific design requirements. When omitted, Gradio uses default dimensions suited for most use cases.\n\nBelow is an example illustrating the use of viewport width (vw):\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(\n        width=\"50vw\",\n    )\n\ndemo.launch()\n```\n\nWhen using percentage values for dimensions, you may want to define a parent component with an absolute unit (e.g. `px` or `vw`). This approach ensures that child components with relative dimensions are sized appropriately:\n\n\n```python\nimport gradio as gr\n\ncss = \"\"\"\n.container {\n    height: 100vh;\n}\n\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    with gr.Column(elem_classes=[\"container\"]):\n        name = gr.Chatbot(value=[[\"1\", \"2\"]], height=\"70%\")\n\ndemo.launch()\n```\n\nIn this example, the Column layout component is given a height of 100% of the viewport height (100vh), and the Chatbot component inside it takes up 70% of the Column's height.\n\nYou can apply any valid CSS unit for these parameters. For a comprehensive list of CSS units, refer to [this guide](https://www.w3schools.com/cssref/css_units.php). We recommend you always consider responsiveness and test your interfaces on various screen sizes to ensure a consistent user experience.\n\n\n\n## Tabs and Accordions\n\nYou can also create Tabs using the `with gr.Tab('tab_name'):` clause. Any component created inside of a `with gr.Tab('tab_name'):` context appears in that tab. Consecutive Tab clauses are grouped together so that a single tab can be selected at one time, and only the components within that Tab's context are shown.\n\nFor example:\n\n```python\nimport numpy as np\nimport gradio as gr\n\n\ndef flip_text(x):\n    return x[::-1]\n\n\ndef flip_image(x):\n    return np.fliplr(x)\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\"):\n        gr.Markdown(\"Look at me...\")\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_flipper'>\u003C/gradio-app>\n\nAlso note the `gr.Accordion('label')` in this example. The Accordion is a layout that can be toggled open or closed. Like `Tabs`, it is a layout element that can selectively hide or show content. Any components that are defined inside of a `with gr.Accordion('label'):` will be hidden or shown when the accordion's toggle icon is clicked.\n\nLearn more about [Tabs](https://gradio.app/docs/tab) and [Accordions](https://gradio.app/docs/accordion) in the docs.\n\n## Visibility\n\nBoth Components and Layout elements have a `visible` argument that can set initially and also updated. Setting `gr.Column(visible=...)` on a Column can be used to show or hide a set of Components.\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    error_box = gr.Textbox(label=\"Error\", visible=False)\n\n    name_box = gr.Textbox(label=\"Name\")\n    age_box = gr.Number(label=\"Age\", minimum=0, maximum=100)\n    symptoms_box = gr.CheckboxGroup([\"Cough\", \"Fever\", \"Runny Nose\"])\n    submit_btn = gr.Button(\"Submit\")\n\n    with gr.Column(visible=False) as output_col:\n        diagnosis_box = gr.Textbox(label=\"Diagnosis\")\n        patient_summary_box = gr.Textbox(label=\"Patient Summary\")\n\n    def submit(name, age, symptoms):\n        if len(name) == 0:\n            return {error_box: gr.Textbox(value=\"Enter name\", visible=True)}\n        return {\n            output_col: gr.Column(visible=True),\n            diagnosis_box: \"covid\" if \"Cough\" in symptoms else \"flu\",\n            patient_summary_box: f\"{name}, {age} y/o\",\n        }\n\n    submit_btn.click(\n        submit,\n        [name_box, age_box, symptoms_box],\n        [error_box, diagnosis_box, patient_summary_box, output_col],\n    )\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_form'>\u003C/gradio-app>\n\n## Variable Number of Outputs\n\nBy adjusting the visibility of components in a dynamic way, it is possible to create\ndemos with Gradio that support a _variable numbers of outputs_. Here's a very simple example\nwhere the number of output textboxes is controlled by an input slider:\n\n```python\nimport gradio as gr\n\nmax_textboxes = 10\n\ndef variable_outputs(k):\n    k = int(k)\n    return [gr.Textbox(visible=True)]*k + [gr.Textbox(visible=False)]*(max_textboxes-k)\n\nwith gr.Blocks() as demo:\n    s = gr.Slider(1, max_textboxes, value=max_textboxes, step=1, label=\"How many textboxes to show:\")\n    textboxes = []\n    for i in range(max_textboxes):\n        t = gr.Textbox(f\"Textbox {i}\")\n        textboxes.append(t)\n\n    s.change(variable_outputs, s, textboxes)\n\nif __name__ == \"__main__\":\n   demo.launch()\n\n```\n\u003Cgradio-app space='gradio/variable_outputs'>\u003C/gradio-app>\n\n## Defining and Rendering Components Separately\n\nIn some cases, you might want to define components before you actually render them in your UI. For instance, you might want to show an examples section using `gr.Examples` above the corresponding `gr.Textbox` input. Since `gr.Examples` requires as a parameter the input component object, you will need to first define the input component, but then render it later, after you have defined the `gr.Examples` object.\n\nThe solution to this is to define the `gr.Textbox` outside of the `gr.Blocks()` scope and use the component's `.render()` method wherever you'd like it placed in the UI.\n\nHere's a full code example:\n\n```python\ninput_textbox = gr.Textbox()\n\nwith gr.Blocks() as demo:\n    gr.Examples([\"hello\", \"bonjour\", \"merhaba\"], input_textbox)\n    input_textbox.render()\n```\n",tags:[],spaces:[],url:"/guides/controlling-layout/",contributor:null},{name:"state-in-blocks",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:3,absolute_index:10,pretty_name:"State In Blocks",content:"# State in Blocks\n\nWe covered [State in Interfaces](https://gradio.app/interface-state), this guide takes a look at state in Blocks, which works mostly the same.\n\n## Global State\n\nGlobal state in Blocks works the same as in Interface. Any variable created outside a function call is a reference shared between all users.\n\n## Session State\n\nGradio supports session **state**, where data persists across multiple submits within a page session, in Blocks apps as well. To reiterate, session data is _not_ shared between different users of your model. To store data in a session state, you need to do three things:\n\n1. Create a `gr.State()` object. If there is a default value to this stateful object, pass that into the constructor.\n2. In the event listener, put the `State` object as an input and output.\n3. In the event listener function, add the variable to the input parameters and the return value.\n\nLet's take a look at a game of hangman.\n\n```python\nimport gradio as gr\n\nsecret_word = \"gradio\"\n\nwith gr.Blocks() as demo:    \n    used_letters_var = gr.State([])\n    with gr.Row() as row:\n        with gr.Column():\n            input_letter = gr.Textbox(label=\"Enter letter\")\n            btn = gr.Button(\"Guess Letter\")\n        with gr.Column():\n            hangman = gr.Textbox(\n                label=\"Hangman\",\n                value=\"_\"*len(secret_word)\n            )\n            used_letters_box = gr.Textbox(label=\"Used Letters\")\n\n    def guess_letter(letter, used_letters):\n        used_letters.append(letter)\n        answer = \"\".join([\n            (letter if letter in used_letters else \"_\")\n            for letter in secret_word\n        ])\n        return {\n            used_letters_var: used_letters,\n            used_letters_box: \", \".join(used_letters),\n            hangman: answer\n        }\n    btn.click(\n        guess_letter, \n        [input_letter, used_letters_var],\n        [used_letters_var, used_letters_box, hangman]\n        )\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/hangman'>\u003C/gradio-app>\n\nLet's see how we do each of the 3 steps listed above in this game:\n\n1. We store the used letters in `used_letters_var`. In the constructor of `State`, we set the initial value of this to `[]`, an empty list.\n2. In `btn.click()`, we have a reference to `used_letters_var` in both the inputs and outputs.\n3. In `guess_letter`, we pass the value of this `State` to `used_letters`, and then return an updated value of this `State` in the return statement.\n\nWith more complex apps, you will likely have many State variables storing session state in a single Blocks app.\n\nLearn more about `State` in the [docs](https://gradio.app/docs/state).\n",tags:[],spaces:[],url:"/guides/state-in-blocks/",contributor:null},{name:"custom-CSS-and-JS",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:4,absolute_index:11,pretty_name:"Custom CSS And JS",content:"# Customizing your demo with CSS and Javascript\n\nGradio allows you to customize your demo in several ways. You can customize the layout of your demo, add custom HTML, and add custom theming as well. This tutorial will go beyond that and walk you through how to add custom CSS and JavaScript code to your demo in order to add custom styling, animations, custom UI functionality, analytics, and more.\n\n## Adding custom CSS to your demo\n\nGradio themes are the easiest way to customize the look and feel of your app. You can choose from a variety of themes, or create your own. To do so, pass the `theme=` kwarg to the `Blocks` constructor. For example:\n\n```python\nwith gr.Blocks(theme=gr.themes.Glass()):\n    ...\n```\n\nGradio comes with a set of prebuilt themes which you can load from `gr.themes.*`. You can extend these themes or create your own themes from scratch - see the [Theming guide](/guides/theming-guide) for more details.\n\nFor additional styling ability, you can pass any CSS to your app using the `css=` kwarg. You can either the filepath to a CSS file, or a string of CSS code.\n\n**Warning**: The use of query selectors in custom JS and CSS is _not_ guaranteed to work across Gradio versions as the Gradio HTML DOM may change. We recommend using query selectors sparingly.\n\nThe base class for the Gradio app is `gradio-container`, so here's an example that changes the background color of the Gradio app:\n\n```python\nwith gr.Blocks(css=\".gradio-container {background-color: red}\") as demo:\n    ...\n```\n\nIf you'd like to reference external files in your css, preface the file path (which can be a relative or absolute path) with `\"file=\"`, for example:\n\n```python\nwith gr.Blocks(css=\".gradio-container {background: url('file=clouds.jpg')}\") as demo:\n    ...\n```\n\nNote: By default, files in the host machine are not accessible to users running the Gradio app. As a result, you should make sure that any referenced files (such as `clouds.jpg` here) are either URLs or allowed via the `allow_list` parameter in `launch()`. Read more in our [section on Security and File Access](/guides/sharing-your-app#security-and-file-access).\n\n\n## The `elem_id` and `elem_classes` Arguments\n\nYou can `elem_id` to add an HTML element `id` to any component, and `elem_classes` to add a class or list of classes. This will allow you to select elements more easily with CSS. This approach is also more likely to be stable across Gradio versions as built-in class names or ids may change (however, as mentioned in the warning above, we cannot guarantee complete compatibility between Gradio versions if you use custom CSS as the DOM elements may themselves change).\n\n```python\ncss = \"\"\"\n#warning {background-color: #FFCCCB}\n.feedback textarea {font-size: 24px !important}\n\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    box1 = gr.Textbox(value=\"Good Job\", elem_classes=\"feedback\")\n    box2 = gr.Textbox(value=\"Failure\", elem_id=\"warning\", elem_classes=\"feedback\")\n```\n\nThe CSS `#warning` ruleset will only target the second Textbox, while the `.feedback` ruleset will target both. Note that when targeting classes, you might need to put the `!important` selector to override the default Gradio styles.\n\n## Adding custom JavaScript to your demo\n\nThere are 3 ways to add javascript code to your Gradio demo:\n\n1. You can add JavaScript code as a string or as a filepath to the `js` parameter of the `Blocks` or `Interface` initializer. This will run the JavaScript code when the demo is first loaded.\n\nBelow is an example of adding custom js to show an animated welcome message when the demo first loads.\n\n```python\nimport gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\njs = \"\"\"\nfunction createGradioAnimation() {\n    var container = document.createElement('div');\n    container.id = 'gradio-animation';\n    container.style.fontSize = '2em';\n    container.style.fontWeight = 'bold';\n    container.style.textAlign = 'center';\n    container.style.marginBottom = '20px';\n\n    var text = 'Welcome to Gradio!';\n    for (var i = 0; i \u003C text.length; i++) {\n        (function(i){\n            setTimeout(function(){\n                var letter = document.createElement('span');\n                letter.style.opacity = '0';\n                letter.style.transition = 'opacity 0.5s';\n                letter.innerText = text[i];\n\n                container.appendChild(letter);\n\n                setTimeout(function() {\n                    letter.style.opacity = '1';\n                }, 50);\n            }, i * 250);\n        })(i);\n    }\n\n    var gradioContainer = document.querySelector('.gradio-container');\n    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n\n    return 'Animation created';\n}\n\"\"\"\nwith gr.Blocks(js=js) as demo:\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/blocks_js_load'>\u003C/gradio-app>\n\nNote: You can also supply your custom js code as a file path. For example, if you have a file called `custom.js` in the same directory as your Python script, you can add it to your demo like so: `with gr.Blocks(js=\"custom.js\") as demo:`. Same goes for `Interface` (ex: `gr.Interface(..., js=\"custom.js\")`).\n\n2. When using `Blocks` and event listeners, events have a `js` argument that can take a JavaScript function as a string and treat it just like a Python event listener function. You can pass both a JavaScript function and a Python function (in which case the JavaScript function is run first) or only Javascript (and set the Python `fn` to `None`). Take a look at the code below:\n   \n```python\nimport gradio as gr\n\nblocks = gr.Blocks()\n\nwith blocks as demo:\n    subject = gr.Textbox(placeholder=\"subject\")\n    verb = gr.Radio([\"ate\", \"loved\", \"hated\"])\n    object = gr.Textbox(placeholder=\"object\")\n\n    with gr.Row():\n        btn = gr.Button(\"Create sentence.\")\n        reverse_btn = gr.Button(\"Reverse sentence.\")\n        foo_bar_btn = gr.Button(\"Append foo\")\n        reverse_then_to_the_server_btn = gr.Button(\n            \"Reverse sentence and send to server.\"\n        )\n\n    def sentence_maker(w1, w2, w3):\n        return f\"{w1} {w2} {w3}\"\n\n    output1 = gr.Textbox(label=\"output 1\")\n    output2 = gr.Textbox(label=\"verb\")\n    output3 = gr.Textbox(label=\"verb reversed\")\n    output4 = gr.Textbox(label=\"front end process and then send to backend\")\n\n    btn.click(sentence_maker, [subject, verb, object], output1)\n    reverse_btn.click(\n        None, [subject, verb, object], output2, js=\"(s, v, o) => o + ' ' + v + ' ' + s\"\n    )\n    verb.change(lambda x: x, verb, output3, js=\"(x) => [...x].reverse().join('')\")\n    foo_bar_btn.click(None, [], subject, js=\"(x) => x + ' foo'\")\n\n    reverse_then_to_the_server_btn.click(\n        sentence_maker,\n        [subject, verb, object],\n        output4,\n        js=\"(s, v, o) => [s, v, o].map(x => [...x].reverse().join(''))\",\n    )\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_js_methods'>\u003C/gradio-app>\n\n3. Lastly, you can add JavaScript code to the `head` param of the `Blocks` initializer. This will add the code to the head of the HTML document. For example, you can add Google Analytics to your demo like so:\n\n\n```python\nhead = f\"\"\"\n\u003Cscript async src=\"https://www.googletagmanager.com/gtag/js?id={google_analytics_tracking_id}\">\u003C/script>\n\u003Cscript>\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){{dataLayer.push(arguments);}}\n  gtag('js', new Date());\n  gtag('config', '{google_analytics_tracking_id}');\n\u003C/script>\n\"\"\"\n\nwith gr.Blocks(head=head) as demo:\n    ...demo code...\n```\n\nThe `head` parameter accepts any HTML tags you would normally insert into the `\u003Chead>` of a page. For example, you can also include `\u003Cmeta>` tags to `head`.\n\nNote that injecting custom HTML can affect browser behavior and compatibility (e.g. keyboard shortcuts). You should test your interface across different browsers and be mindful of how scripts may interact with browser defaults.\nHere's an example where pressing `Shift + s` triggers the `click` event of a specific `Button` component if the browser focus is _not_ on an input component (e.g. `Textbox` component):\n\n```python\nimport gradio as gr\n\nshortcut_js = \"\"\"\n\u003Cscript>\nfunction shortcuts(e) {\n    var event = document.all ? window.event : e;\n    switch (e.target.tagName.toLowerCase()) {\n        case \"input\":\n        case \"textarea\":\n        break;\n        default:\n        if (e.key.toLowerCase() == \"s\" && e.shiftKey) {\n            document.getElementById(\"my_btn\").click();\n        }\n    }\n}\ndocument.addEventListener('keypress', shortcuts, false);\n\u003C/script>\n\"\"\"\n\nwith gr.Blocks(head=shortcut_js) as demo:\n    action_button = gr.Button(value=\"Name\", elem_id=\"my_btn\")\n    textbox = gr.Textbox()\n    action_button.click(lambda : \"button pressed\", None, textbox)\n    \ndemo.launch()\n```\n",tags:[],spaces:[],url:"/guides/custom-CSS-and-JS/",contributor:null},{name:"using-blocks-like-functions",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:5,absolute_index:12,pretty_name:"Using Blocks Like Functions",content:"# Using Gradio Blocks Like Functions\n\n\n\n**Prerequisite**: This Guide builds on the Blocks Introduction. Make sure to [read that guide first](https://gradio.app/blocks-and-event-listeners).\n\n## Introduction\n\nDid you know that apart from being a full-stack machine learning demo, a Gradio Blocks app is also a regular-old python function!?\n\nThis means that if you have a gradio Blocks (or Interface) app called `demo`, you can use `demo` like you would any python function.\n\nSo doing something like `output = demo(\"Hello\", \"friend\")` will run the first event defined in `demo` on the inputs \"Hello\" and \"friend\" and store it\nin the variable `output`.\n\nIf I put you to sleep ü•±, please bear with me! By using apps like functions, you can seamlessly compose Gradio apps.\nThe following section will show how.\n\n## Treating Blocks like functions\n\nLet's say we have the following demo that translates english text to german text.\n\n```python\nimport gradio as gr\n\nfrom transformers import pipeline\n\npipe = pipeline(\"translation\", model=\"t5-base\")\n\n\ndef translate(text):\n    return pipe(text)[0][\"translation_text\"]\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            english = gr.Textbox(label=\"English text\")\n            translate_btn = gr.Button(value=\"Translate\")\n        with gr.Column():\n            german = gr.Textbox(label=\"German Text\")\n\n    translate_btn.click(translate, inputs=english, outputs=german, api_name=\"translate-to-german\")\n    examples = gr.Examples(examples=[\"I went to the supermarket yesterday.\", \"Helen is a good swimmer.\"],\n                           inputs=[english])\n\ndemo.launch()\n```\n\nI already went ahead and hosted it in Hugging Face spaces at [gradio/english_translator](https://huggingface.co/spaces/gradio/english_translator).\n\nYou can see the demo below as well:\n\n\u003Cgradio-app space='gradio/english_translator'>\u003C/gradio-app>\n\nNow, let's say you have an app that generates english text, but you wanted to additionally generate german text.\n\nYou could either:\n\n1. Copy the source code of my english-to-german translation and paste it in your app.\n\n2. Load my english-to-german translation in your app and treat it like a normal python function.\n\nOption 1 technically always works, but it often introduces unwanted complexity.\n\nOption 2 lets you borrow the functionality you want without tightly coupling our apps.\n\nAll you have to do is call the `Blocks.load` class method in your source file.\nAfter that, you can use my translation app like a regular python function!\n\nThe following code snippet and demo shows how to use `Blocks.load`.\n\nNote that the variable `english_translator` is my english to german app, but its used in `generate_text` like a regular function.\n\n```python\nimport gradio as gr\n\nfrom transformers import pipeline\n\nenglish_translator = gr.load(name=\"spaces/gradio/english_translator\")\nenglish_generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n\n\ndef generate_text(text):\n    english_text = english_generator(text)[0][\"generated_text\"]\n    german_text = english_translator(english_text)\n    return english_text, german_text\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            seed = gr.Text(label=\"Input Phrase\")\n        with gr.Column():\n            english = gr.Text(label=\"Generated English Text\")\n            german = gr.Text(label=\"Generated German Text\")\n    btn = gr.Button(\"Generate\")\n    btn.click(generate_text, inputs=[seed], outputs=[english, german])\n    gr.Examples([\"My name is Clara and I am\"], inputs=[seed])\n\ndemo.launch()\n```\n\n\u003Cgradio-app space='gradio/generate_english_german'>\u003C/gradio-app>\n\n## How to control which function in the app to use\n\nIf the app you are loading defines more than one function, you can specify which function to use\nwith the `fn_index` and `api_name` parameters.\n\nIn the code for our english to german demo, you'll see the following line:\n\n```python\ntranslate_btn.click(translate, inputs=english, outputs=german, api_name=\"translate-to-german\")\n```\n\nThe `api_name` gives this function a unique name in our app. You can use this name to tell gradio which\nfunction in the upstream space you want to use:\n\n```python\nenglish_generator(text, api_name=\"translate-to-german\")[0][\"generated_text\"]\n```\n\nYou can also use the `fn_index` parameter.\nImagine my app also defined an english to spanish translation function.\nIn order to use it in our text generation app, we would use the following code:\n\n```python\nenglish_generator(text, fn_index=1)[0][\"generated_text\"]\n```\n\nFunctions in gradio spaces are zero-indexed, so since the spanish translator would be the second function in my space,\nyou would use index 1.\n\n## Parting Remarks\n\nWe showed how treating a Blocks app like a regular python helps you compose functionality across different apps.\nAny Blocks app can be treated like a function, but a powerful pattern is to `load` an app hosted on\n[Hugging Face Spaces](https://huggingface.co/spaces) prior to treating it like a function in your own app.\nYou can also load models hosted on the [Hugging Face Model Hub](https://huggingface.co/models) - see the [Using Hugging Face Integrations](/using_hugging_face_integrations) guide for an example.\n\n### Happy building! ‚öíÔ∏è\n",tags:["TRANSLATION","HUB","SPACES"],spaces:[],url:"/guides/using-blocks-like-functions/",contributor:null}],override_signature:"with gradio.Blocks():",parent:"gradio",slug:"blocks"},accordion:{class:null,name:"Accordion",description:"Accordion is a layout element which can be toggled to show/hide the contained content.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"label",annotation:"str | None",doc:"name of accordion section.",default:"None"},{name:"open",annotation:"bool",doc:"if True, accordion is open by default.",default:"True"},{name:"visible",annotation:"bool",doc:null,default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional string or list of strings that are assigned as the class of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, this layout will not be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:"with gr.Accordion(\"See Details\"):\n    gr.Markdown(\"lorem ipsum\")",fns:[],parent:"gradio",prev_obj:"Group",next_obj:"Components",slug:"accordion"},column:{class:null,name:"Column",description:"Column is a layout element within Blocks that renders all children vertically. The widths of columns can be set through the `scale` and `min_width` parameters. If a certain scale results in a column narrower than min_width, the min_width parameter will win.",tags:{guides:"controlling-layout"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"scale",annotation:"int",doc:"relative width compared to adjacent Columns. For example, if Column A has scale=2, and Column B has scale=1, A will be twice as wide as B.",default:"1"},{name:"min_width",annotation:"int",doc:"minimum pixel width of Column, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in a column narrower than min_width, the min_width parameter will be respected first.",default:"320"},{name:"variant",annotation:"Literal[('default', 'panel', 'compact')]",doc:"column type, &#x27;default&#x27; (no background), &#x27;panel&#x27; (gray background color and rounded corners), or &#x27;compact&#x27; (rounded corners and no internal gap).",default:"\"default\""},{name:"visible",annotation:"bool",doc:"If False, column will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional string or list of strings that are assigned as the class of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:"with gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column(scale=1):\n            text1 = gr.Textbox()\n            text2 = gr.Textbox()\n        with gr.Column(scale=4):\n            btn1 = gr.Button(\"Button 1\")\n            btn2 = gr.Button(\"Button 2\")",fns:[],guides:[{name:"controlling-layout",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:2,absolute_index:9,pretty_name:"Controlling Layout",content:"# Controlling Layout\n\nBy default, Components in Blocks are arranged vertically. Let's take a look at how we can rearrange Components. Under the hood, this layout structure uses the [flexbox model of web development](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox).\n\n## Rows\n\nElements within a `with gr.Row` clause will all be displayed horizontally. For example, to display two Buttons side by side:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn1 = gr.Button(\"Button 1\")\n        btn2 = gr.Button(\"Button 2\")\n```\n\nTo make every element in a Row have the same height, use the `equal_height` argument of the `style` method.\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row(equal_height=True):\n        textbox = gr.Textbox()\n        btn2 = gr.Button(\"Button 2\")\n```\n\nThe widths of elements in a Row can be controlled via a combination of `scale` and `min_width` arguments that are present in every Component.\n\n- `scale` is an integer that defines how an element will take up space in a Row. If scale is set to `0`, and element will not expand to take up space. If scale is set to `1` or greater, the element well expand. Multiple elements in a row will expand proportional to their scale. Below, `btn1` will expand twice as much as `btn2`, while `btn0` will not expand at all:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn0 = gr.Button(\"Button 0\", scale=0)\n        btn1 = gr.Button(\"Button 1\", scale=1)\n        btn2 = gr.Button(\"Button 2\", scale=2)\n```\n\n- `min_width` will set the minimum width the element will take. The Row will wrap if there isn't sufficient space to satisfy all `min_width` values.\n\nLearn more about Rows in the [docs](https://gradio.app/docs/row).\n\n## Columns and Nesting\n\nComponents within a Column will be placed vertically atop each other. Since the vertical layout is the default layout for Blocks apps anyway, to be useful, Columns are usually nested within Rows. For example:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text1 = gr.Textbox(label=\"t1\")\n        slider2 = gr.Textbox(label=\"s2\")\n        drop3 = gr.Dropdown([\"a\", \"b\", \"c\"], label=\"d3\")\n    with gr.Row():\n        with gr.Column(scale=1, min_width=600):\n            text1 = gr.Textbox(label=\"prompt 1\")\n            text2 = gr.Textbox(label=\"prompt 2\")\n            inbtw = gr.Button(\"Between\")\n            text4 = gr.Textbox(label=\"prompt 1\")\n            text5 = gr.Textbox(label=\"prompt 2\")\n        with gr.Column(scale=2, min_width=600):\n            img1 = gr.Image(\"images/cheetah.jpg\")\n            btn = gr.Button(\"Go\")\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/rows_and_columns'>\u003C/gradio-app>\n\nSee how the first column has two Textboxes arranged vertically. The second column has an Image and Button arranged vertically. Notice how the relative widths of the two columns is set by the `scale` parameter. The column with twice the `scale` value takes up twice the width.\n\nLearn more about Columns in the [docs](https://gradio.app/docs/column).\n\n# Dimensions\n\nYou can control the height and width of various components, where the parameters are available. These parameters accept either a number (interpreted as pixels) or a string. Using a string allows the direct application of any CSS unit to the encapsulating Block element, catering to more specific design requirements. When omitted, Gradio uses default dimensions suited for most use cases.\n\nBelow is an example illustrating the use of viewport width (vw):\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(\n        width=\"50vw\",\n    )\n\ndemo.launch()\n```\n\nWhen using percentage values for dimensions, you may want to define a parent component with an absolute unit (e.g. `px` or `vw`). This approach ensures that child components with relative dimensions are sized appropriately:\n\n\n```python\nimport gradio as gr\n\ncss = \"\"\"\n.container {\n    height: 100vh;\n}\n\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    with gr.Column(elem_classes=[\"container\"]):\n        name = gr.Chatbot(value=[[\"1\", \"2\"]], height=\"70%\")\n\ndemo.launch()\n```\n\nIn this example, the Column layout component is given a height of 100% of the viewport height (100vh), and the Chatbot component inside it takes up 70% of the Column's height.\n\nYou can apply any valid CSS unit for these parameters. For a comprehensive list of CSS units, refer to [this guide](https://www.w3schools.com/cssref/css_units.php). We recommend you always consider responsiveness and test your interfaces on various screen sizes to ensure a consistent user experience.\n\n\n\n## Tabs and Accordions\n\nYou can also create Tabs using the `with gr.Tab('tab_name'):` clause. Any component created inside of a `with gr.Tab('tab_name'):` context appears in that tab. Consecutive Tab clauses are grouped together so that a single tab can be selected at one time, and only the components within that Tab's context are shown.\n\nFor example:\n\n```python\nimport numpy as np\nimport gradio as gr\n\n\ndef flip_text(x):\n    return x[::-1]\n\n\ndef flip_image(x):\n    return np.fliplr(x)\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\"):\n        gr.Markdown(\"Look at me...\")\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_flipper'>\u003C/gradio-app>\n\nAlso note the `gr.Accordion('label')` in this example. The Accordion is a layout that can be toggled open or closed. Like `Tabs`, it is a layout element that can selectively hide or show content. Any components that are defined inside of a `with gr.Accordion('label'):` will be hidden or shown when the accordion's toggle icon is clicked.\n\nLearn more about [Tabs](https://gradio.app/docs/tab) and [Accordions](https://gradio.app/docs/accordion) in the docs.\n\n## Visibility\n\nBoth Components and Layout elements have a `visible` argument that can set initially and also updated. Setting `gr.Column(visible=...)` on a Column can be used to show or hide a set of Components.\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    error_box = gr.Textbox(label=\"Error\", visible=False)\n\n    name_box = gr.Textbox(label=\"Name\")\n    age_box = gr.Number(label=\"Age\", minimum=0, maximum=100)\n    symptoms_box = gr.CheckboxGroup([\"Cough\", \"Fever\", \"Runny Nose\"])\n    submit_btn = gr.Button(\"Submit\")\n\n    with gr.Column(visible=False) as output_col:\n        diagnosis_box = gr.Textbox(label=\"Diagnosis\")\n        patient_summary_box = gr.Textbox(label=\"Patient Summary\")\n\n    def submit(name, age, symptoms):\n        if len(name) == 0:\n            return {error_box: gr.Textbox(value=\"Enter name\", visible=True)}\n        return {\n            output_col: gr.Column(visible=True),\n            diagnosis_box: \"covid\" if \"Cough\" in symptoms else \"flu\",\n            patient_summary_box: f\"{name}, {age} y/o\",\n        }\n\n    submit_btn.click(\n        submit,\n        [name_box, age_box, symptoms_box],\n        [error_box, diagnosis_box, patient_summary_box, output_col],\n    )\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_form'>\u003C/gradio-app>\n\n## Variable Number of Outputs\n\nBy adjusting the visibility of components in a dynamic way, it is possible to create\ndemos with Gradio that support a _variable numbers of outputs_. Here's a very simple example\nwhere the number of output textboxes is controlled by an input slider:\n\n```python\nimport gradio as gr\n\nmax_textboxes = 10\n\ndef variable_outputs(k):\n    k = int(k)\n    return [gr.Textbox(visible=True)]*k + [gr.Textbox(visible=False)]*(max_textboxes-k)\n\nwith gr.Blocks() as demo:\n    s = gr.Slider(1, max_textboxes, value=max_textboxes, step=1, label=\"How many textboxes to show:\")\n    textboxes = []\n    for i in range(max_textboxes):\n        t = gr.Textbox(f\"Textbox {i}\")\n        textboxes.append(t)\n\n    s.change(variable_outputs, s, textboxes)\n\nif __name__ == \"__main__\":\n   demo.launch()\n\n```\n\u003Cgradio-app space='gradio/variable_outputs'>\u003C/gradio-app>\n\n## Defining and Rendering Components Separately\n\nIn some cases, you might want to define components before you actually render them in your UI. For instance, you might want to show an examples section using `gr.Examples` above the corresponding `gr.Textbox` input. Since `gr.Examples` requires as a parameter the input component object, you will need to first define the input component, but then render it later, after you have defined the `gr.Examples` object.\n\nThe solution to this is to define the `gr.Textbox` outside of the `gr.Blocks()` scope and use the component's `.render()` method wherever you'd like it placed in the UI.\n\nHere's a full code example:\n\n```python\ninput_textbox = gr.Textbox()\n\nwith gr.Blocks() as demo:\n    gr.Examples([\"hello\", \"bonjour\", \"merhaba\"], input_textbox)\n    input_textbox.render()\n```\n",tags:[],spaces:[],url:"/guides/controlling-layout/",contributor:null}],override_signature:"with gradio.Column():",parent:"gradio",prev_obj:"Row",next_obj:"Tab",slug:"column"},row:{class:null,name:"Row",description:"Row is a layout element within Blocks that renders all children horizontally.",tags:{guides:"controlling-layout"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"variant",annotation:"Literal[('default', 'panel', 'compact')]",doc:"row type, &#x27;default&#x27; (no background), &#x27;panel&#x27; (gray background color and rounded corners), or &#x27;compact&#x27; (rounded corners and no internal gap).",default:"\"default\""},{name:"visible",annotation:"bool",doc:"If False, row will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional string or list of strings that are assigned as the class of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, this layout will not be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"equal_height",annotation:"bool",doc:"If True, makes every child element have equal height",default:"True"}],returns:{annotation:null},example:"with gr.Blocks() as demo:\n    with gr.Row():\n        gr.Image(\"lion.jpg\", scale=2)\n        gr.Image(\"tiger.jpg\", scale=1)\ndemo.launch()",fns:[],guides:[{name:"controlling-layout",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:2,absolute_index:9,pretty_name:"Controlling Layout",content:"# Controlling Layout\n\nBy default, Components in Blocks are arranged vertically. Let's take a look at how we can rearrange Components. Under the hood, this layout structure uses the [flexbox model of web development](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox).\n\n## Rows\n\nElements within a `with gr.Row` clause will all be displayed horizontally. For example, to display two Buttons side by side:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn1 = gr.Button(\"Button 1\")\n        btn2 = gr.Button(\"Button 2\")\n```\n\nTo make every element in a Row have the same height, use the `equal_height` argument of the `style` method.\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row(equal_height=True):\n        textbox = gr.Textbox()\n        btn2 = gr.Button(\"Button 2\")\n```\n\nThe widths of elements in a Row can be controlled via a combination of `scale` and `min_width` arguments that are present in every Component.\n\n- `scale` is an integer that defines how an element will take up space in a Row. If scale is set to `0`, and element will not expand to take up space. If scale is set to `1` or greater, the element well expand. Multiple elements in a row will expand proportional to their scale. Below, `btn1` will expand twice as much as `btn2`, while `btn0` will not expand at all:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn0 = gr.Button(\"Button 0\", scale=0)\n        btn1 = gr.Button(\"Button 1\", scale=1)\n        btn2 = gr.Button(\"Button 2\", scale=2)\n```\n\n- `min_width` will set the minimum width the element will take. The Row will wrap if there isn't sufficient space to satisfy all `min_width` values.\n\nLearn more about Rows in the [docs](https://gradio.app/docs/row).\n\n## Columns and Nesting\n\nComponents within a Column will be placed vertically atop each other. Since the vertical layout is the default layout for Blocks apps anyway, to be useful, Columns are usually nested within Rows. For example:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text1 = gr.Textbox(label=\"t1\")\n        slider2 = gr.Textbox(label=\"s2\")\n        drop3 = gr.Dropdown([\"a\", \"b\", \"c\"], label=\"d3\")\n    with gr.Row():\n        with gr.Column(scale=1, min_width=600):\n            text1 = gr.Textbox(label=\"prompt 1\")\n            text2 = gr.Textbox(label=\"prompt 2\")\n            inbtw = gr.Button(\"Between\")\n            text4 = gr.Textbox(label=\"prompt 1\")\n            text5 = gr.Textbox(label=\"prompt 2\")\n        with gr.Column(scale=2, min_width=600):\n            img1 = gr.Image(\"images/cheetah.jpg\")\n            btn = gr.Button(\"Go\")\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/rows_and_columns'>\u003C/gradio-app>\n\nSee how the first column has two Textboxes arranged vertically. The second column has an Image and Button arranged vertically. Notice how the relative widths of the two columns is set by the `scale` parameter. The column with twice the `scale` value takes up twice the width.\n\nLearn more about Columns in the [docs](https://gradio.app/docs/column).\n\n# Dimensions\n\nYou can control the height and width of various components, where the parameters are available. These parameters accept either a number (interpreted as pixels) or a string. Using a string allows the direct application of any CSS unit to the encapsulating Block element, catering to more specific design requirements. When omitted, Gradio uses default dimensions suited for most use cases.\n\nBelow is an example illustrating the use of viewport width (vw):\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(\n        width=\"50vw\",\n    )\n\ndemo.launch()\n```\n\nWhen using percentage values for dimensions, you may want to define a parent component with an absolute unit (e.g. `px` or `vw`). This approach ensures that child components with relative dimensions are sized appropriately:\n\n\n```python\nimport gradio as gr\n\ncss = \"\"\"\n.container {\n    height: 100vh;\n}\n\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    with gr.Column(elem_classes=[\"container\"]):\n        name = gr.Chatbot(value=[[\"1\", \"2\"]], height=\"70%\")\n\ndemo.launch()\n```\n\nIn this example, the Column layout component is given a height of 100% of the viewport height (100vh), and the Chatbot component inside it takes up 70% of the Column's height.\n\nYou can apply any valid CSS unit for these parameters. For a comprehensive list of CSS units, refer to [this guide](https://www.w3schools.com/cssref/css_units.php). We recommend you always consider responsiveness and test your interfaces on various screen sizes to ensure a consistent user experience.\n\n\n\n## Tabs and Accordions\n\nYou can also create Tabs using the `with gr.Tab('tab_name'):` clause. Any component created inside of a `with gr.Tab('tab_name'):` context appears in that tab. Consecutive Tab clauses are grouped together so that a single tab can be selected at one time, and only the components within that Tab's context are shown.\n\nFor example:\n\n```python\nimport numpy as np\nimport gradio as gr\n\n\ndef flip_text(x):\n    return x[::-1]\n\n\ndef flip_image(x):\n    return np.fliplr(x)\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\"):\n        gr.Markdown(\"Look at me...\")\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_flipper'>\u003C/gradio-app>\n\nAlso note the `gr.Accordion('label')` in this example. The Accordion is a layout that can be toggled open or closed. Like `Tabs`, it is a layout element that can selectively hide or show content. Any components that are defined inside of a `with gr.Accordion('label'):` will be hidden or shown when the accordion's toggle icon is clicked.\n\nLearn more about [Tabs](https://gradio.app/docs/tab) and [Accordions](https://gradio.app/docs/accordion) in the docs.\n\n## Visibility\n\nBoth Components and Layout elements have a `visible` argument that can set initially and also updated. Setting `gr.Column(visible=...)` on a Column can be used to show or hide a set of Components.\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    error_box = gr.Textbox(label=\"Error\", visible=False)\n\n    name_box = gr.Textbox(label=\"Name\")\n    age_box = gr.Number(label=\"Age\", minimum=0, maximum=100)\n    symptoms_box = gr.CheckboxGroup([\"Cough\", \"Fever\", \"Runny Nose\"])\n    submit_btn = gr.Button(\"Submit\")\n\n    with gr.Column(visible=False) as output_col:\n        diagnosis_box = gr.Textbox(label=\"Diagnosis\")\n        patient_summary_box = gr.Textbox(label=\"Patient Summary\")\n\n    def submit(name, age, symptoms):\n        if len(name) == 0:\n            return {error_box: gr.Textbox(value=\"Enter name\", visible=True)}\n        return {\n            output_col: gr.Column(visible=True),\n            diagnosis_box: \"covid\" if \"Cough\" in symptoms else \"flu\",\n            patient_summary_box: f\"{name}, {age} y/o\",\n        }\n\n    submit_btn.click(\n        submit,\n        [name_box, age_box, symptoms_box],\n        [error_box, diagnosis_box, patient_summary_box, output_col],\n    )\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_form'>\u003C/gradio-app>\n\n## Variable Number of Outputs\n\nBy adjusting the visibility of components in a dynamic way, it is possible to create\ndemos with Gradio that support a _variable numbers of outputs_. Here's a very simple example\nwhere the number of output textboxes is controlled by an input slider:\n\n```python\nimport gradio as gr\n\nmax_textboxes = 10\n\ndef variable_outputs(k):\n    k = int(k)\n    return [gr.Textbox(visible=True)]*k + [gr.Textbox(visible=False)]*(max_textboxes-k)\n\nwith gr.Blocks() as demo:\n    s = gr.Slider(1, max_textboxes, value=max_textboxes, step=1, label=\"How many textboxes to show:\")\n    textboxes = []\n    for i in range(max_textboxes):\n        t = gr.Textbox(f\"Textbox {i}\")\n        textboxes.append(t)\n\n    s.change(variable_outputs, s, textboxes)\n\nif __name__ == \"__main__\":\n   demo.launch()\n\n```\n\u003Cgradio-app space='gradio/variable_outputs'>\u003C/gradio-app>\n\n## Defining and Rendering Components Separately\n\nIn some cases, you might want to define components before you actually render them in your UI. For instance, you might want to show an examples section using `gr.Examples` above the corresponding `gr.Textbox` input. Since `gr.Examples` requires as a parameter the input component object, you will need to first define the input component, but then render it later, after you have defined the `gr.Examples` object.\n\nThe solution to this is to define the `gr.Textbox` outside of the `gr.Blocks()` scope and use the component's `.render()` method wherever you'd like it placed in the UI.\n\nHere's a full code example:\n\n```python\ninput_textbox = gr.Textbox()\n\nwith gr.Blocks() as demo:\n    gr.Examples([\"hello\", \"bonjour\", \"merhaba\"], input_textbox)\n    input_textbox.render()\n```\n",tags:[],spaces:[],url:"/guides/controlling-layout/",contributor:null}],override_signature:"with gradio.Row():",parent:"gradio",prev_obj:"Blocks",next_obj:"Column",slug:"row"},group:{class:null,name:"Group",description:"Group is a layout element within Blocks which groups together children so that they do not have any padding or margin between them.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"visible",annotation:"bool",doc:"If False, group will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional string or list of strings that are assigned as the class of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, this layout will not be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:"with gr.Group():\n    gr.Textbox(label=\"First\")\n    gr.Textbox(label=\"Last\")",fns:[],override_signature:"with gradio.Group():",parent:"gradio",prev_obj:"Tab",next_obj:"Accordion",slug:"group"},tab:{class:null,name:"Tab",description:"Tab (or its alias TabItem) is a layout element. Components defined within the Tab will be visible when this tab is selected tab.",tags:{guides:"controlling-layout"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"label",annotation:"str | None",doc:"The visual label for the tab",default:"None"},{name:"visible",annotation:"bool",doc:"If False, Tab will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, Tab will not be clickable.",default:"True"},{name:"id",annotation:"int | str | None",doc:"An optional identifier for the tab, required if you wish to control the selected tab from a predict function.",default:"None"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of the &lt;div&gt; containing the contents of the Tab layout. The same string followed by &quot;-button&quot; is attached to the Tab button. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional string or list of strings that are assigned as the class of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, this layout will not be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:"with gr.Blocks() as demo:\n    with gr.Tab(\"Lion\"):\n        gr.Image(\"lion.jpg\")\n        gr.Button(\"New Lion\")\n    with gr.Tab(\"Tiger\"):\n        gr.Image(\"tiger.jpg\")\n        gr.Button(\"New Tiger\")",fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Tab. Uses event data gradio.SelectData to carry `value` referring to the label of the Tab, and `selected` to refer to state of the Tab. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Tab",slug:"tab-select"}],guides:[{name:"controlling-layout",category:"building-with-blocks",pretty_category:"Building With Blocks",guide_index:2,absolute_index:9,pretty_name:"Controlling Layout",content:"# Controlling Layout\n\nBy default, Components in Blocks are arranged vertically. Let's take a look at how we can rearrange Components. Under the hood, this layout structure uses the [flexbox model of web development](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox).\n\n## Rows\n\nElements within a `with gr.Row` clause will all be displayed horizontally. For example, to display two Buttons side by side:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn1 = gr.Button(\"Button 1\")\n        btn2 = gr.Button(\"Button 2\")\n```\n\nTo make every element in a Row have the same height, use the `equal_height` argument of the `style` method.\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row(equal_height=True):\n        textbox = gr.Textbox()\n        btn2 = gr.Button(\"Button 2\")\n```\n\nThe widths of elements in a Row can be controlled via a combination of `scale` and `min_width` arguments that are present in every Component.\n\n- `scale` is an integer that defines how an element will take up space in a Row. If scale is set to `0`, and element will not expand to take up space. If scale is set to `1` or greater, the element well expand. Multiple elements in a row will expand proportional to their scale. Below, `btn1` will expand twice as much as `btn2`, while `btn0` will not expand at all:\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn0 = gr.Button(\"Button 0\", scale=0)\n        btn1 = gr.Button(\"Button 1\", scale=1)\n        btn2 = gr.Button(\"Button 2\", scale=2)\n```\n\n- `min_width` will set the minimum width the element will take. The Row will wrap if there isn't sufficient space to satisfy all `min_width` values.\n\nLearn more about Rows in the [docs](https://gradio.app/docs/row).\n\n## Columns and Nesting\n\nComponents within a Column will be placed vertically atop each other. Since the vertical layout is the default layout for Blocks apps anyway, to be useful, Columns are usually nested within Rows. For example:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text1 = gr.Textbox(label=\"t1\")\n        slider2 = gr.Textbox(label=\"s2\")\n        drop3 = gr.Dropdown([\"a\", \"b\", \"c\"], label=\"d3\")\n    with gr.Row():\n        with gr.Column(scale=1, min_width=600):\n            text1 = gr.Textbox(label=\"prompt 1\")\n            text2 = gr.Textbox(label=\"prompt 2\")\n            inbtw = gr.Button(\"Between\")\n            text4 = gr.Textbox(label=\"prompt 1\")\n            text5 = gr.Textbox(label=\"prompt 2\")\n        with gr.Column(scale=2, min_width=600):\n            img1 = gr.Image(\"images/cheetah.jpg\")\n            btn = gr.Button(\"Go\")\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/rows_and_columns'>\u003C/gradio-app>\n\nSee how the first column has two Textboxes arranged vertically. The second column has an Image and Button arranged vertically. Notice how the relative widths of the two columns is set by the `scale` parameter. The column with twice the `scale` value takes up twice the width.\n\nLearn more about Columns in the [docs](https://gradio.app/docs/column).\n\n# Dimensions\n\nYou can control the height and width of various components, where the parameters are available. These parameters accept either a number (interpreted as pixels) or a string. Using a string allows the direct application of any CSS unit to the encapsulating Block element, catering to more specific design requirements. When omitted, Gradio uses default dimensions suited for most use cases.\n\nBelow is an example illustrating the use of viewport width (vw):\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(\n        width=\"50vw\",\n    )\n\ndemo.launch()\n```\n\nWhen using percentage values for dimensions, you may want to define a parent component with an absolute unit (e.g. `px` or `vw`). This approach ensures that child components with relative dimensions are sized appropriately:\n\n\n```python\nimport gradio as gr\n\ncss = \"\"\"\n.container {\n    height: 100vh;\n}\n\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    with gr.Column(elem_classes=[\"container\"]):\n        name = gr.Chatbot(value=[[\"1\", \"2\"]], height=\"70%\")\n\ndemo.launch()\n```\n\nIn this example, the Column layout component is given a height of 100% of the viewport height (100vh), and the Chatbot component inside it takes up 70% of the Column's height.\n\nYou can apply any valid CSS unit for these parameters. For a comprehensive list of CSS units, refer to [this guide](https://www.w3schools.com/cssref/css_units.php). We recommend you always consider responsiveness and test your interfaces on various screen sizes to ensure a consistent user experience.\n\n\n\n## Tabs and Accordions\n\nYou can also create Tabs using the `with gr.Tab('tab_name'):` clause. Any component created inside of a `with gr.Tab('tab_name'):` context appears in that tab. Consecutive Tab clauses are grouped together so that a single tab can be selected at one time, and only the components within that Tab's context are shown.\n\nFor example:\n\n```python\nimport numpy as np\nimport gradio as gr\n\n\ndef flip_text(x):\n    return x[::-1]\n\n\ndef flip_image(x):\n    return np.fliplr(x)\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\"):\n        gr.Markdown(\"Look at me...\")\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_flipper'>\u003C/gradio-app>\n\nAlso note the `gr.Accordion('label')` in this example. The Accordion is a layout that can be toggled open or closed. Like `Tabs`, it is a layout element that can selectively hide or show content. Any components that are defined inside of a `with gr.Accordion('label'):` will be hidden or shown when the accordion's toggle icon is clicked.\n\nLearn more about [Tabs](https://gradio.app/docs/tab) and [Accordions](https://gradio.app/docs/accordion) in the docs.\n\n## Visibility\n\nBoth Components and Layout elements have a `visible` argument that can set initially and also updated. Setting `gr.Column(visible=...)` on a Column can be used to show or hide a set of Components.\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    error_box = gr.Textbox(label=\"Error\", visible=False)\n\n    name_box = gr.Textbox(label=\"Name\")\n    age_box = gr.Number(label=\"Age\", minimum=0, maximum=100)\n    symptoms_box = gr.CheckboxGroup([\"Cough\", \"Fever\", \"Runny Nose\"])\n    submit_btn = gr.Button(\"Submit\")\n\n    with gr.Column(visible=False) as output_col:\n        diagnosis_box = gr.Textbox(label=\"Diagnosis\")\n        patient_summary_box = gr.Textbox(label=\"Patient Summary\")\n\n    def submit(name, age, symptoms):\n        if len(name) == 0:\n            return {error_box: gr.Textbox(value=\"Enter name\", visible=True)}\n        return {\n            output_col: gr.Column(visible=True),\n            diagnosis_box: \"covid\" if \"Cough\" in symptoms else \"flu\",\n            patient_summary_box: f\"{name}, {age} y/o\",\n        }\n\n    submit_btn.click(\n        submit,\n        [name_box, age_box, symptoms_box],\n        [error_box, diagnosis_box, patient_summary_box, output_col],\n    )\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/blocks_form'>\u003C/gradio-app>\n\n## Variable Number of Outputs\n\nBy adjusting the visibility of components in a dynamic way, it is possible to create\ndemos with Gradio that support a _variable numbers of outputs_. Here's a very simple example\nwhere the number of output textboxes is controlled by an input slider:\n\n```python\nimport gradio as gr\n\nmax_textboxes = 10\n\ndef variable_outputs(k):\n    k = int(k)\n    return [gr.Textbox(visible=True)]*k + [gr.Textbox(visible=False)]*(max_textboxes-k)\n\nwith gr.Blocks() as demo:\n    s = gr.Slider(1, max_textboxes, value=max_textboxes, step=1, label=\"How many textboxes to show:\")\n    textboxes = []\n    for i in range(max_textboxes):\n        t = gr.Textbox(f\"Textbox {i}\")\n        textboxes.append(t)\n\n    s.change(variable_outputs, s, textboxes)\n\nif __name__ == \"__main__\":\n   demo.launch()\n\n```\n\u003Cgradio-app space='gradio/variable_outputs'>\u003C/gradio-app>\n\n## Defining and Rendering Components Separately\n\nIn some cases, you might want to define components before you actually render them in your UI. For instance, you might want to show an examples section using `gr.Examples` above the corresponding `gr.Textbox` input. Since `gr.Examples` requires as a parameter the input component object, you will need to first define the input component, but then render it later, after you have defined the `gr.Examples` object.\n\nThe solution to this is to define the `gr.Textbox` outside of the `gr.Blocks()` scope and use the component's `.render()` method wherever you'd like it placed in the UI.\n\nHere's a full code example:\n\n```python\ninput_textbox = gr.Textbox()\n\nwith gr.Blocks() as demo:\n    gr.Examples([\"hello\", \"bonjour\", \"merhaba\"], input_textbox)\n    input_textbox.render()\n```\n",tags:[],spaces:[],url:"/guides/controlling-layout/",contributor:null}],override_signature:"with gradio.Tab():",parent:"gradio",prev_obj:"Column",next_obj:"Group",slug:"tab"},interface:{class:null,name:"Interface",description:"Interface is Gradio's main high-level class, and allows you to create a web-based GUI / demo around a machine learning model (or any Python function) in a few lines of code. You must specify three parameters: (1) the function to create a GUI for (2) the desired input components and (3) the desired output components. Additional parameters can be used to control the appearance and behavior of the demo. \u003Cbr>",tags:{demos:"hello_world, hello_world_3, gpt2_xl",guides:"quickstart, key-features, sharing-your-app, interface-state, reactive-interfaces, advanced-interface-features, setting-up-a-gradio-demo-for-maximum-performance"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"fn",annotation:"Callable",doc:"The function to wrap an interface around. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component."},{name:"inputs",annotation:"str | Component | list[str | Component] | None",doc:"A single Gradio component, or list of Gradio components. Components can either be passed as instantiated objects, or referred to by their string shortcuts. The number of input components should match the number of parameters in fn. If set to None, then only the output components will be displayed."},{name:"outputs",annotation:"str | Component | list[str | Component] | None",doc:"A single Gradio component, or list of Gradio components. Components can either be passed as instantiated objects, or referred to by their string shortcuts. The number of output components should match the number of values returned by fn. If set to None, then only the input components will be displayed."},{name:"examples",annotation:"list[Any] | list[list[Any]] | str | None",doc:"Sample inputs for the function; if provided, appear below the UI components and can be clicked to populate the interface. Should be nested list, in which the outer list consists of samples and each inner list consists of an input corresponding to each input component. A string path to a directory of examples can also be provided, but it should be within the directory with the python file running the gradio app. If there are multiple input components and a directory is provided, a log.csv file must be present in the directory to link corresponding inputs.",default:"None"},{name:"cache_examples",annotation:"bool | None",doc:"If True, caches examples in the server for fast runtime in examples. If `fn` is a generator function, then the last yielded value will be used as the output. The default option in HuggingFace Spaces is True. The default option elsewhere is False.",default:"None"},{name:"examples_per_page",annotation:"int",doc:"If examples are provided, how many to display per page.",default:"10"},{name:"live",annotation:"bool",doc:"Whether the interface should automatically rerun if any of the inputs change.",default:"False"},{name:"title",annotation:"str | None",doc:"A title for the interface; if provided, appears above the input and output components in large font. Also used as the tab title when opened in a browser window.",default:"None"},{name:"description",annotation:"str | None",doc:"A description for the interface; if provided, appears above the input and output components and beneath the title in regular font. Accepts Markdown and HTML content.",default:"None"},{name:"article",annotation:"str | None",doc:"An expanded article explaining the interface; if provided, appears below the input and output components in regular font. Accepts Markdown and HTML content.",default:"None"},{name:"thumbnail",annotation:"str | None",doc:"String path or url to image to use as display image when the web demo is shared on social media.",default:"None"},{name:"theme",annotation:"Theme | str | None",doc:"Theme to use, loaded from gradio.themes.",default:"None"},{name:"css",annotation:"str | None",doc:"Custom css as a string or path to a css file. This css will be included in the demo webpage.",default:"None"},{name:"allow_flagging",annotation:"str | None",doc:"One of &quot;never&quot;, &quot;auto&quot;, or &quot;manual&quot;. If &quot;never&quot; or &quot;auto&quot;, users will not see a button to flag an input and output. If &quot;manual&quot;, users will see a button to flag. If &quot;auto&quot;, every input the user submits will be automatically flagged (outputs are not flagged). If &quot;manual&quot;, both the input and outputs are flagged when the user clicks flag button. This parameter can be set with environmental variable GRADIO_ALLOW_FLAGGING; otherwise defaults to &quot;manual&quot;.",default:"None"},{name:"flagging_options",annotation:"list[str] | list[tuple[str, str]] | None",doc:"If provided, allows user to select from the list of options when flagging. Only applies if allow_flagging is &quot;manual&quot;. Can either be a list of tuples of the form (label, value), where label is the string that will be displayed on the button and value is the string that will be stored in the flagging CSV; or it can be a list of strings [&quot;X&quot;, &quot;Y&quot;], in which case the values will be the list of strings and the labels will [&quot;Flag as X&quot;, &quot;Flag as Y&quot;], etc.",default:"None"},{name:"flagging_dir",annotation:"str",doc:"What to name the directory where flagged data is stored.",default:"\"flagged\""},{name:"flagging_callback",annotation:"FlaggingCallback | None",doc:"None or an instance of a subclass of FlaggingCallback which will be called when a sample is flagged. If set to None, an instance of gradio.flagging.CSVLogger will be created and logs will be saved to a local CSV file in flagging_dir. Default to None.",default:"None"},{name:"analytics_enabled",annotation:"bool | None",doc:"Whether to allow basic telemetry. If None, will use GRADIO_ANALYTICS_ENABLED environment variable if defined, or default to True.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"api_name",annotation:"str | Literal[False] | None",doc:"Defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None, the name of the prediction function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"\"predict\""},{name:"allow_duplication",annotation:"bool",doc:"If True, then will show a &#x27;Duplicate Spaces&#x27; button on Hugging Face Spaces.",default:"False"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"js",annotation:"str | None",doc:"Custom js or path to js file to run when demo is first loaded. This javascript will be included in the demo webpage.",default:"None"},{name:"head",annotation:"str | None",doc:"Custom html to insert into the head of the demo webpage. This can be used to add custom meta tags, scripts, stylesheets, etc. to the page.",default:"None"},{name:"additional_inputs",annotation:"str | Component | list[str | Component] | None",doc:"A single Gradio component, or list of Gradio components. Components can either be passed as instantiated objects, or referred to by their string shortcuts. These components will be rendered in an accordion below the main input components. By default, no additional input components will be displayed.",default:"None"},{name:"additional_inputs_accordion",annotation:"str | Accordion | None",doc:"If a string is provided, this is the label of the `gr.Accordion` to use to contain additional inputs. A `gr.Accordion` object can be provided as well to configure other properties of the container holding the additional inputs. Defaults to a `gr.Accordion(label=&quot;Additional Inputs&quot;, open=False)`. This parameter is only used if `additional_inputs` is provided.",default:"None"},{name:"submit_btn",annotation:"str | Button",doc:"The button to use for submitting inputs. Defaults to a `gr.Button(&quot;Submit&quot;, variant=&quot;primary&quot;)`. This parameter does not apply if the Interface is output-only, in which case the submit button always displays &quot;Generate&quot;. Can be set to a string (which becomes the button label) or a `gr.Button` object (which allows for more customization).",default:"\"Submit\""},{name:"stop_btn",annotation:"str | Button",doc:"The button to use for stopping the interface. Defaults to a `gr.Button(&quot;Stop&quot;, variant=&quot;stop&quot;, visible=False)`. Can be set to a string (which becomes the button label) or a `gr.Button` object (which allows for more customization).",default:"\"Stop\""},{name:"clear_btn",annotation:"str | Button",doc:"The button to use for clearing the inputs. Defaults to a `gr.Button(&quot;Clear&quot;, variant=&quot;secondary&quot;)`. Can be set to a string (which becomes the button label) or a `gr.Button` object (which allows for more customization).",default:"\"Clear\""}],returns:{annotation:null},example:"import gradio as gr\n\ndef image_classifier(inp):\n    return {'cat': 0.3, 'dog': 0.7}\n\ndemo = gr.Interface(fn=image_classifier, inputs=\"image\", outputs=\"label\")\ndemo.launch()",fns:[{fn:null,name:"launch",description:"Launches a simple web server that serves the demo. Can also be used to create a public link used by anyone to access the demo from their browser by setting share=True. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"inline",annotation:"bool | None",doc:"whether to display in the interface inline in an iframe. Defaults to True in python notebooks; False otherwise.",default:"None"},{name:"inbrowser",annotation:"bool",doc:"whether to automatically launch the interface in a new tab on the default browser.",default:"False"},{name:"share",annotation:"bool | None",doc:"whether to create a publicly shareable link for the interface. Creates an SSH tunnel to make your UI accessible from anywhere. If not provided, it is set to False by default every time, except when running in Google Colab. When localhost is not accessible (e.g. Google Colab), setting share=False is not supported.",default:"None"},{name:"debug",annotation:"bool",doc:"if True, blocks the main thread from running. If running in Google Colab, this is needed to print the errors in the cell output.",default:"False"},{name:"max_threads",annotation:"int",doc:"the maximum number of total threads that the Gradio app can generate in parallel. The default is inherited from the starlette library (currently 40).",default:"40"},{name:"auth",annotation:"Callable | tuple[str, str] | list[tuple[str, str]] | None",doc:"If provided, username and password (or list of username-password tuples) required to access interface. Can also provide function that takes username and password and returns True if valid login.",default:"None"},{name:"auth_message",annotation:"str | None",doc:"If provided, HTML message provided on login page.",default:"None"},{name:"prevent_thread_lock",annotation:"bool",doc:"If True, the interface will block the main thread while the server is running.",default:"False"},{name:"show_error",annotation:"bool",doc:"If True, any errors in the interface will be displayed in an alert modal and printed in the browser console log",default:"False"},{name:"server_name",annotation:"str | None",doc:"to make app accessible on local network, set this to &quot;0.0.0.0&quot;. Can be set by environment variable GRADIO_SERVER_NAME. If None, will use &quot;127.0.0.1&quot;.",default:"None"},{name:"server_port",annotation:"int | None",doc:"will start gradio app on this port (if available). Can be set by environment variable GRADIO_SERVER_PORT. If None, will search for an available port starting at 7860.",default:"None"},{name:"height",annotation:"int",doc:"The height in pixels of the iframe element containing the interface (used if inline=True)",default:"500"},{name:"width",annotation:"int | str",doc:"The width in pixels of the iframe element containing the interface (used if inline=True)",default:"\"100%\""},{name:"favicon_path",annotation:"str | None",doc:"If a path to a file (.png, .gif, or .ico) is provided, it will be used as the favicon for the web page.",default:"None"},{name:"ssl_keyfile",annotation:"str | None",doc:"If a path to a file is provided, will use this as the private key file to create a local server running on https.",default:"None"},{name:"ssl_certfile",annotation:"str | None",doc:"If a path to a file is provided, will use this as the signed certificate for https. Needs to be provided if ssl_keyfile is provided.",default:"None"},{name:"ssl_keyfile_password",annotation:"str | None",doc:"If a password is provided, will use this with the ssl certificate for https.",default:"None"},{name:"ssl_verify",annotation:"bool",doc:"If False, skips certificate validation which allows self-signed certificates to be used.",default:"True"},{name:"quiet",annotation:"bool",doc:"If True, suppresses most print statements.",default:"False"},{name:"show_api",annotation:"bool",doc:"If True, shows the api docs in the footer of the app. Default True.",default:"True"},{name:"allowed_paths",annotation:"list[str] | None",doc:"List of complete filepaths or parent directories that gradio is allowed to serve (in addition to the directory containing the gradio python file). Must be absolute paths. Warning: if you provide directories, any files in these directories or their subdirectories are accessible to all users of your app.",default:"None"},{name:"blocked_paths",annotation:"list[str] | None",doc:"List of complete filepaths or parent directories that gradio is not allowed to serve (i.e. users of your app are not allowed to access). Must be absolute paths. Warning: takes precedence over `allowed_paths` and all other directories exposed by Gradio by default.",default:"None"},{name:"root_path",annotation:"str | None",doc:"The root path (or &quot;mount point&quot;) of the application, if it&#x27;s not served from the root (&quot;/&quot;) of the domain. Often used when the application is behind a reverse proxy that forwards requests to the application. For example, if the application is served at &quot;https://example.com/myapp&quot;, the `root_path` should be set to &quot;/myapp&quot;. Can be set by environment variable GRADIO_ROOT_PATH. Defaults to &quot;&quot;.",default:"None"},{name:"app_kwargs",annotation:"dict[str, Any] | None",doc:"Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{&quot;docs_url&quot;: &quot;/docs&quot;}`",default:"None"},{name:"state_session_capacity",annotation:"int",doc:"The maximum number of sessions whose information to store in memory. If the number of sessions exceeds this number, the oldest sessions will be removed. Reduce capacity to reduce memory usage when using gradio.State or returning updated components from functions. Defaults to 10000.",default:"10000"},{name:"share_server_address",annotation:"str | None",doc:"Use this to specify a custom FRP server and port for sharing Gradio apps (only applies if share=True). If not provided, will use the default FRP server at https://gradio.live. See https://github.com/huggingface/frp for more information.",default:"None"},{name:"share_server_protocol",annotation:"Literal[('http', 'https')] | None",doc:"Use this to specify the protocol to use for the share links. Defaults to &quot;https&quot;, unless a custom share_server_address is provided, in which case it defaults to &quot;http&quot;. If you are using a custom share_server_address and want to use https, you must set this to &quot;https&quot;.",default:"None"}],returns:{},example:"import gradio as gr\ndef reverse(text):\n    return text[::-1]\ndemo = gr.Interface(reverse, \"text\", \"text\")\ndemo.launch(share=True, auth=(\"username\", \"password\"))",override_signature:null,parent:"gradio.Interface",slug:"interface-launch"},{fn:null,name:"load",description:"This listener is triggered when the Interface initially loads in the browser.",tags:{},parameters:[{name:"block",annotation:"Block | None",doc:null},{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Interface",slug:"interface-load"},{fn:null,name:"from_pipeline",description:"Class method that constructs an Interface from a Hugging Face transformers.Pipeline object. The input and output components are automatically determined from the pipeline.",tags:{},parameters:[{name:"pipeline",annotation:"Pipeline",doc:"the pipeline object to use."}],returns:{annotation:"Interface",doc:"a Gradio Interface object from the given Pipeline"},example:"import gradio as gr\nfrom transformers import pipeline\npipe = pipeline(\"image-classification\")\ngr.Interface.from_pipeline(pipe).launch()",override_signature:null,parent:"gradio.Interface",slug:"interface-from-pipeline"},{fn:null,name:"integrate",description:"A catch-all method for integrating with other libraries. This method should be run after launch()",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"comet_ml",annotation:"\u003Cclass 'inspect._empty'>",doc:"If a comet_ml Experiment object is provided, will integrate with the experiment and appear on Comet dashboard",default:"None"},{name:"wandb",annotation:"ModuleType | None",doc:"If the wandb module is provided, will integrate with it and appear on WandB dashboard",default:"None"},{name:"mlflow",annotation:"ModuleType | None",doc:"If the mlflow module  is provided, will integrate with the experiment and appear on ML Flow dashboard",default:"None"}],returns:{},example:null,override_signature:null,parent:"gradio.Interface",slug:"interface-integrate"},{fn:null,name:"queue",description:"By enabling the queue you can control when users know their position in the queue, and set a limit on maximum number of events allowed.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"status_update_rate",annotation:"float | Literal['auto']",doc:"If &quot;auto&quot;, Queue will send status estimations to all clients whenever a job is finished. Otherwise Queue will send status at regular intervals set by this parameter as the number of seconds.",default:"\"auto\""},{name:"api_open",annotation:"bool | None",doc:"If True, the REST routes of the backend will be open, allowing requests made directly to those endpoints to skip the queue.",default:"None"},{name:"max_size",annotation:"int | None",doc:"The maximum number of events the queue will store at any given moment. If the queue is full, new events will not be added and a user will receive a message saying that the queue is full. If None, the queue size will be unlimited.",default:"None"},{name:"concurrency_count",annotation:"int | None",doc:"Deprecated. Set the concurrency_limit directly on event listeners e.g. btn.click(fn, ..., concurrency_limit=10) or gr.Interface(concurrency_limit=10). If necessary, the total number of workers can be configured via `max_threads` in launch().",default:"None"},{name:"default_concurrency_limit",annotation:"int | None | Literal['not_set']",doc:"The default value of `concurrency_limit` to use for event listeners that don&#x27;t specify a value. Can be set by environment variable GRADIO_DEFAULT_CONCURRENCY_LIMIT. Defaults to 1 if not set otherwise.",default:"\"not_set\""}],returns:{},example:"demo = gr.Interface(image_generator, gr.Textbox(), gr.Image())\ndemo.queue(max_size=20)\ndemo.launch()",override_signature:null,parent:"gradio.Interface",slug:"interface-queue"}],demos:[["hello_world","import gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \nif __name__ == \"__main__\":\n    demo.launch()   "],["hello_world_3","import gradio as gr\n\ndef greet(name, is_morning, temperature):\n    salutation = \"Good morning\" if is_morning else \"Good evening\"\n    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n    celsius = (temperature - 32) * 5 / 9\n    return greeting, round(celsius, 2)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n    outputs=[\"text\", \"number\"],\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["gpt2_xl","import gradio as gr\n\ntitle = \"gpt2-xl\"\n\nexamples = [\n    [\"The tower is 324 metres (1,063 ft) tall,\"],\n    [\"The Moon's orbit around Earth has\"],\n    [\"The smooth Borealis basin in the Northern Hemisphere covers 40%\"],\n]\n\ndemo = gr.load(\n    \"huggingface/gpt2-xl\",\n    inputs=gr.Textbox(lines=5, max_lines=6, label=\"Input Text\"),\n    title=title,\n    examples=examples,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"quickstart",category:"getting-started",pretty_category:"Getting Started",guide_index:1,absolute_index:0,pretty_name:"Quickstart",content:"# Quickstart\n\nGradio is an open-source Python package that allows you to quickly **build** a demo or web application for your machine learning model, API, or any arbitary Python function. You can then **share** a link to your demo or web application in just a few seconds using Gradio's built-in sharing features. *No JavaScript, CSS, or web hosting experience needed!*\n\n\u003Cimg src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/lcm-screenshot-3.gif\" style=\"padding-bottom: 10px\">\n\nIt just takes a few lines of Python to create a beautiful demo like the one above, so let's get started üí´\n\n## Installation\n\n**Prerequisite**: Gradio requires [Python 3.8 or higher](https://www.python.org/downloads/)\n\n\nWe recommend installing Gradio using `pip`, which is included by default in Python. Run this in your terminal or command prompt:\n\n```bash\npip install gradio\n```\n\u003Cp class='tip'>\u003Cstrong>‚úçÔ∏è Tip:\u003C/strong> it is best to install Gradio in a virtual environment. Detailed installation instructions for all common operating systems \u003Ca href=\"https://www.gradio.app/main/guides/installing-gradio-in-a-virtual-environment\">are provided here\u003C/a>. \u003C/p>\n\n## Building Your First Demo\n\nYou can run Gradio in your favorite code editor, Jupyter notebook, Google Colab, or anywhere else you write Python. Let's write your first Gradio app:\n\n\n```python\nimport gradio as gr\n\ndef greet(name, intensity):\n    return \"Hello \" * intensity + name + \"!\"\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"slider\"],\n    outputs=[\"text\"],\n)\n\ndemo.launch()\n\n```\n\u003Cp class='tip'>\u003Cstrong>‚úçÔ∏è Tip:\u003C/strong> We shorten the imported name from \u003Ccode>gradio\u003C/code> to \u003Ccode>gr\u003C/code> for better readability of code. This is a widely adopted convention that you should follow so that anyone working with your code can easily understand it. \u003C/p>\n\nNow, run your code. If you've written the Python code in a file named, for example, `app.py`, then you would run `python app.py` from the terminal.\n\nThe demo below will open in a browser on [http://localhost:7860](http://localhost:7860) if running from a file. If you are running within a notebook, the demo will appear embedded within the notebook.\n\n\u003Cgradio-app space='gradio/hello_world_4'>\u003C/gradio-app>\n\nType your name in the textbox on the left, drag the slider, and then press the Submit button. You should see a friendly greeting on the right.\u003Cp class='tip'>\u003Cstrong>‚úçÔ∏è Tip:\u003C/strong> When developing locally, you can run your Gradio app in \u003Cstrong>hot reload mode\u003C/strong>, which automatically reloads the Gradio app whenever you make changes to the file. To do this, simply type in \u003Ccode>gradio\u003C/code> before the name of the file instead of \u003Ccode>python\u003C/code>. In the example above, you would type: `gradio app.py` in your terminal. Learn more about hot reloading in the \u003Ca href=\"https://www.gradio.app/guides/developing-faster-with-reload-mode\">Hot Reloading Guide\u003C/a>.\u003C/p>\n\n\n**Understanding the `Interface` Class**\n\nYou'll notice that in order to make your first demo, you created an instance of the `gr.Interface` class. The `Interface` class is designed to create demos for machine learning models which accept one or more inputs, and return one or more outputs. \n\nThe `Interface` class has three core arguments:\n\n- `fn`: the function to wrap a user interface (UI) around\n- `inputs`: the Gradio component(s) to use for the input. The number of components should match the number of arguments in your function.\n- `outputs`: the Gradio component(s) to use for the output. The number of components should match the number of return values from your function.\n\nThe `fn` argument is very flexible -- you can pass *any* Python function that you want to wrap with a UI. In the example above, we saw a relatively simple function, but the function could be anything from a music generator to a tax calculator to the prediction function of a pretrained machine learning model.\n\nThe `input` and `output` arguments take one or more Gradio components. As we'll see, Gradio includes more than [30 built-in components](https://www.gradio.app/docs/components) (such as the `gr.Textbox()`, `gr.Image()`, and `gr.HTML()` components) that are designed for machine learning applications. \u003Cp class='tip'>\u003Cstrong>‚úçÔ∏è Tip:\u003C/strong> For the `inputs` and `outputs` arguments, you can pass in the name of these components as a string (`\"textbox\"`) or an instance of the class (`gr.Textbox()`).\u003C/p>\n\nIf your function accepts more than one argument, as is the case above, pass a list of input components to `inputs`, with each input component corresponding to one of the arguments of the function, in order. The same holds true if your function returns more than one value: simply pass in a list of components to `outputs`. This flexibility makes the `Interface` class a very powerful way to create demos.\n\nWe'll dive deeper into the `gr.Interface` on our series on [building Interfaces](https://www.gradio.app/main/guides/the-interface-class).\n\n## Sharing Your Demo\n\nWhat good is a beautiful demo if you can't share it? Gradio lets you easily share a machine learning demo without having to worry about the hassle of hosting on a web server. Simply set `share=True` in `launch()`, and a publicly accessible URL will be created for your demo. Let's revisit our example demo,  but change the last line as follows:\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter üöÄ\n```\n\nWhen you run this code, a public URL will be generated for your demo in a matter of seconds, something like:\n\nüëâ &nbsp; `https://a23dsf231adb.gradio.live`\n\nNow, anyone around the world can try your Gradio demo from their browser, while the machine learning model and all computation continues to run locally on your computer.\n\nTo learn more about sharing your demo, read our dedicated guide on [sharing your Gradio application](https://www.gradio.app/guides/sharing-your-app).\n\n\n## An Overview of Gradio\n\nSo far, we've been discussing the `Interface` class, which is a high-level class that lets to build demos quickly with Gradio. But what else does Gradio do?\n\n### Chatbots with `gr.ChatInterface`\n\nGradio includes another high-level class, `gr.ChatInterface`, which is specifically designed to create Chatbot UIs. Similar to `Interface`, you supply a function and Gradio creates a fully working Chatbot UI. If you're interested in creating a chatbot, you can jump straight to [our dedicated guide on `gr.ChatInterface`](https://www.gradio.app/guides/creating-a-chatbot-fast).\n\n### Custom Demos with `gr.Blocks`\n\nGradio also offers a low-level approach for designing web apps with more flexible layouts and data flows with the `gr.Blocks` class. Blocks allows you to do things like control where components appear on the page, handle complex data flows (e.g. outputs can serve as inputs to other functions), and update properties/visibility of components based on user interaction ‚Äî still all in Python. \n\nYou can build very custom and complex applications using `gr.Blocks()`. For example, the popular image generation [Automatic1111 Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) is built using Gradio Blocks. We dive deeper into the `gr.Blocks` on our series on [building with Blocks](https://www.gradio.app/guides/blocks-and-event-listeners).\n\n\n### The Gradio Python & JavaScript Ecosystem\n\nThat's the gist of the core `gradio` Python library, but Gradio is actually so much more! Its an entire ecosystem of Python and JavaScript libraries that let you build machine learning applications, or query them programmatically, in Python or JavaScript. Here are other related parts of the Gradio ecosystem:\n\n* [Gradio Python Client](https://www.gradio.app/guides/getting-started-with-the-python-client) (`gradio_client`): query any Gradio app programmatically in Python.\n* [Gradio JavaScript Client](https://www.gradio.app/guides/getting-started-with-the-js-client) (`@gradio/client`): query any Gradio app programmatically in JavaScript.\n* [Gradio-Lite](https://www.gradio.app/guides/gradio-lite) (`@gradio/lite`): write Gradio apps in Python that run entirely in the browser (no server needed!), thanks to Pyodide. \n* [Hugging Face Spaces](https://huggingface.co/spaces): the most popular place to host Gradio applications ‚Äî for free!\n\n## What's Next?\n\nKeep learning about Gradio sequentially using the Gradio Guides, which include explanations as well as example code and embedded interactive demos. Next up: [key features about Gradio demos](https://www.gradio.app/guides/key-features).\n\nOr, if you already know the basics and are looking for something specific, you can search the more [technical API documentation](https://www.gradio.app/docs/).\n\n\n",tags:[],spaces:[],url:"/guides/quickstart/",contributor:null},{name:"key-features",category:"getting-started",pretty_category:"Getting Started",guide_index:2,absolute_index:1,pretty_name:"Key Features",content:"# Key Features\n\nLet's go through some of the key features of Gradio. This guide is intended to be a high-level overview of various things that you should be aware of as you build your demo. Where appropriate, we link to more detailed guides on specific topics.\n\n1. [Components](#components)\n2. [Queuing](#queuing)\n3. [Streaming outputs](#streaming-outputs)\n4. [Streaming inputs](#streaming-inputs)\n5. [Alert modals](#alert-modals)\n6. [Styling](#styling)\n7. [Progress bars](#progress-bars)\n8. [Batch functions](#batch-functions)\n\n## Components\n\nGradio includes more than 30 pre-built components (as well as many user-built _custom components_) that can be used as inputs or outputs in your demo with a single line of code. These components correspond to common data types in machine learning and data science, e.g. the `gr.Image` component is designed to handle input or output images, the `gr.Label` component displays classification labels and probabilities, the `gr.Plot` component displays various kinds of plots, and so on.\n\nEach component includes various constructor attributes that control the properties of the component. For example, you can control the number of lines in a `gr.Textbox` using the `lines` argument (which takes a positive integer) in its constructor. Or you can control the way that a user can provide an image in the `gr.Image` component using the `sources` parameter (which takes a list like `[\"webcam\", \"upload\"]`).\n\n**Static and Interactive Components**\n\nEvery component has a _static_ version that is designed to *display* data, and most components also have an _interactive_ version designed to let users input or modify the data. Typically, you don't need to think about this distinction, because when you build a Gradio demo, Gradio automatically figures out whether the component should be static or interactive based on whether it is being used as an input or output. However, you can set this manually using the `interactive` argument that every component supports.\n\n**Preprocessing and Postprocessing**\n\nWhen a component is used as an input, Gradio automatically handles the _preprocessing_ needed to convert the data from a type sent by the user's browser (such as an uploaded image) to a form that can be accepted by your function (such as a `numpy` array).\n\n\nSimilarly, when a component is used as an output, Gradio automatically handles the _postprocessing_ needed to convert the data from what is returned by your function (such as a list of image paths) to a form that can be displayed in the user's browser (a gallery of images).\n\nConsider an example demo with three input components (`gr.Textbox`, `gr.Number`, and `gr.Image`) and two outputs (`gr.Number` and `gr.Gallery`) that serve as a UI for your image-to-image generation model. Below is a diagram of what our preprocessing will send to the model and what our postprocessing will require from it.\n\n![](https://github.com/gradio-app/gradio/blob/main/guides/assets/dataflow.svg?raw=true)\n\nIn this image, the following preprocessing steps happen to send the data from the browser to your function:\n\n* The text in the textbox is converted to a Python `str` (essentially no preprocessing)\n* The number in the number input in converted to a Python `float` (essentially no preprocessing)\n* Most importantly, ihe image supplied by the user is converted to a `numpy.array` representation of the RGB values in the image\n\nImages are converted to NumPy arrays because they are a common format for machine learning workflows. You can control the _preprocessing_ using the component's parameters when constructing the component. For example, if you instantiate the `Image` component with the following parameters, it will preprocess the image to the `PIL` format instead:\n\n```py\nimg = gr.Image(type=\"pil\")\n```\n\nPostprocessing is even simpler! Gradio automatically recognizes the format of the returned data (e.g. does the user's function return a `numpy` array or a `str` filepath for the `gr.Image` component?) and postprocesses it appropriately into a format that can be displayed by the browser.\n\nSo in the image above, the following postprocessing steps happen to send the data returned from a user's function to the browser:\n\n* The `float` is displayed as a number and displayed directly to the user\n* The list of string filepaths (`list[str]`) is interpreted as a list of image filepaths and displayed as a gallery in the browser\n\nTake a look at the [Docs](https://gradio.app/docs) to see all the parameters for each Gradio component.\n\n## Queuing\n\nEvery Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. You can configure the queue by using `queue()` method which is supported by the `gr.Interface`, `gr.Blocks`, and `gr.ChatInterface` classes. \n\nFor example, you can control the number of requests processed at a single time by setting the `default_concurrency_limit` parameter of `queue()`, e.g.\n\n```python\ndemo = gr.Interface(...).queue(default_concurrency_limit=5)\ndemo.launch()\n```\n\nThis limits the number of requests processed for this event listener at a single time to 5. By default, the `default_concurrency_limit` is actually set to `1`, which means that when many users are using your app, only a single user's request will be processed at a time. This is because many machine learning functions consume a significant amount of memory and so it is only suitable to have a single user using the demo at a time. However, you can change this parameter in your demo easily.\n\nSee the [docs on queueing](/docs/interface#interface-queue) for more details on configuring the queuing parameters.\n\n## Streaming outputs\n\nIn some cases, you may want to stream a sequence of outputs rather than show a single output at once. For example, you might have an image generation model and you want to show the image that is generated at each step, leading up to the final image. Or you might have a chatbot which streams its response one token at a time instead of returning it all at once.\n\nIn such cases, you can supply a **generator** function into Gradio instead of a regular function. Creating generators in Python is very simple: instead of a single `return` value, a function should `yield` a series of values instead. Usually the `yield` statement is put in some kind of loop. Here's an example of an generator that simply counts up to a given number:\n\n```python\ndef my_generator(x):\n    for i in range(x):\n        yield i\n```\n\nYou supply a generator into Gradio the same way as you would a regular function. For example, here's a a (fake) image generation model that generates noise for several steps before outputting an image using the `gr.Interface` class:\n\n```python\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef fake_diffusion(steps):\n    for i in range(steps):\n        time.sleep(1)\n        image = np.random.random((600, 600, 3))\n        yield image\n    image = np.ones((1000,1000,3), np.uint8)\n    image[:] = [255, 124, 0]\n    yield image\n\n\ndemo = gr.Interface(fake_diffusion, inputs=gr.Slider(1, 10, 3), outputs=\"image\")\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/fake_diffusion'>\u003C/gradio-app>\n\nNote that we've added a `time.sleep(1)` in the iterator to create an artificial pause between steps so that you are able to observe the steps of the iterator (in a real image generation model, this probably wouldn't be necessary).\n\n## Streaming inputs\n\nSimilarly, Gradio can handle streaming inputs, e.g. a live audio stream that can gets transcribed to text in real time, or an image generation model that reruns every time a user types a letter in a textbox. This is covered in more details in our guide on building [reactive Interfaces](/guides/reactive-interfaces). \n\n## Alert modals\n\nYou may wish to raise alerts to the user. To do so, raise a `gr.Error(\"custom message\")` to display an error message. You can also issue `gr.Warning(\"message\")` and `gr.Info(\"message\")` by having them as standalone lines in your function, which will immediately display modals while continuing the execution of your function. Queueing needs to be enabled for this to work.\n\nNote below how the `gr.Error` has to be raised, while the `gr.Warning` and `gr.Info` are single lines.\n\n```python\ndef start_process(name):\n    gr.Info(\"Starting process\")\n    if name is None:\n        gr.Warning(\"Name is empty\")\n    ...\n    if success == False:\n        raise gr.Error(\"Process failed\")\n```\n\n\n\n## Styling\n\nGradio themes are the easiest way to customize the look and feel of your app. You can choose from a variety of themes, or create your own. To do so, pass the `theme=` kwarg to the `Interface` constructor. For example:\n\n```python\ndemo = gr.Interface(..., theme=gr.themes.Monochrome())\n```\n\nGradio comes with a set of prebuilt themes which you can load from `gr.themes.*`. You can extend these themes or create your own themes from scratch - see the [theming guide](https://gradio.app/guides/theming-guide) for more details.\n\nFor additional styling ability, you can pass any CSS (as well as custom JavaScript) to your Gradio application. This is discussed in more detail in our [custom JS and CSS guide](/guides/custom-CSS-and-JS).\n\n\n## Progress bars\n\nGradio supports the ability to create custom Progress Bars so that you have customizability and control over the progress update that you show to the user. In order to enable this, simply add an argument to your method that has a default value of a `gr.Progress` instance. Then you can update the progress levels by calling this instance directly with a float between 0 and 1, or using the `tqdm()` method of the `Progress` instance to track progress over an iterable, as shown below.\n\n```python\nimport gradio as gr\nimport time\n\ndef slowly_reverse(word, progress=gr.Progress()):\n    progress(0, desc=\"Starting\")\n    time.sleep(1)\n    progress(0.05)\n    new_string = \"\"\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\n        time.sleep(0.25)\n        new_string = letter + new_string\n    return new_string\n\ndemo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/progress_simple'>\u003C/gradio-app>\n\nIf you use the `tqdm` library, you can even report progress updates automatically from any `tqdm.tqdm` that already exists within your function by setting the default argument as `gr.Progress(track_tqdm=True)`!\n\n## Batch functions\n\nGradio supports the ability to pass _batch_ functions. Batch functions are just\nfunctions which take in a list of inputs and return a list of predictions.\n\nFor example, here is a batched function that takes in two lists of inputs (a list of\nwords and a list of ints), and returns a list of trimmed words as output:\n\n```py\nimport time\n\ndef trim_words(words, lens):\n    trimmed_words = []\n    time.sleep(5)\n    for w, l in zip(words, lens):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n```\n\nThe advantage of using batched functions is that if you enable queuing, the Gradio server can automatically _batch_ incoming requests and process them in parallel,\npotentially speeding up your demo. Here's what the Gradio code looks like (notice the `batch=True` and `max_batch_size=16`)\n\nWith the `gr.Interface` class:\n\n```python\ndemo = gr.Interface(\n    fn=trim_words, \n    inputs=[\"textbox\", \"number\"], \n    outputs=[\"output\"],\n    batch=True, \n    max_batch_size=16\n)\n\ndemo.launch()\n```\n\nWith the `gr.Blocks` class:\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        word = gr.Textbox(label=\"word\")\n        leng = gr.Number(label=\"leng\")\n        output = gr.Textbox(label=\"Output\")\n    with gr.Row():\n        run = gr.Button()\n\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\n\ndemo.launch()\n```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference time of 5 seconds), instead of each request being processed separately (for a total\ninference time of 80 seconds). Many Hugging Face `transformers` and `diffusers` models work very naturally with Gradio's batch mode: here's [an example demo using diffusers to\ngenerate images in batches](https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.py)\n\n\n",tags:[],spaces:[],url:"/guides/key-features/",contributor:null},{name:"sharing-your-app",category:"getting-started",pretty_category:"Getting Started",guide_index:3,absolute_index:2,pretty_name:"Sharing Your App",content:"# Sharing Your App\n\nHow to share your Gradio app:\n\n1. [Sharing demos with the share parameter](#sharing-demos)\n2. [Hosting on HF Spaces](#hosting-on-hf-spaces)\n3. [Embedding hosted spaces](#embedding-hosted-spaces)\n4. [Using the API page](#api-page)\n5. [Authentication](#authentication)\n6. [Accessing network requests](#accessing-the-network-request-directly)\n7. [Mounting within FastAPI](#mounting-within-another-fast-api-app)\n8. [Security and file access](#security-and-file-access)\n\n## Sharing Demos\n\nGradio demos can be easily shared publicly by setting `share=True` in the `launch()` method. Like this:\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter üöÄ\n```\n\nThis generates a public, shareable link that you can send to anybody! When you send this link, the user on the other side can try out the model in their browser. Because the processing happens on your device (as long as your device stays on), you don't have to worry about any packaging any dependencies. \n\n![sharing](https://github.com/gradio-app/gradio/blob/main/guides/assets/sharing.svg?raw=true)\n\n\nA share link usually looks something like this: **https://07ff8706ab.gradio.live**. Although the link is served through the Gradio Share Servers, these servers are only a proxy for your local server, and do not store any data sent through your app. Share links expire after 72 hours. (it is [also possible to set up your own Share Server](https://github.com/huggingface/frp/) on your own cloud server to overcome this restriction.)\u003Cp class='tip'>\u003Cstrong>‚úçÔ∏è Tip:\u003C/strong> Keep in mind that share links are publicly accessible, meaning that anyone can use your model for prediction! Therefore, make sure not to expose any sensitive information through the functions you write, or allow any critical changes to occur on your device. Or you can [add authentication to your Gradio app](#authentication) as discussed below.\u003C/p>\n\nNote that by default, `share=False`, which means that your server is only running locally. (This is the default, except in Google Colab notebooks, where share links are automatically created). As an alternative to using share links, you can use use [SSH port-forwarding](https://www.ssh.com/ssh/tunneling/example) to share your local server with specific users.\n\n\n## Hosting on HF Spaces\n\nIf you'd like to have a permanent link to your Gradio demo on the internet, use Hugging Face Spaces. [Hugging Face Spaces](http://huggingface.co/spaces/) provides the infrastructure to permanently host your machine learning model for free!\n\nAfter you have [created a free Hugging Face account](https://huggingface.co/join), you have two methods to deploy your Gradio app to Hugging Face Spaces:\n\n1. From terminal: run `gradio deploy` in your app directory. The CLI will gather some basic metadata and then launch your app. To update your space, you can re-run this command or enable the Github Actions option to automatically update the Spaces on `git push`.\n\n2. From your browser: Drag and drop a folder containing your Gradio model and all related files [here](https://huggingface.co/new-space). See [this guide how to host on Hugging Face Spaces](https://huggingface.co/blog/gradio-spaces) for more information, or watch the embedded video:\n\n\u003Cvideo autoplay muted loop>\n  \u003Csource src=\"https://github.com/gradio-app/gradio/blob/main/guides/assets/hf_demo.mp4?raw=true\" type=\"video/mp4\" />\n\u003C/video>\n\n\n## Embedding Hosted Spaces\n\nOnce you have hosted your app on Hugging Face Spaces (or on your own server), you may want to embed the demo on a different website, such as your blog or your portfolio. Embedding an interactive demo allows people to try out the machine learning model that you have built, without needing to download or install anything ‚Äî right in their browser! The best part is that you can embed interactive demos even in static websites, such as GitHub pages.\n\nThere are two ways to embed your Gradio demos. You can find quick links to both options directly on the Hugging Face Space page, in the \"Embed this Space\" dropdown option:\n\n![Embed this Space dropdown option](https://github.com/gradio-app/gradio/blob/main/guides/assets/embed_this_space.png?raw=true)\n\n### Embedding with Web Components\n\nWeb components typically offer a better experience to users than IFrames. Web components load lazily, meaning that they won't slow down the loading time of your website, and they automatically adjust their height based on the size of the Gradio app.\n\nTo embed with Web Components:\n\n1. Import the gradio JS library into into your site by adding the script below in your site (replace {GRADIO_VERSION} in the URL with the library version of Gradio you are using).\n\n```html\n\u003Cscript\n\ttype=\"module\"\n\tsrc=\"https://gradio.s3-us-west-2.amazonaws.com/{GRADIO_VERSION}/gradio.js\"\n>\u003C/script>\n```\n\n2. Add\n\n```html\n\u003Cgradio-app src=\"https://$your_space_host.hf.space\">\u003C/gradio-app>\n```\n\nelement where you want to place the app. Set the `src=` attribute to your Space's embed URL, which you can find in the \"Embed this Space\" button. For example:\n\n```html\n\u003Cgradio-app\n\tsrc=\"https://abidlabs-pytorch-image-classifier.hf.space\"\n>\u003C/gradio-app>\n```\n\n\u003Cscript>\nfetch(\"https://pypi.org/pypi/gradio/json\"\n).then(r => r.json()\n).then(obj => {\n    let v = obj.info.version;\n    content = document.querySelector('.prose');\n    content.innerHTML = content.innerHTML.replaceAll(\"{GRADIO_VERSION}\", v);\n});\n\u003C/script>\n\nYou can see examples of how web components look \u003Ca href=\"https://www.gradio.app\">on the Gradio landing page\u003C/a>.\n\nYou can also customize the appearance and behavior of your web component with attributes that you pass into the `\u003Cgradio-app>` tag:\n\n- `src`: as we've seen, the `src` attributes links to the URL of the hosted Gradio demo that you would like to embed\n- `space`: an optional shorthand if your Gradio demo is hosted on Hugging Face Space. Accepts a `username/space_name` instead of a full URL. Example: `gradio/Echocardiogram-Segmentation`. If this attribute attribute is provided, then `src` does not need to be provided.\n- `control_page_title`: a boolean designating whether the html title of the page should be set to the title of the Gradio app (by default `\"false\"`)\n- `initial_height`: the initial height of the web component while it is loading the Gradio app, (by default `\"300px\"`). Note that the final height is set based on the size of the Gradio app.\n- `container`: whether to show the border frame and information about where the Space is hosted (by default `\"true\"`)\n- `info`: whether to show just the information about where the Space is hosted underneath the embedded app (by default `\"true\"`)\n- `autoscroll`: whether to autoscroll to the output when prediction has finished (by default `\"false\"`)\n- `eager`: whether to load the Gradio app as soon as the page loads (by default `\"false\"`)\n- `theme_mode`: whether to use the `dark`, `light`, or default `system` theme mode (by default `\"system\"`)\n- `render`: an event that is triggered once the embedded space has finished rendering.\n\nHere's an example of how to use these attributes to create a Gradio app that does not lazy load and has an initial height of 0px.\n\n```html\n\u003Cgradio-app\n\tspace=\"gradio/Echocardiogram-Segmentation\"\n\teager=\"true\"\n\tinitial_height=\"0px\"\n>\u003C/gradio-app>\n```\n\nHere's another example of how to use the `render` event. An event listener is used to capture the `render` event and will call the `handleLoadComplete()` function once rendering is complete. \n\n```html\n\u003Cscript>\n\tfunction handleLoadComplete() {\n\t\tconsole.log(\"Embedded space has finished rendering\");\n\t}\n\n\tconst gradioApp = document.querySelector(\"gradio-app\");\n\tgradioApp.addEventListener(\"render\", handleLoadComplete);\n\u003C/script>\n```\n\n_Note: While Gradio's CSS will never impact the embedding page, the embedding page can affect the style of the embedded Gradio app. Make sure that any CSS in the parent page isn't so general that it could also apply to the embedded Gradio app and cause the styling to break. Element selectors such as `header { ... }` and `footer { ... }` will be the most likely to cause issues._\n\n### Embedding with IFrames\n\nTo embed with IFrames instead (if you cannot add javascript to your website, for example), add this element:\n\n```html\n\u003Ciframe src=\"https://$your_space_host.hf.space\">\u003C/iframe>\n```\n\nAgain, you can find the `src=` attribute to your Space's embed URL, which you can find in the \"Embed this Space\" button.\n\nNote: if you use IFrames, you'll probably want to add a fixed `height` attribute and set `style=\"border:0;\"` to remove the boreder. In addition, if your app requires permissions such as access to the webcam or the microphone, you'll need to provide that as well using the `allow` attribute.\n\n## API Page\n\nYou can use almost any Gradio app as an API! In the footer of a Gradio app [like this one](https://huggingface.co/spaces/gradio/hello_world), you'll see a \"Use via API\" link.\n\n![Use via API](https://github.com/gradio-app/gradio/blob/main/guides/assets/use_via_api.png?raw=true)\n\nThis is a page that lists the endpoints that can be used to query the Gradio app, via our supported clients: either [the Python client](https://gradio.app/guides/getting-started-with-the-python-client/), or [the JavaScript client](https://gradio.app/guides/getting-started-with-the-js-client/). For each endpoint, Gradio automatically generates the parameters and their types, as well as example inputs.\n\nThe endpoints are automatically created when you launch a Gradio `Interface`. If you are using Gradio `Blocks`, you can also set up a Gradio API page, though we recommend that you explicitly name each event listener, such as\n\n```python\nbtn.click(add, [num1, num2], output, api_name=\"addition\")\n```\n\nThis will add and document the endpoint `/api/addition/` to the automatically generated API page. Otherwise, your API endpoints will appear as \"unnamed\" endpoints.\n\n\n## Authentication\n\n### Password-protected app\n\nYou may wish to put an authentication page in front of your app to limit who can open your app. With the `auth=` keyword argument in the `launch()` method, you can provide a tuple with a username and password, or a list of acceptable username/password tuples; Here's an example that provides password-based authentication for a single user named \"admin\":\n\n```python\ndemo.launch(auth=(\"admin\", \"pass1234\"))\n```\n\nFor more complex authentication handling, you can even pass a function that takes a username and password as arguments, and returns True to allow authentication, False otherwise. This can be used for, among other things, making requests to 3rd-party authentication services.\n\nHere's an example of a function that accepts any login where the username and password are the same:\n\n```python\ndef same_auth(username, password):\n    return username == password\ndemo.launch(auth=same_auth)\n```\n\nFor authentication to work properly, third party cookies must be enabled in your browser.\nThis is not the case by default for Safari, Chrome Incognito Mode.\n\n### OAuth (Login via Hugging Face)\n\nGradio supports OAuth login via Hugging Face. This feature is currently **experimental** and only available on Spaces.\nIt allows you to add a _\"Sign in with Hugging Face\"_ button to your demo. Check out [this Space](https://huggingface.co/spaces/Wauplin/gradio-oauth-demo) for a live demo.\n\nTo enable OAuth, you must set `hf_oauth: true` as a Space metadata in your README.md file. This will register your Space\nas an OAuth application on Hugging Face. Next, you can use `gr.LoginButton` and `gr.LogoutButton` to add login and logout buttons to\nyour Gradio app. Once a user is logged in with their HF account, you can retrieve their profile by adding a parameter of type\n`gr.OAuthProfile` to any Gradio function. The user profile will be automatically injected as a parameter value. If you want\nto perform actions on behalf of the user (e.g. list user's private repos, create repo, etc.), you can retrieve the user\ntoken by adding a parameter of type `gr.OAuthToken`. You must define which scopes you will use in your Space metadata\n(see [documentation](https://huggingface.co/docs/hub/spaces-oauth#scopes) for more details).\n\nHere is a short example:\n\n```py\nimport gradio as gr\n\n\ndef hello(profile: gr.OAuthProfile | None) -> str:\n    if profile is None:\n        return \"I don't know you.\"\n    return f\"Hello {profile.name}\"\n\ndef list_organizations(oauth_token: gr.OAuthToken | None) -> str:\n    if oauth_token is None:\n        return \"Please log in to list organizations.\"\n    org_names = [org[\"name\"] for org in whoami(oauth_token.token)[\"orgs\"]]\n    return f\"You belong to {', '.join(org_names)}.\"\n\nwith gr.Blocks() as demo:\n    gr.LoginButton()\n    gr.LogoutButton()\n    m1 = gr.Markdown()\n    m2 = gr.Markdown()\n    demo.load(hello, inputs=None, outputs=m1)\n    demo.load(list_organizations, inputs=None, outputs=m2)\n```\n\nWhen the user clicks on the login button, they get redirected in a new page to authorize your Space.\n\n\u003Ccenter>\n\u003Cimg src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/oauth_sign_in.png\" style=\"width:300px; max-width:80%\">\n\u003C/center>\n\nUsers can revoke access to their profile at any time in their [settings](https://huggingface.co/settings/connected-applications).\n\nAs seen above, OAuth features are available only when your app runs in a Space. However, you often need to test your app\nlocally before deploying it. To help with that, the `gr.LoginButton` is mocked. When a user clicks on it, they are\nautomatically logged in with a fake user profile. This allows you to debug your app before deploying it to a Space.\n\n## Accessing the Network Request Directly\n\nWhen a user makes a prediction to your app, you may need the underlying network request, in order to get the request headers (e.g. for advanced authentication), log the client's IP address, getting the query parameters, or for other reasons. Gradio supports this in a similar manner to FastAPI: simply add a function parameter whose type hint is `gr.Request` and Gradio will pass in the network request as that parameter. Here is an example:\n\n```python\nimport gradio as gr\n\ndef echo(text, request: gr.Request):\n    if request:\n        print(\"Request headers dictionary:\", request.headers)\n        print(\"IP address:\", request.client.host)\n        print(\"Query parameters:\", dict(request.query_params))\n    return text\n\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()\n```\n\nNote: if your function is called directly instead of through the UI (this happens, for\nexample, when examples are cached, or when the Gradio app is called via API), then `request` will be `None`. \nYou should handle this case explicitly to ensure that your app does not throw any errors. That is why\nwe have the explicit check `if request`.\n\n## Mounting Within Another FastAPI App\n\nIn some cases, you might have an existing FastAPI app, and you'd like to add a path for a Gradio demo.\nYou can easily do this with `gradio.mount_gradio_app()`.\n\nHere's a complete example:\n\n```python\nfrom fastapi import FastAPI\nimport gradio as gr\n\nCUSTOM_PATH = \"/gradio\"\n\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef read_main():\n    return {\"message\": \"This is your main app\"}\n\n\nio = gr.Interface(lambda x: \"Hello, \" + x + \"!\", \"textbox\", \"textbox\")\napp = gr.mount_gradio_app(app, io, path=CUSTOM_PATH)\n\n\n# Run this from the terminal as you would normally start a FastAPI app: `uvicorn run:app`\n# and navigate to http://localhost:8000/gradio in your browser.\n\n```\n\nNote that this approach also allows you run your Gradio apps on custom paths (`http://localhost:8000/gradio` in the example above).\n\n\n## Security and File Access\n\nSharing your Gradio app with others (by hosting it on Spaces, on your own server, or through temporary share links) **exposes** certain files on the host machine to users of your Gradio app.\n\nIn particular, Gradio apps ALLOW users to access to three kinds of files:\n\n- **Temporary files created by Gradio.** These are files that are created by Gradio as part of running your prediction function. For example, if your prediction function returns a video file, then Gradio will save that video to a temporary cache on your device and then send the path to the file to the front end. You can customize the location of temporary cache files created by Gradio by setting the environment variable `GRADIO_TEMP_DIR` to an absolute path, such as `/home/usr/scripts/project/temp/`.\n\n\n- **Cached examples created by Gradio.** These are files that are created by Gradio as part of caching examples for faster runtimes, if you set `cache_examples=True` in `gr.Interface()` or in `gr.Examples()`. By default, these files are saved in the `gradio_cached_examples/` subdirectory within your app's working directory. You can customize the location of cached example files created by Gradio by setting the environment variable `GRADIO_EXAMPLES_CACHE` to an absolute path or a path relative to your working directory.\n\n- **Files that you explicitly allow via the `allowed_paths` parameter in `launch()`**. This parameter allows you to pass in a list of additional directories or exact filepaths you'd like to allow users to have access to. (By default, this parameter is an empty list).\n\nGradio DOES NOT ALLOW access to:\n\n- **Files that you explicitly block via the `blocked_paths` parameter in `launch()`**. You can pass in a list of additional directories or exact filepaths to the `blocked_paths` parameter in `launch()`. This parameter takes precedence over the files that Gradio exposes by default or by the `allowed_paths`.\n\n- **Any other paths on the host machine**. Users should NOT be able to access other arbitrary paths on the host.\n\nPlease make sure you are running the latest version of `gradio` for these security settings to apply.\n",tags:[],spaces:[],url:"/guides/sharing-your-app/",contributor:null},{name:"interface-state",category:"building-interfaces",pretty_category:"Building Interfaces",guide_index:3,absolute_index:6,pretty_name:"Interface State",content:"# Interface State\n\nSo far, we've assumed that your demos are *stateless*: that they do not persist information beyond a single function call. What if you want to modify the behavior of your demo based on previous interactions with the demo? There are two approaches in Gradio: *global state* and *session state*.\n\n## Global State\n\nIf the state is something that should be accessible to all function calls and all users, you can create a variable outside the function call and access it inside the function. For example, you may load a large model outside the function and use it inside the function so that every function call does not need to reload the model.\n\n```python\nimport gradio as gr\n\nscores = []\n\ndef track_score(score):\n    scores.append(score)\n    top_scores = sorted(scores, reverse=True)[:3]\n    return top_scores\n\ndemo = gr.Interface(\n    track_score, \n    gr.Number(label=\"Score\"), \n    gr.JSON(label=\"Top Scores\")\n)\ndemo.launch()\n```\n\nIn the code above, the `scores` array is shared between all users. If multiple users are accessing this demo, their scores will all be added to the same list, and the returned top 3 scores will be collected from this shared reference.\n\n## Session State\n\nAnother type of data persistence Gradio supports is session state, where data persists across multiple submits within a page session. However, data is _not_ shared between different users of your model. To store data in a session state, you need to do three things:\n\n1. Pass in an extra parameter into your function, which represents the state of the interface.\n2. At the end of the function, return the updated value of the state as an extra return value.\n3. Add the `'state'` input and `'state'` output components when creating your `Interface`\n\nHere's a simple app to illustrate session state - this app simply stores users previous submissions and displays them back to the user:\n\n\n```python\nimport gradio as gr\n\ndef store_message(message: str, history: list[str]):\n    output = {\n        \"Current messages\": message,\n        \"Previous messages\": history[::-1]\n    }\n    history.append(message)\n    return output, history\n\ndemo = gr.Interface(fn=store_message, \n                    inputs=[\"textbox\", gr.State(value=[])], \n                    outputs=[\"json\", gr.State()])\n\ndemo.launch()\n```\n\u003Cgradio-app space='gradio/interface_state'>\u003C/gradio-app>\n\n\nNotice how the state persists across submits within each page, but if you load this demo in another tab (or refresh the page), the demos will not share chat history. Here, we could not store the submission history in a global variable, otherwise the submission history would then get jumbled between different users.\n\nThe initial value of the `State` is `None` by default. If you pass a parameter to the `value` argument of `gr.State()`, it is used as the default value of the state instead. \n\nNote: the `Interface` class only supports a single session state variable (though it can be a list with multiple elements). For more complex use cases, you can use Blocks, [which supports multiple `State` variables](/guides/state-in-blocks/). Alternatively, if you are building a chatbot that maintains user state, consider using the `ChatInterface` abstraction, [which manages state automatically](/guides/creating-a-chatbot-fast).\n",tags:[],spaces:[],url:"/guides/interface-state/",contributor:null},{name:"reactive-interfaces",category:"building-interfaces",pretty_category:"Building Interfaces",guide_index:4,absolute_index:7,pretty_name:"Reactive Interfaces",content:"# Reactive Interfaces\n\nFinally, we cover how to get Gradio demos to refresh automatically or continuously stream data.\n\n## Live Interfaces\n\nYou can make interfaces automatically refresh by setting `live=True` in the interface. Now the interface will recalculate as soon as the user input changes.\n\n```python\nimport gradio as gr\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\ndemo = gr.Interface(\n    calculator,\n    [\n        \"number\",\n        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n        \"number\"\n    ],\n    \"number\",\n    live=True,\n)\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/calculator_live'>\u003C/gradio-app>\n\nNote there is no submit button, because the interface resubmits automatically on change.\n\n## Streaming Components\n\nSome components have a \"streaming\" mode, such as `Audio` component in microphone mode, or the `Image` component in webcam mode. Streaming means data is sent continuously to the backend and the `Interface` function is continuously being rerun.\n\nThe difference between `gr.Audio(source='microphone')` and `gr.Audio(source='microphone', streaming=True)`, when both are used in `gr.Interface(live=True)`, is that the first `Component` will automatically submit data and run the `Interface` function when the user stops recording, whereas the second `Component` will continuously send data and run the `Interface` function _during_ recording.\n\nHere is example code of streaming images from the webcam.\n\n```python\nimport gradio as gr\nimport numpy as np\n\ndef flip(im):\n    return np.flipud(im)\n\ndemo = gr.Interface(\n    flip, \n    gr.Image(sources=[\"webcam\"], streaming=True), \n    \"image\",\n    live=True\n)\ndemo.launch()\n    \n```\n\nStreaming can also be done in an output component. A `gr.Audio(streaming=True)` output component can take a stream of audio data yielded piece-wise by a generator function and combines them into a single audio file.\n\n```python\nimport gradio as gr\nfrom pydub import AudioSegment\nfrom time import sleep\n\nwith gr.Blocks() as demo:\n    input_audio = gr.Audio(label=\"Input Audio\", type=\"filepath\", format=\"mp3\")\n    with gr.Row():\n        with gr.Column():\n            stream_as_file_btn = gr.Button(\"Stream as File\")\n            format = gr.Radio([\"wav\", \"mp3\"], value=\"wav\", label=\"Format\")\n            stream_as_file_output = gr.Audio(streaming=True)\n\n            def stream_file(audio_file, format):\n                audio = AudioSegment.from_file(audio_file)\n                i = 0\n                chunk_size = 1000\n                while chunk_size * i \u003C len(audio):\n                    chunk = audio[chunk_size * i : chunk_size * (i + 1)]\n                    i += 1\n                    if chunk:\n                        file = f\"/tmp/{i}.{format}\"\n                        chunk.export(file, format=format)\n                        yield file\n                        sleep(0.5)\n\n            stream_as_file_btn.click(\n                stream_file, [input_audio, format], stream_as_file_output\n            )\n\n            gr.Examples(\n                [[\"audio/cantina.wav\", \"wav\"], [\"audio/cantina.wav\", \"mp3\"]],\n                [input_audio, format],\n                fn=stream_file,\n                outputs=stream_as_file_output,\n                cache_examples=True,\n            )\n\n        with gr.Column():\n            stream_as_bytes_btn = gr.Button(\"Stream as Bytes\")\n            stream_as_bytes_output = gr.Audio(format=\"bytes\", streaming=True)\n\n            def stream_bytes(audio_file):\n                chunk_size = 20_000\n                with open(audio_file, \"rb\") as f:\n                    while True:\n                        chunk = f.read(chunk_size)\n                        if chunk:\n                            yield chunk\n                            sleep(1)\n                        else:\n                            break\n            stream_as_bytes_btn.click(stream_bytes, input_audio, stream_as_bytes_output)\n\nif __name__ == \"__main__\":\n    demo.queue().launch()\n\n```\n\nFor a more detailed example, see our guide on performing [automatic speech recognition](/guides/real-time-speech-recognition) with Gradio.\n",tags:[],spaces:[],url:"/guides/reactive-interfaces/",contributor:null}],parent:"gradio",slug:"interface"},tabbedinterface:{class:null,name:"TabbedInterface",description:"A TabbedInterface is created by providing a list of Interfaces, each of which gets rendered in a separate tab.",tags:{demos:"stt_or_tts"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"interface_list",annotation:"list[Interface]",doc:"a list of interfaces to be rendered in tabs."},{name:"tab_names",annotation:"list[str] | None",doc:"a list of tab names. If None, the tab names will be &quot;Tab 1&quot;, &quot;Tab 2&quot;, etc.",default:"None"},{name:"title",annotation:"str | None",doc:"a title for the interface; if provided, appears above the input and output components in large font. Also used as the tab title when opened in a browser window.",default:"None"},{name:"theme",annotation:"Theme | None",doc:null,default:"None"},{name:"analytics_enabled",annotation:"bool | None",doc:"whether to allow basic telemetry. If None, will use GRADIO_ANALYTICS_ENABLED environment variable or default to True.",default:"None"},{name:"css",annotation:"str | None",doc:"custom css or path to custom css file to apply to entire Blocks",default:"None"}],returns:{annotation:null,doc:"a Gradio Tabbed Interface for the given interfaces"},example:null,fns:[],demos:[["stt_or_tts","import gradio as gr\n\ntts_examples = [\n    \"I love learning machine learning\",\n    \"How do you do?\",\n]\n\ntts_demo = gr.load(\n    \"huggingface/facebook/fastspeech2-en-ljspeech\",\n    title=None,\n    examples=tts_examples,\n    description=\"Give me something to say!\",\n    cache_examples=False\n)\n\nstt_demo = gr.load(\n    \"huggingface/facebook/wav2vec2-base-960h\",\n    title=None,\n    inputs=\"mic\",\n    description=\"Let me try to guess what you're saying!\",\n)\n\ndemo = gr.TabbedInterface([tts_demo, stt_demo], [\"Text-to-speech\", \"Speech-to-text\"])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",slug:"tabbed-interface"}},components:a,helpers:b,modals:c,routes:d,events:["stream","upload","clear","click","release","blur","play","edit","focus","select","stop_recording","input","pause_recording","stop","like","end","start_recording","submit","pause","change"],"py-client":e,chatinterface:{chatinterface:{class:null,name:"ChatInterface",description:"ChatInterface is Gradio's high-level abstraction for creating chatbot UIs, and allows you to create a web-based demo around a chatbot model in a few lines of code. Only one parameter is required: fn, which takes a function that governs the response of the chatbot based on the user input and chat history. Additional parameters can be used to control the appearance and behavior of the demo. \u003Cbr>",tags:{demos:"chatinterface_random_response, chatinterface_streaming_echo",guides:"creating-a-chatbot-fast, sharing-your-app"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"fn",annotation:"Callable",doc:"The function to wrap the chat interface around. Should accept two parameters: a string input message and list of two-element lists of the form [[user_message, bot_message], ...] representing the chat history, and return a string response. See the Chatbot documentation for more information on the chat history format."},{name:"chatbot",annotation:"Chatbot | None",doc:"An instance of the gr.Chatbot component to use for the chat interface, if you would like to customize the chatbot properties. If not provided, a default gr.Chatbot component will be created.",default:"None"},{name:"textbox",annotation:"Textbox | None",doc:"An instance of the gr.Textbox component to use for the chat interface, if you would like to customize the textbox properties. If not provided, a default gr.Textbox component will be created.",default:"None"},{name:"additional_inputs",annotation:"str | Component | list[str | Component] | None",doc:"An instance or list of instances of gradio components (or their string shortcuts) to use as additional inputs to the chatbot. If components are not already rendered in a surrounding Blocks, then the components will be displayed under the chatbot, in an accordion.",default:"None"},{name:"additional_inputs_accordion_name",annotation:"str | None",doc:"Deprecated. Will be removed in a future version of Gradio. Use the `additional_inputs_accordion` parameter instead.",default:"None"},{name:"additional_inputs_accordion",annotation:"str | Accordion | None",doc:"If a string is provided, this is the label of the `gr.Accordion` to use to contain additional inputs. A `gr.Accordion` object can be provided as well to configure other properties of the container holding the additional inputs. Defaults to a `gr.Accordion(label=&quot;Additional Inputs&quot;, open=False)`. This parameter is only used if `additional_inputs` is provided.",default:"None"},{name:"examples",annotation:"list[str] | None",doc:"Sample inputs for the function; if provided, appear below the chatbot and can be clicked to populate the chatbot input.",default:"None"},{name:"cache_examples",annotation:"bool | None",doc:"If True, caches examples in the server for fast runtime in examples. The default option in HuggingFace Spaces is True. The default option elsewhere is False.",default:"None"},{name:"title",annotation:"str | None",doc:"a title for the interface; if provided, appears above chatbot in large font. Also used as the tab title when opened in a browser window.",default:"None"},{name:"description",annotation:"str | None",doc:"a description for the interface; if provided, appears above the chatbot and beneath the title in regular font. Accepts Markdown and HTML content.",default:"None"},{name:"theme",annotation:"Theme | str | None",doc:"Theme to use, loaded from gradio.themes.",default:"None"},{name:"css",annotation:"str | None",doc:"Custom css as a string or path to a css file. This css will be included in the demo webpage.",default:"None"},{name:"js",annotation:"str | None",doc:"Custom js or path to js file to run when demo is first loaded. This javascript will be included in the demo webpage.",default:"None"},{name:"head",annotation:"str | None",doc:"Custom html to insert into the head of the demo webpage. This can be used to add custom meta tags, scripts, stylesheets, etc. to the page.",default:"None"},{name:"analytics_enabled",annotation:"bool | None",doc:"Whether to allow basic telemetry. If None, will use GRADIO_ANALYTICS_ENABLED environment variable if defined, or default to True.",default:"None"},{name:"submit_btn",annotation:"str | None | Button",doc:"Text to display on the submit button. If None, no button will be displayed. If a Button object, that button will be used.",default:"\"Submit\""},{name:"stop_btn",annotation:"str | None | Button",doc:"Text to display on the stop button, which replaces the submit_btn when the submit_btn or retry_btn is clicked and response is streaming. Clicking on the stop_btn will halt the chatbot response. If set to None, stop button functionality does not appear in the chatbot. If a Button object, that button will be used as the stop button.",default:"\"Stop\""},{name:"retry_btn",annotation:"str | None | Button",doc:"Text to display on the retry button. If None, no button will be displayed. If a Button object, that button will be used.",default:"\"üîÑ  Retry\""},{name:"undo_btn",annotation:"str | None | Button",doc:"Text to display on the delete last button. If None, no button will be displayed. If a Button object, that button will be used.",default:"\"‚Ü©Ô∏è Undo\""},{name:"clear_btn",annotation:"str | None | Button",doc:"Text to display on the clear button. If None, no button will be displayed. If a Button object, that button will be used.",default:"\"üóëÔ∏è  Clear\""},{name:"autofocus",annotation:"bool",doc:"If True, autofocuses to the textbox when the page loads.",default:"True"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of chatbot submissions that can be running simultaneously. Can be set to None to mean no limit (any number of chatbot submissions can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `.queue()`, which is 1 by default).",default:"\"default\""}],returns:{annotation:null},example:"import gradio as gr\n\ndef echo(message, history):\n    return message\n\ndemo = gr.ChatInterface(fn=echo, examples=[\"hello\", \"hola\", \"merhaba\"], title=\"Echo Bot\")\ndemo.launch()",fns:[],demos:[["chatinterface_random_response","import random\nimport gradio as gr\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n\ndemo = gr.ChatInterface(random_response)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["chatinterface_streaming_echo","import time\nimport gradio as gr\n\ndef slow_echo(message, history):\n    for i in range(len(message)):\n        time.sleep(0.05)\n        yield \"You typed: \" + message[: i+1]\n\ndemo = gr.ChatInterface(slow_echo).queue()\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"creating-a-chatbot-fast",category:"chatbots",pretty_category:"Chatbots",guide_index:1,absolute_index:13,pretty_name:"Creating A Chatbot Fast",content:"# How to Create a Chatbot with Gradio\n\n\n\n## Introduction\n\nChatbots are a popular application of large language models. Using `gradio`, you can easily build a demo of your chatbot model and share that with your users, or try it yourself using an intuitive chatbot UI.\n\nThis tutorial uses `gr.ChatInterface()`, which is a high-level abstraction that allows you to create your chatbot UI fast, often with a single line of code. The chatbot interface that we create will look something like this:\n\n\u003Cgradio-app space='gradio/chatinterface_streaming_echo'>\u003C/gradio-app>\n\nWe'll start with a couple of simple examples, and then show how to use `gr.ChatInterface()` with real language models from several popular APIs and libraries, including `langchain`, `openai`, and Hugging Face.\n\n**Prerequisites**: please make sure you are using the **latest version** version of Gradio:\n\n```bash\n$ pip install --upgrade gradio\n```\n\n## Defining a chat function\n\nWhen working with `gr.ChatInterface()`, the first thing you should do is define your chat function. Your chat function should take two arguments: `message` and then `history` (the arguments can be named anything, but must be in this order).\n\n- `message`: a `str` representing the user's input.\n- `history`: a `list` of `list` representing the conversations up until that point. Each inner list consists of two `str` representing a pair: `[user input, bot response]`.\n\nYour function should return a single string response, which is the bot's response to the particular user input `message`. Your function can take into account the `history` of messages, as well as the current message.\n\nLet's take a look at a few examples.\n\n## Example: a chatbot that responds yes or no\n\nLet's write a chat function that responds `Yes` or `No` randomly.\n\nHere's our chat function:\n\n```python\nimport random\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n```\n\nNow, we can plug this into `gr.ChatInterface()` and call the `.launch()` method to create the web interface:\n\n```python\nimport gradio as gr\n\ngr.ChatInterface(random_response).launch()\n```\n\nThat's it! Here's our running demo, try it out:\n\n\u003Cgradio-app space='gradio/chatinterface_random_response'>\u003C/gradio-app>\n\n## Another example using the user's input and history\n\nOf course, the previous example was very simplistic, it didn't even take user input or the previous history into account! Here's another simple example showing how to incorporate a user's input as well as the history.\n\n```python\nimport random\nimport gradio as gr\n\ndef alternatingly_agree(message, history):\n    if len(history) % 2 == 0:\n        return f\"Yes, I do think that '{message}'\"\n    else:\n        return \"I don't think so\"\n\ngr.ChatInterface(alternatingly_agree).launch()\n```\n\n## Streaming chatbots\n\nIf in your chat function, you use `yield` to generate a sequence of responses, you'll end up with a streaming chatbot. It's that simple!\n\n```python\nimport time\nimport gradio as gr\n\ndef slow_echo(message, history):\n    for i in range(len(message)):\n        time.sleep(0.3)\n        yield \"You typed: \" + message[: i+1]\n\ngr.ChatInterface(slow_echo).launch()\n```\n\nNotice that we've [enabled queuing](/guides/key-features#queuing), which is required to use generator functions. While the response is streaming, the \"Submit\" button turns into a \"Stop\" button that can be used to stop the generator function. You can customize the appearance and behavior of the \"Stop\" button using the `stop_btn` parameter.\n\n## Customizing your chatbot\n\nIf you're familiar with Gradio's `Interface` class, the `gr.ChatInterface` includes many of the same arguments that you can use to customize the look and feel of your Chatbot. For example, you can:\n\n- add a title and description above your chatbot using `title` and `description` arguments.\n- add a theme or custom css using `theme` and `css` arguments respectively.\n- add `examples` and even enable `cache_examples`, which make it easier for users to try it out .\n- You can change the text or disable each of the buttons that appear in the chatbot interface: `submit_btn`, `retry_btn`, `undo_btn`, `clear_btn`.\n\nIf you want to customize the `gr.Chatbot` or `gr.Textbox` that compose the `ChatInterface`, then you can pass in your own chatbot or textbox as well. Here's an example of how we can use these parameters:\n\n```python\nimport gradio as gr\n\ndef yes_man(message, history):\n    if message.endswith(\"?\"):\n        return \"Yes\"\n    else:\n        return \"Ask me anything!\"\n\ngr.ChatInterface(\n    yes_man,\n    chatbot=gr.Chatbot(height=300),\n    textbox=gr.Textbox(placeholder=\"Ask me a yes or no question\", container=False, scale=7),\n    title=\"Yes Man\",\n    description=\"Ask Yes Man any question\",\n    theme=\"soft\",\n    examples=[\"Hello\", \"Am I cool?\", \"Are tomatoes vegetables?\"],\n    cache_examples=True,\n    retry_btn=None,\n    undo_btn=\"Delete Previous\",\n    clear_btn=\"Clear\",\n).launch()\n```\n\n## Additional Inputs\n\nYou may want to add additional parameters to your chatbot and expose them to your users through the Chatbot UI. For example, suppose you want to add a textbox for a system prompt, or a slider that sets the number of tokens in the chatbot's response. The `ChatInterface` class supports an `additional_inputs` parameter which can be used to add additional input components.\n\nThe `additional_inputs` parameters accepts a component or a list of components. You can pass the component instances directly, or use their string shortcuts (e.g. `\"textbox\"` instead of `gr.Textbox()`). If you pass in component instances, and they have _not_ already been rendered, then the components will appear underneath the chatbot (and any examples) within a `gr.Accordion()`. You can set the label of this accordion using the `additional_inputs_accordion_name` parameter.\n\nHere's a complete example:\n\n```python\nimport gradio as gr\nimport time\n\ndef echo(message, history, system_prompt, tokens):\n    response = f\"System prompt: {system_prompt}\\n Message: {message}.\"\n    for i in range(min(len(response), int(tokens))):\n        time.sleep(0.05)\n        yield response[: i+1]\n\ndemo = gr.ChatInterface(echo, \n                        additional_inputs=[\n                            gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\"), \n                            gr.Slider(10, 100)\n                        ]\n                       )\n\nif __name__ == \"__main__\":\n    demo.queue().launch()\n```\n\nIf the components you pass into the `additional_inputs` have already been rendered in a parent `gr.Blocks()`, then they will _not_ be re-rendered in the accordion. This provides flexibility in deciding where to lay out the input components. In the example below, we position the `gr.Textbox()` on top of the Chatbot UI, while keeping the slider underneath.\n\n```python\nimport gradio as gr\nimport time\n\ndef echo(message, history, system_prompt, tokens):\n    response = f\"System prompt: {system_prompt}\\n Message: {message}.\"\n    for i in range(min(len(response), int(tokens))):\n        time.sleep(0.05)\n        yield response[: i+1]\n\nwith gr.Blocks() as demo:\n    system_prompt = gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\")\n    slider = gr.Slider(10, 100, render=False)\n\n    gr.ChatInterface(\n        echo, additional_inputs=[system_prompt, slider]\n    )\n\ndemo.launch()\n```\n\nIf you need to create something even more custom, then its best to construct the chatbot UI using the low-level `gr.Blocks()` API. We have [a dedicated guide for that here](/guides/creating-a-custom-chatbot-with-blocks).\n\n## Using your chatbot via an API\n\nOnce you've built your Gradio chatbot and are hosting it on [Hugging Face Spaces](https://hf.space) or somewhere else, then you can query it with a simple API at the `/chat` endpoint. The endpoint just expects the user's message (and potentially additional inputs if you have set any using the `additional_inputs` parameter), and will return the response, internally keeping track of the messages sent so far.\n\n[](https://github.com/gradio-app/gradio/assets/1778297/7b10d6db-6476-4e2e-bebd-ecda802c3b8f)\n\nTo use the endpoint, you should use either the [Gradio Python Client](/guides/getting-started-with-the-python-client) or the [Gradio JS client](/guides/getting-started-with-the-js-client).\n\n## A `langchain` example\n\nNow, let's actually use the `gr.ChatInterface` with some real large language models. We'll start by using `langchain` on top of `openai` to build a general-purpose streaming chatbot application in 19 lines of code. You'll need to have an OpenAI key for this example (keep reading for the free, open-source equivalent!)\n\n```python\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import AIMessage, HumanMessage\nimport openai\nimport gradio as gr\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # Replace with your key\n\nllm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-0613')\n\ndef predict(message, history):\n    history_langchain_format = []\n    for human, ai in history:\n        history_langchain_format.append(HumanMessage(content=human))\n        history_langchain_format.append(AIMessage(content=ai))\n    history_langchain_format.append(HumanMessage(content=message))\n    gpt_response = llm(history_langchain_format)\n    return gpt_response.content\n\ngr.ChatInterface(predict).launch()\n```\n\n## A streaming example using `openai`\n\nOf course, we could also use the `openai` library directy. Here a similar example, but this time with streaming results as well:\n\n```python\nimport openai\nimport gradio as gr\n\nopenai.api_key = \"sk-...\"  # Replace with your key\n\ndef predict(message, history):\n    history_openai_format = []\n    for human, assistant in history:\n        history_openai_format.append({\"role\": \"user\", \"content\": human })\n        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n    history_openai_format.append({\"role\": \"user\", \"content\": message})\n\n    response = openai.ChatCompletion.create(\n        model='gpt-3.5-turbo',\n        messages= history_openai_format,\n        temperature=1.0,\n        stream=True\n    )\n\n    partial_message = \"\"\n    for chunk in response:\n        if len(chunk['choices'][0]['delta']) != 0:\n            partial_message = partial_message + chunk['choices'][0]['delta']['content']\n            yield partial_message\n\ngr.ChatInterface(predict).launch()\n```\n\n## Example using a local, open-source LLM with Hugging Face\n\nOf course, in many cases you want to run a chatbot locally. Here's the equivalent example using Together's RedePajama model, from Hugging Face (this requires you to have a GPU with CUDA).\n\n```python\nimport gradio as gr\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\nfrom threading import Thread\n\ntokenizer = AutoTokenizer.from_pretrained(\"togethercomputer/RedPajama-INCITE-Chat-3B-v1\")\nmodel = AutoModelForCausalLM.from_pretrained(\"togethercomputer/RedPajama-INCITE-Chat-3B-v1\", torch_dtype=torch.float16)\nmodel = model.to('cuda:0')\n\nclass StopOnTokens(StoppingCriteria):\n    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n        stop_ids = [29, 0]\n        for stop_id in stop_ids:\n            if input_ids[0][-1] == stop_id:\n                return True\n        return False\n\ndef predict(message, history):\n\n    history_transformer_format = history + [[message, \"\"]]\n    stop = StopOnTokens()\n\n    messages = \"\".join([\"\".join([\"\\n\u003Chuman>:\"+item[0], \"\\n\u003Cbot>:\"+item[1]])  #curr_system_message +\n                for item in history_transformer_format])\n\n    model_inputs = tokenizer([messages], return_tensors=\"pt\").to(\"cuda\")\n    streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n    generate_kwargs = dict(\n        model_inputs,\n        streamer=streamer,\n        max_new_tokens=1024,\n        do_sample=True,\n        top_p=0.95,\n        top_k=1000,\n        temperature=1.0,\n        num_beams=1,\n        stopping_criteria=StoppingCriteriaList([stop])\n        )\n    t = Thread(target=model.generate, kwargs=generate_kwargs)\n    t.start()\n\n    partial_message  = \"\"\n    for new_token in streamer:\n        if new_token != '\u003C':\n            partial_message += new_token\n            yield partial_message\n\n\ngr.ChatInterface(predict).launch()\n```\n\nWith those examples, you should be all set to create your own Gradio Chatbot demos soon! For building even more custom Chatbot applications, check out [a dedicated guide](/guides/creating-a-custom-chatbot-with-blocks) using the low-level `gr.Blocks()` API.\n",tags:["NLP","TEXT","CHAT"],spaces:[],url:"/guides/creating-a-chatbot-fast/",contributor:null},{name:"sharing-your-app",category:"getting-started",pretty_category:"Getting Started",guide_index:3,absolute_index:2,pretty_name:"Sharing Your App",content:"# Sharing Your App\n\nHow to share your Gradio app:\n\n1. [Sharing demos with the share parameter](#sharing-demos)\n2. [Hosting on HF Spaces](#hosting-on-hf-spaces)\n3. [Embedding hosted spaces](#embedding-hosted-spaces)\n4. [Using the API page](#api-page)\n5. [Authentication](#authentication)\n6. [Accessing network requests](#accessing-the-network-request-directly)\n7. [Mounting within FastAPI](#mounting-within-another-fast-api-app)\n8. [Security and file access](#security-and-file-access)\n\n## Sharing Demos\n\nGradio demos can be easily shared publicly by setting `share=True` in the `launch()` method. Like this:\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter üöÄ\n```\n\nThis generates a public, shareable link that you can send to anybody! When you send this link, the user on the other side can try out the model in their browser. Because the processing happens on your device (as long as your device stays on), you don't have to worry about any packaging any dependencies. \n\n![sharing](https://github.com/gradio-app/gradio/blob/main/guides/assets/sharing.svg?raw=true)\n\n\nA share link usually looks something like this: **https://07ff8706ab.gradio.live**. Although the link is served through the Gradio Share Servers, these servers are only a proxy for your local server, and do not store any data sent through your app. Share links expire after 72 hours. (it is [also possible to set up your own Share Server](https://github.com/huggingface/frp/) on your own cloud server to overcome this restriction.)\u003Cp class='tip'>\u003Cstrong>‚úçÔ∏è Tip:\u003C/strong> Keep in mind that share links are publicly accessible, meaning that anyone can use your model for prediction! Therefore, make sure not to expose any sensitive information through the functions you write, or allow any critical changes to occur on your device. Or you can [add authentication to your Gradio app](#authentication) as discussed below.\u003C/p>\n\nNote that by default, `share=False`, which means that your server is only running locally. (This is the default, except in Google Colab notebooks, where share links are automatically created). As an alternative to using share links, you can use use [SSH port-forwarding](https://www.ssh.com/ssh/tunneling/example) to share your local server with specific users.\n\n\n## Hosting on HF Spaces\n\nIf you'd like to have a permanent link to your Gradio demo on the internet, use Hugging Face Spaces. [Hugging Face Spaces](http://huggingface.co/spaces/) provides the infrastructure to permanently host your machine learning model for free!\n\nAfter you have [created a free Hugging Face account](https://huggingface.co/join), you have two methods to deploy your Gradio app to Hugging Face Spaces:\n\n1. From terminal: run `gradio deploy` in your app directory. The CLI will gather some basic metadata and then launch your app. To update your space, you can re-run this command or enable the Github Actions option to automatically update the Spaces on `git push`.\n\n2. From your browser: Drag and drop a folder containing your Gradio model and all related files [here](https://huggingface.co/new-space). See [this guide how to host on Hugging Face Spaces](https://huggingface.co/blog/gradio-spaces) for more information, or watch the embedded video:\n\n\u003Cvideo autoplay muted loop>\n  \u003Csource src=\"https://github.com/gradio-app/gradio/blob/main/guides/assets/hf_demo.mp4?raw=true\" type=\"video/mp4\" />\n\u003C/video>\n\n\n## Embedding Hosted Spaces\n\nOnce you have hosted your app on Hugging Face Spaces (or on your own server), you may want to embed the demo on a different website, such as your blog or your portfolio. Embedding an interactive demo allows people to try out the machine learning model that you have built, without needing to download or install anything ‚Äî right in their browser! The best part is that you can embed interactive demos even in static websites, such as GitHub pages.\n\nThere are two ways to embed your Gradio demos. You can find quick links to both options directly on the Hugging Face Space page, in the \"Embed this Space\" dropdown option:\n\n![Embed this Space dropdown option](https://github.com/gradio-app/gradio/blob/main/guides/assets/embed_this_space.png?raw=true)\n\n### Embedding with Web Components\n\nWeb components typically offer a better experience to users than IFrames. Web components load lazily, meaning that they won't slow down the loading time of your website, and they automatically adjust their height based on the size of the Gradio app.\n\nTo embed with Web Components:\n\n1. Import the gradio JS library into into your site by adding the script below in your site (replace {GRADIO_VERSION} in the URL with the library version of Gradio you are using).\n\n```html\n\u003Cscript\n\ttype=\"module\"\n\tsrc=\"https://gradio.s3-us-west-2.amazonaws.com/{GRADIO_VERSION}/gradio.js\"\n>\u003C/script>\n```\n\n2. Add\n\n```html\n\u003Cgradio-app src=\"https://$your_space_host.hf.space\">\u003C/gradio-app>\n```\n\nelement where you want to place the app. Set the `src=` attribute to your Space's embed URL, which you can find in the \"Embed this Space\" button. For example:\n\n```html\n\u003Cgradio-app\n\tsrc=\"https://abidlabs-pytorch-image-classifier.hf.space\"\n>\u003C/gradio-app>\n```\n\n\u003Cscript>\nfetch(\"https://pypi.org/pypi/gradio/json\"\n).then(r => r.json()\n).then(obj => {\n    let v = obj.info.version;\n    content = document.querySelector('.prose');\n    content.innerHTML = content.innerHTML.replaceAll(\"{GRADIO_VERSION}\", v);\n});\n\u003C/script>\n\nYou can see examples of how web components look \u003Ca href=\"https://www.gradio.app\">on the Gradio landing page\u003C/a>.\n\nYou can also customize the appearance and behavior of your web component with attributes that you pass into the `\u003Cgradio-app>` tag:\n\n- `src`: as we've seen, the `src` attributes links to the URL of the hosted Gradio demo that you would like to embed\n- `space`: an optional shorthand if your Gradio demo is hosted on Hugging Face Space. Accepts a `username/space_name` instead of a full URL. Example: `gradio/Echocardiogram-Segmentation`. If this attribute attribute is provided, then `src` does not need to be provided.\n- `control_page_title`: a boolean designating whether the html title of the page should be set to the title of the Gradio app (by default `\"false\"`)\n- `initial_height`: the initial height of the web component while it is loading the Gradio app, (by default `\"300px\"`). Note that the final height is set based on the size of the Gradio app.\n- `container`: whether to show the border frame and information about where the Space is hosted (by default `\"true\"`)\n- `info`: whether to show just the information about where the Space is hosted underneath the embedded app (by default `\"true\"`)\n- `autoscroll`: whether to autoscroll to the output when prediction has finished (by default `\"false\"`)\n- `eager`: whether to load the Gradio app as soon as the page loads (by default `\"false\"`)\n- `theme_mode`: whether to use the `dark`, `light`, or default `system` theme mode (by default `\"system\"`)\n- `render`: an event that is triggered once the embedded space has finished rendering.\n\nHere's an example of how to use these attributes to create a Gradio app that does not lazy load and has an initial height of 0px.\n\n```html\n\u003Cgradio-app\n\tspace=\"gradio/Echocardiogram-Segmentation\"\n\teager=\"true\"\n\tinitial_height=\"0px\"\n>\u003C/gradio-app>\n```\n\nHere's another example of how to use the `render` event. An event listener is used to capture the `render` event and will call the `handleLoadComplete()` function once rendering is complete. \n\n```html\n\u003Cscript>\n\tfunction handleLoadComplete() {\n\t\tconsole.log(\"Embedded space has finished rendering\");\n\t}\n\n\tconst gradioApp = document.querySelector(\"gradio-app\");\n\tgradioApp.addEventListener(\"render\", handleLoadComplete);\n\u003C/script>\n```\n\n_Note: While Gradio's CSS will never impact the embedding page, the embedding page can affect the style of the embedded Gradio app. Make sure that any CSS in the parent page isn't so general that it could also apply to the embedded Gradio app and cause the styling to break. Element selectors such as `header { ... }` and `footer { ... }` will be the most likely to cause issues._\n\n### Embedding with IFrames\n\nTo embed with IFrames instead (if you cannot add javascript to your website, for example), add this element:\n\n```html\n\u003Ciframe src=\"https://$your_space_host.hf.space\">\u003C/iframe>\n```\n\nAgain, you can find the `src=` attribute to your Space's embed URL, which you can find in the \"Embed this Space\" button.\n\nNote: if you use IFrames, you'll probably want to add a fixed `height` attribute and set `style=\"border:0;\"` to remove the boreder. In addition, if your app requires permissions such as access to the webcam or the microphone, you'll need to provide that as well using the `allow` attribute.\n\n## API Page\n\nYou can use almost any Gradio app as an API! In the footer of a Gradio app [like this one](https://huggingface.co/spaces/gradio/hello_world), you'll see a \"Use via API\" link.\n\n![Use via API](https://github.com/gradio-app/gradio/blob/main/guides/assets/use_via_api.png?raw=true)\n\nThis is a page that lists the endpoints that can be used to query the Gradio app, via our supported clients: either [the Python client](https://gradio.app/guides/getting-started-with-the-python-client/), or [the JavaScript client](https://gradio.app/guides/getting-started-with-the-js-client/). For each endpoint, Gradio automatically generates the parameters and their types, as well as example inputs.\n\nThe endpoints are automatically created when you launch a Gradio `Interface`. If you are using Gradio `Blocks`, you can also set up a Gradio API page, though we recommend that you explicitly name each event listener, such as\n\n```python\nbtn.click(add, [num1, num2], output, api_name=\"addition\")\n```\n\nThis will add and document the endpoint `/api/addition/` to the automatically generated API page. Otherwise, your API endpoints will appear as \"unnamed\" endpoints.\n\n\n## Authentication\n\n### Password-protected app\n\nYou may wish to put an authentication page in front of your app to limit who can open your app. With the `auth=` keyword argument in the `launch()` method, you can provide a tuple with a username and password, or a list of acceptable username/password tuples; Here's an example that provides password-based authentication for a single user named \"admin\":\n\n```python\ndemo.launch(auth=(\"admin\", \"pass1234\"))\n```\n\nFor more complex authentication handling, you can even pass a function that takes a username and password as arguments, and returns True to allow authentication, False otherwise. This can be used for, among other things, making requests to 3rd-party authentication services.\n\nHere's an example of a function that accepts any login where the username and password are the same:\n\n```python\ndef same_auth(username, password):\n    return username == password\ndemo.launch(auth=same_auth)\n```\n\nFor authentication to work properly, third party cookies must be enabled in your browser.\nThis is not the case by default for Safari, Chrome Incognito Mode.\n\n### OAuth (Login via Hugging Face)\n\nGradio supports OAuth login via Hugging Face. This feature is currently **experimental** and only available on Spaces.\nIt allows you to add a _\"Sign in with Hugging Face\"_ button to your demo. Check out [this Space](https://huggingface.co/spaces/Wauplin/gradio-oauth-demo) for a live demo.\n\nTo enable OAuth, you must set `hf_oauth: true` as a Space metadata in your README.md file. This will register your Space\nas an OAuth application on Hugging Face. Next, you can use `gr.LoginButton` and `gr.LogoutButton` to add login and logout buttons to\nyour Gradio app. Once a user is logged in with their HF account, you can retrieve their profile by adding a parameter of type\n`gr.OAuthProfile` to any Gradio function. The user profile will be automatically injected as a parameter value. If you want\nto perform actions on behalf of the user (e.g. list user's private repos, create repo, etc.), you can retrieve the user\ntoken by adding a parameter of type `gr.OAuthToken`. You must define which scopes you will use in your Space metadata\n(see [documentation](https://huggingface.co/docs/hub/spaces-oauth#scopes) for more details).\n\nHere is a short example:\n\n```py\nimport gradio as gr\n\n\ndef hello(profile: gr.OAuthProfile | None) -> str:\n    if profile is None:\n        return \"I don't know you.\"\n    return f\"Hello {profile.name}\"\n\ndef list_organizations(oauth_token: gr.OAuthToken | None) -> str:\n    if oauth_token is None:\n        return \"Please log in to list organizations.\"\n    org_names = [org[\"name\"] for org in whoami(oauth_token.token)[\"orgs\"]]\n    return f\"You belong to {', '.join(org_names)}.\"\n\nwith gr.Blocks() as demo:\n    gr.LoginButton()\n    gr.LogoutButton()\n    m1 = gr.Markdown()\n    m2 = gr.Markdown()\n    demo.load(hello, inputs=None, outputs=m1)\n    demo.load(list_organizations, inputs=None, outputs=m2)\n```\n\nWhen the user clicks on the login button, they get redirected in a new page to authorize your Space.\n\n\u003Ccenter>\n\u003Cimg src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/oauth_sign_in.png\" style=\"width:300px; max-width:80%\">\n\u003C/center>\n\nUsers can revoke access to their profile at any time in their [settings](https://huggingface.co/settings/connected-applications).\n\nAs seen above, OAuth features are available only when your app runs in a Space. However, you often need to test your app\nlocally before deploying it. To help with that, the `gr.LoginButton` is mocked. When a user clicks on it, they are\nautomatically logged in with a fake user profile. This allows you to debug your app before deploying it to a Space.\n\n## Accessing the Network Request Directly\n\nWhen a user makes a prediction to your app, you may need the underlying network request, in order to get the request headers (e.g. for advanced authentication), log the client's IP address, getting the query parameters, or for other reasons. Gradio supports this in a similar manner to FastAPI: simply add a function parameter whose type hint is `gr.Request` and Gradio will pass in the network request as that parameter. Here is an example:\n\n```python\nimport gradio as gr\n\ndef echo(text, request: gr.Request):\n    if request:\n        print(\"Request headers dictionary:\", request.headers)\n        print(\"IP address:\", request.client.host)\n        print(\"Query parameters:\", dict(request.query_params))\n    return text\n\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()\n```\n\nNote: if your function is called directly instead of through the UI (this happens, for\nexample, when examples are cached, or when the Gradio app is called via API), then `request` will be `None`. \nYou should handle this case explicitly to ensure that your app does not throw any errors. That is why\nwe have the explicit check `if request`.\n\n## Mounting Within Another FastAPI App\n\nIn some cases, you might have an existing FastAPI app, and you'd like to add a path for a Gradio demo.\nYou can easily do this with `gradio.mount_gradio_app()`.\n\nHere's a complete example:\n\n```python\nfrom fastapi import FastAPI\nimport gradio as gr\n\nCUSTOM_PATH = \"/gradio\"\n\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef read_main():\n    return {\"message\": \"This is your main app\"}\n\n\nio = gr.Interface(lambda x: \"Hello, \" + x + \"!\", \"textbox\", \"textbox\")\napp = gr.mount_gradio_app(app, io, path=CUSTOM_PATH)\n\n\n# Run this from the terminal as you would normally start a FastAPI app: `uvicorn run:app`\n# and navigate to http://localhost:8000/gradio in your browser.\n\n```\n\nNote that this approach also allows you run your Gradio apps on custom paths (`http://localhost:8000/gradio` in the example above).\n\n\n## Security and File Access\n\nSharing your Gradio app with others (by hosting it on Spaces, on your own server, or through temporary share links) **exposes** certain files on the host machine to users of your Gradio app.\n\nIn particular, Gradio apps ALLOW users to access to three kinds of files:\n\n- **Temporary files created by Gradio.** These are files that are created by Gradio as part of running your prediction function. For example, if your prediction function returns a video file, then Gradio will save that video to a temporary cache on your device and then send the path to the file to the front end. You can customize the location of temporary cache files created by Gradio by setting the environment variable `GRADIO_TEMP_DIR` to an absolute path, such as `/home/usr/scripts/project/temp/`.\n\n\n- **Cached examples created by Gradio.** These are files that are created by Gradio as part of caching examples for faster runtimes, if you set `cache_examples=True` in `gr.Interface()` or in `gr.Examples()`. By default, these files are saved in the `gradio_cached_examples/` subdirectory within your app's working directory. You can customize the location of cached example files created by Gradio by setting the environment variable `GRADIO_EXAMPLES_CACHE` to an absolute path or a path relative to your working directory.\n\n- **Files that you explicitly allow via the `allowed_paths` parameter in `launch()`**. This parameter allows you to pass in a list of additional directories or exact filepaths you'd like to allow users to have access to. (By default, this parameter is an empty list).\n\nGradio DOES NOT ALLOW access to:\n\n- **Files that you explicitly block via the `blocked_paths` parameter in `launch()`**. You can pass in a list of additional directories or exact filepaths to the `blocked_paths` parameter in `launch()`. This parameter takes precedence over the files that Gradio exposes by default or by the `allowed_paths`.\n\n- **Any other paths on the host machine**. Users should NOT be able to access other arbitrary paths on the host.\n\nPlease make sure you are running the latest version of `gradio` for these security settings to apply.\n",tags:[],spaces:[],url:"/guides/sharing-your-app/",contributor:null}],parent:"gradio",prev_obj:"Block-Layouts",next_obj:"Themes",slug:"chat-interface"}},events_matrix:{AnnotatedImage:["select"],Audio:["stream","change","clear","play","pause","pause","stop","pause","pause","start_recording","pause_recording","stop_recording","upload"],BarPlot:["change","clear"],Button:["click"],Chatbot:["change","select","like"],Checkbox:["change","input","select"],CheckboxGroup:["change","input","select"],ClearButton:["click"],Code:["change","input","focus","blur"],ColorPicker:["change","input","submit","focus","blur"],Dataframe:["change","input","select"],Dataset:["click","select"],Dropdown:["change","input","select","focus","blur"],DuplicateButton:["click"],File:["change","select","clear","upload"],FileExplorer:["change"],Gallery:["select","upload","change"],HTML:["change"],HighlightedText:["change","select"],Image:["clear","change","stream","select","upload"],ImageEditor:["clear","change","select","upload"],JSON:["change"],Label:["change","select"],LinePlot:["change","clear"],LoginButton:["click"],LogoutButton:["click"],Markdown:["change"],Model3D:["change","upload","edit","clear"],Number:["change","input","submit","focus"],Plot:["change","clear"],Radio:["select","change","input"],ScatterPlot:["change","clear"],Slider:["change","input","release"],State:[],Textbox:["change","input","select","submit","focus","blur"],UploadButton:["click","upload"],Video:["change","clear","start_recording","stop_recording","stop","play","pause","end","upload"]}},components:a,helpers:b,modals:c,routes:d,py_client:e,js:{upload:"# `@gradio/upload`\n [v0.6.1](https://www.npmjs.com/package/@gradio/upload)\n\n```html\n\u003Cscript>\n    import { Upload, ModifyUpload, normalise_file, get_fetchable_url_or_file, upload, prepare_files } from \"@gradio/upload\";\n\u003C/script>\n```\n\nUpload\n```javascript\n\texport let filetype: string | null = null;\n\texport let dragging = false;\n\texport let boundedheight = true;\n\texport let center = true;\n\texport let flex = true;\n\texport let file_count = \"single\";\n\texport let disable_click = false;\n\texport let root: string;\n\texport let hidden = false;\n```\n\nModifyUpload\n```javascript\n    export let editable = false;\n\texport let undoable = false;\n\texport let absolute = true;\n\texport let i18n: I18nFormatter;\n```\n\n```javascript\nexport function normalise_file(\n\tfile: FileData | null,\n\tserver_url: string,\n\tproxy_url: string | null\n): FileData | null;\n\nexport function normalise_file(\n\tfile: FileData[] | null,\n\tserver_url: string,\n\tproxy_url: string | null\n): FileData[] | null;\n\nexport function normalise_file(\n\tfile: FileData[] | FileData | null,\n\tserver_url: string, // root: string,\n\tproxy_url: string | null // root_url: string | null\n): FileData[] | FileData | null;\n\nexport function normalise_file(\n\tfile: FileData[] | FileData | null,\n\tserver_url: string, // root: string,\n\tproxy_url: string | null // root_url: string | null\n): FileData[] | FileData | null;\n\nexport function get_fetchable_url_or_file(\n\tpath: string | null,\n\tserver_url: string,\n\tproxy_url: string | null\n): string\n\nexport async function upload(\n\tfile_data: FileData[],\n\troot: string,\n\tupload_fn: typeof upload_files = upload_files\n): Promise\u003C(FileData | null)[] | null>\n\nexport async function prepare_files(\n\tfiles: File[],\n\tis_stream?: boolean\n): Promise\u003CFileData[]> {\n\treturn files.map(\n\t\t(f, i) =>\n\t\t\tnew FileData({\n\t\t\t\tpath: f.name,\n\t\t\t\torig_name: f.name,\n\t\t\t\tblob: f,\n\t\t\t\tsize: f.size,\n\t\t\t\tmime_type: f.type,\n\t\t\t\tis_stream\n\t\t\t})\n\t);\n}\n```",button:"# `@gradio/button`\n [v0.2.17](https://www.npmjs.com/package/@gradio/button)\n\n```javascript\n\u003Cscript>\n\timport { BaseButton } from \"@gradio/button\";\n\timport { createEventDispatcher, tick, getContext } from \"svelte\";\n\tconst dispatch = createEventDispatcher();\n\u003C/script>\n\n\u003CBaseButton\n\t{value}\n\t{variant}\n\t{elem_id}\n\t{elem_classes}\n\t{size}\n\t{scale}\n\t{link}\n\t{icon}\n\t{min_width}\n\t{visible}\n\t{root}\n\t{root_url}\n\ton:click={() => dispatch(\"click\")}\n>\n\t{\"My Button\"}\n\u003C/Button>\n```\n",markdown:"# `@gradio/markdown`\n [v0.6.0](https://www.npmjs.com/package/@gradio/markdown)\n\n```html\n\u003Cscript>\n    import { BaseMarkdown, MarkdownCode, BaseExample } from `@gradio/markdown`;\n\u003C/script>\n```\n\nBaseMarkdown\n```javascript\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let visible = true;\n\texport let value: string;\n\texport let min_height = false;\n\texport let rtl = false;\n\texport let sanitize_html = true;\n\texport let line_breaks = false;\n\texport let latex_delimiters: {\n\t\tleft: string;\n\t\tright: string;\n\t\tdisplay: boolean;\n\t}[];\n```\n\nMarkdownCode\n```javascript\n\texport let chatbot = true;\n\texport let message: string;\n\texport let sanitize_html = true;\n\texport let latex_delimiters: {\n\t\tleft: string;\n\t\tright: string;\n\t\tdisplay: boolean;\n\t}[] = [];\n\texport let render_markdown = true;\n\texport let line_breaks = true;\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n\texport let sanitize_html: boolean;\n\texport let line_breaks: boolean;\n\texport let latex_delimiters: {\n\t\tleft: string;\n\t\tright: string;\n\t\tdisplay: boolean;\n\t}[];\n```",gallery:"# `@gradio/gallery`\n [v0.5.0](https://www.npmjs.com/package/@gradio/gallery)\n\n```html\n\u003Cscript>\n\timport { BaseGallery } from \"@gradio/gallery\";\n\u003C/script>\n```\n\nBaseGallery\n```javascript\n\texport let show_label = true;\n\texport let label: string;\n\texport let root = \"\";\n\texport let root_url: null | string = null;\n\texport let value: { image: FileData; caption: string | null }[] | null = null;\n\texport let columns: number | number[] | undefined = [2];\n\texport let rows: number | number[] | undefined = undefined;\n\texport let height: number | \"auto\" = \"auto\";\n\texport let preview: boolean;\n\texport let allow_preview = true;\n\texport let object_fit: \"contain\" | \"cover\" | \"fill\" | \"none\" | \"scale-down\" =\n\t\t\"cover\";\n\texport let show_share_button = false;\n\texport let show_download_button = false;\n\texport let i18n: I18nFormatter;\n\texport let selected_index: number | null = null;\n```",atoms:"# `@gradio/atoms`\n [v0.4.1](https://www.npmjs.com/package/@gradio/atoms)\n\n```html\n\u003Cscript lang=\"ts\">\n\timport { Block, BlockTitle, BlockLabel, IconButton, Empty, Info, ShareButton, UploadText} from \"@gradio/atoms\";\n\u003C/script>\n```\n\nBlock:\n```javascript\n\texport let height: number | undefined = undefined;\n\texport let width: number | undefined = undefined;\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let variant: \"solid\" | \"dashed\" | \"none\" = \"solid\";\n\texport let border_mode: \"base\" | \"focus\" = \"base\";\n\texport let padding = true;\n\texport let type: \"normal\" | \"fieldset\" = \"normal\";\n\texport let test_id: string | undefined = undefined;\n\texport let explicit_call = false;\n\texport let container = true;\n\texport let visible = true;\n\texport let allow_overflow = true;\n\texport let scale: number | null = null;\n\texport let min_width = 0;\n```\n\nBlockTitle:\n```javascript\n\texport let show_label = true;\n\texport let info: string | undefined = undefined;\n```\n\nBlockLabel:\n```javascript\n\texport let label: string | null = null;\n\texport let Icon: any;\n\texport let show_label = true;\n\texport let disable = false;\n\texport let float = true;\n```\n\nIconButton:\n```javascript\n\texport let Icon: any;\n\texport let label = \"\";\n\texport let show_label = false;\n\texport let pending = false;\n```\n\nEmpty:\n```javascript\n\texport let size: \"small\" | \"large\" = \"small\";\n\texport let unpadded_box = false;\n```\n\nShareButton:\n```javascript\n\texport let formatter: (arg0: any) => Promise\u003Cstring>;\n\texport let value: any;\n\texport let i18n: I18nFormatter;\n```\n\nUploadText:\n```javascript\n\texport let type: \"video\" | \"image\" | \"audio\" | \"file\" | \"csv\" = \"file\";\n\texport let i18n: I18nFormatter;\n```",checkbox:"# `@gradio/checkbox`\n [v0.2.6](https://www.npmjs.com/package/@gradio/checkbox)\n\n```html\n\u003Cscript>\n    import { BaseCheckbox } from \"@gradio/checkbox\";\n\u003C/script>\n```\n\nBaseCheckBox:\n```javascript\n\texport let value = false;\n\texport let label = \"Checkbox\";\n\texport let mode: \"static\" | \"interactive\";\n```",json:"# `@gradio/json`\n [v0.1.6](https://www.npmjs.com/package/@gradio/json)\n\n```html\n\u003Cscript>\n\timport { BaseJSON } from \"@gradio/json\";\n\u003C/script>\n```\n\nBaseJSON\n```html\n\texport let value: any = {};\n```",tooltip:"# `@gradio/tooltip`\n [v0.1.0](https://www.npmjs.com/package/@gradio/tooltip)\n\n```javascript\nimport { Tooltip } from \"@gradio/tooltip\";\n```\n\n```javascript\n\texport let text: string;\n\texport let x: number;\n\texport let y: number;\n\texport let color: string;\n```",dropdown:"# `@gradio/dropdown`\n [v0.5.0](https://www.npmjs.com/package/@gradio/dropdown)\n\n```html\n\u003Cscript>\n    import {BaseDropdown, BaseMultiselect, BaseExample } from \"@gradio/dropdown\";\n\u003C/script>\n```\n\nBaseDropdown\n```javascript\n\texport let label: string;\n\texport let info: string | undefined = undefined;\n\texport let value: string | number | (string | number)[] | undefined = [];\n\texport let value_is_output = false;\n\texport let choices: [string, string | number][];\n\texport let disabled = false;\n\texport let show_label: boolean;\n\texport let container = true;\n\texport let allow_custom_value = false;\n\texport let filterable = true;\n```\n\nBaseMultiselect\n```javascript\n\texport let label: string;\n\texport let info: string | undefined = undefined;\n\texport let value: string | number | (string | number)[] | undefined = [];\n\texport let value_is_output = false;\n\texport let max_choices: number | null = null;\n\texport let choices: [string, string | number][];\n\texport let disabled = false;\n\texport let show_label: boolean;\n\texport let container = true;\n\texport let allow_custom_value = false;\n\texport let filterable = true;\n\texport let i18n: I18nFormatter;\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;    \n```",audio:"# `@gradio/audio`\n [v0.7.2](https://www.npmjs.com/package/@gradio/audio)\n\n```html\n\u003Cscript>\n\timport { BaseStaticAudio, BaseInteractiveAudio, BasePlayer, BaseExample } from \"@gradio/audio\";\n\u003C/script>\n```\n\n\nBaseExample:\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```\n\nBaseStaticAudio:\n```javascript\n\texport let value: null | { name: string; data: string } = null;\n\texport let label: string;\n\texport let name: string;\n\texport let show_label = true;\n\texport let autoplay: boolean;\n\texport let show_download_button = true;\n\texport let show_share_button = false;\n\texport let i18n: I18nFormatter;\n\texport let waveform_settings = {};\n```\n\nBaseInteractiveAudio:\n```javascript\n\texport let value: null | { name: string; data: string } = null;\n\texport let label: string;\n\texport let root: string;\n\texport let show_label = true;\n\texport let sources:\n\t\t| [\"microphone\"]\n\t\t| [\"upload\"]\n\t\t| [\"microphone\", \"upload\"]\n\t\t| [\"upload\", \"microphone\"] = [\"microphone\", \"upload\"];\n\texport let pending = false;\n\texport let streaming = false;\n\texport let autoplay = false;\n\texport let i18n: I18nFormatter;\n\texport let waveform_settings = {};\n\texport let dragging: boolean;\n\texport let active_source: \"microphone\" | \"upload\";\n\texport let handle_reset_value: () => void = () => {};\n```\n\nBasePlayer:\n```javascript\n\texport let value: null | { name: string; data: string } = null;\n\texport let label: string;\n\texport let autoplay: boolean;\n\texport let i18n: I18nFormatter;\n\texport let dispatch: (event: any, detail?: any) => void;\n\texport let dispatch_blob: (\n\t\tblobs: Uint8Array[] | Blob[],\n\t\tevent: \"stream\" | \"change\" | \"stop_recording\"\n\t) => Promise\u003Cvoid> = () => Promise.resolve();\n\texport let interactive = false;\n\texport let waveform_settings = {};\n\texport let mode = \"\";\n\texport let handle_reset_value: () => void = () => {};\n```",highlightedtext:"# `@gradio/highlightedtext`\n [v0.4.6](https://www.npmjs.com/package/@gradio/highlightedtext)\n\n```html\n\u003Cscript>\n    import { BaseStaticHighlightedText, BaseInteractiveHighlightedText } from `@gradio/highlightedtext`;\n\u003C/script>\n```\n\n\nBaseStaticHighlightedText\n```javascript\n\texport let value: {\n\t\ttoken: string;\n\t\tclass_or_confidence: string | number | null;\n\t}[] = [];\n\texport let show_legend = false;\n\texport let color_map: Record\u003Cstring, string> = {};\n\texport let selectable = false;\n```\n\nBaseInteractiveHighlightedText\n```javascript\n\texport let value: {\n\t\ttoken: string;\n\t\tclass_or_confidence: string | number | null;\n\t}[] = [];\n\texport let show_legend = false;\n\texport let color_map: Record\u003Cstring, string> = {};\n\texport let selectable = false;\n```",imageeditor:"# `@gradio/imageeditor`\n [v0.3.0](https://www.npmjs.com/package/@gradio/imageeditor)\n",form:"# `@gradio/form`\n [v0.1.6](https://www.npmjs.com/package/@gradio/form)\n\n```html\n\u003Cscript>\n\timport { Form } from \"@gradio/form\";\n\u003C/script>\n```\n\nForm\n```javascript\n\texport let visible = true;\n\texport let scale: number | null = null;\n\texport let min_width = 0;\n```\n",lite:"# Gradio-Lite: Serverless Gradio Running Entirely in Your Browser\n [v4.14.1](https://www.npmjs.com/package/@gradio/lite)\n\n\nGradio is a popular Python library for creating interactive machine learning apps. Traditionally, Gradio applications have relied on server-side infrastructure to run, which can be a hurdle for developers who need to host their applications. \n\nEnter Gradio-lite (`@gradio/lite`): a library that leverages [Pyodide](https://pyodide.org/en/stable/) to bring Gradio directly to your browser. \n\n## What is `@gradio/lite`?\n\n`@gradio/lite` is a JavaScript library that enables you to run Gradio applications directly within your web browser. It achieves this by utilizing Pyodide, a Python runtime for WebAssembly, which allows Python code to be executed in the browser environment. With `@gradio/lite`, you can **write regular Python code for your Gradio applications**, and they will **run seamlessly in the browser** without the need for server-side infrastructure.\n\n## Getting Started\n\nLet's build a \"Hello World\" Gradio app in `@gradio/lite`\n\n\n### 1. Import JS and CSS \n\nStart by creating a new HTML file, if you don't have one already. The best way to use @gradio/lite currently is via the CDN. Import the JavaScript and CSS corresponding to the `@gradio/lite` package by using the following code:\n\n\n```html\n\u003Chtml>\n\t\u003Chead>\n\t\t\u003Cscript type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\">\u003C/script>\n\t\t\u003Clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t\u003C/head>\n\u003C/html>\n```\n\nNote that you should generally use the latest version of `@gradio/lite` that is available. You can see the [versions available here](https://www.jsdelivr.com/package/npm/@gradio/lite?tab=files).\n\n### 2. Create the `\u003Cgradio-lite>` tags\n\nSomewhere in the body of your HTML page (wherever you'd like the Gradio app to be rendered), create opening and closing `\u003Cgradio-lite>` tags. \n\n```html\n\u003Chtml>\n\t\u003Chead>\n\t\t\u003Cscript type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\">\u003C/script>\n\t\t\u003Clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t\u003C/head>\n\t\u003Cbody>\n\t\t\u003Cgradio-lite>\n\t\t\u003C/gradio-lite>\n\t\u003C/body>\n\u003C/html>\n```\n\nNote: you can add the `theme` attribute to the `\u003Cgradio-lite>` tag to force the theme to be dark or light (by default, it respects the system theme). E.g.\n\n```html\n\u003Cgradio-lite theme=\"dark\">\n...\n\u003C/gradio-lite>\n```\n\n### 3. Write your Gradio app inside of the tags\n\nNow, write your Gradio app as you would normally, in Python! Keep in mind that since this is Python, whitespace and indentations matter. \n\n```html\n\u003Chtml>\n\t\u003Chead>\n\t\t\u003Cscript type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\">\u003C/script>\n\t\t\u003Clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t\u003C/head>\n\t\u003Cbody>\n\t\t\u003Cgradio-lite>\n\t\timport gradio as gr\n\n\t\tdef greet(name):\n\t\t\treturn \"Hello, \" + name + \"!\"\n\t\t\n\t\tgr.Interface(greet, \"textbox\", \"textbox\").launch()\n\t\t\u003C/gradio-lite>\n\t\u003C/body>\n\u003C/html>\n```\n\nAnd that's it! You should now be able to open your HTML page in the browser and see the Gradio app rendered! Note that it may take a little while for the Gradio app to load initially since Pyodide can take a while to install in your browser.\n\n**Note on debugging**: to see any errors in your Gradio-lite application, open the inspector in your web browser. All errors (including Python errors) will be printed there.\n\n## More Examples: Adding Additional Files and Requirements\n\nWhat if you want to create a Gradio app that spans multiple files? Or that has custom Python requirements? Both are possible with `@gradio/lite`!\n\n### Multiple Files\n\nAdding multiple files within a `@gradio/lite` app is very straightrward: use the `\u003Cgradio-file>` tag. You can have as many `\u003Cgradio-file>` tags as you want, but each one needs to have a `name` attribute and the entry point to your Gradio app should have the `entrypoint` attribute.\n\nHere's an example:\n\n```html\n\u003Cgradio-lite>\n\n\u003Cgradio-file name=\"app.py\" entrypoint>\nimport gradio as gr\nfrom utils import add\n\ndemo = gr.Interface(fn=add, inputs=[\"number\", \"number\"], outputs=\"number\")\n\ndemo.launch()\n\u003C/gradio-file>\n\n\u003Cgradio-file name=\"utils.py\" >\ndef add(a, b):\n\treturn a + b\n\u003C/gradio-file>\n\n\u003C/gradio-lite>\t\t\n\n```\n\n### Additional Requirements\n\nIf your Gradio app has additional requirements, it is usually possible to [install them in the browser using micropip](https://pyodide.org/en/stable/usage/loading-packages.html#loading-packages). We've created a wrapper to make this paticularly convenient: simply list your requirements in the same syntax as a `requirements.txt` and enclose them with `\u003Cgradio-requirements>` tags.\n\nHere, we install `transformers_js_py` to run a text classification model directly in the browser!\n\n```html\n\u003Cgradio-lite>\n\n\u003Cgradio-requirements>\ntransformers_js_py\n\u003C/gradio-requirements>\n\n\u003Cgradio-file name=\"app.py\" entrypoint>\nfrom transformers_js import import_transformers_js\nimport gradio as gr\n\ntransformers = await import_transformers_js()\npipeline = transformers.pipeline\npipe = await pipeline('sentiment-analysis')\n\nasync def classify(text):\n\treturn await pipe(text)\n\ndemo = gr.Interface(classify, \"textbox\", \"json\")\ndemo.launch()\n\u003C/gradio-file>\n\n\u003C/gradio-lite>\t\n\n```\n\n**Try it out**: You can see this example running in [this Hugging Face Static Space](https://huggingface.co/spaces/abidlabs/gradio-lite-classify), which lets you host static (serverless) web applications for free. Visit the page and you'll be able to run a machine learning model without internet access!\n\n## Benefits of Using `@gradio/lite`\n\n### 1. Serverless Deployment\nThe primary advantage of @gradio/lite is that it eliminates the need for server infrastructure. This simplifies deployment, reduces server-related costs, and makes it easier to share your Gradio applications with others.\n\n### 2. Low Latency\nBy running in the browser, @gradio/lite offers low-latency interactions for users. There's no need for data to travel to and from a server, resulting in faster responses and a smoother user experience.\n\n### 3. Privacy and Security\nSince all processing occurs within the user's browser, `@gradio/lite` enhances privacy and security. User data remains on their device, providing peace of mind regarding data handling.\n\n### Limitations\n\n* Currently, the biggest limitation in using `@gradio/lite` is that your Gradio apps will generally take more time (usually 5-15 seconds) to load initially in the browser. This is because the browser needs to load the Pyodide runtime before it can render Python code. \n\n* Not every Python package is supported by Pyodide. While `gradio` and many other popular packages (including `numpy`, `scikit-learn`, and `transformers-js`) can be installed in Pyodide, if your app has many dependencies, its worth checking whether whether the dependencies are included in Pyodide, or can be [installed with `micropip`](https://micropip.pyodide.org/en/v0.2.2/project/api.html#micropip.install).\n\n## Try it out!\n\nYou can immediately try out `@gradio/lite` by copying and pasting this code in a local `index.html` file and opening it with your browser:\n\n```html\n\u003Chtml>\n\t\u003Chead>\n\t\t\u003Cscript type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\">\u003C/script>\n\t\t\u003Clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t\u003C/head>\n\t\u003Cbody>\n\t\t\u003Cgradio-lite>\n\t\timport gradio as gr\n\n\t\tdef greet(name):\n\t\t\treturn \"Hello, \" + name + \"!\"\n\t\t\n\t\tgr.Interface(greet, \"textbox\", \"textbox\").launch()\n\t\t\u003C/gradio-lite>\n\t\u003C/body>\n\u003C/html>\n```\n\n\nWe've also created a playground on the Gradio website that allows you to interactively edit code and see the results immediately! \n\nPlayground: https://www.gradio.app/playground\n\n\n",file:"# `@gradio/file`\n [v0.4.7](https://www.npmjs.com/package/@gradio/file)\n\n```html\n\u003Cscript>\n\timport { BaseFile, BaseFileUpload, FilePreview, BaseExample } from \"@gradio/file\";\n\u003C/script>\n```\n\nBaseFile\n```javascript\n\texport let value: FileData | FileData[] | null = null;\n\texport let label: string;\n\texport let show_label = true;\n\texport let selectable = false;\n\texport let height: number | undefined = undefined;\n\texport let i18n: I18nFormatter;\n```\n\nBaseFileUpload\n```javascript\n\texport let value: null | FileData | FileData[];\n\texport let label: string;\n\texport let show_label = true;\n\texport let file_count = \"single\";\n\texport let file_types: string[] | null = null;\n\texport let selectable = false;\n\texport let root: string;\n\texport let height: number | undefined = undefined;\n\texport let i18n: I18nFormatter;\n```\n\nFilePreview\n```javascript\n\texport let value: FileData | FileData[];\n\texport let selectable = false;\n\texport let height: number | undefined = undefined;\n\texport let i18n: I18nFormatter;\n```\n\nBaseExample\n```javascript\n\texport let value: FileData;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```",label:"# `@gradio/label`\n [v0.2.6](https://www.npmjs.com/package/@gradio/label)\n\n```html\n\u003Cscript>\n\timport { BaseLabel } from \"@gradio/label\";\n\u003C/script>\n```\n\nBaseLabel\n```javascript\n\texport let value: {\n\t\tlabel?: string;\n\t\tconfidences?: { label: string; confidence: number }[];\n\t};\n\texport let color: string | undefined = undefined;\n\texport let selectable = false;\n```\n",textbox:"# `@gradio/textbox`\n [v0.4.7](https://www.npmjs.com/package/@gradio/textbox)\n\n```html\n\u003Cscript>\n    import { BaseTextbox, BaseExample } from \"@gradio/textbox\";\n\u003C/script>\n```\n\nBaseTextbox\n```javascript\n\texport let value = \"\";\n\texport let value_is_output = false;\n\texport let lines = 1;\n\texport let placeholder = \"Type here...\";\n\texport let label: string;\n\texport let info: string | undefined = undefined;\n\texport let disabled = false;\n\texport let show_label = true;\n\texport let container = true;\n\texport let max_lines: number;\n\texport let type: \"text\" | \"password\" | \"email\" = \"text\";\n\texport let show_copy_button = false;\n\texport let rtl = false;\n\texport let autofocus = false;\n\texport let text_align: \"left\" | \"right\" | undefined = undefined;\n\texport let autoscroll = true;\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```",statustracker:"# `@gradio/statustracker`\n [v0.4.3](https://www.npmjs.com/package/@gradio/statustracker)\n\n```html\n\u003Cscript>\n    import {StatusTracker, Toast, Loader} from `@gradio/statustracker`;\n\u003C/script>\n```\n\nStatusTracker\n```javascript\n\texport let i18n: I18nFormatter;\n\texport let eta: number | null = null;\n\texport let queue = false;\n\texport let queue_position: number | null;\n\texport let queue_size: number | null;\n\texport let status: \"complete\" | \"pending\" | \"error\" | \"generating\";\n\texport let scroll_to_output = false;\n\texport let timer = true;\n\texport let show_progress: \"full\" | \"minimal\" | \"hidden\" = \"full\";\n\texport let message: string | null = null;\n\texport let progress: LoadingStatus[\"progress\"] | null | undefined = null;\n\texport let variant: \"default\" | \"center\" = \"default\";\n\texport let loading_text = \"Loading...\";\n\texport let absolute = true;\n\texport let translucent = false;\n\texport let border = false;\n\texport let autoscroll: boolean;\n```\n\nToast\n```javascript\n\texport let messages: ToastMessage[] = [];\n```\n\nLoader\n```javascript\n\texport let margin = true;\n```",uploadbutton:"# `@gradio/uploadbutton`\n [v0.4.2](https://www.npmjs.com/package/@gradio/uploadbutton)\n\n```html\n\u003Cscript>\n    import { BaseUploadButton } from \"@gradio/uploadbutton\";\n\u003C/script>\n```\n\nBaseUploadButton\n```javascript\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let visible = true;\n\texport let label: string;\n\texport let value: null | FileData | FileData[];\n\texport let file_count: string;\n\texport let file_types: string[] = [];\n\texport let root: string;\n\texport let size: \"sm\" | \"lg\" = \"lg\";\n\texport let scale: number | null = null;\n\texport let min_width: number | undefined = undefined;\n\texport let variant: \"primary\" | \"secondary\" | \"stop\" = \"secondary\";\n\texport let disabled = false;\n```",utils:"# `@gradio/utils`\n [v0.2.0](https://www.npmjs.com/package/@gradio/utils)\n\nGeneral functions for handling events in Gradio Svelte components\n\n\n```javascript\nexport async function uploadToHuggingFace(\n\t\tdata: string,\n\t\ttype: \"base64\" | \"url\"\n\t): Promise\u003Cstring>\n\nexport function copy(node: HTMLDivElement): ActionReturn\n\n\n```",code:"# `@gradio/code`\n [v0.3.7](https://www.npmjs.com/package/@gradio/code)\n\n```html\n\u003Cscript>\n    import { BaseCode, BaseCopy, BaseDownload, BaseWidget, BaseExample} from \"gradio/code\";\n\u003C/script>\n```\n\nBaseCode\n```javascript\n\texport let classNames = \"\";\n\texport let value = \"\";\n\texport let dark_mode: boolean;\n\n\texport let basic = true;\n\texport let language: string;\n\texport let lines = 5;\n\texport let extensions: Extension[] = [];\n\n\texport let useTab = true;\n\n\texport let readonly = false;\n\texport let placeholder: string | HTMLElement | null | undefined = undefined;\n```\n\nBaseCopy\n```javascript\n\texport let value: string;\n```\n\nBaseDownload\n```javascript\n\texport let value: string;\n\texport let language: string;\n```\n\nBaseWidget\n```javascript\n\texport let value: string;\n\texport let language: string;\n```\n\nBaseExample\n```\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```",chatbot:"# `@gradio/button`\n [v0.6.2](https://www.npmjs.com/package/@gradio/chatbot)\n\n```html\n\u003Cscript>\n\timport { BaseChatBot } from \"@gradio/chatbot\";\n\u003C/script>\n```\n\n\nBaseChatBot\n```javascript\n\texport let value:\n\t\t| [\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null,\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null\n\t\t  ][]\n\t\t| null;\n\tlet old_value:\n\t\t| [\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null,\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null\n\t\t  ][]\n\t\t| null = null;\n\texport let latex_delimiters: {\n\t\tleft: string;\n\t\tright: string;\n\t\tdisplay: boolean;\n\t}[];\n\texport let pending_message = false;\n\texport let selectable = false;\n\texport let likeable = false;\n\texport let show_share_button = false;\n\texport let rtl = false;\n\texport let show_copy_button = false;\n\texport let avatar_images: [string | null, string | null] = [null, null];\n\texport let sanitize_html = true;\n\texport let bubble_full_width = true;\n\texport let render_markdown = true;\n\texport let line_breaks = true;\n\texport let root: string;\n\texport let root_url: null | string;\n\texport let i18n: I18nFormatter;\n\texport let layout: \"bubble\" | \"panel\" = \"bubble\";\n```",html:"# `@gradio/html`\n [v0.1.6](https://www.npmjs.com/package/@gradio/html)\n\n```javascript\nimport { BaseHTML } from \"@gradio/html\";\n```\n\nBaseHTML\n```javascript\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let value: string;\n\texport let visible = true;\n\texport let min_height = false;\n```",video:"# `@gradio/video`\n [v0.4.0](https://www.npmjs.com/package/@gradio/video)\n\n```javascript\n\u003Cscript>\n\timport { BaseInteractiveVideo, BaseStaticVideo, BasePlayer } from \"@gradio/button\";\n\timport type { FileData } from \"@gradio/upload\";\n\timport type { Gradio } from \"@gradio/utils\";\n\texport let _video: FileData;\n\u003C/script>\n\n\u003CStaticVideo\n\tvalue={_video}\n\t{label}\n\t{show_label}\n\t{autoplay}\n\t{show_share_button}\n\ti18n={gradio.i18n}\n/>\n\n\u003CVideo\n\tvalue={_video}\n\t{label}\n\t{show_label}\n\tsource={\"upload\"}\n\t{mirror_webcam}\n\t{include_audio}\n\t{autoplay}\n\ti18n={gradio.i18n}\n>\n\t\u003Cp>Upload Video Here\u003C/p>\n\u003C/Video>\n\n\u003CBasePlayer\n\tsrc={value.data}\n\t{autoplay}\n\ton:play\n\ton:pause\n\ton:stop\n\ton:end\n\tmirror={false}\n\t{label}\n/>\n```\n",image:"# `@gradio/image`\n [v0.7.0](https://www.npmjs.com/package/@gradio/image)\n\n```html\n\u003Cscript>\n\timport { BaseImageUploader, BaseStaticImage, Webcam, BaseExample } from \"@gradio/image\";\n\u003C/script>\n```\n\nBaseImageUploader\n```javascript\n\texport let sources: (\"clipboard\" | \"webcam\" | \"upload\")[] = [\n\t\t\"upload\",\n\t\t\"clipboard\",\n\t\t\"webcam\"\n\t];\n\texport let streaming = false;\n\texport let pending = false;\n\texport let mirror_webcam: boolean;\n\texport let selectable = false;\n\texport let root: string;\n\texport let i18n: I18nFormatter;\n```\n\nBaseStaticImage\n```javascript\n\texport let value: null | FileData;\n\texport let label: string | undefined = undefined;\n\texport let show_label: boolean;\n\texport let show_download_button = true;\n\texport let selectable = false;\n\texport let show_share_button = false;\n\texport let root: string;\n\texport let i18n: I18nFormatter;\n```\n\nWebcam\n```javascript\n\texport let streaming = false;\n\texport let pending = false;\n\n\texport let mode: \"image\" | \"video\" = \"image\";\n\texport let mirror_webcam: boolean;\n\texport let include_audio: boolean;\n\texport let i18n: I18nFormatter;\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let samples_dir: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```",radio:"# `@gradio/radio`\n [v0.4.0](https://www.npmjs.com/package/@gradio/radio)\n\n```html\n\u003Cscript>\n    import { BaseRadio, BaseExample } from \"@gradio/radio\"; \n\u003C/script>\n```\n\nBaseRadio\n```javascript\n\texport let display_value: string;\n\texport let internal_value: string | number;\n\texport let disabled = false;\n\texport let elem_id = \"\";\n\texport let selected: string | number | null = null;\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```",colorpicker:"# `@gradio/colorpicker`\n [v0.2.6](https://www.npmjs.com/package/@gradio/colorpicker)\n\n```html\n\u003Cscript>\n    import { BaseColorPicker, BaseExample } from \"@gradio/colorpicker\";\n\u003C/script>\n```\n\nBaseColorPicker\n```javascript\n\texport let value = \"#000000\";\n\texport let value_is_output = false;\n\texport let label: string;\n\texport let info: string | undefined = undefined;\n\texport let disabled = false;\n\texport let show_label = true;\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```",dataframe:"# `@gradio/dataframe`\n [v0.5.0](https://www.npmjs.com/package/@gradio/dataframe)\n\n```html\n\u003Cscript>\n    import { BaseDataFrame, BaseExample } from \"@gradio/dataframe\";\n\u003C/script>\n```\n\nBaseDataFrame\n```javascript\n\texport let datatype: Datatype | Datatype[];\n\texport let label: string | null = null;\n\texport let headers: Headers = [];\n\tlet values: (string | number)[][];\n\texport let value: { data: Data; headers: Headers; metadata: Metadata } | null;\n\texport let col_count: [number, \"fixed\" | \"dynamic\"];\n\texport let row_count: [number, \"fixed\" | \"dynamic\"];\n\texport let latex_delimiters: {\n\t\tleft: string;\n\t\tright: string;\n\t\tdisplay: boolean;\n\t}[];\n\n\texport let editable = true;\n\texport let wrap = false;\n\texport let root: string;\n\texport let i18n: I18nFormatter;\n\n\texport let height = 500;\n\texport let line_breaks = true;\n\texport let column_widths: string[] = [];\n```\n\nBaseExample\n```javascript\n\texport let gradio: Gradio;\n\texport let value: (string | number)[][] | string;\n\texport let samples_dir: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n\texport let index: number;\n```",model3D:"# `gradio/model3d`\n\n```html\n\u003Cscript>\n    import {BaseModel3D, BaseModel3DUpload, BaseExample } from `@gradio/model3d`;\n\u003C/script>\n```\n\nBaseModel3D\n```javascript\n\texport let value: FileData | null;\n\texport let clear_color: [number, number, number, number] = [0, 0, 0, 0];\n\texport let label = \"\";\n\texport let show_label: boolean;\n\texport let i18n: I18nFormatter;\n\texport let zoom_speed = 1;\n\n\t// alpha, beta, radius\n\texport let camera_position: [number | null, number | null, number | null] = [\n\t\tnull,\n\t\tnull,\n\t\tnull\n\t];\n```\n\nBaseModel3DUpload\n```javascript\n\texport let value: null | FileData;\n\texport let clear_color: [number, number, number, number] = [0, 0, 0, 0];\n\texport let label = \"\";\n\texport let show_label: boolean;\n\texport let root: string;\n\texport let i18n: I18nFormatter;\n\texport let zoom_speed = 1;\n\n\t// alpha, beta, radius\n\texport let camera_position: [number | null, number | null, number | null] = [\n\t\tnull,\n\t\tnull,\n\t\tnull\n\t];\n```\n\nBaseExample\n```javascript\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```","js-client":"## JavaScript Client Library\n\nA javascript (and typescript) client to call Gradio APIs.\n\n## Installation\n\nThe Gradio JavaScript client is available on npm as `@gradio/client`. You can install it as below:\n\n```sh\nnpm i @gradio/client\n```\n\n## Usage\n\nThe JavaScript Gradio Client exposes two named imports, `client` and `duplicate`.\n\n### `client`\n\nThe client function connects to the API of a hosted Gradio space and returns an object that allows you to make calls to that API.\n\nThe simplest example looks like this:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\nThis function accepts two arguments: `source` and `options`:\n\n#### `source`\n\nThis is the url or name of the gradio app whose API you wish to connect to. This parameter is required and should always be a string. For example:\n\n```ts\nclient(\"user/space-name\");\n```\n\n#### `options`\n\nThe options object can optionally be passed a second parameter. This object has two properties, `hf_token` and `status_callback`.\n\n##### `hf_token`\n\nThis should be a Hugging Face personal access token and is required if you wish to make calls to a private gradio api. This option is optional and should be a string starting with `\"hf_\"`.\n\nExample:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\", { hf_token: \"hf_...\" });\n```\n\n##### `status_callback`\n\nThis should be a function which will notify your of the status of a space if it is not running. If the gradio API you are connecting to is awake and running or is not hosted on Hugging Face space then this function will do nothing.\n\n**Additional context**\n\nApplications hosted on Hugging Face spaces can be in a number of different states. As spaces are a GitOps tool and will rebuild when new changes are pushed to the repository, they have various building, running and error states. If a space is not 'running' then the function passed as the `status_callback` will notify you of the current state of the space and the status of the space as it changes. Spaces that are building or sleeping can take longer than usual to respond, so you can use this information to give users feedback about the progress of their action.\n\n```ts\nimport { client, type SpaceStatus } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\", {\n\t// The space_status parameter does not need to be manually annotated, this is just for illustration.\n\tspace_status: (space_status: SpaceStatus) => console.log(space_status)\n});\n```\n\n```ts\ninterface SpaceStatusNormal {\n\tstatus: \"sleeping\" | \"running\" | \"building\" | \"error\" | \"stopped\";\n\tdetail:\n\t\t| \"SLEEPING\"\n\t\t| \"RUNNING\"\n\t\t| \"RUNNING_BUILDING\"\n\t\t| \"BUILDING\"\n\t\t| \"NOT_FOUND\";\n\tload_status: \"pending\" | \"error\" | \"complete\" | \"generating\";\n\tmessage: string;\n}\n\ninterface SpaceStatusError {\n\tstatus: \"space_error\";\n\tdetail: \"NO_APP_FILE\" | \"CONFIG_ERROR\" | \"BUILD_ERROR\" | \"RUNTIME_ERROR\";\n\tload_status: \"error\";\n\tmessage: string;\n\tdiscussions_enabled: boolean;\n\ntype SpaceStatus = SpaceStatusNormal | SpaceStatusError;\n```\n\nThe gradio client returns an object with a number of methods and properties:\n\n#### `predict`\n\nThe `predict` method allows you to call an api endpoint and get a prediction result:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\n`predict` accepts two parameters, `endpoint` and `payload`. It returns a promise that resolves to the prediction result.\n\n##### `endpoint`\n\nThis is the endpoint for an api request and is required. The default endpoint for a `gradio.Interface` is `\"/predict\"`. Explicitly named endpoints have a custom name. The endpoint names can be found on the \"View API\" page of a space.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\n##### `payload`\n\nThe `payload` argument is generally optional but this depends on the API itself. If the API endpoint depends on values being passed in then it is required for the API request to succeed. The data that should be passed in is detailed on the \"View API\" page of a space, or accessible via the `view_api()` method of the client.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\", [1, \"Hello\", \"friends\"]);\n```\n\n#### `submit`\n\nThe `submit` method provides a more flexible way to call an API endpoint, providing you with status updates about the current progress of the prediction as well as supporting more complex endpoint types.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst submission = app.submit(\"/predict\", payload);\n```\n\nThe `submit` method accepts the same [`endpoint`](#endpoint) and [`payload`](#payload) arguments as `predict`.\n\nThe `submit` method does not return a promise and should not be awaited, instead it returns an object with a `on`, `off`, and `cancel` methods.\n\n##### `on`\n\nThe `on` method allows you to subscribe to events related to the submitted API request. There are two types of event that can be subscribed to: `\"data\"` updates and `\"status\"` updates.\n\n`\"data\"` updates are issued when the API computes a value, the callback provided as the second argument will be called when such a value is sent to the client. The shape of the data depends on the way the API itself is constructed. This event may fire more than once if that endpoint supports emmitting new values over time.\n\n`\"status` updates are issued when the status of a request changes. This information allows you to offer feedback to users when the queue position of the request changes, or when the request changes from queued to processing.\n\nThe status payload look like this:\n\n```ts\ninterface Status {\n\tqueue: boolean;\n\tcode?: string;\n\tsuccess?: boolean;\n\tstage: \"pending\" | \"error\" | \"complete\" | \"generating\";\n\tsize?: number;\n\tposition?: number;\n\teta?: number;\n\tmessage?: string;\n\tprogress_data?: Array\u003C{\n\t\tprogress: number | null;\n\t\tindex: number | null;\n\t\tlength: number | null;\n\t\tunit: string | null;\n\t\tdesc: string | null;\n\t}>;\n\ttime?: Date;\n}\n```\n\nUsage of these subscribe callback looks like this:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst submission = app\n\t.submit(\"/predict\", payload)\n\t.on(\"data\", (data) => console.log(data))\n\t.on(\"status\", (status: Status) => console.log(status));\n```\n\n##### `off`\n\nThe `off` method unsubscribes from a specific event of the submitted job and works similarly to `document.removeEventListener`; both the event name and the original callback must be passed in to successfully unsubscribe:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst handle_data = (data) => console.log(data);\n\nconst submission = app.submit(\"/predict\", payload).on(\"data\", handle_data);\n\n// later\nsubmission.off(\"/predict\", handle_data);\n```\n\n##### `destroy`\n\nThe `destroy` method will remove all subscriptions to a job, regardless of whether or not they are `\"data\"` or `\"status\"` events. This is a convenience method for when you do not want to unsubscribe use the `off` method.\n\n```js\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst handle_data = (data) => console.log(data);\n\nconst submission = app.submit(\"/predict\", payload).on(\"data\", handle_data);\n\n// later\nsubmission.destroy();\n```\n\n##### `cancel`\n\nCertain types of gradio function can run repeatedly and in some cases indefinitely. the `cancel` method will stop such an endpoints and prevent the API from issuing additional updates.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst submission = app\n\t.submit(\"/predict\", payload)\n\t.on(\"data\", (data) => console.log(data));\n\n// later\n\nsubmission.cancel();\n```\n\n#### `view_api`\n\nThe `view_api` method provides details about the API you are connected to. It returns a JavaScript object of all named endpoints, unnamed endpoints and what values they accept and return. This method does not accept arguments.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst api_info = await app.view_api();\n\nconsole.log(api_info);\n```\n\n#### `config`\n\nThe `config` property contains the configuration for the gradio application you are connected to. This object may contain useful meta information about the application.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconsole.log(app.config);\n```\n\n### `duplicate`\n\nThe duplicate function will attempt to duplicate the space that is referenced and return an instance of `client` connected to that space. If the space has already been duplicated then it will not create a new duplicate and will instead connect to the existing duplicated space. The huggingface token that is passed in will dictate the user under which the space is created.\n\n`duplicate` accepts the same arguments as `client` with the addition of a `private` options property dictating whether the duplicated space should be private or public. A huggingface token is required for duplication to work.\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\"\n});\n```\n\nThis function accepts two arguments: `source` and `options`:\n\n#### `source`\n\nThe space to duplicate and connect to. [See `client`'s `source` parameter](#source).\n\n#### `options`\n\nAccepts all options that `client` accepts, except `hf_token` is required. [See `client`'s `options` parameter](#source).\n\n`duplicate` also accepts one additional `options` property.\n\n##### `private`\n\nThis is an optional property specific to `duplicate`'s options object and will determine whether the space should be public or private. Spaces duplicated via the `duplicate` method are public by default.\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true\n});\n```\n\n##### `timeout`\n\nThis is an optional property specific to `duplicate`'s options object and will set the timeout in minutes before the duplicated space will go to sleep.\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true,\n\ttimeout: 5\n});\n```\n\n##### `hardware`\n\nThis is an optional property specific to `duplicate`'s options object and will set the hardware for the duplicated space. By default the hardware used will match that of the original space. If this cannot be obtained it will default to `\"cpu-basic\"`. For hardware upgrades (beyond the basic CPU tier), you may be required to provide [billing information on Hugging Face](https://huggingface.co/settings/billing).\n\nPossible hardware options are:\n\n- `\"cpu-basic\"`\n- `\"cpu-upgrade\"`\n- `\"t4-small\"`\n- `\"t4-medium\"`\n- `\"a10g-small\"`\n- `\"a10g-large\"`\n- `\"a100-large\"`\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true,\n\thardware: \"a10g-small\"\n});\n```\n"},js_pages:["atoms","audio","button","chatbot","checkbox","code","colorpicker","dataframe","dropdown","file","form","gallery","highlightedtext","html","image","imageeditor","js-client","json","label","lite","markdown","model3D","radio","statustracker","textbox","tooltip","upload","uploadbutton","utils","video"],on_main:false,wheel:"https://gradio-builds.s3.amazonaws.com/e3217b41862925a6a05f44070ac2bdabbeee6769/gradio-4.16.0-py3-none-any.whl",pages:["client","job","examples","progress","make_waveform","load","error","eventdata","warning","info","simplecsvlogger","csvlogger","huggingfacedatasetsaver","request","mount_gradio_app","base","queue","blocks","accordion","column","row","group","tab","annotatedimage","audio","barplot","button","chatbot","checkbox","checkboxgroup","clearbutton","code","colorpicker","dataframe","dataset","dropdown","duplicatebutton","file","fileexplorer","gallery","html","highlightedtext","image","imageeditor","json","label","lineplot","loginbutton","logoutbutton","markdown","model3d","number","plot","radio","scatterplot","slider","state","textbox","uploadbutton","video","chatinterface","interface","tabbedinterface"],js_client:"## JavaScript Client Library\n\nA javascript (and typescript) client to call Gradio APIs.\n\n## Installation\n\nThe Gradio JavaScript client is available on npm as `@gradio/client`. You can install it as below:\n\n```sh\nnpm i @gradio/client\n```\n\n## Usage\n\nThe JavaScript Gradio Client exposes two named imports, `client` and `duplicate`.\n\n### `client`\n\nThe client function connects to the API of a hosted Gradio space and returns an object that allows you to make calls to that API.\n\nThe simplest example looks like this:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\nThis function accepts two arguments: `source` and `options`:\n\n#### `source`\n\nThis is the url or name of the gradio app whose API you wish to connect to. This parameter is required and should always be a string. For example:\n\n```ts\nclient(\"user/space-name\");\n```\n\n#### `options`\n\nThe options object can optionally be passed a second parameter. This object has two properties, `hf_token` and `status_callback`.\n\n##### `hf_token`\n\nThis should be a Hugging Face personal access token and is required if you wish to make calls to a private gradio api. This option is optional and should be a string starting with `\"hf_\"`.\n\nExample:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\", { hf_token: \"hf_...\" });\n```\n\n##### `status_callback`\n\nThis should be a function which will notify your of the status of a space if it is not running. If the gradio API you are connecting to is awake and running or is not hosted on Hugging Face space then this function will do nothing.\n\n**Additional context**\n\nApplications hosted on Hugging Face spaces can be in a number of different states. As spaces are a GitOps tool and will rebuild when new changes are pushed to the repository, they have various building, running and error states. If a space is not 'running' then the function passed as the `status_callback` will notify you of the current state of the space and the status of the space as it changes. Spaces that are building or sleeping can take longer than usual to respond, so you can use this information to give users feedback about the progress of their action.\n\n```ts\nimport { client, type SpaceStatus } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\", {\n\t// The space_status parameter does not need to be manually annotated, this is just for illustration.\n\tspace_status: (space_status: SpaceStatus) => console.log(space_status)\n});\n```\n\n```ts\ninterface SpaceStatusNormal {\n\tstatus: \"sleeping\" | \"running\" | \"building\" | \"error\" | \"stopped\";\n\tdetail:\n\t\t| \"SLEEPING\"\n\t\t| \"RUNNING\"\n\t\t| \"RUNNING_BUILDING\"\n\t\t| \"BUILDING\"\n\t\t| \"NOT_FOUND\";\n\tload_status: \"pending\" | \"error\" | \"complete\" | \"generating\";\n\tmessage: string;\n}\n\ninterface SpaceStatusError {\n\tstatus: \"space_error\";\n\tdetail: \"NO_APP_FILE\" | \"CONFIG_ERROR\" | \"BUILD_ERROR\" | \"RUNTIME_ERROR\";\n\tload_status: \"error\";\n\tmessage: string;\n\tdiscussions_enabled: boolean;\n\ntype SpaceStatus = SpaceStatusNormal | SpaceStatusError;\n```\n\nThe gradio client returns an object with a number of methods and properties:\n\n#### `predict`\n\nThe `predict` method allows you to call an api endpoint and get a prediction result:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\n`predict` accepts two parameters, `endpoint` and `payload`. It returns a promise that resolves to the prediction result.\n\n##### `endpoint`\n\nThis is the endpoint for an api request and is required. The default endpoint for a `gradio.Interface` is `\"/predict\"`. Explicitly named endpoints have a custom name. The endpoint names can be found on the \"View API\" page of a space.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\n##### `payload`\n\nThe `payload` argument is generally optional but this depends on the API itself. If the API endpoint depends on values being passed in then it is required for the API request to succeed. The data that should be passed in is detailed on the \"View API\" page of a space, or accessible via the `view_api()` method of the client.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst result = await app.predict(\"/predict\", [1, \"Hello\", \"friends\"]);\n```\n\n#### `submit`\n\nThe `submit` method provides a more flexible way to call an API endpoint, providing you with status updates about the current progress of the prediction as well as supporting more complex endpoint types.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst submission = app.submit(\"/predict\", payload);\n```\n\nThe `submit` method accepts the same [`endpoint`](#endpoint) and [`payload`](#payload) arguments as `predict`.\n\nThe `submit` method does not return a promise and should not be awaited, instead it returns an object with a `on`, `off`, and `cancel` methods.\n\n##### `on`\n\nThe `on` method allows you to subscribe to events related to the submitted API request. There are two types of event that can be subscribed to: `\"data\"` updates and `\"status\"` updates.\n\n`\"data\"` updates are issued when the API computes a value, the callback provided as the second argument will be called when such a value is sent to the client. The shape of the data depends on the way the API itself is constructed. This event may fire more than once if that endpoint supports emmitting new values over time.\n\n`\"status` updates are issued when the status of a request changes. This information allows you to offer feedback to users when the queue position of the request changes, or when the request changes from queued to processing.\n\nThe status payload look like this:\n\n```ts\ninterface Status {\n\tqueue: boolean;\n\tcode?: string;\n\tsuccess?: boolean;\n\tstage: \"pending\" | \"error\" | \"complete\" | \"generating\";\n\tsize?: number;\n\tposition?: number;\n\teta?: number;\n\tmessage?: string;\n\tprogress_data?: Array\u003C{\n\t\tprogress: number | null;\n\t\tindex: number | null;\n\t\tlength: number | null;\n\t\tunit: string | null;\n\t\tdesc: string | null;\n\t}>;\n\ttime?: Date;\n}\n```\n\nUsage of these subscribe callback looks like this:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst submission = app\n\t.submit(\"/predict\", payload)\n\t.on(\"data\", (data) => console.log(data))\n\t.on(\"status\", (status: Status) => console.log(status));\n```\n\n##### `off`\n\nThe `off` method unsubscribes from a specific event of the submitted job and works similarly to `document.removeEventListener`; both the event name and the original callback must be passed in to successfully unsubscribe:\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst handle_data = (data) => console.log(data);\n\nconst submission = app.submit(\"/predict\", payload).on(\"data\", handle_data);\n\n// later\nsubmission.off(\"/predict\", handle_data);\n```\n\n##### `destroy`\n\nThe `destroy` method will remove all subscriptions to a job, regardless of whether or not they are `\"data\"` or `\"status\"` events. This is a convenience method for when you do not want to unsubscribe use the `off` method.\n\n```js\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst handle_data = (data) => console.log(data);\n\nconst submission = app.submit(\"/predict\", payload).on(\"data\", handle_data);\n\n// later\nsubmission.destroy();\n```\n\n##### `cancel`\n\nCertain types of gradio function can run repeatedly and in some cases indefinitely. the `cancel` method will stop such an endpoints and prevent the API from issuing additional updates.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst submission = app\n\t.submit(\"/predict\", payload)\n\t.on(\"data\", (data) => console.log(data));\n\n// later\n\nsubmission.cancel();\n```\n\n#### `view_api`\n\nThe `view_api` method provides details about the API you are connected to. It returns a JavaScript object of all named endpoints, unnamed endpoints and what values they accept and return. This method does not accept arguments.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconst api_info = await app.view_api();\n\nconsole.log(api_info);\n```\n\n#### `config`\n\nThe `config` property contains the configuration for the gradio application you are connected to. This object may contain useful meta information about the application.\n\n```ts\nimport { client } from \"@gradio/client\";\n\nconst app = await client(\"user/space-name\");\nconsole.log(app.config);\n```\n\n### `duplicate`\n\nThe duplicate function will attempt to duplicate the space that is referenced and return an instance of `client` connected to that space. If the space has already been duplicated then it will not create a new duplicate and will instead connect to the existing duplicated space. The huggingface token that is passed in will dictate the user under which the space is created.\n\n`duplicate` accepts the same arguments as `client` with the addition of a `private` options property dictating whether the duplicated space should be private or public. A huggingface token is required for duplication to work.\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\"\n});\n```\n\nThis function accepts two arguments: `source` and `options`:\n\n#### `source`\n\nThe space to duplicate and connect to. [See `client`'s `source` parameter](#source).\n\n#### `options`\n\nAccepts all options that `client` accepts, except `hf_token` is required. [See `client`'s `options` parameter](#source).\n\n`duplicate` also accepts one additional `options` property.\n\n##### `private`\n\nThis is an optional property specific to `duplicate`'s options object and will determine whether the space should be public or private. Spaces duplicated via the `duplicate` method are public by default.\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true\n});\n```\n\n##### `timeout`\n\nThis is an optional property specific to `duplicate`'s options object and will set the timeout in minutes before the duplicated space will go to sleep.\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true,\n\ttimeout: 5\n});\n```\n\n##### `hardware`\n\nThis is an optional property specific to `duplicate`'s options object and will set the hardware for the duplicated space. By default the hardware used will match that of the original space. If this cannot be obtained it will default to `\"cpu-basic\"`. For hardware upgrades (beyond the basic CPU tier), you may be required to provide [billing information on Hugging Face](https://huggingface.co/settings/billing).\n\nPossible hardware options are:\n\n- `\"cpu-basic\"`\n- `\"cpu-upgrade\"`\n- `\"t4-small\"`\n- `\"t4-medium\"`\n- `\"a10g-small\"`\n- `\"a10g-large\"`\n- `\"a100-large\"`\n\n```ts\nimport { duplicate } from \"@gradio/client\";\n\nconst app = await duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true,\n\thardware: \"a10g-small\"\n});\n```\n",url_version:"4.16.0"}}({},{},{},{},{})),"uses":{"params":["version"]}},{"type":"data","data":(function(a){a.class=null;a.name="Progress";a.description="The Progress class provides a custom progress tracker that is used in a function signature. To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a \u003Ccode class='text-orange-500' style='font-family: monospace; font-size: large;'>gradio.Progress()\u003C/code> instance. The Progress tracker can then be updated in the function by calling the Progress object or using the \u003Ccode class='text-orange-500' style='font-family: monospace; font-size: large;'>tqdm\u003C/code> method on an Iterable. The Progress tracker is currently only available with \u003Ccode class='text-orange-500' style='font-family: monospace; font-size: large;'>queue()\u003C/code>.";a.tags={demos:"progress"};a.parameters=[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"track_tqdm",annotation:"bool",doc:"If True, the Progress object will track any tqdm.tqdm iterations with the tqdm library in the function.",default:"False"}];a.returns={annotation:null};a.example="import gradio as gr\nimport time\ndef my_function(x, progress=gr.Progress()):\n    progress(0, desc=\"Starting...\")\n    time.sleep(1)\n    for i in progress.tqdm(range(100)):\n        time.sleep(0.1)\n    return x\ngr.Interface(my_function, gr.Textbox(), gr.Textbox()).queue().launch()";a.fns=[{fn:null,name:"__call__",description:"Updates progress tracker with progress and message text.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"progress",annotation:"float | tuple[int, int | None] | None",doc:"If float, should be between 0 and 1 representing completion. If Tuple, first number represents steps completed, and second value represents total steps or None if unknown. If None, hides progress bar."},{name:"desc",annotation:"str | None",doc:"description to display.",default:"None"},{name:"total",annotation:"int | None",doc:"estimated total number of steps.",default:"None"},{name:"unit",annotation:"str",doc:"unit of iterations.",default:"\"steps\""}],returns:{},example:null,override_signature:null,parent:"gradio.Progress",slug:"progress-call"},{fn:null,name:"tqdm",description:"Attaches progress tracker to iterable, like tqdm.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"iterable",annotation:"Iterable | None",doc:"iterable to attach progress tracker to."},{name:"desc",annotation:"str | None",doc:"description to display.",default:"None"},{name:"total",annotation:"int | None",doc:"estimated total number of steps.",default:"None"},{name:"unit",annotation:"str",doc:"unit of iterations.",default:"\"steps\""}],returns:{},example:null,override_signature:null,parent:"gradio.Progress",slug:"progress-tqdm"}];a.demos=[["progress","import gradio as gr\nimport random\nimport time\nimport tqdm\nfrom datasets import load_dataset\nimport shutil\nfrom uuid import uuid4\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text = gr.Textbox()\n        textb = gr.Textbox()\n    with gr.Row():\n        load_set_btn = gr.Button(\"Load Set\")\n        load_nested_set_btn = gr.Button(\"Load Nested Set\")\n        load_random_btn = gr.Button(\"Load Random\")\n        clean_imgs_btn = gr.Button(\"Clean Images\")\n        wait_btn = gr.Button(\"Wait\")\n        do_all_btn = gr.Button(\"Do All\")\n        track_tqdm_btn = gr.Button(\"Bind TQDM\")\n        bind_internal_tqdm_btn = gr.Button(\"Bind Internal TQDM\")\n\n    text2 = gr.Textbox()\n\n    # track list\n    def load_set(text, text2, progress=gr.Progress()):\n        imgs = [None] * 24\n        for img in progress.tqdm(imgs, desc=\"Loading from list\"):\n            time.sleep(0.1)\n        return \"done\"\n    load_set_btn.click(load_set, [text, textb], text2)\n\n    # track nested list\n    def load_nested_set(text, text2, progress=gr.Progress()):\n        imgs = [[None] * 8] * 3\n        for img_set in progress.tqdm(imgs, desc=\"Nested list\"):\n            time.sleep(2)\n            for img in progress.tqdm(img_set, desc=\"inner list\"):\n                time.sleep(0.1)\n        return \"done\"\n    load_nested_set_btn.click(load_nested_set, [text, textb], text2)\n\n    # track iterable of unknown length\n    def load_random(data, progress=gr.Progress()):\n        def yielder():\n            for i in range(0, random.randint(15, 20)):\n                time.sleep(0.1)\n                yield None\n        for img in progress.tqdm(yielder()):\n            pass\n        return \"done\"\n    load_random_btn.click(load_random, {text, textb}, text2)\n        \n    # manual progress\n    def clean_imgs(text, progress=gr.Progress()):\n        progress(0.2, desc=\"Collecting Images\")\n        time.sleep(1)\n        progress(0.5, desc=\"Cleaning Images\")\n        time.sleep(1.5)\n        progress(0.8, desc=\"Sending Images\")\n        time.sleep(1.5)\n        return \"done\"\n    clean_imgs_btn.click(clean_imgs, text, text2)\n\n    # no progress\n    def wait(text):\n        time.sleep(4)\n        return \"done\"\n    wait_btn.click(wait, text, text2)\n\n    # multiple progressions\n    def do_all(data, progress=gr.Progress()):\n        load_set(data[text], data[textb], progress)\n        load_random(data, progress)\n        clean_imgs(data[text], progress)\n        progress(None)\n        wait(text)\n        return \"done\"\n    do_all_btn.click(do_all, {text, textb}, text2)\n\n    def track_tqdm(data, progress=gr.Progress(track_tqdm=True)):\n        for i in tqdm.tqdm(range(5), desc=\"outer\"):\n            for j in tqdm.tqdm(range(4), desc=\"inner\"):\n                time.sleep(1)\n        return \"done\"\n    track_tqdm_btn.click(track_tqdm, {text, textb}, text2)\n\n    def bind_internal_tqdm(data, progress=gr.Progress(track_tqdm=True)):\n        outdir = \"__tmp/\" + str(uuid4())\n        load_dataset(\"beans\", split=\"train\", cache_dir=outdir)\n        shutil.rmtree(outdir)\n        return \"done\"\n    bind_internal_tqdm_btn.click(bind_internal_tqdm, {text, textb}, text2)\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n","\u003Cspan class=\"token keyword\">import\u003C/span> gradio \u003Cspan class=\"token keyword\">as\u003C/span> gr\n\u003Cspan class=\"token keyword\">import\u003C/span> random\n\u003Cspan class=\"token keyword\">import\u003C/span> time\n\u003Cspan class=\"token keyword\">import\u003C/span> tqdm\n\u003Cspan class=\"token keyword\">from\u003C/span> datasets \u003Cspan class=\"token keyword\">import\u003C/span> load_dataset\n\u003Cspan class=\"token keyword\">import\u003C/span> shutil\n\u003Cspan class=\"token keyword\">from\u003C/span> uuid \u003Cspan class=\"token keyword\">import\u003C/span> uuid4\n\n\u003Cspan class=\"token keyword\">with\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Blocks\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span> \u003Cspan class=\"token keyword\">as\u003C/span> demo\u003Cspan class=\"token punctuation\">:\u003C/span>\n    \u003Cspan class=\"token keyword\">with\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Row\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        text \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        textb \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    \u003Cspan class=\"token keyword\">with\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Row\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        load_set_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Load Set\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_nested_set_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Load Nested Set\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_random_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Load Random\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        clean_imgs_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Clean Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        wait_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Wait\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        do_all_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Do All\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        track_tqdm_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Bind TQDM\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        bind_internal_tqdm_btn \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Button\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"Bind Internal TQDM\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    text2 \u003Cspan class=\"token operator\">=\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># track list\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">load_set\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        imgs \u003Cspan class=\"token operator\">=\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>\u003Cspan class=\"token boolean\">None\u003C/span>\u003Cspan class=\"token punctuation\">]\u003C/span> \u003Cspan class=\"token operator\">*\u003C/span> \u003Cspan class=\"token number\">24\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> img \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>imgs\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Loading from list\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    load_set_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>load_set\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># track nested list\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">load_nested_set\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        imgs \u003Cspan class=\"token operator\">=\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>\u003Cspan class=\"token punctuation\">[\u003C/span>\u003Cspan class=\"token boolean\">None\u003C/span>\u003Cspan class=\"token punctuation\">]\u003C/span> \u003Cspan class=\"token operator\">*\u003C/span> \u003Cspan class=\"token number\">8\u003C/span>\u003Cspan class=\"token punctuation\">]\u003C/span> \u003Cspan class=\"token operator\">*\u003C/span> \u003Cspan class=\"token number\">3\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> img_set \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>imgs\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Nested list\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">2\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n            \u003Cspan class=\"token keyword\">for\u003C/span> img \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>img_set\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"inner list\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n                time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    load_nested_set_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>load_nested_set\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># track iterable of unknown length\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">load_random\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">yielder\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            \u003Cspan class=\"token keyword\">for\u003C/span> i \u003Cspan class=\"token keyword\">in\u003C/span> \u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> random\u003Cspan class=\"token punctuation\">.\u003C/span>randint\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">15\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token number\">20\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n                time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n                \u003Cspan class=\"token keyword\">yield\u003C/span> \u003Cspan class=\"token boolean\">None\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> img \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>yielder\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            \u003Cspan class=\"token keyword\">pass\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    load_random_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>load_random\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \n    \u003Cspan class=\"token comment\"># manual progress\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">clean_imgs\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.2\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Collecting Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.5\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Cleaning Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1.5\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.8\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Sending Images\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1.5\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    clean_imgs_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>clean_imgs\u003Cspan class=\"token punctuation\">,\u003C/span> text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># no progress\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">wait\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">4\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    wait_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>wait\u003Cspan class=\"token punctuation\">,\u003C/span> text\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token comment\"># multiple progressions\u003C/span>\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">do_all\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        load_set\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> data\u003Cspan class=\"token punctuation\">[\u003C/span>textb\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_random\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token punctuation\">)\u003C/span>\n        clean_imgs\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">[\u003C/span>text\u003Cspan class=\"token punctuation\">]\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token punctuation\">)\u003C/span>\n        progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token boolean\">None\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        wait\u003Cspan class=\"token punctuation\">(\u003C/span>text\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    do_all_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>do_all\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">track_tqdm\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>track_tqdm\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token boolean\">True\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        \u003Cspan class=\"token keyword\">for\u003C/span> i \u003Cspan class=\"token keyword\">in\u003C/span> tqdm\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">5\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"outer\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n            \u003Cspan class=\"token keyword\">for\u003C/span> j \u003Cspan class=\"token keyword\">in\u003C/span> tqdm\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">4\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"inner\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n                time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    track_tqdm_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>track_tqdm\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n    \u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">bind_internal_tqdm\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>data\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>track_tqdm\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token boolean\">True\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        outdir \u003Cspan class=\"token operator\">=\u003C/span> \u003Cspan class=\"token string\">\"__tmp/\"\u003C/span> \u003Cspan class=\"token operator\">+\u003C/span> \u003Cspan class=\"token builtin\">str\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>uuid4\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n        load_dataset\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token string\">\"beans\"\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> split\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"train\"\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> cache_dir\u003Cspan class=\"token operator\">=\u003C/span>outdir\u003Cspan class=\"token punctuation\">)\u003C/span>\n        shutil\u003Cspan class=\"token punctuation\">.\u003C/span>rmtree\u003Cspan class=\"token punctuation\">(\u003C/span>outdir\u003Cspan class=\"token punctuation\">)\u003C/span>\n        \u003Cspan class=\"token keyword\">return\u003C/span> \u003Cspan class=\"token string\">\"done\"\u003C/span>\n    bind_internal_tqdm_btn\u003Cspan class=\"token punctuation\">.\u003C/span>click\u003Cspan class=\"token punctuation\">(\u003C/span>bind_internal_tqdm\u003Cspan class=\"token punctuation\">,\u003C/span> \u003Cspan class=\"token punctuation\">{\u003C/span>text\u003Cspan class=\"token punctuation\">,\u003C/span> textb\u003Cspan class=\"token punctuation\">}\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> text2\u003Cspan class=\"token punctuation\">)\u003C/span>\n\n\n\u003Cspan class=\"token keyword\">if\u003C/span> __name__ \u003Cspan class=\"token operator\">==\u003C/span> \u003Cspan class=\"token string\">\"__main__\"\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n    demo\u003Cspan class=\"token punctuation\">.\u003C/span>launch\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n"]];a.parent="gradio";a.prev_obj="Examples";a.next_obj="make_waveform";a.slug="progress";a.highlighted_example="\u003Cspan class=\"token keyword\">import\u003C/span> gradio \u003Cspan class=\"token keyword\">as\u003C/span> gr\n\u003Cspan class=\"token keyword\">import\u003C/span> time\n\u003Cspan class=\"token keyword\">def\u003C/span> \u003Cspan class=\"token function\">my_function\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>x\u003Cspan class=\"token punctuation\">,\u003C/span> progress\u003Cspan class=\"token operator\">=\u003C/span>gr\u003Cspan class=\"token punctuation\">.\u003C/span>Progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n    progress\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> desc\u003Cspan class=\"token operator\">=\u003C/span>\u003Cspan class=\"token string\">\"Starting...\"\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    \u003Cspan class=\"token keyword\">for\u003C/span> i \u003Cspan class=\"token keyword\">in\u003C/span> progress\u003Cspan class=\"token punctuation\">.\u003C/span>tqdm\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token builtin\">range\u003C/span>\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">100\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">:\u003C/span>\n        time\u003Cspan class=\"token punctuation\">.\u003C/span>sleep\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token number\">0.1\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\n    \u003Cspan class=\"token keyword\">return\u003C/span> x\ngr\u003Cspan class=\"token punctuation\">.\u003C/span>Interface\u003Cspan class=\"token punctuation\">(\u003C/span>my_function\u003Cspan class=\"token punctuation\">,\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">,\u003C/span> gr\u003Cspan class=\"token punctuation\">.\u003C/span>Textbox\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">.\u003C/span>queue\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>\u003Cspan class=\"token punctuation\">.\u003C/span>launch\u003Cspan class=\"token punctuation\">(\u003C/span>\u003Cspan class=\"token punctuation\">)\u003C/span>";return {name:"progress",obj:a,mode:"helpers",components:{annotatedimage:{class:null,name:"AnnotatedImage",description:"Displays a base image and colored subsections on top of that image. Subsections can take the from of rectangles (e.g. object detection) or masks (e.g. image segmentation). \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a {Tuple[numpy.ndarray | PIL.Image | str, List[Tuple[numpy.ndarray | Tuple[int, int, int, int], str]]]} consisting of a base image and a list of subsections, that are either (x1, y1, x2, y2) tuples identifying object boundaries, or 0-1 confidence masks of the same shape as the image. A label is provided for each subsection.",demos:"image_segmentation"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"tuple[np.ndarray | _Image.Image | str, list[tuple[np.ndarray | tuple[int, int, int, int], str]]] | None",doc:"Tuple of base image and list of (subsection, label) pairs.",default:"None"},{name:"show_legend",annotation:"bool",doc:"If True, will show a legend of the subsections.",default:"True"},{name:"height",annotation:"int | str | None",doc:"The height of the image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"color_map",annotation:"dict[str, str] | None",doc:"A dictionary mapping labels to colors. The colors must be specified as hex codes.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the AnnotatedImage. Uses event data gradio.SelectData to carry `value` referring to the label of the AnnotatedImage, and `selected` to refer to state of the AnnotatedImage. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.AnnotatedImage",slug:"annotated-image-select"}],string_shortcuts:[["AnnotatedImage","annotatedimage","Uses default values"]],demos:[["image_segmentation","import gradio as gr\nimport numpy as np\nimport random\n\nwith gr.Blocks() as demo:\n    section_labels = [\n        \"apple\",\n        \"banana\",\n        \"carrot\",\n        \"donut\",\n        \"eggplant\",\n        \"fish\",\n        \"grapes\",\n        \"hamburger\",\n        \"ice cream\",\n        \"juice\",\n    ]\n\n    with gr.Row():\n        num_boxes = gr.Slider(0, 5, 2, step=1, label=\"Number of boxes\")\n        num_segments = gr.Slider(0, 5, 1, step=1, label=\"Number of segments\")\n\n    with gr.Row():\n        img_input = gr.Image()\n        img_output = gr.AnnotatedImage(\n            color_map={\"banana\": \"#a89a00\", \"carrot\": \"#ffae00\"}\n        )\n\n    section_btn = gr.Button(\"Identify Sections\")\n    selected_section = gr.Textbox(label=\"Selected Section\")\n\n    def section(img, num_boxes, num_segments):\n        sections = []\n        for a in range(num_boxes):\n            x = random.randint(0, img.shape[1])\n            y = random.randint(0, img.shape[0])\n            w = random.randint(0, img.shape[1] - x)\n            h = random.randint(0, img.shape[0] - y)\n            sections.append(((x, y, x + w, y + h), section_labels[a]))\n        for b in range(num_segments):\n            x = random.randint(0, img.shape[1])\n            y = random.randint(0, img.shape[0])\n            r = random.randint(0, min(x, y, img.shape[1] - x, img.shape[0] - y))\n            mask = np.zeros(img.shape[:2])\n            for i in range(img.shape[0]):\n                for j in range(img.shape[1]):\n                    dist_square = (i - y) ** 2 + (j - x) ** 2\n                    if dist_square \u003C r**2:\n                        mask[i, j] = round((r**2 - dist_square) / r**2 * 4) / 4\n            sections.append((mask, section_labels[b + num_boxes]))\n        return (img, sections)\n\n    section_btn.click(section, [img_input, num_boxes, num_segments], img_output)\n\n    def select_section(evt: gr.SelectData):\n        return section_labels[evt.index]\n\n    img_output.select(select_section, None, selected_section)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Components",next_obj:"Audio",slug:"annotated-image"},audio:{class:null,name:"Audio",description:"Creates an audio component that can be used to upload/record audio (as an input) or display audio (as an output).",tags:{preprocessing:"depending on `type`, passes the uploaded audio as {str} filepath or a {Tuple(int, numpy.array)} corresponding to (sample rate in Hz, audio data). If the latter, the audio data is a 16-bit int array whose values range from -32768 to 32767 and shape of the audio data array is (samples,) for mono audio or (samples, channels) for multi-channel audio.",postprocessing:"expects a {Tuple(int, numpy.array)} corresponding to (sample rate in Hz, audio data as a float or int numpy array) or as a {str} or {pathlib.Path} filepath or URL to an audio file, or bytes for binary content (recommended for streaming). Note: When converting audio data from float format to WAV, the audio is normalized by its peak value to avoid distortion or clipping in the resulting audio.","examples-format":"a {str} filepath to a local file that contains audio.",demos:"main_note, generate_tone, reverse_audio",guides:"real-time-speech-recognition"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Path | tuple[int, np.ndarray] | Callable | None",doc:"A path, URL, or [sample_rate, numpy array] tuple (sample rate in Hz, audio data as a float or int numpy array) for the default value that Audio component is going to take. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"sources",annotation:"list[Literal[('upload', 'microphone')]] | None",doc:"A list of sources permitted for audio. &quot;upload&quot; creates a box where user can drop an audio file, &quot;microphone&quot; creates a microphone input. The first element in the list will be used as the default source. If None, defaults to [&quot;upload&quot;, &quot;microphone&quot;], or [&quot;microphone&quot;] if `streaming` is True.",default:"None"},{name:"type",annotation:"Literal[('numpy', 'filepath')]",doc:"The format the audio file is converted to before being passed into the prediction function. &quot;numpy&quot; converts the audio to a tuple consisting of: (int sample rate, numpy.array for the data), &quot;filepath&quot; passes a str path to a temporary file containing the audio.",default:"\"numpy\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"If True, will allow users to upload and edit an audio file. If False, can only be used to play audio. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"streaming",annotation:"bool",doc:"If set to True when used in a `live` interface as an input, will automatically stream webcam feed. When used set as an output, takes audio chunks yield from the backend and combines them into one streaming audio output.",default:"False"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"format",annotation:"Literal[('wav', 'mp3')]",doc:"The file format to save audio files. Either &#x27;wav&#x27; or &#x27;mp3&#x27;. wav files are lossless but will tend to be larger files. mp3 files tend to be smaller. Default is wav. Applies both when this component is used as an input (when `type` is &quot;format&quot;) and when this component is used as an output.",default:"\"wav\""},{name:"autoplay",annotation:"bool",doc:"Whether to automatically play the audio when the component is used as an output. Note: browsers will not autoplay audio files if the user has not interacted with the page yet.",default:"False"},{name:"show_download_button",annotation:"bool | None",doc:"If True, will show a download button in the corner of the component for saving audio. If False, icon does not appear. By default, it will be True for output components and False for input components.",default:"None"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"editable",annotation:"bool",doc:"If True, allows users to manipulate the audio file if the component is interactive. Defaults to True.",default:"True"},{name:"min_length",annotation:"int | None",doc:"The minimum length of audio (in seconds) that the user can pass into the prediction function. If None, there is no minimum length.",default:"None"},{name:"max_length",annotation:"int | None",doc:"The maximum length of audio (in seconds) that the user can pass into the prediction function. If None, there is no maximum length.",default:"None"},{name:"waveform_options",annotation:"WaveformOptions | dict | None",doc:"A dictionary of options for the waveform display. Options include: waveform_color (str), waveform_progress_color (str), show_controls (bool), skip_length (int). Default is None, which uses the default values for these options.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"stream",description:"This listener is triggered when the user streams the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"hidden\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-stream"},{fn:null,name:"change",description:"Triggered when the value of the Audio changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Audio using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-clear"},{fn:null,name:"play",description:"This listener is triggered when the user plays the media in the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-play"},{fn:null,name:"pause",description:"This listener is triggered when the media in the Audio stops for any reason.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-pause"},{fn:null,name:"stop",description:"This listener is triggered when the user reaches the end of the media playing in the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-stop"},{fn:null,name:"pause",description:"This listener is triggered when the media in the Audio stops for any reason.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-pause-2"},{fn:null,name:"start_recording",description:"This listener is triggered when the user starts recording with the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-start-recording"},{fn:null,name:"pause_recording",description:"This listener is triggered when the user pauses recording with the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-pause-recording"},{fn:null,name:"stop_recording",description:"This listener is triggered when the user stops recording with the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-stop-recording"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Audio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Audio",slug:"audio-upload"}],string_shortcuts:[["Audio","audio","Uses default values"],["Microphone","microphone","Uses sources=[\"microphone\"]"]],demos:[["main_note","from math import log2, pow\nimport os\n\nimport numpy as np\nfrom scipy.fftpack import fft\n\nimport gradio as gr\n\nA4 = 440\nC0 = A4 * pow(2, -4.75)\nname = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\n\ndef get_pitch(freq):\n    h = round(12 * log2(freq / C0))\n    n = h % 12\n    return name[n]\n\n\ndef main_note(audio):\n    rate, y = audio\n    if len(y.shape) == 2:\n        y = y.T[0]\n    N = len(y)\n    T = 1.0 / rate\n    yf = fft(y)\n    yf2 = 2.0 / N * np.abs(yf[0 : N // 2])\n    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n\n    volume_per_pitch = {}\n    total_volume = np.sum(yf2)\n    for freq, volume in zip(xf, yf2):\n        if freq == 0:\n            continue\n        pitch = get_pitch(freq)\n        if pitch not in volume_per_pitch:\n            volume_per_pitch[pitch] = 0\n        volume_per_pitch[pitch] += 1.0 * volume / total_volume\n    volume_per_pitch = {k: float(v) for k, v in volume_per_pitch.items()}\n    return volume_per_pitch\n\n\ndemo = gr.Interface(\n    main_note,\n    gr.Audio(sources=[\"microphone\"]),\n    gr.Label(num_top_classes=4),\n    examples=[\n        [os.path.join(os.path.dirname(__file__),\"audio/recording1.wav\")],\n        [os.path.join(os.path.dirname(__file__),\"audio/cantina.wav\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["generate_tone","import numpy as np\nimport gradio as gr\n\nnotes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\ndef generate_tone(note, octave, duration):\n    sr = 48000\n    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n    duration = int(duration)\n    audio = np.linspace(0, duration, duration * sr)\n    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n    return sr, audio\n\ndemo = gr.Interface(\n    generate_tone,\n    [\n        gr.Dropdown(notes, type=\"index\"),\n        gr.Slider(4, 6, step=1),\n        gr.Textbox(value=1, label=\"Duration in seconds\"),\n    ],\n    \"audio\",\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["reverse_audio","import os\n\nimport numpy as np\n\nimport gradio as gr\n\n\ndef reverse_audio(audio):\n    sr, data = audio\n    return (sr, np.flipud(data))\n\n\ninput_audio = gr.Audio(\n    sources=[\"microphone\"],\n    waveform_options=gr.WaveformOptions(\n        waveform_color=\"#01C6FF\",\n        waveform_progress_color=\"#0066B4\",\n        skip_length=2,\n        show_controls=False,\n    ),\n)\ndemo = gr.Interface(\n    fn=reverse_audio,\n    inputs=input_audio,\n    outputs=\"audio\",\n    examples=[\n        \"https://samplelib.com/lib/preview/mp3/sample-3s.mp3\",\n        os.path.join(os.path.dirname(__file__), \"audio/recording1.wav\"),\n    ],\n    cache_examples=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"real-time-speech-recognition",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:49,pretty_name:"Real Time Speech Recognition",content:"# Real Time Speech Recognition\n\n\n\n## Introduction\n\nAutomatic speech recognition (ASR), the conversion of spoken speech to text, is a very important and thriving area of machine learning. ASR algorithms run on practically every smartphone, and are becoming increasingly embedded in professional workflows, such as digital assistants for nurses and doctors. Because ASR algorithms are designed to be used directly by customers and end users, it is important to validate that they are behaving as expected when confronted with a wide variety of speech patterns (different accents, pitches, and background audio conditions).\n\nUsing `gradio`, you can easily build a demo of your ASR model and share that with a testing team, or test it yourself by speaking through the microphone on your device.\n\nThis tutorial will show how to take a pretrained speech-to-text model and deploy it with a Gradio interface. We will start with a **_full-context_** model, in which the user speaks the entire audio before the prediction runs. Then we will adapt the demo to make it **_streaming_**, meaning that the audio model will convert speech as you speak. \n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained speech recognition model. In this tutorial, we will build demos from 2 ASR libraries:\n\n- Transformers (for this, `pip install transformers` and `pip install torch`)\n\nMake sure you have at least one of these installed so that you can follow along the tutorial. You will also need `ffmpeg` [installed on your system](https://www.ffmpeg.org/download.html), if you do not already have it, to process files from the microphone.\n\nHere's how to build a real time speech recognition (ASR) app:\n\n1. [Set up the Transformers ASR Model](#1-set-up-the-transformers-asr-model)\n2. [Create a Full-Context ASR Demo with Transformers](#2-create-a-full-context-asr-demo-with-transformers)\n3. [Create a Streaming ASR Demo with Transformers](#3-create-a-streaming-asr-demo-with-transformers)\n\n## 1. Set up the Transformers ASR Model\n\nFirst, you will need to have an ASR model that you have either trained yourself or you will need to download a pretrained model. In this tutorial, we will start by using a pretrained ASR model from the model, `whisper`.\n\nHere is the code to load `whisper` from Hugging Face `transformers`.\n\n```python\nfrom transformers import pipeline\n\np = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n```\n\nThat's it!\n\n## 2. Create a Full-Context ASR Demo with Transformers\n\nWe will start by creating a _full-context_ ASR demo, in which the user speaks the full audio before using the ASR model to run inference. This is very easy with Gradio -- we simply create a function around the `pipeline` object above.\n\nWe will use `gradio`'s built in `Audio` component, configured to take input from the user's microphone and return a filepath for the recorded audio. The output component will be a plain `Textbox`.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(audio):\n    sr, y = audio\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    gr.Audio(sources=[\"microphone\"]),\n    \"text\",\n)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/asr'>\u003C/gradio-app>\n\nThe `transcribe` function takes a single parameter, `audio`, which is a numpy array of the audio the user recorded. The `pipeline` object expects this in float32 format, so we convert it first to float32, and then extract the transcribed text.\n\n## 3. Create a Streaming ASR Demo with Transformers\n\nTo make this a *streaming* demo, we need to make these changes:\n\n1. Set `streaming=True` in the `Audio` component\n2. Set `live=True` in the `Interface`\n3. Add a `state` to the interface to store the recorded audio of a user\n\nTake a look below.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(stream, new_chunk):\n    sr, y = new_chunk\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    if stream is not None:\n        stream = np.concatenate([stream, y])\n    else:\n        stream = y\n    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n    [\"state\", \"text\"],\n    live=True,\n)\n\ndemo.launch()\n\n```\n\nNotice now we have a state variable now, because we need to track all the audio history. `transcribe` gets called whenever there is a new small chunk of audio, but we also need to keep track of all the audio that has been spoken so far in state. \nAs the interface runs, the `transcribe` function gets called, with a record of all the previously spoken audio in `stream`, as well as the new chunk of audio as `new_chunk`. We return the new full audio so that can be stored back in state, and we also return the transcription.\nHere we naively append the audio together and simply call the `transcriber` object on the entire audio. You can imagine more efficient ways of handling this, such as re-processing only the last 5 seconds of audio whenever a new chunk of audio received. \n\n\u003Cgradio-app space='gradio/stream_asr'>\u003C/gradio-app>\n\nNow the ASR model will run inference as you speak! ",tags:["ASR","SPEECH","STREAMING"],spaces:[],url:"/guides/real-time-speech-recognition/",contributor:null}],parent:"gradio",prev_obj:"AnnotatedImage",next_obj:"BarPlot",slug:"audio"},barplot:{class:null,name:"BarPlot",description:"Create a bar plot. \u003Cbr> \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a pandas dataframe with the data to plot.",demos:"bar_plot, chicago-bikeshare-dashboard"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Callable | None",doc:"The pandas dataframe containing the data to display in a scatter plot.",default:"None"},{name:"x",annotation:"str | None",doc:"Column corresponding to the x axis.",default:"None"},{name:"y",annotation:"str | None",doc:"Column corresponding to the y axis.",default:"None"},{name:"color",annotation:"str | None",doc:"The column to determine the bar color. Must be categorical (discrete values).",default:"None"},{name:"vertical",annotation:"bool",doc:"If True, the bars will be displayed vertically. If False, the x and y axis will be switched, displaying the bars horizontally. Default is True.",default:"True"},{name:"group",annotation:"str | None",doc:"The column with which to split the overall plot into smaller subplots.",default:"None"},{name:"title",annotation:"str | None",doc:"The title to display on top of the chart.",default:"None"},{name:"tooltip",annotation:"list[str] | str | None",doc:"The column (or list of columns) to display on the tooltip when a user hovers over a bar.",default:"None"},{name:"x_title",annotation:"str | None",doc:"The title given to the x axis. By default, uses the value of the x parameter.",default:"None"},{name:"y_title",annotation:"str | None",doc:"The title given to the y axis. By default, uses the value of the y parameter.",default:"None"},{name:"x_label_angle",annotation:"float | None",doc:"The angle (in degrees) of the x axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"y_label_angle",annotation:"float | None",doc:"The angle (in degrees) of the y axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"color_legend_title",annotation:"str | None",doc:"The title given to the color legend. By default, uses the value of color parameter.",default:"None"},{name:"group_title",annotation:"str | None",doc:"The label displayed on top of the subplot columns (or rows if vertical=True). Use an empty string to omit.",default:"None"},{name:"color_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the color legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"y_lim",annotation:"list[int] | None",doc:"A tuple of list containing the limits for the y-axis, specified as [y_min, y_max].",default:"None"},{name:"caption",annotation:"str | None",doc:"The (optional) caption to display below the plot.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether users should be able to interact with the plot by panning or zooming with their mouse or trackpad.",default:"True"},{name:"label",annotation:"str | None",doc:"The (optional) label to display on the top left corner of the plot.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"Whether the label should be displayed.",default:"None"},{name:"container",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"None"},{name:"min_width",annotation:"int",doc:null,default:"160"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"visible",annotation:"bool",doc:"Whether the plot should be visible.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"sort",annotation:"Literal[('x', 'y', '-x', '-y')] | None",doc:"Specifies the sorting axis as either &quot;x&quot;, &quot;y&quot;, &quot;-x&quot; or &quot;-y&quot;. If None, no sorting is applied.",default:"None"},{name:"show_actions_button",annotation:"bool",doc:"Whether to show the actions button on the top right corner of the plot.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.BarPlot",slug:"bar-plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.BarPlot",slug:"bar-plot-clear"}],string_shortcuts:[["BarPlot","barplot","Uses default values"]],demos:[["bar_plot","import gradio as gr\nimport pandas as pd\nimport random\n\nsimple = pd.DataFrame(\n    {\n        \"a\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"],\n        \"b\": [28, 55, 43, 91, 81, 53, 19, 87, 52],\n    }\n)\n\nfake_barley = pd.DataFrame(\n    {\n        \"site\": [\n            random.choice(\n                [\n                    \"University Farm\",\n                    \"Waseca\",\n                    \"Morris\",\n                    \"Crookston\",\n                    \"Grand Rapids\",\n                    \"Duluth\",\n                ]\n            )\n            for _ in range(120)\n        ],\n        \"yield\": [random.randint(25, 75) for _ in range(120)],\n        \"variety\": [\n            random.choice(\n                [\n                    \"Manchuria\",\n                    \"Wisconsin No. 38\",\n                    \"Glabron\",\n                    \"No. 457\",\n                    \"No. 462\",\n                    \"No. 475\",\n                ]\n            )\n            for _ in range(120)\n        ],\n        \"year\": [\n            random.choice(\n                [\n                    \"1931\",\n                    \"1932\",\n                ]\n            )\n            for _ in range(120)\n        ],\n    }\n)\n\n\ndef bar_plot_fn(display):\n    if display == \"simple\":\n        return gr.BarPlot(\n            simple,\n            x=\"a\",\n            y=\"b\",\n            title=\"Simple Bar Plot with made up data\",\n            tooltip=[\"a\", \"b\"],\n            y_lim=[20, 100],\n        )\n    elif display == \"stacked\":\n        return gr.BarPlot(\n            fake_barley,\n            x=\"variety\",\n            y=\"yield\",\n            color=\"site\",\n            title=\"Barley Yield Data\",\n            tooltip=[\"variety\", \"site\"],\n        )\n    elif display == \"grouped\":\n        return gr.BarPlot(\n            fake_barley.astype({\"year\": str}),\n            x=\"year\",\n            y=\"yield\",\n            color=\"year\",\n            group=\"site\",\n            title=\"Barley Yield by Year and Site\",\n            group_title=\"\",\n            tooltip=[\"yield\", \"site\", \"year\"],\n        )\n    elif display == \"simple-horizontal\":\n        return gr.BarPlot(\n            simple,\n            x=\"a\",\n            y=\"b\",\n            x_title=\"Variable A\",\n            y_title=\"Variable B\",\n            title=\"Simple Bar Plot with made up data\",\n            tooltip=[\"a\", \"b\"],\n            vertical=False,\n            y_lim=[20, 100],\n        )\n    elif display == \"stacked-horizontal\":\n        return gr.BarPlot(\n            fake_barley,\n            x=\"variety\",\n            y=\"yield\",\n            color=\"site\",\n            title=\"Barley Yield Data\",\n            vertical=False,\n            tooltip=[\"variety\", \"site\"],\n        )\n    elif display == \"grouped-horizontal\":\n        return gr.BarPlot(\n            fake_barley.astype({\"year\": str}),\n            x=\"year\",\n            y=\"yield\",\n            color=\"year\",\n            group=\"site\",\n            title=\"Barley Yield by Year and Site\",\n            group_title=\"\",\n            tooltip=[\"yield\", \"site\", \"year\"],\n            vertical=False,\n        )\n\n\nwith gr.Blocks() as bar_plot:\n    with gr.Row():\n        with gr.Column():\n            display = gr.Dropdown(\n                choices=[\n                    \"simple\",\n                    \"stacked\",\n                    \"grouped\",\n                    \"simple-horizontal\",\n                    \"stacked-horizontal\",\n                    \"grouped-horizontal\",\n                ],\n                value=\"simple\",\n                label=\"Type of Bar Plot\",\n            )\n        with gr.Column():\n            plot = gr.BarPlot()\n    display.change(bar_plot_fn, inputs=display, outputs=plot)\n    bar_plot.load(fn=bar_plot_fn, inputs=display, outputs=plot)\n\nbar_plot.launch()\n"],["chicago-bikeshare-dashboard","import os\nimport gradio as gr\nimport pandas as pd\n\nDB_USER = os.getenv(\"DB_USER\")\nDB_PASSWORD = os.getenv(\"DB_PASSWORD\")\nDB_HOST = os.getenv(\"DB_HOST\")\nPORT = 8080\nDB_NAME = \"bikeshare\"\n\nconnection_string = (\n    f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}?port={PORT}&dbname={DB_NAME}\"\n)\n\n\ndef get_count_ride_type():\n    df = pd.read_sql(\n        \"\"\"\n        SELECT COUNT(ride_id) as n, rideable_type\n        FROM rides\n        GROUP BY rideable_type\n        ORDER BY n DESC\n    \"\"\",\n        con=connection_string,\n    )\n    return df\n\n\ndef get_most_popular_stations():\n\n    df = pd.read_sql(\n        \"\"\"\n    SELECT COUNT(ride_id) as n, MAX(start_station_name) as station\n    FROM RIDES\n    WHERE start_station_name is NOT NULL\n    GROUP BY start_station_id\n    ORDER BY n DESC\n    LIMIT 5\n    \"\"\",\n        con=connection_string,\n    )\n    return df\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n    # Chicago Bike Share Dashboard\n    \n    This demo pulls Chicago bike share data for March 2022 from a postgresql database hosted on AWS.\n    This demo uses psycopg2 but any postgresql client library (SQLAlchemy)\n    is compatible with gradio.\n    \n    Connection credentials are handled by environment variables\n    defined as secrets in the Space.\n\n    If data were added to the database, the plots in this demo would update\n    whenever the webpage is reloaded.\n    \n    This demo serves as a starting point for your database-connected apps!\n    \"\"\"\n    )\n    with gr.Row():\n        bike_type = gr.BarPlot(\n            x=\"rideable_type\",\n            y='n',\n            title=\"Number of rides per bicycle type\",\n            y_title=\"Number of Rides\",\n            x_title=\"Bicycle Type\",\n            vertical=False,\n            tooltip=['rideable_type', \"n\"],\n            height=300,\n            width=300,\n        )\n        station = gr.BarPlot(\n            x='station',\n            y='n',\n            title=\"Most Popular Stations\",\n            y_title=\"Number of Rides\",\n            x_title=\"Station Name\",\n            vertical=False,\n            tooltip=['station', 'n'],\n            height=300,\n            width=300\n        )\n\n    demo.load(get_count_ride_type, inputs=None, outputs=bike_type)\n    demo.load(get_most_popular_stations, inputs=None, outputs=station)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Audio",next_obj:"Button",slug:"bar-plot"},button:{class:null,name:"Button",description:"Used to create a button, that can be assigned arbitrary click() events. The label (value) of the button can be used as an input or set via the output of a function. \u003Cbr>",tags:{preprocessing:"passes the button value as a {str} into the function",postprocessing:"expects a {str} to be returned from a function, which is set as the label of the button",demos:"blocks_inputs, blocks_kinematics"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Run\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed. Must be within the working directory of the Gradio app or an external URL.",default:"None"},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Button",slug:"button-click"}],string_shortcuts:[["Button","button","Uses default values"],["ClearButton","clearbutton","Uses default values"],["DuplicateButton","duplicatebutton","Uses default values"],["LoginButton","loginbutton","Uses default values"],["LogoutButton","logoutbutton","Uses default values"]],demos:[["blocks_inputs","import gradio as gr\nimport os\n\n\ndef combine(a, b):\n    return a + \" \" + b\n\n\ndef mirror(x):\n    return x\n\n\nwith gr.Blocks() as demo:\n\n    txt = gr.Textbox(label=\"Input\", lines=2)\n    txt_2 = gr.Textbox(label=\"Input 2\")\n    txt_3 = gr.Textbox(value=\"\", label=\"Output\")\n    btn = gr.Button(value=\"Submit\")\n    btn.click(combine, inputs=[txt, txt_2], outputs=[txt_3])\n\n    with gr.Row():\n        im = gr.Image()\n        im_2 = gr.Image()\n\n    btn = gr.Button(value=\"Mirror Image\")\n    btn.click(mirror, inputs=[im], outputs=[im_2])\n\n    gr.Markdown(\"## Text Examples\")\n    gr.Examples(\n        [[\"hi\", \"Adam\"], [\"hello\", \"Eve\"]],\n        [txt, txt_2],\n        txt_3,\n        combine,\n        cache_examples=True,\n    )\n    gr.Markdown(\"## Image Examples\")\n    gr.Examples(\n        examples=[os.path.join(os.path.dirname(__file__), \"lion.jpg\")],\n        inputs=im,\n        outputs=im_2,\n        fn=mirror,\n        cache_examples=True,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_kinematics","import pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"BarPlot",next_obj:"Chatbot",slug:"button"},chatbot:{class:null,name:"Chatbot",description:"Displays a chatbot output showing both user submitted messages and responses. Supports a subset of Markdown including bold, italics, code, tables. Also supports audio/video/image files, which are displayed in the Chatbot, and other kinds of files which are displayed as links. \u003Cbr>",tags:{preprocessing:"passes the messages in the Chatbot as a {List[List[str | None | Tuple]]}, i.e. a list of lists. The inner list has 2 elements: the user message and the response message. See `Postprocessing` for the format of these messages.",postprocessing:"expects function to return a {List[List[str | None | Tuple]]}, i.e. a list of lists. The inner list should have 2 elements: the user message and the response message. The individual messages can be (1) strings in valid Markdown, (2) tuples if sending files: (a filepath or URL to a file, [optional string alt text]) -- if the file is image/video/audio, it is displayed in the Chatbot, or (3) None, in which case the message is not displayed.",demos:"chatbot_simple, chatbot_multimodal",guides:"creating-a-chatbot"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"list[list[str | tuple[str] | tuple[str | Path, str] | None]] | Callable | None",doc:"Default value to show in chatbot. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"height",annotation:"int | str | None",doc:"The height of the component, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"latex_delimiters",annotation:"list[dict[str, str | bool]] | None",doc:"A list of dicts of the form {&quot;left&quot;: open delimiter (str), &quot;right&quot;: close delimiter (str), &quot;display&quot;: whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ &quot;left&quot;: &quot;$$&quot;, &quot;right&quot;: &quot;$$&quot;, &quot;display&quot;: True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html).",default:"None"},{name:"rtl",annotation:"bool",doc:"If True, sets the direction of the rendered text to right-to-left. Default is False, which renders text left-to-right.",default:"False"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"show_copy_button",annotation:"bool",doc:"If True, will show a copy button for each chatbot message.",default:"False"},{name:"avatar_images",annotation:"tuple[str | Path | None, str | Path | None] | None",doc:"Tuple of two avatar image paths or URLs for user and bot (in that order). Pass None for either the user or bot image to skip. Must be within the working directory of the Gradio app or an external URL.",default:"None"},{name:"sanitize_html",annotation:"bool",doc:"If False, will disable HTML sanitization for chatbot messages. This is not recommended, as it can lead to security vulnerabilities.",default:"True"},{name:"render_markdown",annotation:"bool",doc:"If False, will disable Markdown rendering for chatbot messages.",default:"True"},{name:"bubble_full_width",annotation:"bool",doc:"If False, the chat bubble will fit to the content of the message. If True (default), the chat bubble will be the full width of the component.",default:"True"},{name:"line_breaks",annotation:"bool",doc:"If True (default), will enable Github-flavored Markdown line breaks in chatbot messages. If False, single new lines will be ignored. Only applies if `render_markdown` is True.",default:"True"},{name:"likeable",annotation:"bool",doc:"Whether the chat messages display a like or dislike button. Set automatically by the .like method but has to be present in the signature for it to show up in the config.",default:"False"},{name:"layout",annotation:"Literal[('panel', 'bubble')] | None",doc:"If &quot;panel&quot;, will display the chatbot in a llm style layout. If &quot;bubble&quot;, will display the chatbot with message bubbles, with the user and bot messages on alterating sides. Will default to &quot;bubble&quot;.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Chatbot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Chatbot",slug:"chatbot-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Chatbot. Uses event data gradio.SelectData to carry `value` referring to the label of the Chatbot, and `selected` to refer to state of the Chatbot. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Chatbot",slug:"chatbot-select"},{fn:null,name:"like",description:"This listener is triggered when the user likes/dislikes from within the Chatbot. This event has EventData of type gradio.LikeData that carries information, accessible through LikeData.index and LikeData.value. See EventData documentation on how to use this event data.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Chatbot",slug:"chatbot-like"}],string_shortcuts:[["Chatbot","chatbot","Uses default values"]],demos:[["chatbot_simple","import gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chat_history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        chat_history.append((message, bot_message))\n        time.sleep(2)\n        return \"\", chat_history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["chatbot_multimodal","import gradio as gr\nimport os\nimport time\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n\n\ndef print_like_dislike(x: gr.LikeData):\n    print(x.index, x.value, x.liked)\n\n\ndef add_text(history, text):\n    history = history + [(text, None)]\n    return history, gr.Textbox(value=\"\", interactive=False)\n\n\ndef add_file(history, file):\n    history = history + [((file.name,), None)]\n    return history\n\n\ndef bot(history):\n    response = \"**That's cool!**\"\n    history[-1][1] = \"\"\n    for character in response:\n        history[-1][1] += character\n        time.sleep(0.05)\n        yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(\n        [],\n        elem_id=\"chatbot\",\n        bubble_full_width=False,\n        avatar_images=(None, (os.path.join(os.path.dirname(__file__), \"avatar.png\"))),\n    )\n\n    with gr.Row():\n        txt = gr.Textbox(\n            scale=4,\n            show_label=False,\n            placeholder=\"Enter text and press enter, or upload an image\",\n            container=False,\n        )\n        btn = gr.UploadButton(\"üìÅ\", file_types=[\"image\", \"video\", \"audio\"])\n\n    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n        bot, chatbot, chatbot, api_name=\"bot_response\"\n    )\n    txt_msg.then(lambda: gr.Textbox(interactive=True), None, [txt], queue=False)\n    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n\n    chatbot.like(print_like_dislike, None, None)\n\n\ndemo.queue()\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[],parent:"gradio",prev_obj:"Button",next_obj:"Checkbox",slug:"chatbot"},checkbox:{class:null,name:"Checkbox",description:"Creates a checkbox that can be set to `True` or `False`. \u003Cbr>",tags:{preprocessing:"passes the status of the checkbox as a {bool} into the function.",postprocessing:"expects a {bool} returned from the function and, if it is True, checks the checkbox.","examples-format":"a {bool} representing whether the box is checked.",demos:"sentence_builder, titanic_survival"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"bool | Callable",doc:"if True, checked by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"False"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, this checkbox can be checked; if False, checking will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Checkbox changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Checkbox",slug:"checkbox-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Checkbox.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Checkbox",slug:"checkbox-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Checkbox. Uses event data gradio.SelectData to carry `value` referring to the label of the Checkbox, and `selected` to refer to state of the Checkbox. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Checkbox",slug:"checkbox-select"}],string_shortcuts:[["Checkbox","checkbox","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Chatbot",next_obj:"CheckboxGroup",slug:"checkbox"},checkboxgroup:{class:null,name:"CheckboxGroup",description:"Creates a set of checkboxes of which a subset can be checked.",tags:{preprocessing:"passes the list of checked checkboxes as a {List[str | int | float]} or their indices as a {List[int]} into the function, depending on `type`.",postprocessing:"expects a {List[str | int | float]}, each element of which becomes a checked checkbox.","examples-format":"a {List[str | int | float]} representing the values to be checked.",demos:"sentence_builder, titanic_survival"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"choices",annotation:"list[str | int | float | tuple[str, str | int | float]] | None",doc:"A list of string or numeric options to select from. An option can also be a tuple of the form (name, value), where name is the displayed name of the checkbox button and value is the value to be passed to the function, or returned by the function.",default:"None"},{name:"value",annotation:"list[str | float | int] | str | float | int | Callable | None",doc:"Default selected list of options. If a single choice is selected, it can be passed in as a string or numeric type. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"type",annotation:"Literal[('value', 'index')]",doc:"Type of value to be returned by component. &quot;value&quot; returns the list of strings of the choices selected, &quot;index&quot; returns the list of indices of the choices selected.",default:"\"value\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"Additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"If True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"Relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"Minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"If True, choices in this checkbox group will be checkable; if False, checking will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the CheckboxGroup changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.CheckboxGroup",slug:"checkbox-group-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the CheckboxGroup.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.CheckboxGroup",slug:"checkbox-group-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the CheckboxGroup. Uses event data gradio.SelectData to carry `value` referring to the label of the CheckboxGroup, and `selected` to refer to state of the CheckboxGroup. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.CheckboxGroup",slug:"checkbox-group-select"}],string_shortcuts:[["CheckboxGroup","checkboxgroup","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Checkbox",next_obj:"ClearButton",slug:"checkbox-group"},clearbutton:{class:null,name:"ClearButton",description:"Button that clears the value of a component or a list of components when clicked. It is instantiated with the list of components to clear.",tags:{preprocessing:"passes the button value as a {str} into the function",postprocessing:"expects a {str} to be returned from a function, which is set as the label of the button"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"components",annotation:"None | list[Component] | Component",doc:null,default:"None"},{name:"value",annotation:"str",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Clear\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed. Must be within the working directory of the Gradio app or an external URL.",default:"None"},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"},{name:"api_name",annotation:"str | None | Literal['False']",doc:null,default:"None"},{name:"show_api",annotation:"bool",doc:null,default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"add",description:"Adds a component or list of components to the list of components that will be cleared when the button is clicked.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"components",annotation:"None | Component | list[Component]",doc:null}],returns:{},example:null,override_signature:null,parent:"gradio.ClearButton",slug:"clear-button-add"},{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ClearButton",slug:"clear-button-click"}],string_shortcuts:[["ClearButton","clearbutton","Uses default values"]],parent:"gradio",prev_obj:"CheckboxGroup",next_obj:"Code",slug:"clear-button"},code:{class:null,name:"Code",description:"Creates a Code editor for entering, editing or viewing code.",tags:{preprocessing:"passes a {str} of code into the function.",postprocessing:"expects the function to return a {str} of code or a single-element {tuple}: {(string_filepath,)}"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | tuple[str] | None",doc:"Default value to show in the code editor. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"language",annotation:"Literal[('python', 'markdown', 'json', 'html', 'css', 'javascript', 'typescript', 'yaml', 'dockerfile', 'shell', 'r')] | None",doc:"The language to display the code as. Supported languages listed in `gr.Code.languages`.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"lines",annotation:"int",doc:null,default:"5"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether user should be able to enter code or only view it.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"languages",description:"[&#x27;python&#x27;, &#x27;markdown&#x27;, &#x27;json&#x27;, &#x27;html&#x27;, &#x27;css&#x27;, &#x27;javascript&#x27;, &#x27;typescript&#x27;, &#x27;yaml&#x27;, &#x27;dockerfile&#x27;, &#x27;shell&#x27;, &#x27;r&#x27;, None]",tags:{},parameters:[],returns:{},example:"",override_signature:"gr.Code.languages",parent:"gradio.Code",slug:"code-languages"},{fn:null,name:"change",description:"Triggered when the value of the Code changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Code.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-input"},{fn:null,name:"focus",description:"This listener is triggered when the Code is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-focus"},{fn:null,name:"blur",description:"This listener is triggered when the Code is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Code",slug:"code-blur"}],string_shortcuts:[["Code","code","Uses default values"]],parent:"gradio",prev_obj:"ClearButton",next_obj:"ColorPicker",slug:"code"},colorpicker:{class:null,name:"ColorPicker",description:"Creates a color picker for user to select a color as string input.",tags:{preprocessing:"passes selected color value as a {str} into the function.",postprocessing:"expects a {str} returned from function and sets color picker value to it.","examples-format":"a {str} with a hexadecimal representation of a color, e.g. &quot;#ff0000&quot; for red.",demos:"color_picker, color_generator"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable | None",doc:"default text to provide in color picker. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will be rendered as an editable color picker; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the ColorPicker changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the ColorPicker.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-input"},{fn:null,name:"submit",description:"This listener is triggered when the user presses the Enter key while the ColorPicker is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-submit"},{fn:null,name:"focus",description:"This listener is triggered when the ColorPicker is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-focus"},{fn:null,name:"blur",description:"This listener is triggered when the ColorPicker is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ColorPicker",slug:"color-picker-blur"}],string_shortcuts:[["ColorPicker","colorpicker","Uses default values"]],demos:[["color_picker","import gradio as gr\nimport numpy as np\nimport os\nfrom PIL import Image, ImageColor\n\n\ndef change_color(icon, color):\n\n    \"\"\"\n    Function that given an icon in .png format changes its color\n    Args:\n        icon: Icon whose color needs to be changed.\n        color: Chosen color with which to edit the input icon.\n    Returns:\n        edited_image: Edited icon.\n    \"\"\"\n    img = icon.convert(\"LA\")\n    img = img.convert(\"RGBA\")\n    image_np = np.array(icon)\n    _, _, _, alpha = image_np.T\n    mask = alpha > 0\n    image_np[..., :-1][mask.T] = ImageColor.getcolor(color, \"RGB\")\n    edited_image = Image.fromarray(image_np)\n    return edited_image\n\n\ninputs = [\n    gr.Image(label=\"icon\", type=\"pil\", image_mode=\"RGBA\"),\n    gr.ColorPicker(label=\"color\"),\n]\noutputs = gr.Image(label=\"colored icon\")\n\ndemo = gr.Interface(\n    fn=change_color,\n    inputs=inputs,\n    outputs=outputs,\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"rabbit.png\"), \"#ff0000\"],\n        [os.path.join(os.path.dirname(__file__), \"rabbit.png\"), \"#0000FF\"],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["color_generator","import gradio as gr\nimport cv2\nimport numpy as np\nimport random\n\n\n# Convert decimal color to hexadecimal color\ndef RGB_to_Hex(rgb):\n    color = \"#\"\n    for i in rgb:\n        num = int(i)\n        color += str(hex(num))[-2:].replace(\"x\", \"0\").upper()\n    return color\n\n\n# Randomly generate light or dark colors\ndef random_color(is_light=True):\n    return (\n        random.randint(0, 127) + int(is_light) * 128,\n        random.randint(0, 127) + int(is_light) * 128,\n        random.randint(0, 127) + int(is_light) * 128,\n    )\n\n\ndef switch_color(color_style):\n    if color_style == \"light\":\n        is_light = True\n    elif color_style == \"dark\":\n        is_light = False\n    back_color_ = random_color(is_light)  # Randomly generate colors\n    back_color = RGB_to_Hex(back_color_)  # Convert to hexadecimal\n\n    # Draw color pictures.\n    w, h = 50, 50\n    img = np.zeros((h, w, 3), np.uint8)\n    cv2.rectangle(img, (0, 0), (w, h), back_color_, thickness=-1)\n\n    return back_color, back_color, img\n\n\ninputs = [gr.Radio([\"light\", \"dark\"], value=\"light\")]\n\noutputs = [\n    gr.ColorPicker(label=\"color\"),\n    gr.Textbox(label=\"hexadecimal color\"),\n    gr.Image(type=\"numpy\", label=\"color picture\"),\n]\n\ntitle = \"Color Generator\"\ndescription = (\n    \"Click the Submit button, and a dark or light color will be randomly generated.\"\n)\n\ndemo = gr.Interface(\n    fn=switch_color,\n    inputs=inputs,\n    outputs=outputs,\n    title=title,\n    description=description,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Code",next_obj:"Dataframe",slug:"color-picker"},dataframe:{class:null,name:"Dataframe",description:"Accepts or displays 2D input through a spreadsheet-like component for dataframes.",tags:{preprocessing:"passes the uploaded spreadsheet data as a {pandas.DataFrame}, {numpy.array}, {polars.DataFrame}, or {List[List]} depending on `type`",postprocessing:"expects a {pandas.DataFrame}, {pandas.Styler}, {numpy.array}, {polars.DataFrame}, {List[List]}, {List}, a {Dict} with keys `data` (and optionally `headers`), or {str} path to a csv, which is rendered in the spreadsheet.","examples-format":"a {str} filepath to a csv with data, a pandas dataframe, a polars dataframe, or a list of lists (excluding headers) where each sublist is a row of data.",demos:"filter_records, matrix_transpose, tax_calculator, sort_records"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Styler | np.ndarray | pl.DataFrame | list | list[list] | dict | str | Callable | None",doc:"Default value to display in the DataFrame. If a Styler is provided, it will be used to set the displayed value in the DataFrame (e.g. to set precision of numbers) if the `interactive` is False. If a Callable function is provided, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"headers",annotation:"list[str] | None",doc:"List of str header names. If None, no headers are shown.",default:"None"},{name:"row_count",annotation:"int | tuple[int, str]",doc:"Limit number of rows for input and decide whether user can create new rows. The first element of the tuple is an `int`, the row count; the second should be &#x27;fixed&#x27; or &#x27;dynamic&#x27;, the new row behaviour. If an `int` is passed the rows default to &#x27;dynamic&#x27;",default:"(1, 'dynamic')"},{name:"col_count",annotation:"int | tuple[int, str] | None",doc:"Limit number of columns for input and decide whether user can create new columns. The first element of the tuple is an `int`, the number of columns; the second should be &#x27;fixed&#x27; or &#x27;dynamic&#x27;, the new column behaviour. If an `int` is passed the columns default to &#x27;dynamic&#x27;",default:"None"},{name:"datatype",annotation:"str | list[str]",doc:"Datatype of values in sheet. Can be provided per column as a list of strings, or for the entire sheet as a single string. Valid datatypes are &quot;str&quot;, &quot;number&quot;, &quot;bool&quot;, &quot;date&quot;, and &quot;markdown&quot;.",default:"\"str\""},{name:"type",annotation:"Literal[('pandas', 'numpy', 'array', 'polars')]",doc:"Type of value to be returned by component. &quot;pandas&quot; for pandas dataframe, &quot;numpy&quot; for numpy array, &quot;polars&quot; for polars dataframe, or &quot;array&quot; for a Python list of lists.",default:"\"pandas\""},{name:"latex_delimiters",annotation:"list[dict[str, str | bool]] | None",doc:"A list of dicts of the form {&quot;left&quot;: open delimiter (str), &quot;right&quot;: close delimiter (str), &quot;display&quot;: whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ &quot;left&quot;: &quot;$$&quot;, &quot;right&quot;: &quot;$$&quot;, &quot;display&quot;: True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html). Only applies to columns whose datatype is &quot;markdown&quot;.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"height",annotation:"int",doc:"The maximum height of the dataframe, specified in pixels if a number is passed, or in CSS units if a string is passed. If more rows are created than can fit in the height, a scrollbar will appear.",default:"500"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to edit the dataframe; if False, can only be used to display data. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"wrap",annotation:"bool",doc:"If True, the text in table cells will wrap when appropriate. If False and the `column_width` parameter is not set, the column widths will expand based on the cell contents and the table may need to be horizontally scrolled. If `column_width` is set, then any overflow text will be hidden.",default:"False"},{name:"line_breaks",annotation:"bool",doc:"If True (default), will enable Github-flavored Markdown line breaks in chatbot messages. If False, single new lines will be ignored. Only applies for columns of type &quot;markdown.&quot;",default:"True"},{name:"column_widths",annotation:"list[str | int] | None",doc:"An optional list representing the width of each column. The elements of the list should be in the format &quot;100px&quot; (ints are also accepted and converted to pixel values) or &quot;10%&quot;. If not provided, the column widths will be automatically determined based on the content of the cells. Setting this parameter will cause the browser to try to fit the table within the page width.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Dataframe changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataframe",slug:"dataframe-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Dataframe.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataframe",slug:"dataframe-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Dataframe. Uses event data gradio.SelectData to carry `value` referring to the label of the Dataframe, and `selected` to refer to state of the Dataframe. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataframe",slug:"dataframe-select"}],string_shortcuts:[["Dataframe","dataframe","Uses default values"],["Numpy","numpy","Uses type=\"numpy\""],["Matrix","matrix","Uses type=\"array\""],["List","list","Uses type=\"array\", col_count=1"]],demos:[["filter_records","import gradio as gr\n\n\ndef filter_records(records, gender):\n    return records[records[\"gender\"] == gender]\n\n\ndemo = gr.Interface(\n    filter_records,\n    [\n        gr.Dataframe(\n            headers=[\"name\", \"age\", \"gender\"],\n            datatype=[\"str\", \"number\", \"str\"],\n            row_count=5,\n            col_count=(3, \"fixed\"),\n        ),\n        gr.Dropdown([\"M\", \"F\", \"O\"]),\n    ],\n    \"dataframe\",\n    description=\"Enter gender as 'M', 'F', or 'O' for other.\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["matrix_transpose","import numpy as np\n\nimport gradio as gr\n\n\ndef transpose(matrix):\n    return matrix.T\n\n\ndemo = gr.Interface(\n    transpose,\n    gr.Dataframe(type=\"numpy\", datatype=\"number\", row_count=5, col_count=3),\n    \"numpy\",\n    examples=[\n        [np.zeros((3, 3)).tolist()],\n        [np.ones((2, 2)).tolist()],\n        [np.random.randint(0, 10, (3, 10)).tolist()],\n        [np.random.randint(0, 10, (10, 3)).tolist()],\n        [np.random.randint(0, 10, (10, 10)).tolist()],\n    ],\n    cache_examples=False\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["tax_calculator","import gradio as gr\n\ndef tax_calculator(income, marital_status, assets):\n    tax_brackets = [(10, 0), (25, 8), (60, 12), (120, 20), (250, 30)]\n    total_deductible = sum(assets[\"Cost\"])\n    taxable_income = income - total_deductible\n\n    total_tax = 0\n    for bracket, rate in tax_brackets:\n        if taxable_income > bracket:\n            total_tax += (taxable_income - bracket) * rate / 100\n\n    if marital_status == \"Married\":\n        total_tax *= 0.75\n    elif marital_status == \"Divorced\":\n        total_tax *= 0.8\n\n    return round(total_tax)\n\ndemo = gr.Interface(\n    tax_calculator,\n    [\n        \"number\",\n        gr.Radio([\"Single\", \"Married\", \"Divorced\"]),\n        gr.Dataframe(\n            headers=[\"Item\", \"Cost\"],\n            datatype=[\"str\", \"number\"],\n            label=\"Assets Purchased this Year\",\n        ),\n    ],\n    \"number\",\n    examples=[\n        [10000, \"Married\", [[\"Suit\", 5000], [\"Laptop\", 800], [\"Car\", 1800]]],\n        [80000, \"Single\", [[\"Suit\", 800], [\"Watch\", 1800], [\"Car\", 800]]],\n    ],\n)\n\ndemo.launch()\n"],["sort_records","import gradio as gr\nimport os\n\ndef sort_records(records):\n    return records.sort(\"Quantity\")\n\ndemo = gr.Interface(\n    sort_records,\n    gr.Dataframe(\n        headers=[\"Item\", \"Quantity\"],\n        datatype=[\"str\", \"number\"],\n        row_count=3,\n        col_count=(2, \"fixed\"),\n        type=\"polars\"\n    ),\n    \"dataframe\",\n    description=\"Sort by Quantity\",\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"polars_sort.csv\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()"]],parent:"gradio",prev_obj:"ColorPicker",next_obj:"Dataset",slug:"dataframe"},dataset:{class:null,name:"Dataset",description:"Used to create an output widget for showing datasets. Used to render the examples box.",tags:{preprocessing:"passes the selected sample either as a {list} of data (if type=&quot;value&quot;) or as an {int} index (if type=&quot;index&quot;)",postprocessing:"expects a {list} of {lists} corresponding to the dataset data."},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"label",annotation:"str | None",doc:null,default:"None"},{name:"components",annotation:"list[Component] | list[str]",doc:"Which component types to show in this dataset widget, can be passed in as a list of string names or Components instances. The following components are supported in a Dataset: Audio, Checkbox, CheckboxGroup, ColorPicker, Dataframe, Dropdown, File, HTML, Image, Markdown, Model3D, Number, Radio, Slider, Textbox, TimeSeries, Video"},{name:"samples",annotation:"list[list[Any]] | None",doc:"a nested list of samples. Each sublist within the outer list represents a data sample, and each element within the sublist represents an value for each component",default:"None"},{name:"headers",annotation:"list[str] | None",doc:"Column headers in the Dataset widget, should be the same len as components. If not provided, inferred from component labels",default:"None"},{name:"type",annotation:"Literal[('values', 'index')]",doc:"&#x27;values&#x27; if clicking on a sample should pass the value of the sample, or &quot;index&quot; if it should pass the index of the sample",default:"\"values\""},{name:"samples_per_page",annotation:"int",doc:"how many examples to show per page.",default:"10"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"proxy_url",annotation:"str | None",doc:"The URL of the external Space used to load this component. Set automatically when using `gr.load()`. This should not be set manually.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Dataset is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataset",slug:"dataset-click"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Dataset. Uses event data gradio.SelectData to carry `value` referring to the label of the Dataset, and `selected` to refer to state of the Dataset. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dataset",slug:"dataset-select"}],string_shortcuts:[["Dataset","dataset","Uses default values"]],override_signature:"gr.Dataset(components, samples)",parent:"gradio",prev_obj:"Dataframe",next_obj:"Dropdown",slug:"dataset"},dropdown:{class:null,name:"Dropdown",description:"Creates a dropdown of choices from which entries can be selected.",tags:{preprocessing:"passes the value of the selected dropdown entry as a {str} or its index as an {int} into the function, depending on `type`.",postprocessing:"expects a {str} corresponding to the value of the dropdown entry to be selected.","examples-format":"a {str} representing the drop down value to select.",demos:"sentence_builder, titanic_survival"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"choices",annotation:"list[str | int | float | tuple[str, str | int | float]] | None",doc:"A list of string options to choose from. An option can also be a tuple of the form (name, value), where name is the displayed name of the dropdown choice and value is the value to be passed to the function, or returned by the function.",default:"None"},{name:"value",annotation:"str | int | float | list[str | int | float] | Callable | None",doc:"default value(s) selected in dropdown. If None, no value is selected by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"type",annotation:"Literal[('value', 'index')]",doc:"Type of value to be returned by component. &quot;value&quot; returns the string of the choice selected, &quot;index&quot; returns the index of the choice selected.",default:"\"value\""},{name:"multiselect",annotation:"bool | None",doc:"if True, multiple choices can be selected.",default:"None"},{name:"allow_custom_value",annotation:"bool",doc:"If True, allows user to enter a custom value that is not in the list of choices.",default:"False"},{name:"max_choices",annotation:"int | None",doc:"maximum number of choices that can be selected. If None, no limit is enforced.",default:"None"},{name:"filterable",annotation:"bool",doc:"If True, user will be able to type into the dropdown and filter the choices by typing. Can only be set to False if `allow_custom_value` is False.",default:"True"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, choices in this dropdown will be selectable; if False, selection will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Dropdown changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Dropdown.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Dropdown. Uses event data gradio.SelectData to carry `value` referring to the label of the Dropdown, and `selected` to refer to state of the Dropdown. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-select"},{fn:null,name:"focus",description:"This listener is triggered when the Dropdown is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-focus"},{fn:null,name:"blur",description:"This listener is triggered when the Dropdown is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Dropdown",slug:"dropdown-blur"}],string_shortcuts:[["Dropdown","dropdown","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Dataset",next_obj:"DuplicateButton",slug:"dropdown"},duplicatebutton:{class:null,name:"DuplicateButton",description:"Button that triggers a Spaces Duplication, when the demo is on Hugging Face Spaces. Does nothing locally.",tags:{preprocessing:"passes the button value as a {str} into the function",postprocessing:"expects a {str} to be returned from a function, which is set as the label of the button"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Duplicate Space\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"\"sm\""},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed.",default:"None"},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"0"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.DuplicateButton",slug:"duplicate-button-click"}],string_shortcuts:[["DuplicateButton","duplicatebutton","Uses default values"]],parent:"gradio",prev_obj:"Dropdown",next_obj:"File",slug:"duplicate-button"},file:{class:null,name:"File",description:"Creates a file component that allows uploading generic file (when used as an input) and or displaying generic files (output).",tags:{preprocessing:"passes the uploaded file as a {tempfile._TemporaryFileWrapper} or {List[tempfile._TemporaryFileWrapper]} depending on `file_count` (or a {bytes}/{List[bytes]} depending on `type`)",postprocessing:"expects function to return a {str} path to a file, or {List[str]} consisting of paths to files.","examples-format":"a {str} path to a local file that populates the component.",demos:"zip_to_json, zip_files"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | list[str] | Callable | None",doc:"Default file to display, given as str file path. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"file_count",annotation:"Literal[('single', 'multiple', 'directory')]",doc:"if single, allows user to upload one file. If &quot;multiple&quot;, user uploads multiple files. If &quot;directory&quot;, user uploads all files in selected directory. Return type will be list for each file in case of &quot;multiple&quot; or &quot;directory&quot;.",default:"\"single\""},{name:"file_types",annotation:"list[str] | None",doc:"List of file extensions or types of files to be uploaded (e.g. [&#x27;image&#x27;, &#x27;.json&#x27;, &#x27;.mp4&#x27;]). &quot;file&quot; allows any file to be uploaded, &quot;image&quot; allows only image files to be uploaded, &quot;audio&quot; allows only audio files to be uploaded, &quot;video&quot; allows only video files to be uploaded, &quot;text&quot; allows only text files to be uploaded.",default:"None"},{name:"type",annotation:"Literal[('filepath', 'binary')]",doc:"Type of value to be returned by component. &quot;file&quot; returns a temporary file object with the same base name as the uploaded file, whose full path can be retrieved by file_obj.name, &quot;binary&quot; returns an bytes object.",default:"\"filepath\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"height",annotation:"int | float | None",doc:"The maximum height of the file component, specified in pixels if a number is passed, or in CSS units if a string is passed. If more files are uploaded than can fit in the height, a scrollbar will appear.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a file; if False, can only be used to display files. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the File changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the File. Uses event data gradio.SelectData to carry `value` referring to the label of the File, and `selected` to refer to state of the File. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-select"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the File using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-clear"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the File.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.File",slug:"file-upload"}],string_shortcuts:[["File","file","Uses default values"],["Files","files","Uses file_count=\"multiple\""]],demos:[["zip_to_json","from zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["zip_files","import os\nfrom zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_files(files):\n    with ZipFile(\"tmp.zip\", \"w\") as zipObj:\n        for idx, file in enumerate(files):\n            zipObj.write(file.name, file.name.split(\"/\")[-1])\n    return \"tmp.zip\"\n\ndemo = gr.Interface(\n    zip_files,\n    gr.File(file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\"]),\n    \"file\",\n    examples=[[[os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\")]]], \n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"DuplicateButton",next_obj:"FileExplorer",slug:"file"},fileexplorer:{class:null,name:"FileExplorer",description:"Creates a file explorer component that allows users to browse and select files on the machine hosting the Gradio app.",tags:{preprocessing:"passes the selected file or directory as a {str} path (relative to root) or {list[str}} depending on `file_count`",postprocessing:"expects function to return a {str} path to a file, or {List[str]} consisting of paths to files.","examples-format":"a {str} path to a local file that populates the component.",demos:"zip_to_json, zip_files"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"glob",annotation:"str",doc:"The glob-style pattern used to select which files to display, e.g. &quot;*&quot; to match all files, &quot;*.png&quot; to match all .png files, &quot;**/*.txt&quot; to match any .txt file in any subdirectory, etc. The default value matches all files and folders recursively. See the Python glob documentation at https://docs.python.org/3/library/glob.html for more information.",default:"\"**/*.*\""},{name:"value",annotation:"str | list[str] | Callable | None",doc:"The file (or list of files, depending on the `file_count` parameter) to show as &quot;selected&quot; when the component is first loaded. If a callable is provided, it will be called when the app loads to set the initial value of the component. If not provided, no files are shown as selected.",default:"None"},{name:"file_count",annotation:"Literal[('single', 'multiple')]",doc:"Whether to allow single or multiple files to be selected. If &quot;single&quot;, the component will return a single absolute file path as a string. If &quot;multiple&quot;, the component will return a list of absolute file paths as a list of strings.",default:"\"multiple\""},{name:"root_dir",annotation:"str | Path",doc:"Path to root directory to select files from. If not provided, defaults to current working directory.",default:"\".\""},{name:"ignore_glob",annotation:"str | None",doc:"The glob-tyle pattern that will be used to exclude files from the list. For example, &quot;*.py&quot; will exclude all .py files from the list. See the Python glob documentation at https://docs.python.org/3/library/glob.html for more information.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"height",annotation:"int | float | None",doc:"The maximum height of the file component, specified in pixels if a number is passed, or in CSS units if a string is passed. If more files are uploaded than can fit in the height, a scrollbar will appear.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a file; if False, can only be used to display files. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"root",annotation:"None",doc:null,default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.FileExplorer",slug:"file-explorer-change"}],string_shortcuts:[["FileExplorer","fileexplorer","Uses default values"]],demos:[["zip_to_json","from zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["zip_files","import os\nfrom zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_files(files):\n    with ZipFile(\"tmp.zip\", \"w\") as zipObj:\n        for idx, file in enumerate(files):\n            zipObj.write(file.name, file.name.split(\"/\")[-1])\n    return \"tmp.zip\"\n\ndemo = gr.Interface(\n    zip_files,\n    gr.File(file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\"]),\n    \"file\",\n    examples=[[[os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n    os.path.join(os.path.dirname(__file__),\"files/titanic.csv\")]]], \n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"File",next_obj:"Gallery",slug:"file-explorer"},gallery:{class:null,name:"Gallery",description:"Used to display a list of images as a gallery that can be scrolled through. \u003Cbr>",tags:{preprocessing:"A list of (image, caption) tuples. Each image is a filepath, numpy array or PIL.image depending on the `type` parameter. {List[tuple[str | PIL.Image | numpy.array, str | None]]}.",postprocessing:"expects a list of images in any format, {List[numpy.array | PIL.Image | str | pathlib.Path]}, or a {List} of (image, {str} caption) tuples and displays them.",demos:"fake_gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"list[np.ndarray | _Image.Image | str | Path | tuple] | Callable | None",doc:"List of images to display in the gallery by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"columns",annotation:"int | tuple | None",doc:"Represents the number of images that should be shown in one row, for each of the six standard screen sizes (&lt;576px, &lt;768px, &lt;992px, &lt;1200px, &lt;1400px, &gt;1400px). If fewer than 6 are given then the last will be used for all subsequent breakpoints",default:"2"},{name:"rows",annotation:"int | tuple | None",doc:"Represents the number of rows in the image grid, for each of the six standard screen sizes (&lt;576px, &lt;768px, &lt;992px, &lt;1200px, &lt;1400px, &gt;1400px). If fewer than 6 are given then the last will be used for all subsequent breakpoints",default:"None"},{name:"height",annotation:"int | float | None",doc:"The height of the gallery component, specified in pixels if a number is passed, or in CSS units if a string is passed. If more images are displayed than can fit in the height, a scrollbar will appear.",default:"None"},{name:"allow_preview",annotation:"bool",doc:"If True, images in the gallery will be enlarged when they are clicked. Default is True.",default:"True"},{name:"preview",annotation:"bool | None",doc:"If True, Gallery will start in preview mode, which shows all of the images as thumbnails and allows the user to click on them to view them in full size. Only works if allow_preview is True.",default:"None"},{name:"selected_index",annotation:"int | None",doc:"The index of the image that should be initially selected. If None, no image will be selected at start. If provided, will set Gallery to preview mode unless allow_preview is set to False.",default:"None"},{name:"object_fit",annotation:"Literal[('contain', 'cover', 'fill', 'none', 'scale-down')] | None",doc:"CSS object-fit property for the thumbnail images in the gallery. Can be &quot;contain&quot;, &quot;cover&quot;, &quot;fill&quot;, &quot;none&quot;, or &quot;scale-down&quot;.",default:"None"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"show_download_button",annotation:"bool | None",doc:"If True, will show a download button in the corner of the selected image. If False, the icon does not appear. Default is True.",default:"True"},{name:"interactive",annotation:"bool | None",doc:"If True, the gallery will be interactive, allowing the user to upload images. If False, the gallery will be static. Default is True.",default:"None"},{name:"type",annotation:"Literal[('numpy', 'pil', 'filepath')]",doc:"The format the image is converted to before being passed into the prediction function. &quot;numpy&quot; converts the image to a numpy array with shape (height, width, 3) and values from 0 to 255, &quot;pil&quot; converts the image to a PIL image object, &quot;filepath&quot; passes a str path to a temporary file containing the image. If the image is SVG, the `type` is ignored and the filepath of the SVG is returned.",default:"\"filepath\""}],returns:{annotation:null},example:null,fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Gallery. Uses event data gradio.SelectData to carry `value` referring to the label of the Gallery, and `selected` to refer to state of the Gallery. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Gallery",slug:"gallery-select"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Gallery.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Gallery",slug:"gallery-upload"},{fn:null,name:"change",description:"Triggered when the value of the Gallery changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Gallery",slug:"gallery-change"}],string_shortcuts:[["Gallery","gallery","Uses default values"]],demos:[["fake_gan","# This demo needs to be run from the repo folder.\n# python demo/fake_gan/run.py\nimport random\n\nimport gradio as gr\n\n\ndef fake_gan():\n    images = [\n        (random.choice(\n            [\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1151ce9f4b2043de0d2e3b7826127998.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-116b5e92936b766b7fdfc242649337f7.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1163530ca19b5cebe1b002b8ec67b6fc.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1116395d6e6a6581eef8b8038f4c8e55.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-11319be65db395d0e8e6855d18ddcef0.jpg\",\n            ]\n        ), f\"label {i}\")\n        for i in range(3)\n    ]\n    return images\n\n\nwith gr.Blocks() as demo:\n    gallery = gr.Gallery(\n        label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n    , columns=[3], rows=[1], object_fit=\"contain\", height=\"auto\")\n    btn = gr.Button(\"Generate images\", scale=0)\n\n    btn.click(fake_gan, None, gallery)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"FileExplorer",next_obj:"HTML",slug:"gallery"},html:{class:null,name:"HTML",description:"Used to display arbitrary HTML output. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a valid HTML {str}.",demos:"text_analysis",guides:"key-features"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable",doc:"Default value. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"\""},{name:"label",annotation:"str | None",doc:"The label for this component. Is used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"This parameter has no effect.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the HTML changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.HTML",slug:"html-change"}],string_shortcuts:[["HTML","html","Uses default values"]],demos:[["text_analysis","import gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"\u003Cdiv style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"\u003C/div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n"]],guides:[{name:"key-features",category:"getting-started",pretty_category:"Getting Started",guide_index:2,absolute_index:1,pretty_name:"Key Features",content:"# Key Features\n\nLet's go through some of the key features of Gradio. This guide is intended to be a high-level overview of various things that you should be aware of as you build your demo. Where appropriate, we link to more detailed guides on specific topics.\n\n1. [Components](#components)\n2. [Queuing](#queuing)\n3. [Streaming outputs](#streaming-outputs)\n4. [Streaming inputs](#streaming-inputs)\n5. [Alert modals](#alert-modals)\n6. [Styling](#styling)\n7. [Progress bars](#progress-bars)\n8. [Batch functions](#batch-functions)\n\n## Components\n\nGradio includes more than 30 pre-built components (as well as many user-built _custom components_) that can be used as inputs or outputs in your demo with a single line of code. These components correspond to common data types in machine learning and data science, e.g. the `gr.Image` component is designed to handle input or output images, the `gr.Label` component displays classification labels and probabilities, the `gr.Plot` component displays various kinds of plots, and so on.\n\nEach component includes various constructor attributes that control the properties of the component. For example, you can control the number of lines in a `gr.Textbox` using the `lines` argument (which takes a positive integer) in its constructor. Or you can control the way that a user can provide an image in the `gr.Image` component using the `sources` parameter (which takes a list like `[\"webcam\", \"upload\"]`).\n\n**Static and Interactive Components**\n\nEvery component has a _static_ version that is designed to *display* data, and most components also have an _interactive_ version designed to let users input or modify the data. Typically, you don't need to think about this distinction, because when you build a Gradio demo, Gradio automatically figures out whether the component should be static or interactive based on whether it is being used as an input or output. However, you can set this manually using the `interactive` argument that every component supports.\n\n**Preprocessing and Postprocessing**\n\nWhen a component is used as an input, Gradio automatically handles the _preprocessing_ needed to convert the data from a type sent by the user's browser (such as an uploaded image) to a form that can be accepted by your function (such as a `numpy` array).\n\n\nSimilarly, when a component is used as an output, Gradio automatically handles the _postprocessing_ needed to convert the data from what is returned by your function (such as a list of image paths) to a form that can be displayed in the user's browser (a gallery of images).\n\nConsider an example demo with three input components (`gr.Textbox`, `gr.Number`, and `gr.Image`) and two outputs (`gr.Number` and `gr.Gallery`) that serve as a UI for your image-to-image generation model. Below is a diagram of what our preprocessing will send to the model and what our postprocessing will require from it.\n\n![](https://github.com/gradio-app/gradio/blob/main/guides/assets/dataflow.svg?raw=true)\n\nIn this image, the following preprocessing steps happen to send the data from the browser to your function:\n\n* The text in the textbox is converted to a Python `str` (essentially no preprocessing)\n* The number in the number input in converted to a Python `float` (essentially no preprocessing)\n* Most importantly, ihe image supplied by the user is converted to a `numpy.array` representation of the RGB values in the image\n\nImages are converted to NumPy arrays because they are a common format for machine learning workflows. You can control the _preprocessing_ using the component's parameters when constructing the component. For example, if you instantiate the `Image` component with the following parameters, it will preprocess the image to the `PIL` format instead:\n\n```py\nimg = gr.Image(type=\"pil\")\n```\n\nPostprocessing is even simpler! Gradio automatically recognizes the format of the returned data (e.g. does the user's function return a `numpy` array or a `str` filepath for the `gr.Image` component?) and postprocesses it appropriately into a format that can be displayed by the browser.\n\nSo in the image above, the following postprocessing steps happen to send the data returned from a user's function to the browser:\n\n* The `float` is displayed as a number and displayed directly to the user\n* The list of string filepaths (`list[str]`) is interpreted as a list of image filepaths and displayed as a gallery in the browser\n\nTake a look at the [Docs](https://gradio.app/docs) to see all the parameters for each Gradio component.\n\n## Queuing\n\nEvery Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. You can configure the queue by using `queue()` method which is supported by the `gr.Interface`, `gr.Blocks`, and `gr.ChatInterface` classes. \n\nFor example, you can control the number of requests processed at a single time by setting the `default_concurrency_limit` parameter of `queue()`, e.g.\n\n```python\ndemo = gr.Interface(...).queue(default_concurrency_limit=5)\ndemo.launch()\n```\n\nThis limits the number of requests processed for this event listener at a single time to 5. By default, the `default_concurrency_limit` is actually set to `1`, which means that when many users are using your app, only a single user's request will be processed at a time. This is because many machine learning functions consume a significant amount of memory and so it is only suitable to have a single user using the demo at a time. However, you can change this parameter in your demo easily.\n\nSee the [docs on queueing](/docs/interface#interface-queue) for more details on configuring the queuing parameters.\n\n## Streaming outputs\n\nIn some cases, you may want to stream a sequence of outputs rather than show a single output at once. For example, you might have an image generation model and you want to show the image that is generated at each step, leading up to the final image. Or you might have a chatbot which streams its response one token at a time instead of returning it all at once.\n\nIn such cases, you can supply a **generator** function into Gradio instead of a regular function. Creating generators in Python is very simple: instead of a single `return` value, a function should `yield` a series of values instead. Usually the `yield` statement is put in some kind of loop. Here's an example of an generator that simply counts up to a given number:\n\n```python\ndef my_generator(x):\n    for i in range(x):\n        yield i\n```\n\nYou supply a generator into Gradio the same way as you would a regular function. For example, here's a a (fake) image generation model that generates noise for several steps before outputting an image using the `gr.Interface` class:\n\n```python\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef fake_diffusion(steps):\n    for i in range(steps):\n        time.sleep(1)\n        image = np.random.random((600, 600, 3))\n        yield image\n    image = np.ones((1000,1000,3), np.uint8)\n    image[:] = [255, 124, 0]\n    yield image\n\n\ndemo = gr.Interface(fake_diffusion, inputs=gr.Slider(1, 10, 3), outputs=\"image\")\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/fake_diffusion'>\u003C/gradio-app>\n\nNote that we've added a `time.sleep(1)` in the iterator to create an artificial pause between steps so that you are able to observe the steps of the iterator (in a real image generation model, this probably wouldn't be necessary).\n\n## Streaming inputs\n\nSimilarly, Gradio can handle streaming inputs, e.g. a live audio stream that can gets transcribed to text in real time, or an image generation model that reruns every time a user types a letter in a textbox. This is covered in more details in our guide on building [reactive Interfaces](/guides/reactive-interfaces). \n\n## Alert modals\n\nYou may wish to raise alerts to the user. To do so, raise a `gr.Error(\"custom message\")` to display an error message. You can also issue `gr.Warning(\"message\")` and `gr.Info(\"message\")` by having them as standalone lines in your function, which will immediately display modals while continuing the execution of your function. Queueing needs to be enabled for this to work.\n\nNote below how the `gr.Error` has to be raised, while the `gr.Warning` and `gr.Info` are single lines.\n\n```python\ndef start_process(name):\n    gr.Info(\"Starting process\")\n    if name is None:\n        gr.Warning(\"Name is empty\")\n    ...\n    if success == False:\n        raise gr.Error(\"Process failed\")\n```\n\n\n\n## Styling\n\nGradio themes are the easiest way to customize the look and feel of your app. You can choose from a variety of themes, or create your own. To do so, pass the `theme=` kwarg to the `Interface` constructor. For example:\n\n```python\ndemo = gr.Interface(..., theme=gr.themes.Monochrome())\n```\n\nGradio comes with a set of prebuilt themes which you can load from `gr.themes.*`. You can extend these themes or create your own themes from scratch - see the [theming guide](https://gradio.app/guides/theming-guide) for more details.\n\nFor additional styling ability, you can pass any CSS (as well as custom JavaScript) to your Gradio application. This is discussed in more detail in our [custom JS and CSS guide](/guides/custom-CSS-and-JS).\n\n\n## Progress bars\n\nGradio supports the ability to create custom Progress Bars so that you have customizability and control over the progress update that you show to the user. In order to enable this, simply add an argument to your method that has a default value of a `gr.Progress` instance. Then you can update the progress levels by calling this instance directly with a float between 0 and 1, or using the `tqdm()` method of the `Progress` instance to track progress over an iterable, as shown below.\n\n```python\nimport gradio as gr\nimport time\n\ndef slowly_reverse(word, progress=gr.Progress()):\n    progress(0, desc=\"Starting\")\n    time.sleep(1)\n    progress(0.05)\n    new_string = \"\"\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\n        time.sleep(0.25)\n        new_string = letter + new_string\n    return new_string\n\ndemo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/progress_simple'>\u003C/gradio-app>\n\nIf you use the `tqdm` library, you can even report progress updates automatically from any `tqdm.tqdm` that already exists within your function by setting the default argument as `gr.Progress(track_tqdm=True)`!\n\n## Batch functions\n\nGradio supports the ability to pass _batch_ functions. Batch functions are just\nfunctions which take in a list of inputs and return a list of predictions.\n\nFor example, here is a batched function that takes in two lists of inputs (a list of\nwords and a list of ints), and returns a list of trimmed words as output:\n\n```py\nimport time\n\ndef trim_words(words, lens):\n    trimmed_words = []\n    time.sleep(5)\n    for w, l in zip(words, lens):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n```\n\nThe advantage of using batched functions is that if you enable queuing, the Gradio server can automatically _batch_ incoming requests and process them in parallel,\npotentially speeding up your demo. Here's what the Gradio code looks like (notice the `batch=True` and `max_batch_size=16`)\n\nWith the `gr.Interface` class:\n\n```python\ndemo = gr.Interface(\n    fn=trim_words, \n    inputs=[\"textbox\", \"number\"], \n    outputs=[\"output\"],\n    batch=True, \n    max_batch_size=16\n)\n\ndemo.launch()\n```\n\nWith the `gr.Blocks` class:\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        word = gr.Textbox(label=\"word\")\n        leng = gr.Number(label=\"leng\")\n        output = gr.Textbox(label=\"Output\")\n    with gr.Row():\n        run = gr.Button()\n\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\n\ndemo.launch()\n```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference time of 5 seconds), instead of each request being processed separately (for a total\ninference time of 80 seconds). Many Hugging Face `transformers` and `diffusers` models work very naturally with Gradio's batch mode: here's [an example demo using diffusers to\ngenerate images in batches](https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.py)\n\n\n",tags:[],spaces:[],url:"/guides/key-features/",contributor:null}],parent:"gradio",prev_obj:"Gallery",next_obj:"HighlightedText",slug:"html"},highlightedtext:{class:null,name:"HighlightedText",description:"Displays text that contains spans that are highlighted by category or numerical value. \u003Cbr>",tags:{preprocessing:"passes a list of tuples as a {List[Tuple[str, float | str | None]]]} into the function. If no labels are provided, the text will be displayed as a single span.",postprocessing:"expects a {List[Tuple[str, float | str]]]} consisting of spans of text and their associated labels, or a {Dict} with two keys: (1) &quot;text&quot; whose value is the complete text, and (2) &quot;entities&quot;, which is a list of dictionaries, each of which have the keys: &quot;entity&quot; (consisting of the entity label, can alternatively be called &quot;entity_group&quot;), &quot;start&quot; (the character index where the label starts), and &quot;end&quot; (the character index where the label ends). Entities should not overlap.",demos:"diff_texts, text_analysis",guides:"named-entity-recognition"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"list[tuple[str, str | float | None]] | dict | Callable | None",doc:"Default value to show. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"color_map",annotation:"dict[str, str] | None",doc:"A dictionary mapping labels to colors. The colors may be specified as hex codes or by their names. For example: {&quot;person&quot;: &quot;red&quot;, &quot;location&quot;: &quot;#FFEE22&quot;}",default:"None"},{name:"show_legend",annotation:"bool",doc:"whether to show span categories in a separate legend or inline.",default:"False"},{name:"combine_adjacent",annotation:"bool",doc:"If True, will merge the labels of adjacent tokens belonging to the same category.",default:"False"},{name:"adjacent_separator",annotation:"str",doc:"Specifies the separator to be used between tokens if combine_adjacent is True.",default:"\"\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"interactive",annotation:"bool | None",doc:"If True, the component will be editable, and allow user to select spans of text and label them.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the HighlightedText changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.HighlightedText",slug:"highlighted-text-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the HighlightedText. Uses event data gradio.SelectData to carry `value` referring to the label of the HighlightedText, and `selected` to refer to state of the HighlightedText. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.HighlightedText",slug:"highlighted-text-select"}],string_shortcuts:[["HighlightedText","highlightedtext","Uses default values"]],demos:[["diff_texts","from difflib import Differ\n\nimport gradio as gr\n\n\ndef diff_texts(text1, text2):\n    d = Differ()\n    return [\n        (token[2:], token[0] if token[0] != \" \" else None)\n        for token in d.compare(text1, text2)\n    ]\n\n\ndemo = gr.Interface(\n    diff_texts,\n    [\n        gr.Textbox(\n            label=\"Text 1\",\n            info=\"Initial text\",\n            lines=3,\n            value=\"The quick brown fox jumped over the lazy dogs.\",\n        ),\n        gr.Textbox(\n            label=\"Text 2\",\n            info=\"Text to compare\",\n            lines=3,\n            value=\"The fast brown fox jumps over lazy dogs.\",\n        ),\n    ],\n    gr.HighlightedText(\n        label=\"Diff\",\n        combine_adjacent=True,\n        show_legend=True,\n        color_map={\"+\": \"red\", \"-\": \"green\"}),\n    theme=gr.themes.Base()\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["text_analysis","import gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"\u003Cdiv style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"\u003C/div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n"]],guides:[{name:"named-entity-recognition",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:48,pretty_name:"Named Entity Recognition",content:"# Named-Entity Recognition\n\n\n\n\n## Introduction\n\nNamed-entity recognition (NER), also known as token classification or text tagging, is the task of taking a sentence and classifying every word (or \"token\") into different categories, such as names of people or names of locations, or different parts of speech.\n\nFor example, given the sentence:\n\n> Does Chicago have any Pakistani restaurants?\n\nA named-entity recognition algorithm may identify:\n\n- \"Chicago\" as a **location**\n- \"Pakistani\" as an **ethnicity**\n\nand so on.\n\nUsing `gradio` (specifically the `HighlightedText` component), you can easily build a web demo of your NER model and share that with the rest of your team.\n\nHere is an example of a demo that you'll be able to build:\n\n\u003Cgradio-app space='gradio/ner_pipeline'>\u003C/gradio-app>\n\nThis tutorial will show how to take a pretrained NER model and deploy it with a Gradio interface. We will show two different ways to use the `HighlightedText` component -- depending on your NER model, either of these two ways may be easier to learn!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained named-entity recognition model. You can use your own, while in this tutorial, we will use one from the `transformers` library.\n\n### Approach 1: List of Entity Dictionaries\n\nMany named-entity recognition models output a list of dictionaries. Each dictionary consists of an _entity_, a \"start\" index, and an \"end\" index. This is, for example, how NER models in the `transformers` library operate:\n\n```py\nfrom transformers import pipeline\nner_pipeline = pipeline(\"ner\")\nner_pipeline(\"Does Chicago have any Pakistani restaurants\")\n```\n\nOutput:\n\n```bash\n[{'entity': 'I-LOC',\n  'score': 0.9988978,\n  'index': 2,\n  'word': 'Chicago',\n  'start': 5,\n  'end': 12},\n {'entity': 'I-MISC',\n  'score': 0.9958592,\n  'index': 5,\n  'word': 'Pakistani',\n  'start': 22,\n  'end': 31}]\n```\n\nIf you have such a model, it is very easy to hook it up to Gradio's `HighlightedText` component. All you need to do is pass in this **list of entities**, along with the **original text** to the model, together as dictionary, with the keys being `\"entities\"` and `\"text\"` respectively.\n\nHere is a complete example:\n\n```python\nfrom transformers import pipeline\n\nimport gradio as gr\n\nner_pipeline = pipeline(\"ner\")\n\nexamples = [\n    \"Does Chicago have any stores and does Joe live here?\",\n]\n\ndef ner(text):\n    output = ner_pipeline(text)\n    return {\"text\": text, \"entities\": output}    \n\ndemo = gr.Interface(ner,\n             gr.Textbox(placeholder=\"Enter sentence here...\"), \n             gr.HighlightedText(),\n             examples=examples)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/ner_pipeline'>\u003C/gradio-app>\n\n### Approach 2: List of Tuples\n\nAn alternative way to pass data into the `HighlightedText` component is a list of tuples. The first element of each tuple should be the word or words that are being classified into a particular entity. The second element should be the entity label (or `None` if they should be unlabeled). The `HighlightedText` component automatically strings together the words and labels to display the entities.\n\nIn some cases, this can be easier than the first approach. Here is a demo showing this approach using Spacy's parts-of-speech tagger:\n\n```python\nimport gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"\u003Cdiv style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"\u003C/div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/text_analysis'>\u003C/gradio-app>\n\n---\n\nAnd you're done! That's all you need to know to build a web-based GUI for your NER model.\n\nFun tip: you can share your NER demo instantly with others simply by setting `share=True` in `launch()`.\n",tags:["NER","TEXT","HIGHLIGHT"],spaces:["https://huggingface.co/spaces/rajistics/biobert_ner_demo","https://huggingface.co/spaces/abidlabs/ner","https://huggingface.co/spaces/rajistics/Financial_Analyst_AI"],url:"/guides/named-entity-recognition/",contributor:null}],parent:"gradio",prev_obj:"HTML",next_obj:"Image",slug:"highlighted-text"},image:{class:null,name:"Image",description:"Creates an image component that can be used to upload images (as an input) or display images (as an output).",tags:{preprocessing:"passes the uploaded image as a {numpy.array}, {PIL.Image} or {str} filepath depending on `type`. For SVGs, the `type` parameter is ignored and the filepath of the SVG is returned.",postprocessing:"expects a {numpy.array}, {PIL.Image} or {str} or {pathlib.Path} filepath to an image and displays the image.","examples-format":"a {str} local filepath or URL to an image.",demos:"image_mod, image_mod_default_image",guides:"image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers, create-your-own-friends-with-a-gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | _Image.Image | np.ndarray | None",doc:"A PIL Image, numpy array, path or URL for the default value that Image component is going to take. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the displayed image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the displayed image, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"image_mode",annotation:"Literal[('1', 'L', 'P', 'RGB', 'RGBA', 'CMYK', 'YCbCr', 'LAB', 'HSV', 'I', 'F')]",doc:"&quot;RGB&quot; if color, or &quot;L&quot; if black and white. See https://pillow.readthedocs.io/en/stable/handbook/concepts.html for other supported image modes and their meaning.",default:"\"RGB\""},{name:"sources",annotation:"list[Literal[('upload', 'webcam', 'clipboard')]] | None",doc:"List of sources for the image. &quot;upload&quot; creates a box where user can drop an image file, &quot;webcam&quot; allows user to take snapshot from their webcam, &quot;clipboard&quot; allows users to paste an image from the clipboard. If None, defaults to [&quot;upload&quot;, &quot;webcam&quot;, &quot;clipboard&quot;] if streaming is False, otherwise defaults to [&quot;webcam&quot;].",default:"None"},{name:"type",annotation:"Literal[('numpy', 'pil', 'filepath')]",doc:"The format the image is converted before being passed into the prediction function. &quot;numpy&quot; converts the image to a numpy array with shape (height, width, 3) and values from 0 to 255, &quot;pil&quot; converts the image to a PIL image object, &quot;filepath&quot; passes a str path to a temporary file containing the image. If the image is SVG, the `type` is ignored and the filepath of the SVG is returned.",default:"\"numpy\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"show_download_button",annotation:"bool",doc:"If True, will display button to download image.",default:"True"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload and edit an image; if False, can only be used to display images. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"streaming",annotation:"bool",doc:"If True when used in a `live` interface, will automatically stream webcam feed. Only valid is source is &#x27;webcam&#x27;.",default:"False"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"mirror_webcam",annotation:"bool",doc:"If True webcam will be mirrored. Default is True.",default:"True"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"clear",description:"This listener is triggered when the user clears the Image using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-clear"},{fn:null,name:"change",description:"Triggered when the value of the Image changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-change"},{fn:null,name:"stream",description:"This listener is triggered when the user streams the Image.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"hidden\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-stream"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Image. Uses event data gradio.SelectData to carry `value` referring to the label of the Image, and `selected` to refer to state of the Image. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-select"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Image.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Image",slug:"image-upload"}],string_shortcuts:[["Image","image","Uses default values"]],demos:[["image_mod","import gradio as gr\nimport os\n\n\ndef image_mod(image):\n    return image.rotate(45)\n\n\ndemo = gr.Interface(\n    image_mod,\n    gr.Image(type=\"pil\"),\n    \"image\",\n    flagging_options=[\"blurry\", \"incorrect\", \"other\"],\n    examples=[\n        os.path.join(os.path.dirname(__file__), \"images/cheetah1.jpg\"),\n        os.path.join(os.path.dirname(__file__), \"images/lion.jpg\"),\n        os.path.join(os.path.dirname(__file__), \"images/logo.png\"),\n        os.path.join(os.path.dirname(__file__), \"images/tower.jpg\"),\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["image_mod_default_image","import gradio as gr\nimport os\n\n\ndef image_mod(image):\n    return image.rotate(45)\n\n\ncheetah = os.path.join(os.path.dirname(__file__), \"images/cheetah1.jpg\")\n\ndemo = gr.Interface(image_mod, gr.Image(type=\"pil\", value=cheetah), \"image\",\n    flagging_options=[\"blurry\", \"incorrect\", \"other\"], examples=[\n        os.path.join(os.path.dirname(__file__), \"images/lion.jpg\"),\n        os.path.join(os.path.dirname(__file__), \"images/logo.png\")\n        ])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"image-classification-in-pytorch",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:29,pretty_name:"Image Classification In Pytorch",content:"# Image Classification in PyTorch\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own.\n\n```python\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\nBecause we will be using the model for inference, we have called the `.eval()` method.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `PIL` image\n\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image.\n\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/pytorch-image-classifier\">\n\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","RESNET","PYTORCH"],spaces:["https://huggingface.co/spaces/abidlabs/pytorch-image-classifier","https://huggingface.co/spaces/pytorch/ResNet","https://huggingface.co/spaces/pytorch/ResNext","https://huggingface.co/spaces/pytorch/SqueezeNet"],url:"/guides/image-classification-in-pytorch/",contributor:null},{name:"image-classification-in-tensorflow",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:30,pretty_name:"Image Classification In Tensorflow",content:"# Image Classification in TensorFlow and Keras\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own.\n\n```python\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\nThis line automatically downloads the MobileNet model and weights using the Keras library.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `numpy` array\n\nThen, the function adds a batch dimension, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(shape=(224, 224)),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/keras-image-classifier\">\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","MOBILENET","TENSORFLOW"],spaces:["https://huggingface.co/spaces/abidlabs/keras-image-classifier"],url:"/guides/image-classification-in-tensorflow/",contributor:null},{name:"image-classification-with-vision-transformers",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:31,pretty_name:"Image Classification With Vision Transformers",content:"# Image Classification with Vision Transformers\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control.\n\nState-of-the-art image classifiers are based on the _transformers_ architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started).\n\n## Step 1 ‚Äî Choosing a Vision Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks.\n\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\n\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at a resolution of 224x224 pixels. We will use this model for our demo.\n\n## Step 2 ‚Äî Loading the Vision Transformer Model with Gradio\n\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing.\nAll of these are automatically inferred from the model tags.\n\nBesides the import statement, it only takes a single line of Python to load and launch the demo.\n\nWe use the `gr.Interface.load()` method and pass in the path to the model including the `huggingface/` to designate that it is from the Hugging Face Hub.\n\n```python\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples.\n\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a human-interpretable prediction. Try uploading your own image!\n\n\u003Cgradio-app space=\"gradio/vision-transformer\">\n\n---\n\nAnd you're done! In one line of code, you have built a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","TRANSFORMERS","HUB"],spaces:["https://huggingface.co/spaces/abidlabs/vision-transformer"],url:"/guides/image-classification-with-vision-transformers/",contributor:null},{name:"create-your-own-friends-with-a-gan",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:44,pretty_name:"Create Your Own Friends With A Gan",content:"# Create Your Own Friends with a GAN\n\n\n\n\n\n\n## Introduction\n\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we'll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\n\nGenerative Adversarial Networks, often known just as _GANs_, are a specific class of deep-learning models that are designed to learn from an input dataset to create (_generate!_) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\n\nToday we'll briefly look at the high-level intuition behind GANs, and then we'll build a small demo around a pre-trained GAN to see what all the fuss is about. Here's a [peek](https://nimaboscarino-cryptopunks.hf.space) at what we're going to be putting together.\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\n\n## GANs: a very brief introduction\n\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the _generator_, is responsible for generating images. The other network, the _discriminator_, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\n\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (_adversarial!_) relationship, the images that get generated improve to the point where they become indistinguishable to human eyes!\n\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\n\n## Step 1 ‚Äî Create the Generator model\n\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\n\n```python\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\n\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n## Step 2 ‚Äî Defining a `predict` function\n\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it's common to pass random noise into our model as the input, so we'll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`'s `save_image` function to save the output of the model as a `png` file, and return the file name:\n\n```python\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWe're giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We'll then be able to reproduce punks if we want to see them again by passing in the same seed.\n\n_Note!_ Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we'll start by generating 4 punks at a time.\n\n## Step 3 ‚Äî Creating a Gradio interface\n\nAt this point you can even run the code you have with `predict(\u003CSOME_NUMBER>)`, and you'll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we'll build out a simple interface with Gradio. Our goals here are to:\n\n- Set a slider input so users can choose the \"seed\" value\n- Use an image component for our output to showcase the generated punks\n- Use our `predict()` to take the seed and generate the images\n\nWith `gr.Interface()`, we can define all of that with a single function call:\n\n```python\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n\n## Step 4 ‚Äî Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\n\n```python\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\n\n```python\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWhen you relaunch your interface, you should see a second slider that'll let you control the number of punks!\n\n## Step 5 - Polishing it up\n\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ‚ú®\n\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\n\n```python\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we've listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\n\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens üëÄ `article` will also accept HTML, as [explored in a previous guide](/guides/key-features/#descriptive-content)!\n\nWhen you're all done, you may end up with something like [this](https://nimaboscarino-cryptopunks.hf.space).\n\nFor reference, here is our full code:\n\n```python\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n---\n\nCongratulations! You've built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making even more awesome demos ü§ó\n",tags:["GAN","IMAGE","HUB"],spaces:["https://huggingface.co/spaces/NimaBoscarino/cryptopunks","https://huggingface.co/spaces/nateraw/cryptopunks-generator"],url:"/guides/create-your-own-friends-with-a-gan/",contributor:"\u003Ca href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino\u003C/a> and \u003Ca href=\"https://huggingface.co/nateraw\">Nate Raw\u003C/a>"}],parent:"gradio",prev_obj:"HighlightedText",next_obj:"ImageEditor",slug:"image"},imageeditor:{class:null,name:"ImageEditor",description:"Creates an image component that can be used to upload and edit images (as an input) or display images (as an output).",tags:{preprocessing:"passes the uploaded images as a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` are images, while `layers` is a list of images. The images are of type PIL.Image, np.array, or str filepath, depending on the `type` parameter.",postprocessing:"expects a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` should be images or None, while `layers` should be a list of images. Images can be of type PIL.Image, np.array, or str filepath/URL. Or, the value can be simply a single image, in which case it will be used as the background.","examples-format":"a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` should be strings or None, while `layers` should be a list of strings. The image corresponding to `composite`, if not None, is used as the example image. Otherwise, the image corresonding to `background` is used. The strings should be filepaths or URLs. Or, the value can be simply a single string filepath/URL to an image, which is used directly as the example image.",demos:"image_editor"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"EditorValue | ImageType | None",doc:"Optional initial image(s) to populate the image editor. Should be a dictionary with keys: `background`, `layers`, and `composite`. The values corresponding to `background` and `composite` should be images or None, while `layers` should be a list of images. Images can be of type PIL.Image, np.array, or str filepath/URL. Or, the value can be a callable, in which case the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the displayed images, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the displayed images, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"image_mode",annotation:"Literal[('1', 'L', 'P', 'RGB', 'RGBA', 'CMYK', 'YCbCr', 'LAB', 'HSV', 'I', 'F')]",doc:"&quot;RGB&quot; if color, or &quot;L&quot; if black and white. See https://pillow.readthedocs.io/en/stable/handbook/concepts.html for other supported image modes and their meaning.",default:"\"RGBA\""},{name:"sources",annotation:"Iterable[Literal[('upload', 'webcam', 'clipboard')]]",doc:"List of sources that can be used to set the background image. &quot;upload&quot; creates a box where user can drop an image file, &quot;webcam&quot; allows user to take snapshot from their webcam, &quot;clipboard&quot; allows users to paste an image from the clipboard.",default:"('upload', 'webcam', 'clipboard')"},{name:"type",annotation:"Literal[('numpy', 'pil', 'filepath')]",doc:"The format the images are converted to before being passed into the prediction function. &quot;numpy&quot; converts the images to numpy arrays with shape (height, width, 3) and values from 0 to 255, &quot;pil&quot; converts the images to PIL image objects, &quot;filepath&quot; passes images as str filepaths to temporary copies of the images.",default:"\"numpy\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"show_download_button",annotation:"bool",doc:"If True, will display button to download image.",default:"True"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload and edit an image; if False, can only be used to display images. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"mirror_webcam",annotation:"bool",doc:"If True webcam will be mirrored. Default is True.",default:"True"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"crop_size",annotation:"tuple[int | float, int | float] | str | None",doc:"The size of the crop box in pixels. If a tuple, the first value is the width and the second value is the height. If a string, the value must be a ratio in the form `width:height` (e.g. &quot;16:9&quot;).",default:"None"},{name:"transforms",annotation:"Iterable[Literal['crop']]",doc:"The transforms tools to make available to users. &quot;crop&quot; allows the user to crop the image.",default:"('crop',)"},{name:"eraser",annotation:"Eraser | None | Literal[False]",doc:"The options for the eraser tool in the image editor. Should be an instance of the `gr.Eraser` class, or None to use the default settings. Can also be False to hide the eraser tool.",default:"None"},{name:"brush",annotation:"Brush | None | Literal[False]",doc:"The options for the brush tool in the image editor. Should be an instance of the `gr.Brush` class, or None to use the default settings. Can also be False to hide the brush tool, which will also hide the eraser tool.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"clear",description:"This listener is triggered when the user clears the ImageEditor using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-clear"},{fn:null,name:"change",description:"Triggered when the value of the ImageEditor changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the ImageEditor. Uses event data gradio.SelectData to carry `value` referring to the label of the ImageEditor, and `selected` to refer to state of the ImageEditor. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-select"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the ImageEditor.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ImageEditor",slug:"image-editor-upload"}],string_shortcuts:[["ImageEditor","imageeditor","Uses default values"],["Sketchpad","sketchpad","Uses sources=(), brush=Brush(colors=[\"#000000\"], color_mode=\"fixed\")"],["Paint","paint","Uses sources=()"],["ImageMask","imagemask","Uses brush=Brush(colors=[\"#000000\"], color_mode=\"fixed\")"]],demos:[["image_editor","import gradio as gr\nimport time\n\n\ndef sleep(im):\n    time.sleep(5)\n    return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1], im[\"composite\"]]\n\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(\n        type=\"pil\",\n        crop_size=\"1:1\",\n    )\n\n    with gr.Group():\n        with gr.Row():\n            im_out_1 = gr.Image(type=\"pil\")\n            im_out_2 = gr.Image(type=\"pil\")\n            im_out_3 = gr.Image(type=\"pil\")\n            im_out_4 = gr.Image(type=\"pil\")\n\n    btn = gr.Button()\n    im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3, im_out_4], inputs=im)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Image",next_obj:"JSON",slug:"image-editor"},json:{class:null,name:"JSON",description:"Used to display arbitrary JSON output prettily. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a {str} filepath to a file containing valid JSON -- or a {list} or {dict} that is valid JSON",demos:"zip_to_json, blocks_xray"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | dict | list | Callable | None",doc:"Default value. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the JSON changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.JSON",slug:"json-change"}],string_shortcuts:[["JSON","json","Uses default values"]],demos:[["zip_to_json","from zipfile import ZipFile\n\nimport gradio as gr\n\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_xray","import gradio as gr\nimport time\n\ndisease_values = [0.25, 0.5, 0.75]\n\ndef xray_model(diseases, img):\n    return [{disease: disease_values[idx] for idx,disease in enumerate(diseases)}]\n\n\ndef ct_model(diseases, img):\n    return [{disease: 0.1 for disease in diseases}]\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n# Detect Disease From Scan\nWith this model you can lorem ipsum\n- ipsum 1\n- ipsum 2\n\"\"\"\n    )\n    gr.DuplicateButton()\n    disease = gr.CheckboxGroup(\n        info=\"Select the diseases you want to scan for.\",\n        choices=[\"Covid\", \"Malaria\", \"Lung Cancer\"], label=\"Disease to Scan For\"\n    )\n    slider = gr.Slider(0, 100)\n\n    with gr.Tab(\"X-ray\") as x_tab:\n        with gr.Row():\n            xray_scan = gr.Image()\n            xray_results = gr.JSON()\n        xray_run = gr.Button(\"Run\")\n        xray_run.click(\n            xray_model,\n            inputs=[disease, xray_scan],\n            outputs=xray_results,\n            api_name=\"xray_model\"\n        )\n\n    with gr.Tab(\"CT Scan\"):\n        with gr.Row():\n            ct_scan = gr.Image()\n            ct_results = gr.JSON()\n        ct_run = gr.Button(\"Run\")\n        ct_run.click(\n            ct_model,\n            inputs=[disease, ct_scan],\n            outputs=ct_results,\n            api_name=\"ct_model\"\n        )\n\n    upload_btn = gr.Button(\"Upload Results\", variant=\"primary\")\n    upload_btn.click(\n        lambda ct, xr: None,\n        inputs=[ct_results, xray_results],\n        outputs=[],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"ImageEditor",next_obj:"Label",slug:"json"},label:{class:null,name:"Label",description:"Displays a classification label, along with confidence scores of top categories, if provided. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a {Dict[str, float]} of classes and confidences, or {str} with just the class or an {int}/{float} for regression outputs, or a {str} path to a .json file containing a json dictionary in the structure produced by Label.postprocess().",demos:"main_note, titanic_survival",guides:"image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"dict[str, float] | str | float | Callable | None",doc:"Default value to show in the component. If a str or number is provided, simply displays the string or number. If a {Dict[str, float]} of classes and confidences is provided, displays the top class on top and the `num_top_classes` below, along with their confidence bars. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"num_top_classes",annotation:"int | None",doc:"number of most confident classes to show.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"color",annotation:"str | None",doc:"The background color of the label (either a valid css color name or hexadecimal string).",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Label changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Label",slug:"label-change"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Label. Uses event data gradio.SelectData to carry `value` referring to the label of the Label, and `selected` to refer to state of the Label. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Label",slug:"label-select"}],string_shortcuts:[["Label","label","Uses default values"]],demos:[["main_note","from math import log2, pow\nimport os\n\nimport numpy as np\nfrom scipy.fftpack import fft\n\nimport gradio as gr\n\nA4 = 440\nC0 = A4 * pow(2, -4.75)\nname = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\n\ndef get_pitch(freq):\n    h = round(12 * log2(freq / C0))\n    n = h % 12\n    return name[n]\n\n\ndef main_note(audio):\n    rate, y = audio\n    if len(y.shape) == 2:\n        y = y.T[0]\n    N = len(y)\n    T = 1.0 / rate\n    yf = fft(y)\n    yf2 = 2.0 / N * np.abs(yf[0 : N // 2])\n    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n\n    volume_per_pitch = {}\n    total_volume = np.sum(yf2)\n    for freq, volume in zip(xf, yf2):\n        if freq == 0:\n            continue\n        pitch = get_pitch(freq)\n        if pitch not in volume_per_pitch:\n            volume_per_pitch[pitch] = 0\n        volume_per_pitch[pitch] += 1.0 * volume / total_volume\n    volume_per_pitch = {k: float(v) for k, v in volume_per_pitch.items()}\n    return volume_per_pitch\n\n\ndemo = gr.Interface(\n    main_note,\n    gr.Audio(sources=[\"microphone\"]),\n    gr.Label(num_top_classes=4),\n    examples=[\n        [os.path.join(os.path.dirname(__file__),\"audio/recording1.wav\")],\n        [os.path.join(os.path.dirname(__file__),\"audio/cantina.wav\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"image-classification-in-pytorch",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:29,pretty_name:"Image Classification In Pytorch",content:"# Image Classification in PyTorch\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own.\n\n```python\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\nBecause we will be using the model for inference, we have called the `.eval()` method.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `PIL` image\n\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image.\n\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/pytorch-image-classifier\">\n\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","RESNET","PYTORCH"],spaces:["https://huggingface.co/spaces/abidlabs/pytorch-image-classifier","https://huggingface.co/spaces/pytorch/ResNet","https://huggingface.co/spaces/pytorch/ResNext","https://huggingface.co/spaces/pytorch/SqueezeNet"],url:"/guides/image-classification-in-pytorch/",contributor:null},{name:"image-classification-in-tensorflow",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:30,pretty_name:"Image Classification In Tensorflow",content:"# Image Classification in TensorFlow and Keras\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own.\n\n```python\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\nThis line automatically downloads the MobileNet model and weights using the Keras library.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `numpy` array\n\nThen, the function adds a batch dimension, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(shape=(224, 224)),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/keras-image-classifier\">\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","MOBILENET","TENSORFLOW"],spaces:["https://huggingface.co/spaces/abidlabs/keras-image-classifier"],url:"/guides/image-classification-in-tensorflow/",contributor:null},{name:"image-classification-with-vision-transformers",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:31,pretty_name:"Image Classification With Vision Transformers",content:"# Image Classification with Vision Transformers\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control.\n\nState-of-the-art image classifiers are based on the _transformers_ architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started).\n\n## Step 1 ‚Äî Choosing a Vision Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks.\n\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\n\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at a resolution of 224x224 pixels. We will use this model for our demo.\n\n## Step 2 ‚Äî Loading the Vision Transformer Model with Gradio\n\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing.\nAll of these are automatically inferred from the model tags.\n\nBesides the import statement, it only takes a single line of Python to load and launch the demo.\n\nWe use the `gr.Interface.load()` method and pass in the path to the model including the `huggingface/` to designate that it is from the Hugging Face Hub.\n\n```python\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples.\n\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a human-interpretable prediction. Try uploading your own image!\n\n\u003Cgradio-app space=\"gradio/vision-transformer\">\n\n---\n\nAnd you're done! In one line of code, you have built a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","TRANSFORMERS","HUB"],spaces:["https://huggingface.co/spaces/abidlabs/vision-transformer"],url:"/guides/image-classification-with-vision-transformers/",contributor:null}],parent:"gradio",prev_obj:"JSON",next_obj:"LinePlot",slug:"label"},lineplot:{class:null,name:"LinePlot",description:"Create a line plot. \u003Cbr> \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a pandas dataframe with the data to plot.",demos:"line_plot, live_dashboard"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Callable | None",doc:"The pandas dataframe containing the data to display in a scatter plot.",default:"None"},{name:"x",annotation:"str | None",doc:"Column corresponding to the x axis.",default:"None"},{name:"y",annotation:"str | None",doc:"Column corresponding to the y axis.",default:"None"},{name:"color",annotation:"str | None",doc:"The column to determine the point color. If the column contains numeric data, gradio will interpolate the column data so that small values correspond to light colors and large values correspond to dark values.",default:"None"},{name:"stroke_dash",annotation:"str | None",doc:"The column to determine the symbol used to draw the line, e.g. dashed lines, dashed lines with points.",default:"None"},{name:"overlay_point",annotation:"bool | None",doc:"Whether to draw a point on the line for each (x, y) coordinate pair.",default:"None"},{name:"title",annotation:"str | None",doc:"The title to display on top of the chart.",default:"None"},{name:"tooltip",annotation:"list[str] | str | None",doc:"The column (or list of columns) to display on the tooltip when a user hovers a point on the plot.",default:"None"},{name:"x_title",annotation:"str | None",doc:"The title given to the x axis. By default, uses the value of the x parameter.",default:"None"},{name:"y_title",annotation:"str | None",doc:"The title given to the y axis. By default, uses the value of the y parameter.",default:"None"},{name:"x_label_angle",annotation:"float | None",doc:"The angle for the x axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"y_label_angle",annotation:"float | None",doc:"The angle for the y axis labels. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"color_legend_title",annotation:"str | None",doc:"The title given to the color legend. By default, uses the value of color parameter.",default:"None"},{name:"stroke_dash_legend_title",annotation:"str | None",doc:"The title given to the stroke_dash legend. By default, uses the value of the stroke_dash parameter.",default:"None"},{name:"color_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the color legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"stroke_dash_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the stoke_dash legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"x_lim",annotation:"list[int] | None",doc:"A tuple or list containing the limits for the x-axis, specified as [x_min, x_max].",default:"None"},{name:"y_lim",annotation:"list[int] | None",doc:"A tuple of list containing the limits for the y-axis, specified as [y_min, y_max].",default:"None"},{name:"caption",annotation:"str | None",doc:"The (optional) caption to display below the plot.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether users should be able to interact with the plot by panning or zooming with their mouse or trackpad.",default:"True"},{name:"label",annotation:"str | None",doc:"The (optional) label to display on the top left corner of the plot.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"Whether the label should be displayed.",default:"None"},{name:"container",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"None"},{name:"min_width",annotation:"int",doc:null,default:"160"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"visible",annotation:"bool",doc:"Whether the plot should be visible.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"show_actions_button",annotation:"bool",doc:"Whether to show the actions button on the top right corner of the plot.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LinePlot",slug:"line-plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LinePlot",slug:"line-plot-clear"}],string_shortcuts:[["LinePlot","lineplot","Uses default values"]],demos:[["line_plot","import gradio as gr\nfrom vega_datasets import data\n\nstocks = data.stocks()\ngapminder = data.gapminder()\ngapminder = gapminder.loc[\n    gapminder.country.isin([\"Argentina\", \"Australia\", \"Afghanistan\"])\n]\nclimate = data.climate()\nseattle_weather = data.seattle_weather()\n\n## Or generate your own fake data, here's an example for stocks:\n#\n# import pandas as pd\n# import random\n#\n# stocks = pd.DataFrame(\n#     {\n#         \"symbol\": [\n#             random.choice(\n#                 [\n#                     \"MSFT\",\n#                     \"AAPL\",\n#                     \"AMZN\",\n#                     \"IBM\",\n#                     \"GOOG\",\n#                 ]\n#             )\n#             for _ in range(120)\n#         ],\n#         \"date\": [\n#             pd.Timestamp(year=2000 + i, month=j, day=1)\n#             for i in range(10)\n#             for j in range(1, 13)\n#         ],\n#         \"price\": [random.randint(10, 200) for _ in range(120)],\n#     }\n# )\n\n\ndef line_plot_fn(dataset):\n    if dataset == \"stocks\":\n        return gr.LinePlot(\n            stocks,\n            x=\"date\",\n            y=\"price\",\n            color=\"symbol\",\n            color_legend_position=\"bottom\",\n            title=\"Stock Prices\",\n            tooltip=[\"date\", \"price\", \"symbol\"],\n            height=300,\n            width=500,\n        )\n    elif dataset == \"climate\":\n        return gr.LinePlot(\n            climate,\n            x=\"DATE\",\n            y=\"HLY-TEMP-NORMAL\",\n            y_lim=[250, 500],\n            title=\"Climate\",\n            tooltip=[\"DATE\", \"HLY-TEMP-NORMAL\"],\n            height=300,\n            width=500,\n        )\n    elif dataset == \"seattle_weather\":\n        return gr.LinePlot(\n            seattle_weather,\n            x=\"date\",\n            y=\"temp_min\",\n            tooltip=[\"weather\", \"date\"],\n            overlay_point=True,\n            title=\"Seattle Weather\",\n            height=300,\n            width=500,\n        )\n    elif dataset == \"gapminder\":\n        return gr.LinePlot(\n            gapminder,\n            x=\"year\",\n            y=\"life_expect\",\n            color=\"country\",\n            title=\"Life expectancy for countries\",\n            stroke_dash=\"cluster\",\n            x_lim=[1950, 2010],\n            tooltip=[\"country\", \"life_expect\"],\n            stroke_dash_legend_title=\"Country Cluster\",\n            height=300,\n            width=500,\n        )\n\n\nwith gr.Blocks() as line_plot:\n    with gr.Row():\n        with gr.Column():\n            dataset = gr.Dropdown(\n                choices=[\"stocks\", \"climate\", \"seattle_weather\", \"gapminder\"],\n                value=\"stocks\",\n            )\n        with gr.Column():\n            plot = gr.LinePlot()\n    dataset.change(line_plot_fn, inputs=dataset, outputs=plot)\n    line_plot.load(fn=line_plot_fn, inputs=dataset, outputs=plot)\n\n\nif __name__ == \"__main__\":\n    line_plot.launch()\n"],["live_dashboard","import math\n\nimport pandas as pd\n\nimport gradio as gr\nimport datetime\nimport numpy as np\n\n\ndef get_time():\n    return datetime.datetime.now()\n\n\nplot_end = 2 * math.pi\n\n\ndef get_plot(period=1):\n    global plot_end\n    x = np.arange(plot_end - 2 * math.pi, plot_end, 0.02)\n    y = np.sin(2 * math.pi * period * x)\n    update = gr.LinePlot(\n        value=pd.DataFrame({\"x\": x, \"y\": y}),\n        x=\"x\",\n        y=\"y\",\n        title=\"Plot (updates every second)\",\n        width=600,\n        height=350,\n    )\n    plot_end += 2 * math.pi\n    if plot_end > 1000:\n        plot_end = 2 * math.pi\n    return update\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            c_time2 = gr.Textbox(label=\"Current Time refreshed every second\")\n            gr.Textbox(\n                \"Change the value of the slider to automatically update the plot\",\n                label=\"\",\n            )\n            period = gr.Slider(\n                label=\"Period of plot\", value=1, minimum=0, maximum=10, step=1\n            )\n            plot = gr.LinePlot(show_label=False)\n        with gr.Column():\n            name = gr.Textbox(label=\"Enter your name\")\n            greeting = gr.Textbox(label=\"Greeting\")\n            button = gr.Button(value=\"Greet\")\n            button.click(lambda s: f\"Hello {s}\", name, greeting)\n\n    demo.load(lambda: datetime.datetime.now(), None, c_time2, every=1)\n    dep = demo.load(get_plot, None, plot, every=1)\n    period.change(get_plot, period, plot, every=1, cancels=[dep])\n\nif __name__ == \"__main__\":\n    demo.queue().launch()\n"]],parent:"gradio",prev_obj:"Label",next_obj:"LoginButton",slug:"line-plot"},loginbutton:{class:null,name:"LoginButton",description:"Button that redirects the user to Sign with Hugging Face using OAuth.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str",doc:null,default:"\"Sign in with Hugging Face\""},{name:"logout_value",annotation:"str",doc:"The text to display when the user is signed in. The string should contain a placeholder for the username with a call-to-action to logout, e.g. &quot;Logout ({})&quot;.",default:"\"Logout ({})\""},{name:"every",annotation:"float | None",doc:null,default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:null,default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:null,default:"None"},{name:"icon",annotation:"str | None",doc:null,default:"\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\""},{name:"link",annotation:"str | None",doc:null,default:"None"},{name:"visible",annotation:"bool",doc:null,default:"True"},{name:"interactive",annotation:"bool",doc:null,default:"True"},{name:"elem_id",annotation:"str | None",doc:null,default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:null,default:"None"},{name:"render",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"0"},{name:"min_width",annotation:"int | None",doc:null,default:"None"},{name:"signed_in_value",annotation:"str",doc:null,default:"\"Signed in as {}\""}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LoginButton",slug:"login-button-click"}],string_shortcuts:[["LoginButton","loginbutton","Uses default values"]],parent:"gradio",prev_obj:"LinePlot",next_obj:"LogoutButton",slug:"login-button"},logoutbutton:{class:null,name:"LogoutButton",description:"Button to log out a user from a Space. \u003Cbr>       which handles both the login and logout processes.",tags:{note:"`LogoutButton` component is deprecated. Please use `gr.LoginButton` instead"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str",doc:"Default text for the button to display. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"Logout\""},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:"URL or path to the icon file to display within the button. If None, no icon will be displayed. Must be within the working directory of the Gradio app or an external URL.",default:"\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\""},{name:"link",annotation:"str | None",doc:"URL to open when the button is clicked. If None, no link will be used.",default:"\"/logout\""},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"interactive",annotation:"bool",doc:"If False, the Button will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"0"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the Button is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.LogoutButton",slug:"logout-button-click"}],string_shortcuts:[["LogoutButton","logoutbutton","Uses default values"]],parent:"gradio",prev_obj:"LoginButton",next_obj:"Markdown",slug:"logout-button"},markdown:{class:null,name:"Markdown",description:"Used to render arbitrary Markdown output. Can also render latex enclosed by dollar signs. \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a valid {str} that can be rendered as Markdown.",demos:"blocks_hello, blocks_kinematics",guides:"key-features"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable",doc:"Value to show in Markdown component. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"\""},{name:"label",annotation:"str | None",doc:"The label for this component. Is used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"This parameter has no effect.",default:"None"},{name:"rtl",annotation:"bool",doc:"If True, sets the direction of the rendered text to right-to-left. Default is False, which renders text left-to-right.",default:"False"},{name:"latex_delimiters",annotation:"list[dict[str, str | bool]] | None",doc:"A list of dicts of the form {&quot;left&quot;: open delimiter (str), &quot;right&quot;: close delimiter (str), &quot;display&quot;: whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ &quot;left&quot;: &quot;$$&quot;, &quot;right&quot;: &quot;$$&quot;, &quot;display&quot;: True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html).",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"sanitize_html",annotation:"bool",doc:"If False, will disable HTML sanitization when converted from markdown. This is not recommended, as it can lead to security vulnerabilities.",default:"True"},{name:"line_breaks",annotation:"bool",doc:"If True, will enable Github-flavored Markdown line breaks in chatbot messages. If False (default), single new lines will be ignored.",default:"False"},{name:"header_links",annotation:"bool",doc:"If True, will automatically create anchors for headings, displaying a link icon on hover.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Markdown changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Markdown",slug:"markdown-change"}],string_shortcuts:[["Markdown","markdown","Uses default values"]],demos:[["blocks_hello","import gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    \"\"\"\n    # Hello World!\n    Start typing below to see the output.\n    \"\"\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\nif __name__ == \"__main__\":\n    demo.launch()"],["blocks_kinematics","import pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"key-features",category:"getting-started",pretty_category:"Getting Started",guide_index:2,absolute_index:1,pretty_name:"Key Features",content:"# Key Features\n\nLet's go through some of the key features of Gradio. This guide is intended to be a high-level overview of various things that you should be aware of as you build your demo. Where appropriate, we link to more detailed guides on specific topics.\n\n1. [Components](#components)\n2. [Queuing](#queuing)\n3. [Streaming outputs](#streaming-outputs)\n4. [Streaming inputs](#streaming-inputs)\n5. [Alert modals](#alert-modals)\n6. [Styling](#styling)\n7. [Progress bars](#progress-bars)\n8. [Batch functions](#batch-functions)\n\n## Components\n\nGradio includes more than 30 pre-built components (as well as many user-built _custom components_) that can be used as inputs or outputs in your demo with a single line of code. These components correspond to common data types in machine learning and data science, e.g. the `gr.Image` component is designed to handle input or output images, the `gr.Label` component displays classification labels and probabilities, the `gr.Plot` component displays various kinds of plots, and so on.\n\nEach component includes various constructor attributes that control the properties of the component. For example, you can control the number of lines in a `gr.Textbox` using the `lines` argument (which takes a positive integer) in its constructor. Or you can control the way that a user can provide an image in the `gr.Image` component using the `sources` parameter (which takes a list like `[\"webcam\", \"upload\"]`).\n\n**Static and Interactive Components**\n\nEvery component has a _static_ version that is designed to *display* data, and most components also have an _interactive_ version designed to let users input or modify the data. Typically, you don't need to think about this distinction, because when you build a Gradio demo, Gradio automatically figures out whether the component should be static or interactive based on whether it is being used as an input or output. However, you can set this manually using the `interactive` argument that every component supports.\n\n**Preprocessing and Postprocessing**\n\nWhen a component is used as an input, Gradio automatically handles the _preprocessing_ needed to convert the data from a type sent by the user's browser (such as an uploaded image) to a form that can be accepted by your function (such as a `numpy` array).\n\n\nSimilarly, when a component is used as an output, Gradio automatically handles the _postprocessing_ needed to convert the data from what is returned by your function (such as a list of image paths) to a form that can be displayed in the user's browser (a gallery of images).\n\nConsider an example demo with three input components (`gr.Textbox`, `gr.Number`, and `gr.Image`) and two outputs (`gr.Number` and `gr.Gallery`) that serve as a UI for your image-to-image generation model. Below is a diagram of what our preprocessing will send to the model and what our postprocessing will require from it.\n\n![](https://github.com/gradio-app/gradio/blob/main/guides/assets/dataflow.svg?raw=true)\n\nIn this image, the following preprocessing steps happen to send the data from the browser to your function:\n\n* The text in the textbox is converted to a Python `str` (essentially no preprocessing)\n* The number in the number input in converted to a Python `float` (essentially no preprocessing)\n* Most importantly, ihe image supplied by the user is converted to a `numpy.array` representation of the RGB values in the image\n\nImages are converted to NumPy arrays because they are a common format for machine learning workflows. You can control the _preprocessing_ using the component's parameters when constructing the component. For example, if you instantiate the `Image` component with the following parameters, it will preprocess the image to the `PIL` format instead:\n\n```py\nimg = gr.Image(type=\"pil\")\n```\n\nPostprocessing is even simpler! Gradio automatically recognizes the format of the returned data (e.g. does the user's function return a `numpy` array or a `str` filepath for the `gr.Image` component?) and postprocesses it appropriately into a format that can be displayed by the browser.\n\nSo in the image above, the following postprocessing steps happen to send the data returned from a user's function to the browser:\n\n* The `float` is displayed as a number and displayed directly to the user\n* The list of string filepaths (`list[str]`) is interpreted as a list of image filepaths and displayed as a gallery in the browser\n\nTake a look at the [Docs](https://gradio.app/docs) to see all the parameters for each Gradio component.\n\n## Queuing\n\nEvery Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. You can configure the queue by using `queue()` method which is supported by the `gr.Interface`, `gr.Blocks`, and `gr.ChatInterface` classes. \n\nFor example, you can control the number of requests processed at a single time by setting the `default_concurrency_limit` parameter of `queue()`, e.g.\n\n```python\ndemo = gr.Interface(...).queue(default_concurrency_limit=5)\ndemo.launch()\n```\n\nThis limits the number of requests processed for this event listener at a single time to 5. By default, the `default_concurrency_limit` is actually set to `1`, which means that when many users are using your app, only a single user's request will be processed at a time. This is because many machine learning functions consume a significant amount of memory and so it is only suitable to have a single user using the demo at a time. However, you can change this parameter in your demo easily.\n\nSee the [docs on queueing](/docs/interface#interface-queue) for more details on configuring the queuing parameters.\n\n## Streaming outputs\n\nIn some cases, you may want to stream a sequence of outputs rather than show a single output at once. For example, you might have an image generation model and you want to show the image that is generated at each step, leading up to the final image. Or you might have a chatbot which streams its response one token at a time instead of returning it all at once.\n\nIn such cases, you can supply a **generator** function into Gradio instead of a regular function. Creating generators in Python is very simple: instead of a single `return` value, a function should `yield` a series of values instead. Usually the `yield` statement is put in some kind of loop. Here's an example of an generator that simply counts up to a given number:\n\n```python\ndef my_generator(x):\n    for i in range(x):\n        yield i\n```\n\nYou supply a generator into Gradio the same way as you would a regular function. For example, here's a a (fake) image generation model that generates noise for several steps before outputting an image using the `gr.Interface` class:\n\n```python\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef fake_diffusion(steps):\n    for i in range(steps):\n        time.sleep(1)\n        image = np.random.random((600, 600, 3))\n        yield image\n    image = np.ones((1000,1000,3), np.uint8)\n    image[:] = [255, 124, 0]\n    yield image\n\n\ndemo = gr.Interface(fake_diffusion, inputs=gr.Slider(1, 10, 3), outputs=\"image\")\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/fake_diffusion'>\u003C/gradio-app>\n\nNote that we've added a `time.sleep(1)` in the iterator to create an artificial pause between steps so that you are able to observe the steps of the iterator (in a real image generation model, this probably wouldn't be necessary).\n\n## Streaming inputs\n\nSimilarly, Gradio can handle streaming inputs, e.g. a live audio stream that can gets transcribed to text in real time, or an image generation model that reruns every time a user types a letter in a textbox. This is covered in more details in our guide on building [reactive Interfaces](/guides/reactive-interfaces). \n\n## Alert modals\n\nYou may wish to raise alerts to the user. To do so, raise a `gr.Error(\"custom message\")` to display an error message. You can also issue `gr.Warning(\"message\")` and `gr.Info(\"message\")` by having them as standalone lines in your function, which will immediately display modals while continuing the execution of your function. Queueing needs to be enabled for this to work.\n\nNote below how the `gr.Error` has to be raised, while the `gr.Warning` and `gr.Info` are single lines.\n\n```python\ndef start_process(name):\n    gr.Info(\"Starting process\")\n    if name is None:\n        gr.Warning(\"Name is empty\")\n    ...\n    if success == False:\n        raise gr.Error(\"Process failed\")\n```\n\n\n\n## Styling\n\nGradio themes are the easiest way to customize the look and feel of your app. You can choose from a variety of themes, or create your own. To do so, pass the `theme=` kwarg to the `Interface` constructor. For example:\n\n```python\ndemo = gr.Interface(..., theme=gr.themes.Monochrome())\n```\n\nGradio comes with a set of prebuilt themes which you can load from `gr.themes.*`. You can extend these themes or create your own themes from scratch - see the [theming guide](https://gradio.app/guides/theming-guide) for more details.\n\nFor additional styling ability, you can pass any CSS (as well as custom JavaScript) to your Gradio application. This is discussed in more detail in our [custom JS and CSS guide](/guides/custom-CSS-and-JS).\n\n\n## Progress bars\n\nGradio supports the ability to create custom Progress Bars so that you have customizability and control over the progress update that you show to the user. In order to enable this, simply add an argument to your method that has a default value of a `gr.Progress` instance. Then you can update the progress levels by calling this instance directly with a float between 0 and 1, or using the `tqdm()` method of the `Progress` instance to track progress over an iterable, as shown below.\n\n```python\nimport gradio as gr\nimport time\n\ndef slowly_reverse(word, progress=gr.Progress()):\n    progress(0, desc=\"Starting\")\n    time.sleep(1)\n    progress(0.05)\n    new_string = \"\"\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\n        time.sleep(0.25)\n        new_string = letter + new_string\n    return new_string\n\ndemo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/progress_simple'>\u003C/gradio-app>\n\nIf you use the `tqdm` library, you can even report progress updates automatically from any `tqdm.tqdm` that already exists within your function by setting the default argument as `gr.Progress(track_tqdm=True)`!\n\n## Batch functions\n\nGradio supports the ability to pass _batch_ functions. Batch functions are just\nfunctions which take in a list of inputs and return a list of predictions.\n\nFor example, here is a batched function that takes in two lists of inputs (a list of\nwords and a list of ints), and returns a list of trimmed words as output:\n\n```py\nimport time\n\ndef trim_words(words, lens):\n    trimmed_words = []\n    time.sleep(5)\n    for w, l in zip(words, lens):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n```\n\nThe advantage of using batched functions is that if you enable queuing, the Gradio server can automatically _batch_ incoming requests and process them in parallel,\npotentially speeding up your demo. Here's what the Gradio code looks like (notice the `batch=True` and `max_batch_size=16`)\n\nWith the `gr.Interface` class:\n\n```python\ndemo = gr.Interface(\n    fn=trim_words, \n    inputs=[\"textbox\", \"number\"], \n    outputs=[\"output\"],\n    batch=True, \n    max_batch_size=16\n)\n\ndemo.launch()\n```\n\nWith the `gr.Blocks` class:\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        word = gr.Textbox(label=\"word\")\n        leng = gr.Number(label=\"leng\")\n        output = gr.Textbox(label=\"Output\")\n    with gr.Row():\n        run = gr.Button()\n\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\n\ndemo.launch()\n```\n\nIn the example above, 16 requests could be processed in parallel (for a total inference time of 5 seconds), instead of each request being processed separately (for a total\ninference time of 80 seconds). Many Hugging Face `transformers` and `diffusers` models work very naturally with Gradio's batch mode: here's [an example demo using diffusers to\ngenerate images in batches](https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.py)\n\n\n",tags:[],spaces:[],url:"/guides/key-features/",contributor:null}],parent:"gradio",prev_obj:"LogoutButton",next_obj:"Model3D",slug:"markdown"},model3d:{class:null,name:"Model3D",description:"Component allows users to upload or view 3D Model files (.obj, .glb, or .gltf). \u003Cbr>",tags:{preprocessing:"This component passes the uploaded file as a {str}filepath.",postprocessing:"expects function to return a {str} or {pathlib.Path} filepath of type (.obj, glb, or .gltf)",demos:"model3D",guides:"how-to-use-3D-model-component"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable | None",doc:"path to (.obj, glb, or .gltf) file to show in model3D viewer. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"clear_color",annotation:"tuple[float, float, float, float] | None",doc:"background color of scene, should be a tuple of 4 floats between 0 and 1 representing RGBA values.",default:"None"},{name:"camera_position",annotation:"tuple[int | float | None, int | float | None, int | float | None]",doc:"initial camera position of scene, provided as a tuple of `(alpha, beta, radius)`. Each value is optional. If provided, `alpha` and `beta` should be in degrees reflecting the angular position along the longitudinal and latitudinal axes, respectively. Radius corresponds to the distance from the center of the object to the camera.",default:"(None, None, None)"},{name:"zoom_speed",annotation:"float",doc:"the speed of zooming in and out of the scene when the cursor wheel is rotated or when screen is pinched on a mobile device. Should be a positive float, increase this value to make zooming faster, decrease to make it slower. Affects the wheelPrecision property of the camera.",default:"1"},{name:"pan_speed",annotation:"float",doc:"the speed of panning the scene when the cursor is dragged or when the screen is dragged on a mobile device. Should be a positive float, increase this value to make panning faster, decrease to make it slower. Affects the panSensibility property of the camera.",default:"1"},{name:"height",annotation:"int | str | None",doc:"The height of the model3D component, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a file; if False, can only be used to display files. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Model3D changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-change"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Model3D.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-upload"},{fn:null,name:"edit",description:"This listener is triggered when the user edits the Model3D (e.g. image) using the built-in editor.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-edit"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Model3D using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Model3D",slug:"model3-d-clear"}],string_shortcuts:[["Model3D","model3d","Uses default values"]],demos:[["model3D","import gradio as gr\nimport os\n\n\ndef load_mesh(mesh_file_name):\n    return mesh_file_name\n\n\ndemo = gr.Interface(\n    fn=load_mesh,\n    inputs=gr.Model3D(),\n    outputs=gr.Model3D(\n            clear_color=[0.0, 0.0, 0.0, 0.0],  label=\"3D Model\"),\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"files/Bunny.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Duck.glb\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Fox.gltf\")],\n        [os.path.join(os.path.dirname(__file__), \"files/face.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/sofia.stl\")],\n    ],\n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"how-to-use-3D-model-component",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:46,pretty_name:"How To Use 3D Model Component",content:"# How to Use the 3D Model Component\n\n\n\n\n## Introduction\n\n3D models are becoming more popular in machine learning and make for some of the most fun demos to experiment with. Using `gradio`, you can easily build a demo of your 3D image model and share it with anyone. The Gradio 3D Model component accepts 3 file types including: _.obj_, _.glb_, & _.gltf_.\n\nThis guide will show you how to build a demo for your 3D image model in a few lines of code; like the one below. Play around with 3D object by clicking around, dragging and zooming:\n\n\u003Cgradio-app space=\"gradio/Model3D\"> \u003C/gradio-app>\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](https://gradio.app/guides/quickstart).\n\n## Taking a Look at the Code\n\nLet's take a look at how to create the minimal interface above. The prediction function in this case will just return the original 3D model mesh, but you can change this function to run inference on your machine learning model. We'll take a look at more complex examples below.\n\n```python\nimport gradio as gr\nimport os\n\n\ndef load_mesh(mesh_file_name):\n    return mesh_file_name\n\n\ndemo = gr.Interface(\n    fn=load_mesh,\n    inputs=gr.Model3D(),\n    outputs=gr.Model3D(\n            clear_color=[0.0, 0.0, 0.0, 0.0],  label=\"3D Model\"),\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"files/Bunny.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Duck.glb\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Fox.gltf\")],\n        [os.path.join(os.path.dirname(__file__), \"files/face.obj\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\nLet's break down the code above:\n\n`load_mesh`: This is our 'prediction' function and for simplicity, this function will take in the 3D model mesh and return it.\n\nCreating the Interface:\n\n- `fn`: the prediction function that is used when the user clicks submit. In our case this is the `load_mesh` function.\n- `inputs`: create a model3D input component. The input expects an uploaded file as a {str} filepath.\n- `outputs`: create a model3D output component. The output component also expects a file as a {str} filepath.\n  - `clear_color`: this is the background color of the 3D model canvas. Expects RGBa values.\n  - `label`: the label that appears on the top left of the component.\n- `examples`: list of 3D model files. The 3D model component can accept _.obj_, _.glb_, & _.gltf_ file types.\n- `cache_examples`: saves the predicted output for the examples, to save time on inference.\n\n## Exploring a more complex Model3D Demo:\n\nBelow is a demo that uses the DPT model to predict the depth of an image and then uses 3D Point Cloud to create a 3D object. Take a look at the [app.py](https://huggingface.co/spaces/gradio/dpt-depth-estimation-3d-obj/blob/main/app.py) file for a peek into the code and the model prediction function.\n\u003Cgradio-app space=\"gradio/dpt-depth-estimation-3d-obj\"> \u003C/gradio-app>\n\n---\n\nAnd you're done! That's all the code you need to build an interface for your Model3D model. Here are some references that you may find useful:\n\n- Gradio's [\"Getting Started\" guide](https://gradio.app/getting_started/)\n- The first [3D Model Demo](https://huggingface.co/spaces/gradio/Model3D) and [complete code](https://huggingface.co/spaces/gradio/Model3D/tree/main) (on Hugging Face Spaces)\n",tags:["VISION","IMAGE"],spaces:["https://huggingface.co/spaces/gradio/Model3D","https://huggingface.co/spaces/gradio/PIFu-Clothed-Human-Digitization","https://huggingface.co/spaces/gradio/dpt-depth-estimation-3d-obj"],url:"/guides/how-to-use-3D-model-component/",contributor:null}],parent:"gradio",prev_obj:"Markdown",next_obj:"Number",slug:"model3-d"},number:{class:null,name:"Number",description:"Creates a numeric field for user to enter numbers as input or display numeric output. \u003Cbr>",tags:{preprocessing:"passes field value as a {float} or {int} into the function, depending on `precision`.",postprocessing:"expects an {int} or {float} returned from the function and sets field value to it.","examples-format":"a {float} or {int} representing the number&#x27;s value.",demos:"tax_calculator, titanic_survival, blocks_simple_squares"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"float | Callable | None",doc:"default value. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will be editable; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"precision",annotation:"int | None",doc:"Precision to round input/output to. If set to 0, will round to nearest integer and convert type to int. If None, no rounding happens.",default:"None"},{name:"minimum",annotation:"float | None",doc:"Minimum value. Only applied when component is used as an input. If a user provides a smaller value, a gr.Error exception is raised by the backend.",default:"None"},{name:"maximum",annotation:"float | None",doc:"Maximum value. Only applied when component is used as an input. If a user provides a larger value, a gr.Error exception is raised by the backend.",default:"None"},{name:"step",annotation:"float",doc:"The interval between allowed numbers in the component. Can be used along with optional parameters `minimum` and `maximum` to create a range of legal values starting from `minimum` and incrementing according to this parameter.",default:"1"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Number changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Number.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-input"},{fn:null,name:"submit",description:"This listener is triggered when the user presses the Enter key while the Number is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-submit"},{fn:null,name:"focus",description:"This listener is triggered when the Number is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Number",slug:"number-focus"}],string_shortcuts:[["Number","number","Uses default values"]],demos:[["tax_calculator","import gradio as gr\n\ndef tax_calculator(income, marital_status, assets):\n    tax_brackets = [(10, 0), (25, 8), (60, 12), (120, 20), (250, 30)]\n    total_deductible = sum(assets[\"Cost\"])\n    taxable_income = income - total_deductible\n\n    total_tax = 0\n    for bracket, rate in tax_brackets:\n        if taxable_income > bracket:\n            total_tax += (taxable_income - bracket) * rate / 100\n\n    if marital_status == \"Married\":\n        total_tax *= 0.75\n    elif marital_status == \"Divorced\":\n        total_tax *= 0.8\n\n    return round(total_tax)\n\ndemo = gr.Interface(\n    tax_calculator,\n    [\n        \"number\",\n        gr.Radio([\"Single\", \"Married\", \"Divorced\"]),\n        gr.Dataframe(\n            headers=[\"Item\", \"Cost\"],\n            datatype=[\"str\", \"number\"],\n            label=\"Assets Purchased this Year\",\n        ),\n    ],\n    \"number\",\n    examples=[\n        [10000, \"Married\", [[\"Suit\", 5000], [\"Laptop\", 800], [\"Car\", 1800]]],\n        [80000, \"Single\", [[\"Suit\", 800], [\"Watch\", 1800], [\"Car\", 800]]],\n    ],\n)\n\ndemo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_simple_squares","import gradio as gr\n\ndemo = gr.Blocks(css=\"\"\"#btn {color: red} .abc {font-family: \"Comic Sans MS\", \"Comic Sans\", cursive !important}\"\"\")\n\nwith demo:\n    default_json = {\"a\": \"a\"}\n\n    num = gr.State(value=0)\n    squared = gr.Number(value=0)\n    btn = gr.Button(\"Next Square\", elem_id=\"btn\", elem_classes=[\"abc\", \"def\"])\n\n    stats = gr.State(value=default_json)\n    table = gr.JSON()\n\n    def increase(var, stats_history):\n        var += 1\n        stats_history[str(var)] = var**2\n        return var, var**2, stats_history, stats_history\n\n    btn.click(increase, [num, stats], [num, squared, stats, table])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Model3D",next_obj:"Plot",slug:"number"},plot:{class:null,name:"Plot",description:"Used to display various kinds of plots (matplotlib, plotly, or bokeh are supported). \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects either a {matplotlib.figure.Figure}, a {plotly.graph_objects._figure.Figure}, or a {dict} corresponding to a bokeh plot (json_item format)",demos:"altair_plot, outbreak_forecast, blocks_kinematics, stock_forecast, map_airbnb",guides:"plot-component-for-maps"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"Callable | None | pd.DataFrame",doc:"Optionally, supply a default plot object to display, must be a matplotlib, plotly, altair, or bokeh figure, or a callable. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Plot",slug:"plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Plot",slug:"plot-clear"}],string_shortcuts:[["Plot","plot","Uses default values"]],demos:[["altair_plot","import altair as alt\nimport gradio as gr\nimport numpy as np\nimport pandas as pd\nfrom vega_datasets import data\n\n\ndef make_plot(plot_type):\n    if plot_type == \"scatter_plot\":\n        cars = data.cars()\n        return alt.Chart(cars).mark_point().encode(\n            x='Horsepower',\n            y='Miles_per_Gallon',\n            color='Origin',\n        )\n    elif plot_type == \"heatmap\":\n        # Compute x^2 + y^2 across a 2D grid\n        x, y = np.meshgrid(range(-5, 5), range(-5, 5))\n        z = x ** 2 + y ** 2\n\n        # Convert this grid to columnar data expected by Altair\n        source = pd.DataFrame({'x': x.ravel(),\n                            'y': y.ravel(),\n                            'z': z.ravel()})\n        return alt.Chart(source).mark_rect().encode(\n            x='x:O',\n            y='y:O',\n            color='z:Q'\n        )\n    elif plot_type == \"us_map\":\n        states = alt.topo_feature(data.us_10m.url, 'states')\n        source = data.income.url\n\n        return alt.Chart(source).mark_geoshape().encode(\n            shape='geo:G',\n            color='pct:Q',\n            tooltip=['name:N', 'pct:Q'],\n            facet=alt.Facet('group:N', columns=2),\n        ).transform_lookup(\n            lookup='id',\n            from_=alt.LookupData(data=states, key='id'),\n            as_='geo'\n        ).properties(\n            width=300,\n            height=175,\n        ).project(\n            type='albersUsa'\n        )\n    elif plot_type == \"interactive_barplot\":\n        source = data.movies.url\n\n        pts = alt.selection(type=\"single\", encodings=['x'])\n\n        rect = alt.Chart(data.movies.url).mark_rect().encode(\n            alt.X('IMDB_Rating:Q', bin=True),\n            alt.Y('Rotten_Tomatoes_Rating:Q', bin=True),\n            alt.Color('count()',\n                scale=alt.Scale(scheme='greenblue'),\n                legend=alt.Legend(title='Total Records')\n            )\n        )\n\n        circ = rect.mark_point().encode(\n            alt.ColorValue('grey'),\n            alt.Size('count()',\n                legend=alt.Legend(title='Records in Selection')\n            )\n        ).transform_filter(\n            pts\n        )\n\n        bar = alt.Chart(source).mark_bar().encode(\n            x='Major_Genre:N',\n            y='count()',\n            color=alt.condition(pts, alt.ColorValue(\"steelblue\"), alt.ColorValue(\"grey\"))\n        ).properties(\n            width=550,\n            height=200\n        ).add_selection(pts)\n\n        plot = alt.vconcat(\n            rect + circ,\n            bar\n        ).resolve_legend(\n            color=\"independent\",\n            size=\"independent\"\n        )\n        return plot\n    elif plot_type == \"radial\":\n        source = pd.DataFrame({\"values\": [12, 23, 47, 6, 52, 19]})\n\n        base = alt.Chart(source).encode(\n            theta=alt.Theta(\"values:Q\", stack=True),\n            radius=alt.Radius(\"values\", scale=alt.Scale(type=\"sqrt\", zero=True, rangeMin=20)),\n            color=\"values:N\",\n        )\n\n        c1 = base.mark_arc(innerRadius=20, stroke=\"#fff\")\n\n        c2 = base.mark_text(radiusOffset=10).encode(text=\"values:Q\")\n\n        return c1 + c2\n    elif plot_type == \"multiline\":\n        source = data.stocks()\n\n        highlight = alt.selection(type='single', on='mouseover',\n                                fields=['symbol'], nearest=True)\n\n        base = alt.Chart(source).encode(\n            x='date:T',\n            y='price:Q',\n            color='symbol:N'\n        )\n\n        points = base.mark_circle().encode(\n            opacity=alt.value(0)\n        ).add_selection(\n            highlight\n        ).properties(\n            width=600\n        )\n\n        lines = base.mark_line().encode(\n            size=alt.condition(~highlight, alt.value(1), alt.value(3))\n        )\n\n        return points + lines\n\n\nwith gr.Blocks() as demo:\n    button = gr.Radio(label=\"Plot type\",\n                      choices=['scatter_plot', 'heatmap', 'us_map',\n                               'interactive_barplot', \"radial\", \"multiline\"], value='scatter_plot')\n    plot = gr.Plot(label=\"Plot\")\n    button.change(make_plot, inputs=button, outputs=[plot])\n    demo.load(make_plot, inputs=[button], outputs=[plot])\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["outbreak_forecast","import altair\n\nimport gradio as gr\nfrom math import sqrt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport pandas as pd\n\n\ndef outbreak(plot_type, r, month, countries, social_distancing):\n    months = [\"January\", \"February\", \"March\", \"April\", \"May\"]\n    m = months.index(month)\n    start_day = 30 * m\n    final_day = 30 * (m + 1)\n    x = np.arange(start_day, final_day + 1)\n    pop_count = {\"USA\": 350, \"Canada\": 40, \"Mexico\": 300, \"UK\": 120}\n    if social_distancing:\n        r = sqrt(r)\n    df = pd.DataFrame({\"day\": x})\n    for country in countries:\n        df[country] = x ** (r) * (pop_count[country] + 1)\n\n    if plot_type == \"Matplotlib\":\n        fig = plt.figure()\n        plt.plot(df[\"day\"], df[countries].to_numpy())\n        plt.title(\"Outbreak in \" + month)\n        plt.ylabel(\"Cases\")\n        plt.xlabel(\"Days since Day 0\")\n        plt.legend(countries)\n        return fig\n    elif plot_type == \"Plotly\":\n        fig = px.line(df, x=\"day\", y=countries)\n        fig.update_layout(\n            title=\"Outbreak in \" + month,\n            xaxis_title=\"Cases\",\n            yaxis_title=\"Days Since Day 0\",\n        )\n        return fig\n    elif plot_type == \"Altair\":\n        df = df.melt(id_vars=\"day\").rename(columns={\"variable\": \"country\"})\n        fig = altair.Chart(df).mark_line().encode(x=\"day\", y='value', color='country')\n        return fig\n    else:\n        raise ValueError(\"A plot type must be selected\")\n\n\ninputs = [\n    gr.Dropdown([\"Matplotlib\", \"Plotly\", \"Altair\"], label=\"Plot Type\"),\n    gr.Slider(1, 4, 3.2, label=\"R\"),\n    gr.Dropdown([\"January\", \"February\", \"March\", \"April\", \"May\"], label=\"Month\"),\n    gr.CheckboxGroup(\n        [\"USA\", \"Canada\", \"Mexico\", \"UK\"], label=\"Countries\", value=[\"USA\", \"Canada\"]\n    ),\n    gr.Checkbox(label=\"Social Distancing?\"),\n]\noutputs = gr.Plot()\n\ndemo = gr.Interface(\n    fn=outbreak,\n    inputs=inputs,\n    outputs=outputs,\n    examples=[\n        [\"Matplotlib\", 2, \"March\", [\"Mexico\", \"UK\"], True],\n        [\"Altair\", 2, \"March\", [\"Mexico\", \"Canada\"], True],\n        [\"Plotly\", 3.6, \"February\", [\"Canada\", \"Mexico\", \"UK\"], False],\n    ],\n    cache_examples=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n\n\n"],["blocks_kinematics","import pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["stock_forecast","import matplotlib.pyplot as plt\nimport numpy as np\n\nimport gradio as gr\n\n\ndef plot_forecast(final_year, companies, noise, show_legend, point_style):\n    start_year = 2020\n    x = np.arange(start_year, final_year + 1)\n    year_count = x.shape[0]\n    plt_format = ({\"cross\": \"X\", \"line\": \"-\", \"circle\": \"o--\"})[point_style]\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    for i, company in enumerate(companies):\n        series = np.arange(0, year_count, dtype=float)\n        series = series**2 * (i + 1)\n        series += np.random.rand(year_count) * noise\n        ax.plot(x, series, plt_format)\n    if show_legend:\n        plt.legend(companies)\n    return fig\n\n\ndemo = gr.Interface(\n    plot_forecast,\n    [\n        gr.Radio([2025, 2030, 2035, 2040], label=\"Project to:\"),\n        gr.CheckboxGroup([\"Google\", \"Microsoft\", \"Gradio\"], label=\"Company Selection\"),\n        gr.Slider(1, 100, label=\"Noise Level\"),\n        gr.Checkbox(label=\"Show Legend\"),\n        gr.Dropdown([\"cross\", \"line\", \"circle\"], label=\"Style\"),\n    ],\n    gr.Plot(label=\"forecast\"),\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["map_airbnb","import gradio as gr\nimport plotly.graph_objects as go\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n\n    filtered_df = df[(df['neighbourhood_group'].isin(boroughs)) & \n          (df['price'] > min_price) & (df['price'] \u003C max_price)]\n    names = filtered_df[\"name\"].tolist()\n    prices = filtered_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n    fig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=filtered_df['latitude'].tolist(),\n            lon=filtered_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='\u003Cb>Name\u003C/b>: %{customdata[0]}\u003Cbr>\u003Cb>Price\u003C/b>: $%{customdata[1]}'\n        ))\n\n    fig.update_layout(\n        mapbox_style=\"open-street-map\",\n        hovermode='closest',\n        mapbox=dict(\n            bearing=0,\n            center=go.layout.mapbox.Center(\n                lat=40.67,\n                lon=-73.90\n            ),\n            pitch=0,\n            zoom=9\n        ),\n    )\n\n    return fig\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n\nif __name__ == \"__main__\":\n    demo.launch()"]],guides:[{name:"plot-component-for-maps",category:"tabular-data-science-and-plots",pretty_category:"Tabular Data Science And Plots",guide_index:null,absolute_index:36,pretty_name:"Plot Component For Maps",content:"# How to Use the Plot Component for Maps\n\n\n\n## Introduction\n\nThis guide explains how you can use Gradio to plot geographical data on a map using the `gradio.Plot` component. The Gradio `Plot` component works with Matplotlib, Bokeh and Plotly. Plotly is what we will be working with in this guide. Plotly allows developers to easily create all sorts of maps with their geographical data. Take a look [here](https://plotly.com/python/maps/) for some examples.\n\n## Overview\n\nWe will be using the New York City Airbnb dataset, which is hosted on kaggle [here](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data). I've uploaded it to the Hugging Face Hub as a dataset [here](https://huggingface.co/datasets/gradio/NYC-Airbnb-Open-Data) for easier use and download. Using this data we will plot Airbnb locations on a map output and allow filtering based on price and location. Below is the demo that we will be building. ‚ö°Ô∏è\n\n\u003Cgradio-app space='gradio/map_airbnb'>\u003C/gradio-app>\n\n## Step 1 - Loading CSV data üíæ\n\nLet's start by loading the Airbnb NYC data from the Hugging Face Hub.\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n    new_df = df[(df['neighbourhood_group'].isin(boroughs)) &\n            (df['price'] > min_price) & (df['price'] \u003C max_price)]\n    names = new_df[\"name\"].tolist()\n    prices = new_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n```\n\nIn the code above, we first load the csv data into a pandas dataframe. Let's begin by defining a function that we will use as the prediction function for the gradio app. This function will accept the minimum price and maximum price range as well as the list of boroughs to filter the resulting map. We can use the passed in values (`min_price`, `max_price`, and list of `boroughs`) to filter the dataframe and create `new_df`. Next we will create `text_list` of the names and prices of each Airbnb to use as labels on the map.\n\n## Step 2 - Map Figure üåê\n\nPlotly makes it easy to work with maps. Let's take a look below how we can create a map figure.\n\n```python\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=new_df['latitude'].tolist(),\n            lon=new_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='\u003Cb>Name\u003C/b>: %{customdata[0]}\u003Cbr>\u003Cb>Price\u003C/b>: $%{customdata[1]}'\n        ))\n\nfig.update_layout(\n    mapbox_style=\"open-street-map\",\n    hovermode='closest',\n    mapbox=dict(\n        bearing=0,\n        center=go.layout.mapbox.Center(\n            lat=40.67,\n            lon=-73.90\n        ),\n        pitch=0,\n        zoom=9\n    ),\n)\n```\n\nAbove, we create a scatter plot on mapbox by passing it our list of latitudes and longitudes to plot markers. We also pass in our custom data of names and prices for additional info to appear on every marker we hover over. Next we use `update_layout` to specify other map settings such as zoom, and centering.\n\nMore info [here](https://plotly.com/python/scattermapbox/) on scatter plots using Mapbox and Plotly.\n\n## Step 3 - Gradio App ‚ö°Ô∏è\n\nWe will use two `gr.Number` components and a `gr.CheckboxGroup` to allow users of our app to specify price ranges and borough locations. We will then use the `gr.Plot` component as an output for our Plotly + Mapbox map we created earlier.\n\n```python\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n```\n\nWe layout these components using the `gr.Column` and `gr.Row` and we'll also add event triggers for when the demo first loads and when our \"Update Filter\" button is clicked in order to trigger the map to update with our new filters.\n\nThis is what the full demo code looks like:\n\n```python\nimport gradio as gr\nimport plotly.graph_objects as go\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n\n    filtered_df = df[(df['neighbourhood_group'].isin(boroughs)) & \n          (df['price'] > min_price) & (df['price'] \u003C max_price)]\n    names = filtered_df[\"name\"].tolist()\n    prices = filtered_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n    fig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=filtered_df['latitude'].tolist(),\n            lon=filtered_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='\u003Cb>Name\u003C/b>: %{customdata[0]}\u003Cbr>\u003Cb>Price\u003C/b>: $%{customdata[1]}'\n        ))\n\n    fig.update_layout(\n        mapbox_style=\"open-street-map\",\n        hovermode='closest',\n        mapbox=dict(\n            bearing=0,\n            center=go.layout.mapbox.Center(\n                lat=40.67,\n                lon=-73.90\n            ),\n            pitch=0,\n            zoom=9\n        ),\n    )\n\n    return fig\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n\ndemo.launch()\n```\n\n## Step 4 - Deployment ü§ó\n\nIf you run the code above, your app will start running locally.\nYou can even get a temporary shareable link by passing the `share=True` parameter to `launch`.\n\nBut what if you want to a permanent deployment solution?\nLet's deploy our Gradio app to the free HuggingFace Spaces platform.\n\nIf you haven't used Spaces before, follow the previous guide [here](/using_hugging_face_integrations).\n\n## Conclusion üéâ\n\nAnd you're all done! That's all the code you need to build a map demo.\n\nHere's a link to the demo [Map demo](https://huggingface.co/spaces/gradio/map_airbnb) and [complete code](https://huggingface.co/spaces/gradio/map_airbnb/blob/main/run.py) (on Hugging Face Spaces)\n",tags:["PLOTS","MAPS"],spaces:[],url:"/guides/plot-component-for-maps/",contributor:null}],parent:"gradio",prev_obj:"Number",next_obj:"Radio",slug:"plot"},radio:{class:null,name:"Radio",description:"Creates a set of (string or numeric type) radio buttons of which only one can be selected. \u003Cbr>",tags:{preprocessing:"passes the value of the selected radio button as a {str} or {int} or {float} or its index as an {int} into the function, depending on `type`.",postprocessing:"expects a {str} or {int} or {float} corresponding to the value of the radio button to be selected.","examples-format":"a {str} representing the radio option to select.",demos:"sentence_builder, titanic_survival, blocks_essay"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"choices",annotation:"list[str | int | float | tuple[str, str | int | float]] | None",doc:"A list of string or numeric options to select from. An option can also be a tuple of the form (name, value), where name is the displayed name of the radio button and value is the value to be passed to the function, or returned by the function.",default:"None"},{name:"value",annotation:"str | int | float | Callable | None",doc:"The option selected by default. If None, no option is selected by default. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"type",annotation:"str",doc:"Type of value to be returned by component. &quot;value&quot; returns the string of the choice selected, &quot;index&quot; returns the index of the choice selected.",default:"\"value\""},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"Additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"Relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"Minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"If True, choices in this radio group will be selectable; if False, selection will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Radio. Uses event data gradio.SelectData to carry `value` referring to the label of the Radio, and `selected` to refer to state of the Radio. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Radio",slug:"radio-select"},{fn:null,name:"change",description:"Triggered when the value of the Radio changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Radio",slug:"radio-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Radio.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Radio",slug:"radio-input"}],string_shortcuts:[["Radio","radio","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["titanic_survival","import os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_essay","import gradio as gr\n\ncountries_cities_dict = {\n    \"USA\": [\"New York\", \"Los Angeles\", \"Chicago\"],\n    \"Canada\": [\"Toronto\", \"Montreal\", \"Vancouver\"],\n    \"Pakistan\": [\"Karachi\", \"Lahore\", \"Islamabad\"],\n}\n\n\ndef change_textbox(choice):\n    if choice == \"short\":\n        return gr.Textbox(lines=2, visible=True), gr.Button(interactive=True)\n    elif choice == \"long\":\n        return gr.Textbox(lines=8, visible=True, value=\"Lorem ipsum dolor sit amet\"), gr.Button(interactive=True)\n    else:\n        return gr.Textbox(visible=False), gr.Button(interactive=False)\n\n\nwith gr.Blocks() as demo:\n    radio = gr.Radio(\n        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n    )\n    text = gr.Textbox(lines=2, interactive=True, show_copy_button=True)\n\n    with gr.Row():\n        num = gr.Number(minimum=0, maximum=100, label=\"input\")\n        out = gr.Number(label=\"output\")\n    minimum_slider = gr.Slider(0, 100, 0, label=\"min\")\n    maximum_slider = gr.Slider(0, 100, 100, label=\"max\")\n    submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n\n    with gr.Row():\n        country = gr.Dropdown(list(countries_cities_dict.keys()), label=\"Country\")\n        cities = gr.Dropdown([], label=\"Cities\")\n        \n    @country.change(inputs=country, outputs=cities)\n    def update_cities(country):\n        cities = list(countries_cities_dict[country])\n        return gr.Dropdown(choices=cities, value=cities[0], interactive=True)\n\n    def reset_bounds(minimum, maximum):\n        return gr.Number(minimum=minimum, maximum=maximum)\n\n    radio.change(fn=change_textbox, inputs=radio, outputs=[text, submit_btn])\n    gr.on(\n        [minimum_slider.change, maximum_slider.change],\n        reset_bounds,\n        [minimum_slider, maximum_slider],\n        outputs=num,\n    )\n    num.submit(lambda x: x, num, out)\n\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"Plot",next_obj:"ScatterPlot",slug:"radio"},scatterplot:{class:null,name:"ScatterPlot",description:"Create a scatter plot. \u003Cbr> \u003Cbr>",tags:{preprocessing:"this component does *not* accept input.",postprocessing:"expects a pandas dataframe with the data to plot.",demos:"scatter_plot",guides:"creating-a-dashboard-from-bigquery-data"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"pd.DataFrame | Callable | None",doc:"The pandas dataframe containing the data to display in a scatter plot, or a callable. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"x",annotation:"str | None",doc:"Column corresponding to the x axis.",default:"None"},{name:"y",annotation:"str | None",doc:"Column corresponding to the y axis.",default:"None"},{name:"color",annotation:"str | None",doc:"The column to determine the point color. If the column contains numeric data, gradio will interpolate the column data so that small values correspond to light colors and large values correspond to dark values.",default:"None"},{name:"size",annotation:"str | None",doc:"The column used to determine the point size. Should contain numeric data so that gradio can map the data to the point size.",default:"None"},{name:"shape",annotation:"str | None",doc:"The column used to determine the point shape. Should contain categorical data. Gradio will map each unique value to a different shape.",default:"None"},{name:"title",annotation:"str | None",doc:"The title to display on top of the chart.",default:"None"},{name:"tooltip",annotation:"list[str] | str | None",doc:"The column (or list of columns) to display on the tooltip when a user hovers a point on the plot.",default:"None"},{name:"x_title",annotation:"str | None",doc:"The title given to the x-axis. By default, uses the value of the x parameter.",default:"None"},{name:"y_title",annotation:"str | None",doc:"The title given to the y-axis. By default, uses the value of the y parameter.",default:"None"},{name:"x_label_angle",annotation:"float | None",doc:" The angle for the x axis labels rotation. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"y_label_angle",annotation:"float | None",doc:" The angle for the y axis labels rotation. Positive values are clockwise, and negative values are counter-clockwise.",default:"None"},{name:"color_legend_title",annotation:"str | None",doc:"The title given to the color legend. By default, uses the value of color parameter.",default:"None"},{name:"size_legend_title",annotation:"str | None",doc:"The title given to the size legend. By default, uses the value of the size parameter.",default:"None"},{name:"shape_legend_title",annotation:"str | None",doc:"The title given to the shape legend. By default, uses the value of the shape parameter.",default:"None"},{name:"color_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the color legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"size_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the size legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"shape_legend_position",annotation:"Literal[('left', 'right', 'top', 'bottom', 'top-left', 'top-right', 'bottom-left', 'bottom-right', 'none')] | None",doc:"The position of the shape legend. If the string value &#x27;none&#x27; is passed, this legend is omitted. For other valid position values see: https://vega.github.io/vega/docs/legends/#orientation.",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the plot, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"x_lim",annotation:"list[int | float] | None",doc:"A tuple or list containing the limits for the x-axis, specified as [x_min, x_max].",default:"None"},{name:"y_lim",annotation:"list[int | float] | None",doc:"A tuple of list containing the limits for the y-axis, specified as [y_min, y_max].",default:"None"},{name:"caption",annotation:"str | None",doc:"The (optional) caption to display below the plot.",default:"None"},{name:"interactive",annotation:"bool | None",doc:"Whether users should be able to interact with the plot by panning or zooming with their mouse or trackpad.",default:"True"},{name:"label",annotation:"str | None",doc:"The (optional) label to display on the top left corner of the plot.",default:"None"},{name:"every",annotation:"float | None",doc:" If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"Whether the label should be displayed.",default:"None"},{name:"container",annotation:"bool",doc:null,default:"True"},{name:"scale",annotation:"int | None",doc:null,default:"None"},{name:"min_width",annotation:"int",doc:null,default:"160"},{name:"visible",annotation:"bool",doc:"Whether the plot should be visible.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"show_actions_button",annotation:"bool",doc:"Whether to show the actions button on the top right corner of the plot.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Plot changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ScatterPlot",slug:"scatter-plot-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Plot using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.ScatterPlot",slug:"scatter-plot-clear"}],string_shortcuts:[["ScatterPlot","scatterplot","Uses default values"]],demos:[["scatter_plot","import gradio as gr\nfrom vega_datasets import data\n\ncars = data.cars()\niris = data.iris()\n\n# # Or generate your own fake data\n\n# import pandas as pd\n# import random\n\n# cars_data = {\n#     \"Name\": [\"car name \" + f\" {int(i/10)}\" for i in range(400)],\n#     \"Miles_per_Gallon\": [random.randint(10, 30) for _ in range(400)],\n#     \"Origin\": [random.choice([\"USA\", \"Europe\", \"Japan\"]) for _ in range(400)],\n#     \"Horsepower\": [random.randint(50, 250) for _ in range(400)],\n# }\n\n# iris_data = {\n#     \"petalWidth\": [round(random.uniform(0, 2.5), 2) for _ in range(150)],\n#     \"petalLength\": [round(random.uniform(0, 7), 2) for _ in range(150)],\n#     \"species\": [\n#         random.choice([\"setosa\", \"versicolor\", \"virginica\"]) for _ in range(150)\n#     ],\n# }\n\n# cars = pd.DataFrame(cars_data)\n# iris = pd.DataFrame(iris_data)\n\n\ndef scatter_plot_fn(dataset):\n    if dataset == \"iris\":\n        return gr.ScatterPlot(\n            value=iris,\n            x=\"petalWidth\",\n            y=\"petalLength\",\n            color=\"species\",\n            title=\"Iris Dataset\",\n            color_legend_title=\"Species\",\n            x_title=\"Petal Width\",\n            y_title=\"Petal Length\",\n            tooltip=[\"petalWidth\", \"petalLength\", \"species\"],\n            caption=\"\",\n        )\n    else:\n        return gr.ScatterPlot(\n            value=cars,\n            x=\"Horsepower\",\n            y=\"Miles_per_Gallon\",\n            color=\"Origin\",\n            tooltip=\"Name\",\n            title=\"Car Data\",\n            y_title=\"Miles per Gallon\",\n            color_legend_title=\"Origin of Car\",\n            caption=\"MPG vs Horsepower of various cars\",\n        )\n\n\nwith gr.Blocks() as scatter_plot:\n    with gr.Row():\n        with gr.Column():\n            dataset = gr.Dropdown(choices=[\"cars\", \"iris\"], value=\"cars\")\n        with gr.Column():\n            plot = gr.ScatterPlot()\n    dataset.change(scatter_plot_fn, inputs=dataset, outputs=plot)\n    scatter_plot.load(fn=scatter_plot_fn, inputs=dataset, outputs=plot)\n\nif __name__ == \"__main__\":\n    scatter_plot.launch()\n"]],guides:[{name:"creating-a-dashboard-from-bigquery-data",category:"tabular-data-science-and-plots",pretty_category:"Tabular Data Science And Plots",guide_index:null,absolute_index:33,pretty_name:"Creating A Dashboard From Bigquery Data",content:"# Creating a Real-Time Dashboard from BigQuery Data\n\n\n\n[Google BigQuery](https://cloud.google.com/bigquery) is a cloud-based service for processing very large data sets. It is a serverless and highly scalable data warehousing solution that enables users to analyze data [using SQL-like queries](https://www.oreilly.com/library/view/google-bigquery-the/9781492044451/ch01.html).\n\nIn this tutorial, we will show you how to query a BigQuery dataset in Python and display the data in a dashboard that updates in real time using `gradio`. The dashboard will look like this:\n\n\u003Cimg src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/bigquery-dashboard.gif\">\n\nWe'll cover the following steps in this Guide:\n\n1. Setting up your BigQuery credentials\n2. Using the BigQuery client\n3. Building the real-time dashboard (in just _7 lines of Python_)\n\nWe'll be working with the [New York Times' COVID dataset](https://www.nytimes.com/interactive/2021/us/covid-cases.html) that is available as a public dataset on BigQuery. The dataset, named `covid19_nyt.us_counties` contains the latest information about the number of confirmed cases and deaths from COVID across US counties.\n\n**Prerequisites**: This Guide uses [Gradio Blocks](/guides/quickstart/#blocks-more-flexibility-and-control), so make your are familiar with the Blocks class.\n\n## Setting up your BigQuery Credentials\n\nTo use Gradio with BigQuery, you will need to obtain your BigQuery credentials and use them with the [BigQuery Python client](https://pypi.org/project/google-cloud-bigquery/). If you already have BigQuery credentials (as a `.json` file), you can skip this section. If not, you can do this for free in just a couple of minutes.\n\n1. First, log in to your Google Cloud account and go to the Google Cloud Console (https://console.cloud.google.com/)\n\n2. In the Cloud Console, click on the hamburger menu in the top-left corner and select \"APIs & Services\" from the menu. If you do not have an existing project, you will need to create one.\n\n3. Then, click the \"+ Enabled APIs & services\" button, which allows you to enable specific services for your project. Search for \"BigQuery API\", click on it, and click the \"Enable\" button. If you see the \"Manage\" button, then the BigQuery is already enabled, and you're all set.\n\n4. In the APIs & Services menu, click on the \"Credentials\" tab and then click on the \"Create credentials\" button.\n\n5. In the \"Create credentials\" dialog, select \"Service account key\" as the type of credentials to create, and give it a name. Also grant the service account permissions by giving it a role such as \"BigQuery User\", which will allow you to run queries.\n\n6. After selecting the service account, select the \"JSON\" key type and then click on the \"Create\" button. This will download the JSON key file containing your credentials to your computer. It will look something like this:\n\n```json\n{\n\t\"type\": \"service_account\",\n\t\"project_id\": \"your project\",\n\t\"private_key_id\": \"your private key id\",\n\t\"private_key\": \"private key\",\n\t\"client_email\": \"email\",\n\t\"client_id\": \"client id\",\n\t\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n\t\"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n\t\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n\t\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/email_id\"\n}\n```\n\n## Using the BigQuery Client\n\nOnce you have the credentials, you will need to use the BigQuery Python client to authenticate using your credentials. To do this, you will need to install the BigQuery Python client by running the following command in the terminal:\n\n```bash\npip install google-cloud-bigquery[pandas]\n```\n\nYou'll notice that we've installed the pandas add-on, which will be helpful for processing the BigQuery dataset as a pandas dataframe. Once the client is installed, you can authenticate using your credentials by running the following code:\n\n```py\nfrom google.cloud import bigquery\n\nclient = bigquery.Client.from_service_account_json(\"path/to/key.json\")\n```\n\nWith your credentials authenticated, you can now use the BigQuery Python client to interact with your BigQuery datasets.\n\nHere is an example of a function which queries the `covid19_nyt.us_counties` dataset in BigQuery to show the top 20 counties with the most confirmed cases as of the current day:\n\n```py\nimport numpy as np\n\nQUERY = (\n    'SELECT * FROM `bigquery-public-data.covid19_nyt.us_counties` '\n    'ORDER BY date DESC,confirmed_cases DESC '\n    'LIMIT 20')\n\ndef run_query():\n    query_job = client.query(QUERY)\n    query_result = query_job.result()\n    df = query_result.to_dataframe()\n    # Select a subset of columns\n    df = df[[\"confirmed_cases\", \"deaths\", \"county\", \"state_name\"]]\n    # Convert numeric columns to standard numpy types\n    df = df.astype({\"deaths\": np.int64, \"confirmed_cases\": np.int64})\n    return df\n```\n\n## Building the Real-Time Dashboard\n\nOnce you have a function to query the data, you can use the `gr.DataFrame` component from the Gradio library to display the results in a tabular format. This is a useful way to inspect the data and make sure that it has been queried correctly.\n\nHere is an example of how to use the `gr.DataFrame` component to display the results. By passing in the `run_query` function to `gr.DataFrame`, we instruct Gradio to run the function as soon as the page loads and show the results. In addition, you also pass in the keyword `every` to tell the dashboard to refresh every hour (60\\*60 seconds).\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.DataFrame(run_query, every=60*60)\n\ndemo.queue().launch()  # Run the demo using queuing\n```\n\nPerhaps you'd like to add a visualization to our dashboard. You can use the `gr.ScatterPlot()` component to visualize the data in a scatter plot. This allows you to see the relationship between different variables such as case count and case deaths in the dataset and can be useful for exploring the data and gaining insights. Again, we can do this in real-time\nby passing in the `every` parameter.\n\nHere is a complete example showing how to use the `gr.ScatterPlot` to visualize in addition to displaying data with the `gr.DataFrame`\n\n```py\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# üíâ Covid Dashboard (Updated Hourly)\")\n    with gr.Row():\n        gr.DataFrame(run_query, every=60*60)\n        gr.ScatterPlot(run_query, every=60*60, x=\"confirmed_cases\",\n                        y=\"deaths\", tooltip=\"county\", width=500, height=500)\n\ndemo.queue().launch()  # Run the demo with queuing enabled\n```\n",tags:["TABULAR","DASHBOARD","PLOTS"],spaces:[],url:"/guides/creating-a-dashboard-from-bigquery-data/",contributor:null}],parent:"gradio",prev_obj:"Radio",next_obj:"Slider",slug:"scatter-plot"},slider:{class:null,name:"Slider",description:"Creates a slider that ranges from {minimum} to {maximum} with a step size of {step}. \u003Cbr>",tags:{preprocessing:"passes slider value as a {float} into the function.",postprocessing:"expects an {int} or {float} returned from function and sets slider value to it as long as it is within range.","examples-format":"A {float} or {int} representing the slider&#x27;s value.",demos:"sentence_builder, slider_release, interface_random_slider, blocks_random_slider",guides:"create-your-own-friends-with-a-gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"minimum",annotation:"float",doc:"minimum value for slider.",default:"0"},{name:"maximum",annotation:"float",doc:"maximum value for slider.",default:"100"},{name:"value",annotation:"float | Callable | None",doc:"default value. If callable, the function will be called whenever the app loads to set the initial value of the component. Ignored if randomized=True.",default:"None"},{name:"step",annotation:"float | None",doc:"increment between slider values.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, slider will be adjustable; if False, adjusting will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"randomize",annotation:"bool",doc:"If True, the value of the slider when the app loads is taken uniformly at random from the range given by the minimum and maximum.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Slider changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Slider",slug:"slider-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Slider.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Slider",slug:"slider-input"},{fn:null,name:"release",description:"This listener is triggered when the user releases the mouse on this Slider.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Slider",slug:"slider-release"}],string_shortcuts:[["Slider","slider","Uses default values"]],demos:[["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["slider_release","import gradio as gr\n\n\ndef identity(x, state):\n    state += 1\n    return x, state, state\n\n\nwith gr.Blocks() as demo:\n    slider = gr.Slider(0, 100, step=0.1)\n    state = gr.State(value=0)\n    with gr.Row():\n        number = gr.Number(label=\"On release\")\n        number2 = gr.Number(label=\"Number of events fired\")\n    slider.release(identity, inputs=[slider, state], outputs=[number, state, number2], api_name=\"predict\")\n\nif __name__ == \"__main__\":\n    print(\"here\")\n    demo.launch()\n    print(demo.server_port)\n"],["interface_random_slider","import gradio as gr\n\n\ndef func(slider_1, slider_2, *args):\n    return slider_1 + slider_2 * 5\n\n\ndemo = gr.Interface(\n    func,\n    [\n        gr.Slider(minimum=1.5, maximum=250000.89, randomize=True, label=\"Random Big Range\"),\n        gr.Slider(minimum=-1, maximum=1, randomize=True, step=0.05, label=\"Random only multiple of 0.05 allowed\"),\n        gr.Slider(minimum=0, maximum=1, randomize=True, step=0.25, label=\"Random only multiples of 0.25 allowed\"),\n        gr.Slider(minimum=-100, maximum=100, randomize=True, step=3, label=\"Random between -100 and 100 step 3\"),\n        gr.Slider(minimum=-100, maximum=100, randomize=True, label=\"Random between -100 and 100\"),\n        gr.Slider(value=0.25, minimum=5, maximum=30, step=-1),\n    ],\n    \"number\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_random_slider","\nimport gradio as gr\n\n\ndef func(slider_1, slider_2):\n    return slider_1 * 5 + slider_2\n\n\nwith gr.Blocks() as demo:\n    slider = gr.Slider(minimum=-10.2, maximum=15, label=\"Random Slider (Static)\", randomize=True)\n    slider_1 = gr.Slider(minimum=100, maximum=200, label=\"Random Slider (Input 1)\", randomize=True)\n    slider_2 = gr.Slider(minimum=10, maximum=23.2, label=\"Random Slider (Input 2)\", randomize=True)\n    slider_3 = gr.Slider(value=3, label=\"Non random slider\")\n    btn = gr.Button(\"Run\")\n    btn.click(func, inputs=[slider_1, slider_2], outputs=gr.Number())\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"create-your-own-friends-with-a-gan",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:44,pretty_name:"Create Your Own Friends With A Gan",content:"# Create Your Own Friends with a GAN\n\n\n\n\n\n\n## Introduction\n\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we'll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\n\nGenerative Adversarial Networks, often known just as _GANs_, are a specific class of deep-learning models that are designed to learn from an input dataset to create (_generate!_) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\n\nToday we'll briefly look at the high-level intuition behind GANs, and then we'll build a small demo around a pre-trained GAN to see what all the fuss is about. Here's a [peek](https://nimaboscarino-cryptopunks.hf.space) at what we're going to be putting together.\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\n\n## GANs: a very brief introduction\n\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the _generator_, is responsible for generating images. The other network, the _discriminator_, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\n\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (_adversarial!_) relationship, the images that get generated improve to the point where they become indistinguishable to human eyes!\n\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\n\n## Step 1 ‚Äî Create the Generator model\n\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\n\n```python\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\n\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n## Step 2 ‚Äî Defining a `predict` function\n\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it's common to pass random noise into our model as the input, so we'll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`'s `save_image` function to save the output of the model as a `png` file, and return the file name:\n\n```python\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWe're giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We'll then be able to reproduce punks if we want to see them again by passing in the same seed.\n\n_Note!_ Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we'll start by generating 4 punks at a time.\n\n## Step 3 ‚Äî Creating a Gradio interface\n\nAt this point you can even run the code you have with `predict(\u003CSOME_NUMBER>)`, and you'll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we'll build out a simple interface with Gradio. Our goals here are to:\n\n- Set a slider input so users can choose the \"seed\" value\n- Use an image component for our output to showcase the generated punks\n- Use our `predict()` to take the seed and generate the images\n\nWith `gr.Interface()`, we can define all of that with a single function call:\n\n```python\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n\n## Step 4 ‚Äî Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\n\n```python\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\n\n```python\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWhen you relaunch your interface, you should see a second slider that'll let you control the number of punks!\n\n## Step 5 - Polishing it up\n\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ‚ú®\n\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\n\n```python\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we've listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\n\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens üëÄ `article` will also accept HTML, as [explored in a previous guide](/guides/key-features/#descriptive-content)!\n\nWhen you're all done, you may end up with something like [this](https://nimaboscarino-cryptopunks.hf.space).\n\nFor reference, here is our full code:\n\n```python\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n---\n\nCongratulations! You've built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making even more awesome demos ü§ó\n",tags:["GAN","IMAGE","HUB"],spaces:["https://huggingface.co/spaces/NimaBoscarino/cryptopunks","https://huggingface.co/spaces/nateraw/cryptopunks-generator"],url:"/guides/create-your-own-friends-with-a-gan/",contributor:"\u003Ca href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino\u003C/a> and \u003Ca href=\"https://huggingface.co/nateraw\">Nate Raw\u003C/a>"}],parent:"gradio",prev_obj:"ScatterPlot",next_obj:"State",slug:"slider"},state:{class:null,name:"State",description:"A base class for defining methods that all input/output components should have.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"Any",doc:"the initial value (of arbitrary type) of the state. The provided argument is deepcopied. If a callable is provided, the function will be called whenever the app loads to set the initial value of the state.",default:"None"},{name:"render",annotation:"bool",doc:"has no effect, but is included for consistency with other components.",default:"True"}],returns:{annotation:null},example:null,fns:[],parent:"gradio",prev_obj:"Slider",next_obj:"Textbox",slug:"state"},textbox:{class:null,name:"Textbox",description:"Creates a textarea for user to enter string input or display string output. \u003Cbr>",tags:{preprocessing:"passes textarea value as a {str} into the function.",postprocessing:"expects a {str} returned from function and sets textarea value to it.","examples-format":"a {str} representing the textbox input.",demos:"hello_world, diff_texts, sentence_builder",guides:"creating-a-chatbot, real-time-speech-recognition"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Callable | None",doc:"default text to provide in textarea. If callable, the function will be called whenever the app loads to set the initial value of the component.",default:"\"\""},{name:"lines",annotation:"int",doc:"minimum number of line rows to provide in textarea.",default:"1"},{name:"max_lines",annotation:"int",doc:"maximum number of line rows to provide in textarea.",default:"20"},{name:"placeholder",annotation:"str | None",doc:"placeholder hint to provide behind textarea.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"info",annotation:"str | None",doc:"additional component description.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will be rendered as an editable textbox; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"autofocus",annotation:"bool",doc:"If True, will focus on the textbox when the page loads. Use this carefully, as it can cause usability issues for sighted and non-sighted users.",default:"False"},{name:"autoscroll",annotation:"bool",doc:"If True, will automatically scroll to the bottom of the textbox when the value changes, unless the user scrolls up. If False, will not scroll to the bottom of the textbox when the value changes.",default:"True"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"type",annotation:"Literal[('text', 'password', 'email')]",doc:"The type of textbox. One of: &#x27;text&#x27;, &#x27;password&#x27;, &#x27;email&#x27;, Default is &#x27;text&#x27;.",default:"\"text\""},{name:"text_align",annotation:"Literal[('left', 'right')] | None",doc:"How to align the text in the textbox, can be: &quot;left&quot;, &quot;right&quot;, or None (default). If None, the alignment is left if `rtl` is False, or right if `rtl` is True. Can only be changed if `type` is &quot;text&quot;.",default:"None"},{name:"rtl",annotation:"bool",doc:"If True and `type` is &quot;text&quot;, sets the direction of the text to right-to-left (cursor appears on the left of the text). Default is False, which renders cursor on the right.",default:"False"},{name:"show_copy_button",annotation:"bool",doc:"If True, includes a copy button to copy the text in the textbox. Only applies if show_label is True.",default:"False"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Textbox changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-change"},{fn:null,name:"input",description:"This listener is triggered when the user changes the value of the Textbox.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-input"},{fn:null,name:"select",description:"Event listener for when the user selects or deselects the Textbox. Uses event data gradio.SelectData to carry `value` referring to the label of the Textbox, and `selected` to refer to state of the Textbox. See EventData documentation on how to use this event data",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-select"},{fn:null,name:"submit",description:"This listener is triggered when the user presses the Enter key while the Textbox is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-submit"},{fn:null,name:"focus",description:"This listener is triggered when the Textbox is focused.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-focus"},{fn:null,name:"blur",description:"This listener is triggered when the Textbox is unfocused/blurred.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Textbox",slug:"textbox-blur"}],string_shortcuts:[["Textbox","textbox","Uses default values"],["TextArea","textarea","Uses lines=7"]],demos:[["hello_world","import gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \nif __name__ == \"__main__\":\n    demo.launch()   "],["diff_texts","from difflib import Differ\n\nimport gradio as gr\n\n\ndef diff_texts(text1, text2):\n    d = Differ()\n    return [\n        (token[2:], token[0] if token[0] != \" \" else None)\n        for token in d.compare(text1, text2)\n    ]\n\n\ndemo = gr.Interface(\n    diff_texts,\n    [\n        gr.Textbox(\n            label=\"Text 1\",\n            info=\"Initial text\",\n            lines=3,\n            value=\"The quick brown fox jumped over the lazy dogs.\",\n        ),\n        gr.Textbox(\n            label=\"Text 2\",\n            info=\"Text to compare\",\n            lines=3,\n            value=\"The fast brown fox jumps over lazy dogs.\",\n        ),\n    ],\n    gr.HighlightedText(\n        label=\"Diff\",\n        combine_adjacent=True,\n        show_legend=True,\n        color_map={\"+\": \"red\", \"-\": \"green\"}),\n    theme=gr.themes.Base()\n)\nif __name__ == \"__main__\":\n    demo.launch()\n"],["sentence_builder","import gradio as gr\n\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"real-time-speech-recognition",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:49,pretty_name:"Real Time Speech Recognition",content:"# Real Time Speech Recognition\n\n\n\n## Introduction\n\nAutomatic speech recognition (ASR), the conversion of spoken speech to text, is a very important and thriving area of machine learning. ASR algorithms run on practically every smartphone, and are becoming increasingly embedded in professional workflows, such as digital assistants for nurses and doctors. Because ASR algorithms are designed to be used directly by customers and end users, it is important to validate that they are behaving as expected when confronted with a wide variety of speech patterns (different accents, pitches, and background audio conditions).\n\nUsing `gradio`, you can easily build a demo of your ASR model and share that with a testing team, or test it yourself by speaking through the microphone on your device.\n\nThis tutorial will show how to take a pretrained speech-to-text model and deploy it with a Gradio interface. We will start with a **_full-context_** model, in which the user speaks the entire audio before the prediction runs. Then we will adapt the demo to make it **_streaming_**, meaning that the audio model will convert speech as you speak. \n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained speech recognition model. In this tutorial, we will build demos from 2 ASR libraries:\n\n- Transformers (for this, `pip install transformers` and `pip install torch`)\n\nMake sure you have at least one of these installed so that you can follow along the tutorial. You will also need `ffmpeg` [installed on your system](https://www.ffmpeg.org/download.html), if you do not already have it, to process files from the microphone.\n\nHere's how to build a real time speech recognition (ASR) app:\n\n1. [Set up the Transformers ASR Model](#1-set-up-the-transformers-asr-model)\n2. [Create a Full-Context ASR Demo with Transformers](#2-create-a-full-context-asr-demo-with-transformers)\n3. [Create a Streaming ASR Demo with Transformers](#3-create-a-streaming-asr-demo-with-transformers)\n\n## 1. Set up the Transformers ASR Model\n\nFirst, you will need to have an ASR model that you have either trained yourself or you will need to download a pretrained model. In this tutorial, we will start by using a pretrained ASR model from the model, `whisper`.\n\nHere is the code to load `whisper` from Hugging Face `transformers`.\n\n```python\nfrom transformers import pipeline\n\np = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n```\n\nThat's it!\n\n## 2. Create a Full-Context ASR Demo with Transformers\n\nWe will start by creating a _full-context_ ASR demo, in which the user speaks the full audio before using the ASR model to run inference. This is very easy with Gradio -- we simply create a function around the `pipeline` object above.\n\nWe will use `gradio`'s built in `Audio` component, configured to take input from the user's microphone and return a filepath for the recorded audio. The output component will be a plain `Textbox`.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(audio):\n    sr, y = audio\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    gr.Audio(sources=[\"microphone\"]),\n    \"text\",\n)\n\ndemo.launch()\n\n```\n\u003Cgradio-app space='gradio/asr'>\u003C/gradio-app>\n\nThe `transcribe` function takes a single parameter, `audio`, which is a numpy array of the audio the user recorded. The `pipeline` object expects this in float32 format, so we convert it first to float32, and then extract the transcribed text.\n\n## 3. Create a Streaming ASR Demo with Transformers\n\nTo make this a *streaming* demo, we need to make these changes:\n\n1. Set `streaming=True` in the `Audio` component\n2. Set `live=True` in the `Interface`\n3. Add a `state` to the interface to store the recorded audio of a user\n\nTake a look below.\n\n```python\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(stream, new_chunk):\n    sr, y = new_chunk\n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    if stream is not None:\n        stream = np.concatenate([stream, y])\n    else:\n        stream = y\n    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n\n\ndemo = gr.Interface(\n    transcribe,\n    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n    [\"state\", \"text\"],\n    live=True,\n)\n\ndemo.launch()\n\n```\n\nNotice now we have a state variable now, because we need to track all the audio history. `transcribe` gets called whenever there is a new small chunk of audio, but we also need to keep track of all the audio that has been spoken so far in state. \nAs the interface runs, the `transcribe` function gets called, with a record of all the previously spoken audio in `stream`, as well as the new chunk of audio as `new_chunk`. We return the new full audio so that can be stored back in state, and we also return the transcription.\nHere we naively append the audio together and simply call the `transcriber` object on the entire audio. You can imagine more efficient ways of handling this, such as re-processing only the last 5 seconds of audio whenever a new chunk of audio received. \n\n\u003Cgradio-app space='gradio/stream_asr'>\u003C/gradio-app>\n\nNow the ASR model will run inference as you speak! ",tags:["ASR","SPEECH","STREAMING"],spaces:[],url:"/guides/real-time-speech-recognition/",contributor:null}],parent:"gradio",prev_obj:"State",next_obj:"UploadButton",slug:"textbox"},uploadbutton:{class:null,name:"UploadButton",description:"Used to create an upload button, when clicked allows a user to upload files that satisfy the specified file type or generic files (if file_type not set).",tags:{preprocessing:"passes the uploaded file as a {file-object} or {List[file-object]} depending on `file_count` (or a {bytes}/{List[bytes]} depending on `type`)",postprocessing:"expects function to return a {str} path to a file, or {List[str]} consisting of paths to files.","examples-format":"a {str} path to a local file that populates the component.",demos:"upload_button"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"label",annotation:"str",doc:"Text to display on the button. Defaults to &quot;Upload a File&quot;.",default:"\"Upload a File\""},{name:"value",annotation:"str | list[str] | Callable | None",doc:"File or list of files to upload by default.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"variant",annotation:"Literal[('primary', 'secondary', 'stop')]",doc:"&#x27;primary&#x27; for main call-to-action, &#x27;secondary&#x27; for a more subdued style, &#x27;stop&#x27; for a stop button.",default:"\"secondary\""},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"size",annotation:"Literal[('sm', 'lg')] | None",doc:"Size of the button. Can be &quot;sm&quot; or &quot;lg&quot;.",default:"None"},{name:"icon",annotation:"str | None",doc:null,default:"None"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int | None",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"None"},{name:"interactive",annotation:"bool",doc:"If False, the UploadButton will be in a disabled state.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"type",annotation:"Literal[('filepath', 'bytes')]",doc:"Type of value to be returned by component. &quot;file&quot; returns a temporary file object with the same base name as the uploaded file, whose full path can be retrieved by file_obj.name, &quot;binary&quot; returns an bytes object.",default:"\"filepath\""},{name:"file_count",annotation:"Literal[('single', 'multiple', 'directory')]",doc:"if single, allows user to upload one file. If &quot;multiple&quot;, user uploads multiple files. If &quot;directory&quot;, user uploads all files in selected directory. Return type will be list for each file in case of &quot;multiple&quot; or &quot;directory&quot;.",default:"\"single\""},{name:"file_types",annotation:"list[str] | None",doc:"List of type of files to be uploaded. &quot;file&quot; allows any file to be uploaded, &quot;image&quot; allows only image files to be uploaded, &quot;audio&quot; allows only audio files to be uploaded, &quot;video&quot; allows only video files to be uploaded, &quot;text&quot; allows only text files to be uploaded.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"click",description:"Triggered when the UploadButton is clicked.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.UploadButton",slug:"upload-button-click"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the UploadButton.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.UploadButton",slug:"upload-button-upload"}],string_shortcuts:[["UploadButton","uploadbutton","Uses default values"]],demos:[["upload_button","import gradio as gr\n\ndef upload_file(files):\n    file_paths = [file.name for file in files]\n    return file_paths\n\nwith gr.Blocks() as demo:\n    file_output = gr.File()\n    upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"image\", \"video\"], file_count=\"multiple\")\n    upload_button.upload(upload_file, upload_button, file_output)\n\ndemo.launch()\n"]],parent:"gradio",prev_obj:"Textbox",next_obj:"Video",slug:"upload-button"},video:{class:null,name:"Video",description:"Creates a video component that can be used to upload/record videos (as an input) or display videos (as an output). For the video to be playable in the browser it must have a compatible container and codec combination. Allowed combinations are .mp4 with h264 codec, .ogg with theora codec, and .webm with vp9 codec. If the component detects that the output video would not be playable in the browser it will attempt to convert it to a playable mp4 video. If the conversion fails, the original video is returned.",tags:{preprocessing:"passes the uploaded video as a {str} filepath or URL whose extension can be modified by `format`.",postprocessing:"expects a {str} or {pathlib.Path} filepath to a video which is displayed, or a {Tuple[str | pathlib.Path, str | pathlib.Path | None]} where the first element is a filepath to a video and the second element is an optional filepath to a subtitle file.","examples-format":"a {str} filepath to a local file that contains the video, or a {Tuple[str, str]} where the first element is a filepath to a video file and the second element is a filepath to a subtitle file.",demos:"video_identity, video_subtitle"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"value",annotation:"str | Path | tuple[str | Path, str | Path | None] | Callable | None",doc:"A path or URL for the default value that Video component is going to take. Can also be a tuple consisting of (video filepath, subtitle filepath). If a subtitle file is provided, it should be of type .srt or .vtt. Or can be callable, in which case the function will be called whenever the app loads to set the initial value of the component.",default:"None"},{name:"format",annotation:"str | None",doc:"Format of video format to be returned by component, such as &#x27;avi&#x27; or &#x27;mp4&#x27;. Use &#x27;mp4&#x27; to ensure browser playability. If set to None, video will keep uploaded format.",default:"None"},{name:"sources",annotation:"list[Literal[('upload', 'webcam')]] | None",doc:"A list of sources permitted for video. &quot;upload&quot; creates a box where user can drop an video file, &quot;webcam&quot; allows user to record a video from their webcam. If None, defaults to [&quot;upload, &quot;webcam&quot;].",default:"None"},{name:"height",annotation:"int | str | None",doc:"The height of the displayed video, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"width",annotation:"int | str | None",doc:"The width of the displayed video, specified in pixels if a number is passed, or in CSS units if a string is passed.",default:"None"},{name:"label",annotation:"str | None",doc:"The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",default:"None"},{name:"every",annotation:"float | None",doc:"If `value` is a callable, run the function &#x27;every&#x27; number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component&#x27;s .load_event attribute.",default:"None"},{name:"show_label",annotation:"bool | None",doc:"if True, will display label.",default:"None"},{name:"container",annotation:"bool",doc:"If True, will place the component in a container - providing some extra padding around the border.",default:"True"},{name:"scale",annotation:"int | None",doc:"relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.",default:"None"},{name:"min_width",annotation:"int",doc:"minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",default:"160"},{name:"interactive",annotation:"bool | None",doc:"if True, will allow users to upload a video; if False, can only be used to display videos. If not provided, this is inferred based on whether the component is used as an input or output.",default:"None"},{name:"visible",annotation:"bool",doc:"If False, component will be hidden.",default:"True"},{name:"elem_id",annotation:"str | None",doc:"An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"elem_classes",annotation:"list[str] | str | None",doc:"An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",default:"None"},{name:"render",annotation:"bool",doc:"If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",default:"True"},{name:"mirror_webcam",annotation:"bool",doc:"If True webcam will be mirrored. Default is True.",default:"True"},{name:"include_audio",annotation:"bool | None",doc:"Whether the component should record/retain the audio track for a video. By default, audio is excluded for webcam videos and included for uploaded videos.",default:"None"},{name:"autoplay",annotation:"bool",doc:"Whether to automatically play the video when the component is used as an output. Note: browsers will not autoplay video files if the user has not interacted with the page yet.",default:"False"},{name:"show_share_button",annotation:"bool | None",doc:"If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.",default:"None"},{name:"show_download_button",annotation:"bool | None",doc:"If True, will show a download icon in the corner of the component that allows user to download the output. If False, icon does not appear. By default, it will be True for output components and False for input components.",default:"None"},{name:"min_length",annotation:"int | None",doc:"The minimum length of video (in seconds) that the user can pass into the prediction function. If None, there is no minimum length.",default:"None"},{name:"max_length",annotation:"int | None",doc:"The maximum length of video (in seconds) that the user can pass into the prediction function. If None, there is no maximum length.",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"change",description:"Triggered when the value of the Video changes either because of user input (e.g. a user types in a textbox) OR because of a function update (e.g. an image receives a value from the output of an event trigger). See `.input()` for a listener that is only triggered by user input.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-change"},{fn:null,name:"clear",description:"This listener is triggered when the user clears the Video using the X button for the component.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-clear"},{fn:null,name:"start_recording",description:"This listener is triggered when the user starts recording with the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-start-recording"},{fn:null,name:"stop_recording",description:"This listener is triggered when the user stops recording with the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-stop-recording"},{fn:null,name:"stop",description:"This listener is triggered when the user reaches the end of the media playing in the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-stop"},{fn:null,name:"play",description:"This listener is triggered when the user plays the media in the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-play"},{fn:null,name:"pause",description:"This listener is triggered when the media in the Video stops for any reason.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-pause"},{fn:null,name:"end",description:"This listener is triggered when the user reaches the end of the media playing in the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-end"},{fn:null,name:"upload",description:"This listener is triggered when the user uploads a file into the Video.",tags:{},parameters:[{name:"fn",annotation:"Callable | None | Literal['decorator']",doc:"the function to call when this event is triggered. Often a machine learning model&#x27;s prediction function. Each parameter of the function corresponds to one input component, and the function should return a single value or a tuple of values, with each element in the tuple corresponding to one output component.",default:"\"decorator\""},{name:"inputs",annotation:"Component | list[Component] | set[Component] | None",doc:"List of gradio.components to use as inputs. If the function takes no inputs, this should be an empty list.",default:"None"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"List of gradio.components to use as outputs. If the function returns no outputs, this should be an empty list.",default:"None"},{name:"api_name",annotation:"str | None | Literal[False]",doc:"defines how the endpoint appears in the API docs. Can be a string, None, or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If None (default), the name of the function will be used as the API endpoint. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use this event.",default:"None"},{name:"scroll_to_output",annotation:"bool",doc:"If True, will scroll to output component on completion",default:"False"},{name:"show_progress",annotation:"Literal[('full', 'minimal', 'hidden')]",doc:"If True, will show progress animation while pending",default:"\"full\""},{name:"queue",annotation:"bool | None",doc:"If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.",default:"None"},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. The lists should be of equal length (and be up to length `max_batch_size`). The function is then *required* to return a tuple of lists (even if there is only 1 output component), with each list in the tuple corresponding to one output component.",default:"False"},{name:"max_batch_size",annotation:"int",doc:"Maximum number of inputs to batch together if this is called from the queue (only relevant if batch=True)",default:"4"},{name:"preprocess",annotation:"bool",doc:"If False, will not run preprocessing of component data before running &#x27;fn&#x27; (e.g. leaving it as a base64 string if this method is called with the `Image` component).",default:"True"},{name:"postprocess",annotation:"bool",doc:"If False, will not run postprocessing of component data before returning &#x27;fn&#x27; output to the browser.",default:"True"},{name:"cancels",annotation:"dict[str, Any] | list[dict[str, Any]] | None",doc:"A list of other events to cancel when this listener is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method. Functions that have not yet run (or generators that are iterating) will be cancelled, but functions that are currently running will be allowed to finish.",default:"None"},{name:"every",annotation:"float | None",doc:"Run this event &#x27;every&#x27; number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.",default:"None"},{name:"trigger_mode",annotation:"Literal[('once', 'multiple', 'always_last')] | None",doc:"If &quot;once&quot; (default for all events except `.change()`) would not allow any submissions while an event is pending. If set to &quot;multiple&quot;, unlimited submissions are allowed while pending, and &quot;always_last&quot; (default for `.change()` event) would allow a second submission after the pending event is complete.",default:"None"},{name:"js",annotation:"str | None",doc:"Optional frontend js method to run before running &#x27;fn&#x27;. Input arguments for js method are values of &#x27;inputs&#x27; and &#x27;outputs&#x27;, return should be a list of values for output components.",default:"None"},{name:"concurrency_limit",annotation:"int | None | Literal['default']",doc:"If set, this is the maximum number of this event that can be running simultaneously. Can be set to None to mean no concurrency_limit (any number of this event can be running simultaneously). Set to &quot;default&quot; to use the default concurrency limit (defined by the `default_concurrency_limit` parameter in `Blocks.queue()`, which itself is 1 by default).",default:"\"default\""},{name:"concurrency_id",annotation:"str | None",doc:"If set, this is the id of the concurrency group. Events with the same concurrency_id will be limited by the lowest set concurrency_limit.",default:"None"},{name:"show_api",annotation:"bool",doc:"whether to show this event in the &quot;view API&quot; page of the Gradio app, or in the &quot;.view_api()&quot; method of the Gradio clients. Unlike setting api_name to False, setting show_api to False will still allow downstream apps to use this event. If fn is None, show_api will automatically be set to False.",default:"True"}],returns:{},example:null,override_signature:null,parent:"gradio.Video",slug:"video-upload"}],string_shortcuts:[["Video","video","Uses default values"],["PlayableVideo","playablevideo","Uses format=\"mp4\""]],demos:[["video_identity","import gradio as gr\nimport os\n\n\ndef video_identity(video):\n    return video\n\n\ndemo = gr.Interface(video_identity, \n                    gr.Video(), \n                    \"playable_video\", \n                    examples=[\n                        os.path.join(os.path.dirname(__file__), \n                                     \"video/video_sample.mp4\")], \n                    cache_examples=True)\n\nif __name__ == \"__main__\":\n    demo.launch()"],["video_subtitle","import gradio as gr\nimport os\n\na = os.path.join(os.path.dirname(__file__), \"files/a.mp4\")  # Video\nb = os.path.join(os.path.dirname(__file__), \"files/b.mp4\")  # Video\ns1 = os.path.join(os.path.dirname(__file__), \"files/s1.srt\")  # Subtitle\ns2 = os.path.join(os.path.dirname(__file__), \"files/s2.vtt\")  # Subtitle\n\n\ndef video_demo(video, subtitle=None):\n    if subtitle is None:\n        return video\n\n    return [video, subtitle.name]\n\n\ndemo = gr.Interface(\n    fn=video_demo,\n    inputs=[\n        gr.Video(label=\"In\", interactive=True),\n        gr.File(label=\"Subtitle\", file_types=[\".srt\", \".vtt\"]),\n    ],\n    outputs=gr.Video(label=\"Out\"),\n    examples=[\n        [a, s1],\n        [b, s2],\n        [a, None],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],parent:"gradio",prev_obj:"UploadButton",next_obj:"load",slug:"video"}},helpers:{examples:{class:null,name:"Examples",description:"This class is a wrapper over the Dataset component and can be used to create Examples for Blocks / Interfaces. Populates the Dataset component with examples and assigns event listener so that clicking on an example populates the input/output components. Optionally handles example caching for fast inference. \u003Cbr>",tags:{demos:"blocks_inputs, fake_gan",guides:"more-on-examples-and-flagging, using-hugging-face-integrations, image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers, create-your-own-friends-with-a-gan"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"examples",annotation:"list[Any] | list[list[Any]] | str",doc:"example inputs that can be clicked to populate specific components. Should be nested list, in which the outer list consists of samples and each inner list consists of an input corresponding to each input component. A string path to a directory of examples can also be provided but it should be within the directory with the python file running the gradio app. If there are multiple input components and a directory is provided, a log.csv file must be present in the directory to link corresponding inputs."},{name:"inputs",annotation:"Component | list[Component]",doc:"the component or list of components corresponding to the examples"},{name:"outputs",annotation:"Component | list[Component] | None",doc:"optionally, provide the component or list of components corresponding to the output of the examples. Required if `cache_examples` is True.",default:"None"},{name:"fn",annotation:"Callable | None",doc:"optionally, provide the function to run to generate the outputs corresponding to the examples. Required if `cache_examples` is True.",default:"None"},{name:"cache_examples",annotation:"bool",doc:"if True, caches examples for fast runtime. If True, then `fn` and `outputs` must be provided. If `fn` is a generator function, then the last yielded value will be used as the output.",default:"False"},{name:"examples_per_page",annotation:"int",doc:"how many examples to show per page.",default:"10"},{name:"label",annotation:"str | None",doc:"the label to use for the examples component (by default, &quot;Examples&quot;)",default:"\"Examples\""},{name:"elem_id",annotation:"str | None",doc:"an optional string that is assigned as the id of this component in the HTML DOM.",default:"None"},{name:"run_on_click",annotation:"bool",doc:"if cache_examples is False, clicking on an example does not run the function when an example is clicked. Set this to True to run the function when an example is clicked. Has no effect if cache_examples is True.",default:"False"},{name:"preprocess",annotation:"bool",doc:"if True, preprocesses the example input before running the prediction function and caching the output. Only applies if `cache_examples` is True.",default:"True"},{name:"postprocess",annotation:"bool",doc:"if True, postprocesses the example output after running the prediction function and before caching. Only applies if `cache_examples` is True.",default:"True"},{name:"api_name",annotation:"str | Literal[False]",doc:"Defines how the event associated with clicking on the examples appears in the API docs. Can be a string or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use the example function.",default:"\"load_example\""},{name:"batch",annotation:"bool",doc:"If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. Used only if cache_examples is True.",default:"False"}],returns:{annotation:null},example:null,fns:[],demos:[["blocks_inputs","import gradio as gr\nimport os\n\n\ndef combine(a, b):\n    return a + \" \" + b\n\n\ndef mirror(x):\n    return x\n\n\nwith gr.Blocks() as demo:\n\n    txt = gr.Textbox(label=\"Input\", lines=2)\n    txt_2 = gr.Textbox(label=\"Input 2\")\n    txt_3 = gr.Textbox(value=\"\", label=\"Output\")\n    btn = gr.Button(value=\"Submit\")\n    btn.click(combine, inputs=[txt, txt_2], outputs=[txt_3])\n\n    with gr.Row():\n        im = gr.Image()\n        im_2 = gr.Image()\n\n    btn = gr.Button(value=\"Mirror Image\")\n    btn.click(mirror, inputs=[im], outputs=[im_2])\n\n    gr.Markdown(\"## Text Examples\")\n    gr.Examples(\n        [[\"hi\", \"Adam\"], [\"hello\", \"Eve\"]],\n        [txt, txt_2],\n        txt_3,\n        combine,\n        cache_examples=True,\n    )\n    gr.Markdown(\"## Image Examples\")\n    gr.Examples(\n        examples=[os.path.join(os.path.dirname(__file__), \"lion.jpg\")],\n        inputs=im,\n        outputs=im_2,\n        fn=mirror,\n        cache_examples=True,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["fake_gan","# This demo needs to be run from the repo folder.\n# python demo/fake_gan/run.py\nimport random\n\nimport gradio as gr\n\n\ndef fake_gan():\n    images = [\n        (random.choice(\n            [\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1151ce9f4b2043de0d2e3b7826127998.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-116b5e92936b766b7fdfc242649337f7.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1163530ca19b5cebe1b002b8ec67b6fc.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1116395d6e6a6581eef8b8038f4c8e55.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-11319be65db395d0e8e6855d18ddcef0.jpg\",\n            ]\n        ), f\"label {i}\")\n        for i in range(3)\n    ]\n    return images\n\n\nwith gr.Blocks() as demo:\n    gallery = gr.Gallery(\n        label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n    , columns=[3], rows=[1], object_fit=\"contain\", height=\"auto\")\n    btn = gr.Button(\"Generate images\", scale=0)\n\n    btn.click(fake_gan, None, gallery)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"]],guides:[{name:"using-hugging-face-integrations",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:1,absolute_index:25,pretty_name:"Using Hugging Face Integrations",content:"# Using Hugging Face Integrations\n\n\n\n\n\n\n## Introduction\n\nThe Hugging Face Hub is a central platform that has hundreds of thousands of [models](https://huggingface.co/models), [datasets](https://huggingface.co/datasets) and [demos](https://huggingface.co/spaces) (also known as Spaces). \n\nGradio has multiple features that make it extremely easy to leverage existing models and Spaces on the Hub. This guide walks through these features.\n\n\n## Demos with the Hugging Face Inference API\n\nHugging Face has a free service called the [Inference API](https://huggingface.co/inference-api), which allows you to send HTTP requests to models in the Hub. For transformers or diffusers-based models, the API can be 2 to 10 times faster than running the inference yourself. The API is free (rate limited), and you can switch to dedicated [Inference Endpoints](https://huggingface.co/pricing) when you want to use it in production. Gradio integrates directly with the Hugging Face Inference API so that you can create a demo simply by specifying a model's name (e.g. `Helsinki-NLP/opus-mt-en-es`), like this:\n\n```python\nimport gradio as gr\n\ndemo = gr.load(\"Helsinki-NLP/opus-mt-en-es\", src=\"models\")\n\ndemo.launch()\n```\n\nFor any Hugging Face model supported in the Inference API, Gradio automatically infers the expected input and output and make the underlying server calls, so you don't have to worry about defining the prediction function. \n\nNotice that we just put specify the model name and state that the `src` should be `models` (Hugging Face's Model Hub). There is no need to install any dependencies (except `gradio`) since you are not loading the model on your computer.\n\nYou might notice that the first inference takes about 20 seconds. This happens since the Inference API is loading the model in the server. You get some benefits afterward:\n\n- The inference will be much faster.\n- The server caches your requests.\n- You get built-in automatic scaling.\n\n## Hosting your Gradio demos on Spaces\n\n[Hugging Face Spaces](https://hf.co/spaces) allows anyone to host their Gradio demos freely, and uploading your Gradio demos take a couple of minutes. You can head to [hf.co/new-space](https://huggingface.co/new-space), select the Gradio SDK, create an `app.py` file, and voila! You have a demo you can share with anyone else. To learn more, read [this guide how to host on Hugging Face Spaces using the website](https://huggingface.co/blog/gradio-spaces).\n\nAlternatively, you can create a Space programmatically, making use of the [huggingface_hub client library](https://huggingface.co/docs/huggingface_hub/index) library. Here's an example:\n\n```python\nfrom huggingface_hub import (\n    create_repo,\n    get_full_repo_name,\n    upload_file,\n)\ncreate_repo(name=target_space_name, token=hf_token, repo_type=\"space\", space_sdk=\"gradio\")\nrepo_name = get_full_repo_name(model_id=target_space_name, token=hf_token)\nfile_url = upload_file(\n    path_or_fileobj=\"file.txt\",\n    path_in_repo=\"app.py\",\n    repo_id=repo_name,\n    repo_type=\"space\",\n    token=hf_token,\n)\n```\n\nHere, `create_repo` creates a gradio repo with the target name under a specific account using that account's Write Token. `repo_name` gets the full repo name of the related repo. Finally `upload_file` uploads a file inside the repo with the name `app.py`.\n\n\n## Loading demos from Spaces\n\nYou can also use and remix existing Gradio demos on Hugging Face Spaces. For example, you could take two existing Gradio demos on Spaces and put them as separate tabs and create a new demo. You can run this new demo locally, or upload it to Spaces, allowing endless possibilities to remix and create new demos!\n\nHere's an example that does exactly that:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n  with gr.Tab(\"Translate to Spanish\"):\n    gr.load(\"gradio/en2es\", src=\"spaces\")\n  with gr.Tab(\"Translate to French\"):\n    gr.load(\"abidlabs/en2fr\", src=\"spaces\")\n\ndemo.launch()\n```\n\nNotice that we use `gr.load()`, the same method we used to load models using the Inference API. However, here we specify that the `src` is `spaces` (Hugging Face Spaces). \n\nNote: loading a Space in this way may result in slight differences from the original Space. In particular, any attributes that apply to the entire Blocks, such as the theme or custom CSS/JS, will not be loaded. You can copy these properties from the Space you are loading into your own `Blocks` object. \n\n## Demos with the `Pipeline` in `transformers`\n\nHugging Face's popular `transformers` library has a very easy-to-use abstraction, [`pipeline()`](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/pipelines#transformers.pipeline) that handles most of the complex code to offer a simple API for common tasks. By specifying the task and an (optional) model, you can build a demo around an existing model with few lines of Python:\n\n```python\nimport gradio as gr\n\nfrom transformers import pipeline\n\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ndef predict(text):\n  return pipe(text)[0][\"translation_text\"]\n\ndemo = gr.Interface(\n  fn=predict,\n  inputs='text',\n  outputs='text',\n)\n\ndemo.launch()\n```\n\nBut `gradio` actually makes it even easier to convert a `pipeline` to a demo, simply by using the `gradio.Interface.from_pipeline` methods, which skips the need to specify the input and output components:\n\n```python\nfrom transformers import pipeline\nimport gradio as gr\n\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ndemo = gr.Interface.from_pipeline(pipe)\ndemo.launch()\n```\n\nThe previous code produces the following interface, which you can try right here in your browser:\n\n\u003Cgradio-app space=\"gradio/en2es\">\u003C/gradio-app>\n\n\n## Recap\n\nThat's it! Let's recap the various ways Gradio and Hugging Face work together:\n\n1. You can build a demo around the Inference API without having to load the model easily using `gr.load()`.\n2. You host your Gradio demo on Hugging Face Spaces, either using the GUI or entirely in Python.\n3. You can load demos from Hugging Face Spaces to remix and create new Gradio demos using `gr.load()`.\n4. You can convert a `transformers` pipeline into a Gradio demo using `from_pipeline()`.\n\nü§ó\n",tags:["HUB","SPACES","EMBED"],spaces:["https://huggingface.co/spaces/gradio/en2es"],url:"/guides/using-hugging-face-integrations/",contributor:"\u003Ca href=\"https://huggingface.co/osanseviero\">Omar Sanseviero\u003C/a> ü¶ô"},{name:"image-classification-in-pytorch",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:29,pretty_name:"Image Classification In Pytorch",content:"# Image Classification in PyTorch\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own.\n\n```python\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\nBecause we will be using the model for inference, we have called the `.eval()` method.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `PIL` image\n\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image.\n\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/pytorch-image-classifier\">\n\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","RESNET","PYTORCH"],spaces:["https://huggingface.co/spaces/abidlabs/pytorch-image-classifier","https://huggingface.co/spaces/pytorch/ResNet","https://huggingface.co/spaces/pytorch/ResNext","https://huggingface.co/spaces/pytorch/SqueezeNet"],url:"/guides/image-classification-in-pytorch/",contributor:null},{name:"image-classification-in-tensorflow",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:30,pretty_name:"Image Classification In Tensorflow",content:"# Image Classification in TensorFlow and Keras\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging.\n\nSuch models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like the demo on the bottom of the page.\n\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\n\n## Step 1 ‚Äî Setting up the Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own.\n\n```python\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\nThis line automatically downloads the MobileNet model and weights using the Keras library.\n\n## Step 2 ‚Äî Defining a `predict` function\n\nNext, we will need to define a function that takes in the _user input_, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\nLet's break this down. The function takes one parameter:\n\n- `inp`: the input image as a `numpy` array\n\nThen, the function adds a batch dimension, passes it through the model, and returns:\n\n- `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## Step 3 ‚Äî Creating a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it.\n\nIn this case, the input component is a drag-and-drop image component. To create this input, we can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n\nFinally, we'll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(shape=(224, 224)),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\n\n\u003Cgradio-app space=\"gradio/keras-image-classifier\">\n\n---\n\nAnd you're done! That's all the code you need to build a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","MOBILENET","TENSORFLOW"],spaces:["https://huggingface.co/spaces/abidlabs/keras-image-classifier"],url:"/guides/image-classification-in-tensorflow/",contributor:null},{name:"image-classification-with-vision-transformers",category:"integrating-other-frameworks",pretty_category:"Integrating Other Frameworks",guide_index:null,absolute_index:31,pretty_name:"Image Classification With Vision Transformers",content:"# Image Classification with Vision Transformers\n\n\n\n\n## Introduction\n\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control.\n\nState-of-the-art image classifiers are based on the _transformers_ architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio's _image_ input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like the demo on the bottom of the page.\n\nLet's get started!\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started).\n\n## Step 1 ‚Äî Choosing a Vision Image Classification Model\n\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks.\n\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\n\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at a resolution of 224x224 pixels. We will use this model for our demo.\n\n## Step 2 ‚Äî Loading the Vision Transformer Model with Gradio\n\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing.\nAll of these are automatically inferred from the model tags.\n\nBesides the import statement, it only takes a single line of Python to load and launch the demo.\n\nWe use the `gr.Interface.load()` method and pass in the path to the model including the `huggingface/` to designate that it is from the Hugging Face Hub.\n\n```python\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples.\n\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a human-interpretable prediction. Try uploading your own image!\n\n\u003Cgradio-app space=\"gradio/vision-transformer\">\n\n---\n\nAnd you're done! In one line of code, you have built a web demo for an image classifier. If you'd like to share with others, try setting `share=True` when you `launch()` the Interface!\n",tags:["VISION","TRANSFORMERS","HUB"],spaces:["https://huggingface.co/spaces/abidlabs/vision-transformer"],url:"/guides/image-classification-with-vision-transformers/",contributor:null},{name:"create-your-own-friends-with-a-gan",category:"other-tutorials",pretty_category:"Other Tutorials",guide_index:null,absolute_index:44,pretty_name:"Create Your Own Friends With A Gan",content:"# Create Your Own Friends with a GAN\n\n\n\n\n\n\n## Introduction\n\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we'll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\n\nGenerative Adversarial Networks, often known just as _GANs_, are a specific class of deep-learning models that are designed to learn from an input dataset to create (_generate!_) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\n\nToday we'll briefly look at the high-level intuition behind GANs, and then we'll build a small demo around a pre-trained GAN to see what all the fuss is about. Here's a [peek](https://nimaboscarino-cryptopunks.hf.space) at what we're going to be putting together.\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\n\n## GANs: a very brief introduction\n\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the _generator_, is responsible for generating images. The other network, the _discriminator_, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\n\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (_adversarial!_) relationship, the images that get generated improve to the point where they become indistinguishable to human eyes!\n\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\n\n## Step 1 ‚Äî Create the Generator model\n\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\n\n```python\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\n\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\n\n```python\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n## Step 2 ‚Äî Defining a `predict` function\n\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it's common to pass random noise into our model as the input, so we'll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`'s `save_image` function to save the output of the model as a `png` file, and return the file name:\n\n```python\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWe're giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We'll then be able to reproduce punks if we want to see them again by passing in the same seed.\n\n_Note!_ Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we'll start by generating 4 punks at a time.\n\n## Step 3 ‚Äî Creating a Gradio interface\n\nAt this point you can even run the code you have with `predict(\u003CSOME_NUMBER>)`, and you'll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we'll build out a simple interface with Gradio. Our goals here are to:\n\n- Set a slider input so users can choose the \"seed\" value\n- Use an image component for our output to showcase the generated punks\n- Use our `predict()` to take the seed and generate the images\n\nWith `gr.Interface()`, we can define all of that with a single function call:\n\n```python\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n\n## Step 4 ‚Äî Even more punks!\n\nGenerating 4 punks at a time is a good start, but maybe we'd like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\n\n```python\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\n\n```python\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\nWhen you relaunch your interface, you should see a second slider that'll let you control the number of punks!\n\n## Step 5 - Polishing it up\n\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ‚ú®\n\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\n\n```python\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we've listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\n\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens üëÄ `article` will also accept HTML, as [explored in a previous guide](/guides/key-features/#descriptive-content)!\n\nWhen you're all done, you may end up with something like [this](https://nimaboscarino-cryptopunks.hf.space).\n\nFor reference, here is our full code:\n\n```python\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n---\n\nCongratulations! You've built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making even more awesome demos ü§ó\n",tags:["GAN","IMAGE","HUB"],spaces:["https://huggingface.co/spaces/NimaBoscarino/cryptopunks","https://huggingface.co/spaces/nateraw/cryptopunks-generator"],url:"/guides/create-your-own-friends-with-a-gan/",contributor:"\u003Ca href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino\u003C/a> and \u003Ca href=\"https://huggingface.co/nateraw\">Nate Raw\u003C/a>"}],parent:"gradio",prev_obj:"Video",next_obj:"Progress",slug:"examples"},progress:a,make_waveform:{class:null,name:"make_waveform",description:"Generates a waveform video from an audio file. Useful for creating an easy to share audio visualization. The output should be passed into a `gr.Video` component.",tags:{parameters:"audio: Audio file path or tuple of (sample_rate, audio_data)\u003Cbr>bg_color: Background color of waveform (ignored if bg_image is provided)\u003Cbr>bg_image: Background image of waveform\u003Cbr>fg_alpha: Opacity of foreground waveform\u003Cbr>bars_color: Color of waveform bars. Can be a single color or a tuple of (start_color, end_color) of gradient\u003Cbr>bar_count: Number of bars in waveform\u003Cbr>bar_width: Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.\u003Cbr>animate: If true, the audio waveform overlay will be animated, if false, it will be static.",returns:"A filepath to the output video in mp4 format."},parameters:[{name:"audio",annotation:"str | tuple[int, np.ndarray]",doc:"Audio file path or tuple of (sample_rate, audio_data)"},{name:"bg_color",annotation:"str",doc:"Background color of waveform (ignored if bg_image is provided)",default:"\"#f3f4f6\""},{name:"bg_image",annotation:"str | None",doc:"Background image of waveform",default:"None"},{name:"fg_alpha",annotation:"float",doc:"Opacity of foreground waveform",default:"0.75"},{name:"bars_color",annotation:"str | tuple[str, str]",doc:"Color of waveform bars. Can be a single color or a tuple of (start_color, end_color) of gradient",default:"('#fbbf24', '#ea580c')"},{name:"bar_count",annotation:"int",doc:"Number of bars in waveform",default:"50"},{name:"bar_width",annotation:"float",doc:"Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.",default:"0.6"},{name:"animate",annotation:"bool",doc:"If true, the audio waveform overlay will be animated, if false, it will be static.",default:"False"}],returns:{annotation:null,doc:"A filepath to the output video in mp4 format."},example:null,fns:[],parent:"gradio",prev_obj:"Progress",next_obj:"load",slug:"make-waveform"},load:{class:null,name:"load",description:"Method that constructs a Blocks from a Hugging Face repo. Can accept model repos (if src is \"models\") or Space repos (if src is \"spaces\"). The input and output components are automatically loaded from the repo.",tags:{parameters:"name: the name of the model (e.g. \"gpt2\" or \"facebook/bart-base\") or space (e.g. \"flax-community/spanish-gpt2\"), can include the `src` as prefix (e.g. \"models/facebook/bart-base\")\u003Cbr>src: the source of the model: `models` or `spaces` (or leave empty if source is provided as a prefix in `name`)\u003Cbr>hf_token: optional access token for loading private Hugging Face Hub models or spaces. Find your token here: https://huggingface.co/settings/tokens.  Warning: only provide this if you are loading a trusted private Space as it can be read by the Space you are loading.\u003Cbr>alias: optional string used as the name of the loaded model instead of the default name (only applies if loading a Space running Gradio 2.x)",returns:"a Gradio Blocks object for the given model"},parameters:[{name:"name",annotation:"str",doc:"the name of the model (e.g. &quot;gpt2&quot; or &quot;facebook/bart-base&quot;) or space (e.g. &quot;flax-community/spanish-gpt2&quot;), can include the `src` as prefix (e.g. &quot;models/facebook/bart-base&quot;)"},{name:"src",annotation:"str | None",doc:"the source of the model: `models` or `spaces` (or leave empty if source is provided as a prefix in `name`)",default:"None"},{name:"hf_token",annotation:"str | None",doc:"optional access token for loading private Hugging Face Hub models or spaces. Find your token here: https://huggingface.co/settings/tokens.  Warning: only provide this if you are loading a trusted private Space as it can be read by the Space you are loading.",default:"None"},{name:"alias",annotation:"str | None",doc:"optional string used as the name of the loaded model instead of the default name (only applies if loading a Space running Gradio 2.x)",default:"None"}],returns:{annotation:null,doc:"a Gradio Blocks object for the given model"},example:"import gradio as gr\ndemo = gr.load(\"gradio/question-answering\", src=\"spaces\")\ndemo.launch()",fns:[],parent:"gradio",prev_obj:"make_waveform",next_obj:"Error",slug:"load"}},modals:{error:{class:null,name:"Error",description:"This class allows you to pass custom error messages to the user. You can do so by raising a gr.Error(\"custom message\") anywhere in the code, and when that line is executed the custom message will appear in a modal on the demo.",tags:{demos:"calculator, blocks_chained_events"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"message",annotation:"\u003Cclass 'str'>",doc:"The error message to be displayed to the user.",default:"\"Error raised.\""}],returns:{annotation:null},example:"import gradio as gr\ndef divide(numerator, denominator):\n    if denominator == 0:\n        raise gr.Error(\"Cannot divide by zero!\")\ngr.Interface(divide, [\"number\", \"number\"], \"number\").launch()",fns:[],demos:[["calculator","import gradio as gr\n#from foo import BAR\n#\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        if num2 == 0:\n            raise gr.Error(\"Cannot divide by zero!\")\n        return num1 / num2\n\ndemo = gr.Interface(\n    calculator,\n    [\n        \"number\", \n        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n        \"number\"\n    ],\n    \"number\",\n    examples=[\n        [45, \"add\", 3],\n        [3.14, \"divide\", 2],\n        [144, \"multiply\", 2.5],\n        [0, \"subtract\", 1.2],\n    ],\n    title=\"Toy Calculator\",\n    description=\"Here's a sample toy calculator. Allows you to calculate things like $2+2=4$\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["blocks_chained_events","import gradio as gr\nimport time\n\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\ndemo.queue()\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)"]],parent:"gradio",prev_obj:"EventData",next_obj:"EventData",slug:"error"},eventdata:{class:null,name:"EventData",description:"When a subclass of EventData is added as a type hint to an argument of an event listener method, this object will be passed as that argument. It contains information about the event that triggered the listener, such the target object, and other data related to the specific event that are attributes of the subclass. \u003Cbr>",tags:{demos:"gallery_selections, tictactoe"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"target",annotation:"Block | None",doc:"The target object that triggered the event. Can be used to distinguish if multiple components are bound to the same listener."}],returns:{annotation:null},example:"table = gr.Dataframe([[1, 2, 3], [4, 5, 6]])\ngallery = gr.Gallery([(\"cat.jpg\", \"Cat\"), (\"dog.jpg\", \"Dog\")])\ntextbox = gr.Textbox(\"Hello World!\")\n\nstatement = gr.Textbox()\n\ndef on_select(evt: gr.SelectData):  # SelectData is a subclass of EventData\n    return f\"You selected {evt.value} at {evt.index} from {evt.target}\"\n\ntable.select(on_select, None, statement)\ngallery.select(on_select, None, statement)\ntextbox.select(on_select, None, statement)",fns:[],demos:[["gallery_selections","import gradio as gr\nimport numpy as np\n\nwith gr.Blocks() as demo:\n    imgs = gr.State()\n    gallery = gr.Gallery(allow_preview=False)\n\n    def deselect_images():\n        return gr.Gallery(selected_index=None)\n\n    def generate_images():\n        images = []\n        for _ in range(9):\n            image = np.ones((100, 100, 3), dtype=np.uint8) * np.random.randint(\n                0, 255, 3\n            )  # image is a solid single color\n            images.append(image)\n        return images, images\n\n    demo.load(generate_images, None, [gallery, imgs])\n\n    with gr.Row():\n        selected = gr.Number(show_label=False)\n        darken_btn = gr.Button(\"Darken selected\")\n    deselect_button = gr.Button(\"Deselect\")\n\n    deselect_button.click(deselect_images, None, gallery)\n\n    def get_select_index(evt: gr.SelectData):\n        return evt.index\n\n    gallery.select(get_select_index, None, selected)\n\n    def darken_img(imgs, index):\n        index = int(index)\n        imgs[index] = np.round(imgs[index] * 0.8).astype(np.uint8)\n        return imgs, imgs\n\n    darken_btn.click(darken_img, [imgs, selected], [imgs, gallery])\n\nif __name__ == \"__main__\":\n    demo.launch()\n"],["tictactoe","import gradio as gr\n\nwith gr.Blocks() as demo:\n    turn = gr.Textbox(\"X\", interactive=False, label=\"Turn\")\n    board = gr.Dataframe(value=[[\"\", \"\", \"\"]] * 3, interactive=False, type=\"array\")\n\n    def place(board, turn, evt: gr.SelectData):\n        if evt.value:\n            return board, turn\n        board[evt.index[0]][evt.index[1]] = turn\n        turn = \"O\" if turn == \"X\" else \"X\"\n        return board, turn\n\n    board.select(place, [board, turn], [board, turn], show_progress=\"hidden\")\n\nif __name__ == \"__main__\":\n    demo.launch()"]],parent:"gradio",prev_obj:"Error",next_obj:"Warning",slug:"event-data"},warning:{class:null,name:"Warning",description:"This function allows you to pass custom warning messages to the user. You can do so simply by writing `gr.Warning('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is yellow by default and has the heading: \"Warning.\" Queue must be enabled for this behavior; otherwise, the warning will be printed to the console using the `warnings` library.",tags:{demos:"blocks_chained_events",parameters:"message: The warning message to be displayed to the user."},parameters:[{name:"message",annotation:"str",doc:"The warning message to be displayed to the user.",default:"\"Warning issued.\""}],returns:{annotation:null},example:"import gradio as gr\ndef hello_world():\n    gr.Warning('This is a warning message.')\n    return \"hello world\"\nwith gr.Blocks() as demo:\n    md = gr.Markdown()\n    demo.load(hello_world, inputs=None, outputs=[md])\ndemo.queue().launch()",fns:[],demos:[["blocks_chained_events","import gradio as gr\nimport time\n\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\ndemo.queue()\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)"]],parent:"gradio",prev_obj:"EventData",next_obj:"Info",slug:"warning"},info:{class:null,name:"Info",description:"This function allows you to pass custom info messages to the user. You can do so simply by writing `gr.Info('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is gray by default and has the heading: \"Info.\" Queue must be enabled for this behavior; otherwise, the message will be printed to the console.",tags:{demos:"blocks_chained_events",parameters:"message: The info message to be displayed to the user."},parameters:[{name:"message",annotation:"str",doc:"The info message to be displayed to the user.",default:"\"Info issued.\""}],returns:{annotation:null},example:"import gradio as gr\ndef hello_world():\n    gr.Info('This is some info.')\n    return \"hello world\"\nwith gr.Blocks() as demo:\n    md = gr.Markdown()\n    demo.load(hello_world, inputs=None, outputs=[md])\ndemo.queue().launch()",fns:[],demos:[["blocks_chained_events","import gradio as gr\nimport time\n\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\ndemo.queue()\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)"]],parent:"gradio",prev_obj:"Warning",next_obj:"Request",slug:"info"}},routes:{request:{class:null,name:"Request",description:"A Gradio request object that can be used to access the request headers, cookies, query parameters and other information about the request from within the prediction function. The class is a thin wrapper around the fastapi.Request class. Attributes of this class include: `headers`, `client`, `query_params`, and `path_params`. If auth is enabled, the `username` attribute can be used to get the logged in user.",tags:{demos:"request_ip_headers"},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"request",annotation:"fastapi.Request | None",doc:"A fastapi.Request",default:"None"},{name:"username",annotation:"str | None",doc:null,default:"None"}],returns:{annotation:null},example:"import gradio as gr\ndef echo(text, request: gr.Request):\n    if request:\n        print(\"Request headers dictionary:\", request.headers)\n        print(\"IP address:\", request.client.host)\n        print(\"Query parameters:\", dict(request.query_params))\n    return text\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()",fns:[],demos:[["request_ip_headers","import gradio as gr\n\n\ndef predict(text, request: gr.Request):\n    headers = request.headers\n    host = request.client.host\n    user_agent = request.headers[\"user-agent\"]\n    return {\n        \"ip\": host,\n        \"user_agent\": user_agent,\n        \"headers\": headers,\n    }\n\n\ngr.Interface(predict, \"text\", \"json\").queue().launch()\n"]],parent:"gradio",prev_obj:"Info",next_obj:"mount_gradio_app",slug:"request"},mount_gradio_app:{class:null,name:"mount_gradio_app",description:"Mount a gradio.Blocks to an existing FastAPI application. \u003Cbr>",tags:{parameters:"app: The parent FastAPI application.\u003Cbr>blocks: The blocks object we want to mount to the parent app.\u003Cbr>path: The path at which the gradio application will be mounted.\u003Cbr>app_kwargs: Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{\"docs_url\": \"/docs\"}`"},parameters:[{name:"app",annotation:"fastapi.FastAPI",doc:"The parent FastAPI application."},{name:"blocks",annotation:"gradio.Blocks",doc:"The blocks object we want to mount to the parent app."},{name:"path",annotation:"str",doc:"The path at which the gradio application will be mounted."},{name:"app_kwargs",annotation:"dict[str, Any] | None",doc:"Additional keyword arguments to pass to the underlying FastAPI app as a dictionary of parameter keys and argument values. For example, `{&quot;docs_url&quot;: &quot;/docs&quot;}`",default:"None"}],returns:{annotation:null},example:"from fastapi import FastAPI\nimport gradio as gr\napp = FastAPI()\n@app.get(\"/\")\ndef read_main():\n    return {\"message\": \"This is your main app\"}\nio = gr.Interface(lambda x: \"Hello, \" + x + \"!\", \"textbox\", \"textbox\")\napp = gr.mount_gradio_app(app, io, path=\"/gradio\")\n# Then run `uvicorn run:app` from the terminal and navigate to http://localhost:8000/gradio.",fns:[],parent:"gradio",prev_obj:"Request",next_obj:"Flagging",slug:"mount-gradio-app"}},py_client:{client:{class:null,name:"Client",description:"The main Client class for the Python client. This class is used to connect to a remote Gradio app and call its API endpoints. \u003Cbr>",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"src",annotation:"str",doc:"Either the name of the Hugging Face Space to load, (e.g. &quot;abidlabs/whisper-large-v2&quot;) or the full URL (including &quot;http&quot; or &quot;https&quot;) of the hosted Gradio app to load (e.g. &quot;http://mydomain.com/app&quot; or &quot;https://bec81a83-5b5c-471e.gradio.live/&quot;)."},{name:"hf_token",annotation:"str | None",doc:"The Hugging Face token to use to access private Spaces. Automatically fetched if you are logged in via the Hugging Face Hub CLI. Obtain from: https://huggingface.co/settings/token",default:"None"},{name:"max_workers",annotation:"int",doc:"The maximum number of thread workers that can be used to make requests to the remote Gradio app simultaneously.",default:"40"},{name:"serialize",annotation:"bool",doc:"Whether the client should serialize the inputs and deserialize the outputs of the remote API. If set to False, the client will pass the inputs and outputs as-is, without serializing/deserializing them. E.g. you if you set this to False, you&#x27;d submit an image in base64 format instead of a filepath, and you&#x27;d get back an image in base64 format from the remote API instead of a filepath.",default:"True"},{name:"output_dir",annotation:"str | Path",doc:"The directory to save files that are downloaded from the remote API. If None, reads from the GRADIO_TEMP_DIR environment variable. Defaults to a temporary directory on your machine.",default:"\"/tmp/gradio\""},{name:"verbose",annotation:"bool",doc:"Whether the client should print statements to the console.",default:"True"},{name:"auth",annotation:"tuple[str, str] | None",doc:null,default:"None"}],returns:{annotation:null},example:"from gradio_client import Client\n\nclient = Client(\"abidlabs/whisper-large-v2\")  # connecting to a Hugging Face Space\nclient.predict(\"test.mp4\", api_name=\"/predict\")\n>> What a nice recording! # returns the result of the remote API call\n\nclient = Client(\"https://bec81a83-5b5c-471e.gradio.live\")  # connecting to a temporary Gradio share URL\njob = client.submit(\"hello\", api_name=\"/predict\")  # runs the prediction in a background thread\njob.result()\n>> 49 # returns the result of the remote API call (blocking call)",fns:[{fn:null,name:"predict",description:"Calls the Gradio API and returns the result (this is a blocking call). &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"args",annotation:"\u003Cclass 'inspect._empty'>",doc:"The arguments to pass to the remote API. The order of the arguments must match the order of the inputs in the Gradio app."},{name:"api_name",annotation:"str | None",doc:"The name of the API endpoint to call starting with a leading slash, e.g. &quot;/predict&quot;. Does not need to be provided if the Gradio app has only one named API endpoint.",default:"None"},{name:"fn_index",annotation:"int | None",doc:"As an alternative to api_name, this parameter takes the index of the API endpoint to call, e.g. 0. Both api_name and fn_index can be provided, but if they conflict, api_name will take precedence.",default:"None"}],returns:{annotation:"Any",doc:"The result of the API call. Will be a Tuple if the API has multiple outputs."},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\nclient.predict(5, \"add\", 4, api_name=\"/predict\")\n>> 9.0",override_signature:null,parent:"gradio.Client",slug:"client-predict"},{fn:null,name:"submit",description:"Creates and returns a Job object which calls the Gradio API in a background thread. The job can be used to retrieve the status and result of the remote API call. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"args",annotation:"\u003Cclass 'inspect._empty'>",doc:"The arguments to pass to the remote API. The order of the arguments must match the order of the inputs in the Gradio app."},{name:"api_name",annotation:"str | None",doc:"The name of the API endpoint to call starting with a leading slash, e.g. &quot;/predict&quot;. Does not need to be provided if the Gradio app has only one named API endpoint.",default:"None"},{name:"fn_index",annotation:"int | None",doc:"As an alternative to api_name, this parameter takes the index of the API endpoint to call, e.g. 0. Both api_name and fn_index can be provided, but if they conflict, api_name will take precedence.",default:"None"},{name:"result_callbacks",annotation:"Callable | list[Callable] | None",doc:"A callback function, or list of callback functions, to be called when the result is ready. If a list of functions is provided, they will be called in order. The return values from the remote API are provided as separate parameters into the callback. If None, no callback will be called.",default:"None"}],returns:{annotation:"Job",doc:"A Job object that can be used to retrieve the status and result of the remote API call."},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\njob = client.submit(5, \"add\", 4, api_name=\"/predict\")\njob.status()\n>> \u003CStatus.STARTING: 'STARTING'>\njob.result()  # blocking call\n>> 9.0",override_signature:null,parent:"gradio.Client",slug:"client-submit"},{fn:null,name:"view_api",description:"Prints the usage info for the API. If the Gradio app has multiple API endpoints, the usage info for each endpoint will be printed separately. If return_format=&quot;dict&quot; the info is returned in dictionary format, as shown in the example below. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"all_endpoints",annotation:"bool | None",doc:"If True, prints information for both named and unnamed endpoints in the Gradio app. If False, will only print info about named endpoints. If None (default), will print info about named endpoints, unless there aren&#x27;t any -- in which it will print info about unnamed endpoints.",default:"None"},{name:"print_info",annotation:"bool",doc:"If True, prints the usage info to the console. If False, does not print the usage info.",default:"True"},{name:"return_format",annotation:"Literal[('dict', 'str')] | None",doc:"If None, nothing is returned. If &quot;str&quot;, returns the same string that would be printed to the console. If &quot;dict&quot;, returns the usage info as a dictionary that can be programmatically parsed, and *all endpoints are returned in the dictionary* regardless of the value of `all_endpoints`. The format of the dictionary is in the docstring of this method.",default:"None"}],returns:{},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\nclient.view_api(return_format=\"dict\")\n>> {\n    'named_endpoints': {\n        '/predict': {\n            'parameters': [\n                {\n                    'label': 'num1',\n                    'type_python': 'int | float',\n                    'type_description': 'numeric value',\n                    'component': 'Number',\n                    'example_input': '5'\n                },\n                {\n                    'label': 'operation',\n                    'type_python': 'str',\n                    'type_description': 'string value',\n                    'component': 'Radio',\n                    'example_input': 'add'\n                },\n                {\n                    'label': 'num2',\n                    'type_python': 'int | float',\n                    'type_description': 'numeric value',\n                    'component': 'Number',\n                    'example_input': '5'\n                },\n            ],\n            'returns': [\n                {\n                    'label': 'output',\n                    'type_python': 'int | float',\n                    'type_description': 'numeric value',\n                    'component': 'Number',\n                },\n            ]\n        },\n        '/flag': {\n            'parameters': [\n                ...\n                ],\n            'returns': [\n                ...\n                ]\n            }\n        }\n    'unnamed_endpoints': {\n        2: {\n            'parameters': [\n                ...\n                ],\n            'returns': [\n                ...\n                ]\n            }\n        }\n    }\n}",override_signature:null,parent:"gradio.Client",slug:"client-view-api"},{fn:null,name:"duplicate",description:"Duplicates a Hugging Face Space under your account and returns a Client object for the new Space. No duplication is created if the Space already exists in your account (to override this, provide a new name for the new Space using `to_id`). To use this method, you must provide an `hf_token` or be logged in via the Hugging Face Hub CLI. &lt;br&gt; The new Space will be private by default and use the same hardware as the original Space. This can be changed by using the `private` and `hardware` parameters. For hardware upgrades (beyond the basic CPU tier), you may be required to provide billing information on Hugging Face: https://huggingface.co/settings/billing &lt;br&gt;",tags:{},parameters:[{name:"from_id",annotation:"str",doc:"The name of the Hugging Face Space to duplicate in the format &quot;{username}/{space_id}&quot;, e.g. &quot;gradio/whisper&quot;."},{name:"to_id",annotation:"str | None",doc:"The name of the new Hugging Face Space to create, e.g. &quot;abidlabs/whisper-duplicate&quot;. If not provided, the new Space will be named &quot;{your_HF_username}/{space_id}&quot;.",default:"None"},{name:"hf_token",annotation:"str | None",doc:"The Hugging Face token to use to access private Spaces. Automatically fetched if you are logged in via the Hugging Face Hub CLI. Obtain from: https://huggingface.co/settings/token",default:"None"},{name:"private",annotation:"bool",doc:"Whether the new Space should be private (True) or public (False). Defaults to True.",default:"True"},{name:"hardware",annotation:"Literal[('cpu-basic', 'cpu-upgrade', 't4-small', 't4-medium', 'a10g-small', 'a10g-large', 'a100-large')] | SpaceHardware | None",doc:"The hardware tier to use for the new Space. Defaults to the same hardware tier as the original Space. Options include &quot;cpu-basic&quot;, &quot;cpu-upgrade&quot;, &quot;t4-small&quot;, &quot;t4-medium&quot;, &quot;a10g-small&quot;, &quot;a10g-large&quot;, &quot;a100-large&quot;, subject to availability.",default:"None"},{name:"secrets",annotation:"dict[str, str] | None",doc:"A dictionary of (secret key, secret value) to pass to the new Space. Defaults to None. Secrets are only used when the Space is duplicated for the first time, and are not updated if the duplicated Space already exists.",default:"None"},{name:"sleep_timeout",annotation:"int",doc:"The number of minutes after which the duplicate Space will be puased if no requests are made to it (to minimize billing charges). Defaults to 5 minutes.",default:"5"},{name:"max_workers",annotation:"int",doc:"The maximum number of thread workers that can be used to make requests to the remote Gradio app simultaneously.",default:"40"},{name:"verbose",annotation:"bool",doc:"Whether the client should print statements to the console.",default:"True"}],returns:{},example:"import os\nfrom gradio_client import Client\nHF_TOKEN = os.environ.get(\"HF_TOKEN\")\nclient = Client.duplicate(\"abidlabs/whisper\", hf_token=HF_TOKEN)\nclient.predict(\"audio_sample.wav\")\n>> \"This is a test of the whisper speech recognition model.\"",override_signature:null,parent:"gradio.Client",slug:"client-duplicate"},{fn:null,name:"deploy_discord",description:"Deploy the upstream app as a discord bot. Currently only supports gr.ChatInterface.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"discord_bot_token",annotation:"str | None",doc:"This is the &quot;password&quot; needed to be able to launch the bot. Users can get a token by creating a bot app on the discord website. If run the method without specifying a token, the space will explain how to get one. See here: https://huggingface.co/spaces/freddyaboulton/test-discord-bot-v1.",default:"None"},{name:"api_names",annotation:"list[str | tuple[str, str]] | None",doc:"The api_names of the app to turn into bot commands. This parameter currently has no effect as ChatInterface only has one api_name (&#x27;/chat&#x27;).",default:"None"},{name:"to_id",annotation:"str | None",doc:"The name of the space hosting the discord bot. If None, the name will be gradio-discord-bot-{random-substring}",default:"None"},{name:"hf_token",annotation:"str | None",doc:"HF api token with write priviledges in order to upload the files to HF space. Can be ommitted if logged in via the HuggingFace CLI, unless the upstream space is private. Obtain from: https://huggingface.co/settings/token",default:"None"},{name:"private",annotation:"bool",doc:"Whether the space hosting the discord bot is private. The visibility of the discord bot itself is set via the discord website. See https://huggingface.co/spaces/freddyaboulton/test-discord-bot-v1",default:"False"}],returns:{},example:null,override_signature:null,parent:"gradio.Client",slug:"client-deploy-discord"}],parent:"gradio",prev_obj:"Python-Client",next_obj:"Job",slug:"client"},job:{class:null,name:"Job",description:"A Job is a wrapper over the Future class that represents a prediction call that has been submitted by the Gradio client. This class is not meant to be instantiated directly, but rather is created by the Client.submit() method. \u003Cbr> A Job object includes methods to get the status of the prediction call, as well to get the outputs of the prediction call. Job objects are also iterable, and can be used in a loop to get the outputs of prediction calls as they become available for generator endpoints.",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"future",annotation:"Future",doc:"The future object that represents the prediction call, created by the Client.submit() method"},{name:"communicator",annotation:"Communicator | None",doc:"The communicator object that is used to communicate between the client and the background thread running the job",default:"None"},{name:"verbose",annotation:"bool",doc:"Whether to print any status-related messages to the console",default:"True"},{name:"space_id",annotation:"str | None",doc:"The space ID corresponding to the Client object that created this Job object",default:"None"}],returns:{annotation:null},example:null,fns:[{fn:null,name:"result",description:"Return the result of the call that the future represents. Raises CancelledError: If the future was cancelled, TimeoutError: If the future didn&#x27;t finish executing before the given timeout, and Exception: If the call raised then that exception will be raised. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null},{name:"timeout",annotation:"float | None",doc:"The number of seconds to wait for the result if the future isn&#x27;t done. If None, then there is no limit on the wait time.",default:"None"}],returns:{annotation:"Any",doc:"The result of the call that the future represents. For generator functions, it will return the final iteration."},example:"from gradio_client import Client\ncalculator = Client(src=\"gradio/calculator\")\njob = calculator.submit(\"foo\", \"add\", 4, fn_index=0)\njob.result(timeout=5)\n>> 9",override_signature:null,parent:"gradio.Job",slug:"job-result"},{fn:null,name:"outputs",description:"Returns a list containing the latest outputs from the Job. &lt;br&gt; If the endpoint has multiple output components, the list will contain a tuple of results. Otherwise, it will contain the results without storing them in tuples. &lt;br&gt; For endpoints that are queued, this list will contain the final job output even if that endpoint does not use a generator function. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{},example:"from gradio_client import Client\nclient = Client(src=\"gradio/count_generator\")\njob = client.submit(3, api_name=\"/count\")\nwhile not job.done():\n    time.sleep(0.1)\njob.outputs()\n>> ['0', '1', '2']",override_signature:null,parent:"gradio.Job",slug:"job-outputs"},{fn:null,name:"status",description:"Returns the latest status update from the Job in the form of a StatusUpdate object, which contains the following fields: code, rank, queue_size, success, time, eta, and progress_data. &lt;br&gt; progress_data is a list of updates emitted by the gr.Progress() tracker of the event handler. Each element of the list has the following fields: index, length, unit, progress, desc. If the event handler does not have a gr.Progress() tracker, the progress_data field will be None. &lt;br&gt;",tags:{},parameters:[{name:"self",annotation:"\u003Cclass 'inspect._empty'>",doc:null}],returns:{},example:"from gradio_client import Client\nclient = Client(src=\"gradio/calculator\")\njob = client.submit(5, \"add\", 4, api_name=\"/predict\")\njob.status()\n>> \u003CStatus.STARTING: 'STARTING'>\njob.status().eta\n>> 43.241  # seconds",override_signature:null,parent:"gradio.Job",slug:"job-status"}],parent:"gradio",prev_obj:"Client",next_obj:"JS-Client",slug:"job"}},COLOR_SETS:[["from-green-100","to-green-50"],["from-yellow-100","to-yellow-50"],["from-red-100","to-red-50"],["from-blue-100","to-blue-50"],["from-pink-100","to-pink-50"],["from-purple-100","to-purple-50"]],headers:[["Description","description"],["Example Usage","example-usage"],["Initialization","initialization"],["Demos","demos"],["Methods","methods"]],method_headers:[["__call__","progress-call"],["tqdm","progress-tqdm"]],on_main:false,wheel:"https://gradio-builds.s3.amazonaws.com/e3217b41862925a6a05f44070ac2bdabbeee6769/gradio-4.16.0-py3-none-any.whl",url_version:"4.16.0"}}({})),"uses":{"params":["doc"],"parent":1}}];

					Promise.all([
						import("../_app/immutable/entry/start.85a9379b.js"),
						import("../_app/immutable/entry/app.cc28a8d6.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2, 5],
							data,
							form: null,
							error: null
						});
					});
				}
   </script>
  </div>
 </body>
</html>
