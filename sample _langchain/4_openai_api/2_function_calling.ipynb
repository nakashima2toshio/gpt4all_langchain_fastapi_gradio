{"cells":[{"cell_type":"markdown","source":["# OpenAI APIの前準備"],"metadata":{"id":"Qf_XcjXD89hw"}},{"cell_type":"code","source":["# パッケージのインストール\n","!pip install openai"],"metadata":{"id":"mkPbwp6-ploX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 環境変数の準備 (左端の鍵アイコンでOPENAI_API_KEYを設定)\n","import os\n","from google.colab import userdata\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"],"metadata":{"id":"_Gf8Rfw2MiG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","# クライアントの準備\n","client = OpenAI()"],"metadata":{"id":"CD_pIMlhTaTX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# JSON出力ヘルパーの準備\n","def show_json(obj):\n","    display(json.loads(obj.model_dump_json()))"],"metadata":{"id":"Ci_3eoYtiKX6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Function Calling"],"metadata":{"id":"x_tyBk7nTaiQ"}},{"cell_type":"code","source":["# メッセージリストの準備\n","messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"群馬県の気温は？\",\n","    }\n","]"],"metadata":{"id":"6XMPdBGIiNO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 関数定義の準備\n","tool = {\n","    \"type\": \"function\",\n","    \"function\": {\n","        \"name\": \"get_current_temperature\",\n","        \"description\": \"特定の場所の気温を取得\",\n","        \"parameters\": {\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"location\": {\"type\": \"string\", \"description\": \"場所 (例:東京)\"},\n","                \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n","            },\n","            \"required\": [\"location\"]\n","        }\n","    }\n","}"],"metadata":{"id":"Y6h2IzayiNSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# テキスト生成\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=messages,\n","    temperature=0.2,\n","    max_tokens=500,\n","    tools=[tool]\n",")\n","\n","# レスポンスメッセージの確認\n","response_message = response.choices[0].message\n","show_json(response_message)"],"metadata":{"id":"zsTxPv0MUD5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 特定の場所の気温を取得する関数 (ダミー)\n","def get_current_temperature(location, unit):\n","    return \"22度\"\n","\n","# 関数名と関数の関連付け\n","available_functions = {\n","    \"get_current_temperature\": get_current_temperature,\n","}"],"metadata":{"id":"T56DK06YY6i8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# レスポンスにtool_callが存在\n","if response_message.tool_calls:\n","    # レスポンスメッセージの追加\n","    messages.append(response_message)\n","\n","    for tool_call in response_message.tool_calls:\n","        # 関数を呼び出す\n","        function_name = tool_call.function.name\n","        function_to_call = available_functions[function_name]\n","        function_args = json.loads(tool_call.function.arguments)\n","        function_response = function_to_call(\n","            location=function_args.get(\"location\"),\n","            unit=function_args.get(\"unit\"),\n","        )\n","\n","        # 関数呼び出し結果メッセージの追加\n","        messages.append(\n","            {\n","                \"tool_call_id\": tool_call.id,\n","                \"role\": \"tool\",\n","                \"name\": function_name,\n","                \"content\": function_response,\n","            }\n","        )\n","\n","    # 再度 chat.completions.create() を呼び出す\n","    second_response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=messages,\n","    )\n","\n","    # セカンドレスポンスメッセージの確認\n","    second_response_message = second_response.choices[0].message\n","    show_json(second_response_message)"],"metadata":{"id":"LvIBtRrGW8D5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# メッセージリストの確認\n","print(messages)"],"metadata":{"id":"8kzQdyLn-3jk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Parallel Function Calling"],"metadata":{"id":"s9GECVLFlC1s"}},{"cell_type":"code","source":["# メッセージリストの準備\n","messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"京都と大阪の気温は？\",\n","    }\n","]"],"metadata":{"id":"hh-BeVARlFnS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 関数定義の準備\n","tool = {\n","    \"type\": \"function\",\n","    \"function\": {\n","        \"name\": \"get_current_temperature\",\n","        \"description\": \"特定の場所の気温を取得\",\n","        \"parameters\": {\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"location\": {\"type\": \"string\", \"description\": \"場所 (例:東京)\"},\n","                \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n","            },\n","            \"required\": [\"location\"]\n","        }\n","    }\n","}"],"metadata":{"id":"yvvCJ6NLmP0p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# テキスト生成\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo-1106\",\n","    messages=messages,\n","    temperature=0.2,\n","    max_tokens=500,\n","    tools=[tool]\n",")\n","\n","# レスポンスメッセージの確認\n","response_message = response.choices[0].message\n","show_json(response_message)"],"metadata":{"id":"-A1gLLsomP3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 特定の場所の気温を取得する関数 (ダミー)\n","def get_current_temperature(location, unit):\n","    return \"22度\"\n","\n","# 関数名と関数の関連付け\n","available_functions = {\n","    \"get_current_temperature\": get_current_temperature,\n","}"],"metadata":{"id":"zCFY7aoUlFtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# レスポンスにtool_callが存在\n","if response_message.tool_calls:\n","    # レスポンスメッセージの追加\n","    messages.append(response_message)\n","\n","    for tool_call in response_message.tool_calls:\n","        # 関数を呼び出す\n","        function_name = tool_call.function.name\n","        function_to_call = available_functions[function_name]\n","        function_args = json.loads(tool_call.function.arguments)\n","        function_response = function_to_call(\n","            location=function_args.get(\"location\"),\n","            unit=function_args.get(\"unit\"),\n","        )\n","\n","        # 関数呼び出し結果メッセージの追加\n","        messages.append(\n","            {\n","                \"tool_call_id\": tool_call.id,\n","                \"role\": \"tool\",\n","                \"name\": function_name,\n","                \"content\": function_response,\n","            }\n","        )\n","\n","    # 再度 chat.completions.create() を呼び出す\n","    second_response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=messages,\n","    )\n","\n","    # セカンドレスポンスメッセージの確認\n","    second_response_message = second_response.choices[0].message\n","    show_json(second_response_message)"],"metadata":{"id":"IQnSHmIulmOH"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDc5CbyLZ8LHvWshc28NRb"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}